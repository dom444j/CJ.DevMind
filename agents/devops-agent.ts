import * as path from 'path';
import * as fs from 'fs';
import { exec, spawn } from 'child_process';
import { promisify } from 'util';
import { BaseAgent } from './base-agent';
import { AgentEventType, AgentType, TaskPriority, TaskStatus } from '../types/agent-types';
import { DeploymentConfig, DeploymentEnvironment, DeploymentResult, InfrastructureType, MonitoringConfig, ScalingConfig } from '../types/devops-types';
import { CloudProvider, ContainerConfig, DockerComposeConfig, KubernetesConfig, TerraformConfig } from '../types/infrastructure-types';
import { Logger } from '../utils/logger';
import { ConfigManager } from '../utils/config-manager';
import { GitService } from '../services/git-service';
import { DockerService } from '../services/docker-service';
import { KubernetesService } from '../services/kubernetes-service';
import { CloudService } from '../services/cloud-service';
import { MonitoringService } from '../services/monitoring-service';
import { CIService } from '../services/ci-service';

const execAsync = promisify(exec);

export class DevOpsAgent extends BaseAgent {
  private gitService: GitService;
  private dockerService: DockerService;
  private kubernetesService: KubernetesService;
  private cloudService: CloudService;
  private monitoringService: MonitoringService;
  private ciService: CIService;
  private configManager: ConfigManager;
  private deploymentHistory: Map<string, DeploymentResult[]> = new Map();
  private infrastructureConfigs: Map<string, any> = new Map();
  private monitoringConfigs: Map<string, any> = new Map();
  private cicdPipelines: Map<string, any> = new Map();
  private scalingConfigs: Map<string, ScalingConfig> = new Map();
  private environmentVariables: Map<string, Map<string, string>> = new Map();
  private deploymentLocks: Set<string> = new Set();

  constructor() {
    super(AgentType.DEVOPS);
    this.gitService = new GitService();
    this.dockerService = new DockerService();
    this.kubernetesService = new KubernetesService();
    this.cloudService = new CloudService();
    this.monitoringService = new MonitoringService();
    this.ciService = new CIService();
    this.configManager = ConfigManager.getInstance();
    
    // Inicializar mapas de entornos
    this.environmentVariables.set('development', new Map());
    this.environmentVariables.set('staging', new Map());
    this.environmentVariables.set('production', new Map());
    
    // Registrar manejadores de eventos
    this.registerEventHandlers();
  }

  private registerEventHandlers(): void {
    this.on(AgentEventType.DEPLOYMENT_REQUESTED, this.handleDeploymentRequest.bind(this));
    this.on(AgentEventType.INFRASTRUCTURE_SETUP_REQUESTED, this.handleInfrastructureSetup.bind(this));
    this.on(AgentEventType.MONITORING_SETUP_REQUESTED, this.handleMonitoringSetup.bind(this));
    this.on(AgentEventType.CI_PIPELINE_REQUESTED, this.handleCIPipelineSetup.bind(this));
    this.on(AgentEventType.SCALING_CONFIG_REQUESTED, this.handleScalingConfigSetup.bind(this));
    this.on(AgentEventType.ENVIRONMENT_VARIABLES_REQUESTED, this.handleEnvironmentVariablesSetup.bind(this));
  }

  public async initialize(): Promise<void> {
    this.logger.info('Inicializando DevOpsAgent...');
    
    try {
      // Verificar herramientas necesarias
      await this.checkRequiredTools();
      
      // Cargar configuraciones existentes
      await this.loadExistingConfigurations();
      
      this.logger.info('DevOpsAgent inicializado correctamente');
      this.emit(AgentEventType.AGENT_INITIALIZED, { agentId: this.id, type: this.type });
    } catch (error) {
      this.logger.error(`Error al inicializar DevOpsAgent: ${error.message}`);
      this.emit(AgentEventType.AGENT_INITIALIZATION_FAILED, { 
        agentId: this.id, 
        type: this.type,
        error: error.message 
      });
      throw error;
    }
  }

  private async checkRequiredTools(): Promise<void> {
    this.logger.info('Verificando herramientas necesarias...');
    
    const requiredTools = [
      { name: 'git', command: 'git --version' },
      { name: 'docker', command: 'docker --version' },
      { name: 'kubectl', command: 'kubectl version --client' },
      { name: 'terraform', command: 'terraform --version' },
      { name: 'aws', command: 'aws --version' },
      { name: 'az', command: 'az --version' },
      { name: 'gcloud', command: 'gcloud --version' }
    ];
    
    const toolStatus = new Map<string, boolean>();
    
    for (const tool of requiredTools) {
      try {
        await execAsync(tool.command);
        toolStatus.set(tool.name, true);
        this.logger.debug(`${tool.name} está instalado`);
      } catch (error) {
        toolStatus.set(tool.name, false);
        this.logger.warn(`${tool.name} no está instalado o no está en el PATH`);
      }
    }
    
    // Emitir evento con el estado de las herramientas
    this.emit(AgentEventType.TOOLS_STATUS_UPDATED, { 
      agentId: this.id, 
      toolStatus: Object.fromEntries(toolStatus) 
    });
  }

  private async loadExistingConfigurations(): Promise<void> {
    this.logger.info('Cargando configuraciones existentes...');
    
    try {
      // Cargar configuraciones de infraestructura
      const infraConfigPath = path.join(this.configManager.getConfigDir(), 'infrastructure');
      if (fs.existsSync(infraConfigPath)) {
        const files = fs.readdirSync(infraConfigPath);
        for (const file of files) {
          if (file.endsWith('.json')) {
            const configName = path.basename(file, '.json');
            const configContent = fs.readFileSync(path.join(infraConfigPath, file), 'utf8');
            this.infrastructureConfigs.set(configName, JSON.parse(configContent));
          }
        }
      }
      
      // Cargar configuraciones de monitoreo
      const monitoringConfigPath = path.join(this.configManager.getConfigDir(), 'monitoring');
      if (fs.existsSync(monitoringConfigPath)) {
        const files = fs.readdirSync(monitoringConfigPath);
        for (const file of files) {
          if (file.endsWith('.json')) {
            const configName = path.basename(file, '.json');
            const configContent = fs.readFileSync(path.join(monitoringConfigPath, file), 'utf8');
            this.monitoringConfigs.set(configName, JSON.parse(configContent));
          }
        }
      }
      
      // Cargar configuraciones de CI/CD
      const cicdConfigPath = path.join(this.configManager.getConfigDir(), 'cicd');
      if (fs.existsSync(cicdConfigPath)) {
        const files = fs.readdirSync(cicdConfigPath);
        for (const file of files) {
          if (file.endsWith('.json')) {
            const configName = path.basename(file, '.json');
            const configContent = fs.readFileSync(path.join(cicdConfigPath, file), 'utf8');
            this.cicdPipelines.set(configName, JSON.parse(configContent));
          }
        }
      }
      
      // Cargar historial de despliegues
      const deploymentHistoryPath = path.join(this.configManager.getConfigDir(), 'deployment-history.json');
      if (fs.existsSync(deploymentHistoryPath)) {
        const historyContent = fs.readFileSync(deploymentHistoryPath, 'utf8');
        const history = JSON.parse(historyContent);
        
        for (const [env, deployments] of Object.entries(history)) {
          this.deploymentHistory.set(env, deployments as DeploymentResult[]);
        }
      }
      
      // Cargar variables de entorno
      const envVarsPath = path.join(this.configManager.getConfigDir(), 'environment-variables');
      if (fs.existsSync(envVarsPath)) {
        const environments = ['development', 'staging', 'production'];
        
        for (const env of environments) {
          const envFilePath = path.join(envVarsPath, `${env}.json`);
          if (fs.existsSync(envFilePath)) {
            const envVarsContent = fs.readFileSync(envFilePath, 'utf8');
            const envVars = JSON.parse(envVarsContent);
            
            this.environmentVariables.set(env, new Map(Object.entries(envVars)));
          }
        }
      }
      
      this.logger.info('Configuraciones existentes cargadas correctamente');
    } catch (error) {
      this.logger.error(`Error al cargar configuraciones existentes: ${error.message}`);
      throw error;
    }
  }

  private async saveConfigurations(): Promise<void> {
    this.logger.info('Guardando configuraciones...');
    
    try {
      // Crear directorios si no existen
      const configDir = this.configManager.getConfigDir();
      const infraConfigPath = path.join(configDir, 'infrastructure');
      const monitoringConfigPath = path.join(configDir, 'monitoring');
      const cicdConfigPath = path.join(configDir, 'cicd');
      const envVarsPath = path.join(configDir, 'environment-variables');
      
      if (!fs.existsSync(configDir)) fs.mkdirSync(configDir, { recursive: true });
      if (!fs.existsSync(infraConfigPath)) fs.mkdirSync(infraConfigPath, { recursive: true });
      if (!fs.existsSync(monitoringConfigPath)) fs.mkdirSync(monitoringConfigPath, { recursive: true });
      if (!fs.existsSync(cicdConfigPath)) fs.mkdirSync(cicdConfigPath, { recursive: true });
      if (!fs.existsSync(envVarsPath)) fs.mkdirSync(envVarsPath, { recursive: true });
      
      // Guardar configuraciones de infraestructura
      for (const [configName, config] of this.infrastructureConfigs.entries()) {
        fs.writeFileSync(
          path.join(infraConfigPath, `${configName}.json`),
          JSON.stringify(config, null, 2),
          'utf8'
        );
      }
      
      // Guardar configuraciones de monitoreo
      for (const [configName, config] of this.monitoringConfigs.entries()) {
        fs.writeFileSync(
          path.join(monitoringConfigPath, `${configName}.json`),
          JSON.stringify(config, null, 2),
          'utf8'
        );
      }
      
      // Guardar configuraciones de CI/CD
      for (const [configName, config] of this.cicdPipelines.entries()) {
        fs.writeFileSync(
          path.join(cicdConfigPath, `${configName}.json`),
          JSON.stringify(config, null, 2),
          'utf8'
        );
      }
      
      // Guardar historial de despliegues
      const deploymentHistoryObj = {};
      for (const [env, deployments] of this.deploymentHistory.entries()) {
        deploymentHistoryObj[env] = deployments;
      }
      
      fs.writeFileSync(
        path.join(configDir, 'deployment-history.json'),
        JSON.stringify(deploymentHistoryObj, null, 2),
        'utf8'
      );
      
      // Guardar variables de entorno
      for (const [env, variables] of this.environmentVariables.entries()) {
        fs.writeFileSync(
          path.join(envVarsPath, `${env}.json`),
          JSON.stringify(Object.fromEntries(variables), null, 2),
          'utf8'
        );
      }
      
      this.logger.info('Configuraciones guardadas correctamente');
    } catch (error) {
      this.logger.error(`Error al guardar configuraciones: ${error.message}`);
      throw error;
    }
  }

    // Manejadores de eventos (continuación)
    private async handleScalingConfigSetup(data: any): Promise<void> {
      const { environment, config, taskId } = data;
      
      this.logger.info(`Solicitud de configuración de escalado recibida para entorno ${environment}`);
      
      try {
        // Actualizar estado de la tarea
        this.emit(AgentEventType.TASK_STATUS_UPDATED, {
          taskId,
          status: TaskStatus.IN_PROGRESS,
          message: `Configurando escalado para entorno ${environment}`
        });
        
        // Configurar escalado
        const result = await this.setupScalingConfig(environment, config);
        
        // Actualizar estado de la tarea
        this.emit(AgentEventType.TASK_STATUS_UPDATED, {
          taskId,
          status: TaskStatus.COMPLETED,
          message: `Configuración de escalado completada para entorno ${environment}`,
          result
        });
        
        // Notificar resultado de la configuración
        this.emit(AgentEventType.SCALING_CONFIG_SETUP_COMPLETED, {
          environment,
          result,
          taskId
        });
      } catch (error) {
        this.logger.error(`Error en configuración de escalado para entorno ${environment}: ${error.message}`);
        
        // Actualizar estado de la tarea
        this.emit(AgentEventType.TASK_STATUS_UPDATED, {
          taskId,
          status: TaskStatus.ERROR,
          message: `Error en configuración de escalado para entorno ${environment}: ${error.message}`
        });
        
        // Notificar error en configuración
        this.emit(AgentEventType.SCALING_CONFIG_SETUP_FAILED, {
          environment,
          error: error.message,
          taskId
        });
      }
    }
  
    private async handleEnvironmentVariablesSetup(data: any): Promise<void> {
      const { environment, variables, taskId } = data;
      
      this.logger.info(`Solicitud de configuración de variables de entorno recibida para entorno ${environment}`);
      
      try {
        // Actualizar estado de la tarea
        this.emit(AgentEventType.TASK_STATUS_UPDATED, {
          taskId,
          status: TaskStatus.IN_PROGRESS,
          message: `Configurando variables de entorno para entorno ${environment}`
        });
        
        // Configurar variables de entorno
        const result = await this.setupEnvironmentVariables(environment, variables);
        
        // Actualizar estado de la tarea
        this.emit(AgentEventType.TASK_STATUS_UPDATED, {
          taskId,
          status: TaskStatus.COMPLETED,
          message: `Configuración de variables de entorno completada para entorno ${environment}`,
          result
        });
        
        // Notificar resultado de la configuración
        this.emit(AgentEventType.ENVIRONMENT_VARIABLES_SETUP_COMPLETED, {
          environment,
          result,
          taskId
        });
      } catch (error) {
        this.logger.error(`Error en configuración de variables de entorno para entorno ${environment}: ${error.message}`);
        
        // Actualizar estado de la tarea
        this.emit(AgentEventType.TASK_STATUS_UPDATED, {
          taskId,
          status: TaskStatus.ERROR,
          message: `Error en configuración de variables de entorno para entorno ${environment}: ${error.message}`
        });
        
        // Notificar error en configuración
        this.emit(AgentEventType.ENVIRONMENT_VARIABLES_SETUP_FAILED, {
          environment,
          error: error.message,
          taskId
        });
      }
    }
  
    // Métodos principales
    public async deployToEnvironment(environment: DeploymentEnvironment, config: DeploymentConfig): Promise<DeploymentResult> {
      if (this.deploymentLocks.has(environment)) {
        throw new Error(`Ya hay un despliegue en curso para el entorno ${environment}`);
      }
      
      this.deploymentLocks.add(environment);
      
      try {
        this.logger.info(`Iniciando despliegue en entorno ${environment}`);
        
        // Verificar si hay variables de entorno configuradas
        if (!this.environmentVariables.has(environment) || this.environmentVariables.get(environment).size === 0) {
          this.logger.warn(`No hay variables de entorno configuradas para el entorno ${environment}`);
        }
        
        // Crear resultado de despliegue
        const deploymentResult: DeploymentResult = {
          id: `deploy-${Date.now()}`,
          environment,
          timestamp: new Date().toISOString(),
          status: 'in_progress',
          steps: [],
          logs: [],
          config
        };
        
        // Añadir al historial
        if (!this.deploymentHistory.has(environment)) {
          this.deploymentHistory.set(environment, []);
        }
        this.deploymentHistory.get(environment).push(deploymentResult);
        
        // Ejecutar pasos de despliegue
        try {
          // Paso 1: Verificar código fuente
          this.logger.info(`Verificando código fuente para despliegue en ${environment}`);
          deploymentResult.steps.push({
            name: 'source_verification',
            status: 'in_progress',
            timestamp: new Date().toISOString()
          });
          
          await this.gitService.verifySourceCode(config.sourceCodePath, config.branch);
          
          deploymentResult.steps[0].status = 'completed';
          deploymentResult.logs.push(`Código fuente verificado correctamente en rama ${config.branch}`);
          
          // Paso 2: Construir artefactos
          this.logger.info(`Construyendo artefactos para despliegue en ${environment}`);
          deploymentResult.steps.push({
            name: 'build_artifacts',
            status: 'in_progress',
            timestamp: new Date().toISOString()
          });
          
          const buildCommand = config.buildCommand || 'npm run build';
          const { stdout: buildOutput } = await execAsync(buildCommand, { cwd: config.sourceCodePath });
          
          deploymentResult.steps[1].status = 'completed';
          deploymentResult.logs.push(`Artefactos construidos correctamente: ${buildOutput.substring(0, 200)}...`);
          
          // Paso 3: Ejecutar pruebas
          if (config.runTests) {
            this.logger.info(`Ejecutando pruebas para despliegue en ${environment}`);
            deploymentResult.steps.push({
              name: 'run_tests',
              status: 'in_progress',
              timestamp: new Date().toISOString()
            });
            
            const testCommand = config.testCommand || 'npm test';
            const { stdout: testOutput } = await execAsync(testCommand, { cwd: config.sourceCodePath });
            
            deploymentResult.steps[2].status = 'completed';
            deploymentResult.logs.push(`Pruebas ejecutadas correctamente: ${testOutput.substring(0, 200)}...`);
          }
          
          // Paso 4: Desplegar según el tipo de infraestructura
          this.logger.info(`Desplegando en infraestructura de tipo ${config.infrastructureType}`);
          deploymentResult.steps.push({
            name: 'deploy_infrastructure',
            status: 'in_progress',
            timestamp: new Date().toISOString()
          });
          
          let deployOutput = '';
          
          switch (config.infrastructureType) {
            case InfrastructureType.DOCKER:
              deployOutput = await this.deployToDocker(config);
              break;
            case InfrastructureType.KUBERNETES:
              deployOutput = await this.deployToKubernetes(config);
              break;
            case InfrastructureType.AWS:
              deployOutput = await this.deployToAWS(config);
              break;
            case InfrastructureType.AZURE:
              deployOutput = await this.deployToAzure(config);
              break;
            case InfrastructureType.GCP:
              deployOutput = await this.deployToGCP(config);
              break;
            default:
              throw new Error(`Tipo de infraestructura no soportado: ${config.infrastructureType}`);
          }
          
          const lastStepIndex = deploymentResult.steps.length - 1;
          deploymentResult.steps[lastStepIndex].status = 'completed';
          deploymentResult.logs.push(`Despliegue completado en ${config.infrastructureType}: ${deployOutput.substring(0, 200)}...`);
          
          // Paso 5: Verificar despliegue
          this.logger.info(`Verificando despliegue en ${environment}`);
          deploymentResult.steps.push({
            name: 'verify_deployment',
            status: 'in_progress',
            timestamp: new Date().toISOString()
          });
          
          const verificationResult = await this.verifyDeployment(config);
          
          const verifyStepIndex = deploymentResult.steps.length - 1;
          deploymentResult.steps[verifyStepIndex].status = 'completed';
          deploymentResult.logs.push(`Verificación de despliegue completada: ${verificationResult}`);
          
          // Actualizar estado del despliegue
          deploymentResult.status = 'completed';
          deploymentResult.completedAt = new Date().toISOString();
          
          this.logger.info(`Despliegue completado exitosamente en entorno ${environment}`);
        } catch (error) {
          // Marcar el último paso como fallido
          const lastStepIndex = deploymentResult.steps.length - 1;
          if (lastStepIndex >= 0) {
            deploymentResult.steps[lastStepIndex].status = 'failed';
            deploymentResult.steps[lastStepIndex].error = error.message;
          }
          
          // Actualizar estado del despliegue
          deploymentResult.status = 'failed';
          deploymentResult.error = error.message;
          deploymentResult.completedAt = new Date().toISOString();
          
          deploymentResult.logs.push(`Error en despliegue: ${error.message}`);
          
          this.logger.error(`Error en despliegue para entorno ${environment}: ${error.message}`);
          
          // Intentar rollback si está configurado
          if (config.enableRollback) {
            try {
              this.logger.info(`Iniciando rollback para despliegue fallido en ${environment}`);
              
              deploymentResult.steps.push({
                name: 'rollback',
                status: 'in_progress',
                timestamp: new Date().toISOString()
              });
              
              await this.rollbackDeployment(environment, config);
              
              const rollbackStepIndex = deploymentResult.steps.length - 1;
              deploymentResult.steps[rollbackStepIndex].status = 'completed';
              deploymentResult.logs.push('Rollback completado exitosamente');
              
              this.logger.info(`Rollback completado exitosamente para despliegue en ${environment}`);
            } catch (rollbackError) {
              const rollbackStepIndex = deploymentResult.steps.length - 1;
              deploymentResult.steps[rollbackStepIndex].status = 'failed';
              deploymentResult.steps[rollbackStepIndex].error = rollbackError.message;
              
              deploymentResult.logs.push(`Error en rollback: ${rollbackError.message}`);
              
              this.logger.error(`Error en rollback para despliegue en ${environment}: ${rollbackError.message}`);
            }
          }
          
          throw error;
        } finally {
          // Guardar configuraciones
          await this.saveConfigurations();
          
          // Liberar bloqueo de despliegue
          this.deploymentLocks.delete(environment);
        }
        
        return deploymentResult;
      } catch (error) {
        // Liberar bloqueo de despliegue en caso de error
        this.deploymentLocks.delete(environment);
        
        throw error;
      }
    }
  
    private async deployToDocker(config: DeploymentConfig): Promise<string> {
      this.logger.info('Desplegando en Docker...');
      
      try {
        // Verificar si hay configuración de Docker
        if (!config.containerConfig) {
          throw new Error('No se ha proporcionado configuración de contenedor para despliegue en Docker');
        }
        
        const containerConfig = config.containerConfig as ContainerConfig;
        
        // Construir imagen Docker
        const buildImageCommand = `docker build -t ${containerConfig.imageName}:${containerConfig.imageTag} -f ${containerConfig.dockerfilePath} ${config.sourceCodePath}`;
        const { stdout: buildOutput } = await execAsync(buildImageCommand);
        
        this.logger.debug(`Imagen Docker construida: ${buildOutput}`);
        
        // Detener y eliminar contenedor existente si existe
        try {
          await execAsync(`docker stop ${containerConfig.containerName}`);
          await execAsync(`docker rm ${containerConfig.containerName}`);
          this.logger.debug(`Contenedor existente detenido y eliminado: ${containerConfig.containerName}`);
        } catch (error) {
          this.logger.debug(`No se encontró contenedor existente o no se pudo eliminar: ${error.message}`);
        }
        
        // Ejecutar contenedor
        let runCommand = `docker run -d --name ${containerConfig.containerName}`;
        
        // Añadir puertos
        if (containerConfig.ports && containerConfig.ports.length > 0) {
          for (const port of containerConfig.ports) {
            runCommand += ` -p ${port.host}:${port.container}`;
          }
        }
        
        // Añadir variables de entorno
        if (this.environmentVariables.has(config.environment)) {
          const envVars = this.environmentVariables.get(config.environment);
          for (const [key, value] of envVars.entries()) {
            runCommand += ` -e ${key}=${value}`;
          }
        }
        
        // Añadir volúmenes
        if (containerConfig.volumes && containerConfig.volumes.length > 0) {
          for (const volume of containerConfig.volumes) {
            runCommand += ` -v ${volume.host}:${volume.container}`;
          }
        }
        
        // Añadir redes
        if (containerConfig.networks && containerConfig.networks.length > 0) {
          for (const network of containerConfig.networks) {
            runCommand += ` --network ${network}`;
          }
        }
        
        // Añadir imagen
        runCommand += ` ${containerConfig.imageName}:${containerConfig.imageTag}`;
        
        // Ejecutar comando
        const { stdout: runOutput } = await execAsync(runCommand);
        
        this.logger.debug(`Contenedor Docker ejecutado: ${runOutput}`);
        
        return `Imagen construida y contenedor ejecutado: ${containerConfig.imageName}:${containerConfig.imageTag} (${runOutput.trim()})`;
      } catch (error) {
        this.logger.error(`Error al desplegar en Docker: ${error.message}`);
        throw error;
      }
    }
  
    private async deployToKubernetes(config: DeploymentConfig): Promise<string> {
      this.logger.info('Desplegando en Kubernetes...');
      
      try {
        // Verificar si hay configuración de Kubernetes
        if (!config.kubernetesConfig) {
          throw new Error('No se ha proporcionado configuración de Kubernetes para despliegue');
        }
        
        const k8sConfig = config.kubernetesConfig as KubernetesConfig;
        
        // Verificar contexto de Kubernetes
        const { stdout: contextOutput } = await execAsync('kubectl config current-context');
        this.logger.debug(`Contexto actual de Kubernetes: ${contextOutput.trim()}`);
        
        // Cambiar contexto si es necesario
        if (k8sConfig.context && k8sConfig.context !== contextOutput.trim()) {
          await execAsync(`kubectl config use-context ${k8sConfig.context}`);
          this.logger.debug(`Contexto cambiado a: ${k8sConfig.context}`);
        }
        
        // Verificar namespace
        const namespace = k8sConfig.namespace || 'default';
        
        // Aplicar configuraciones de Kubernetes
        let deployOutput = '';
        
        for (const manifestPath of k8sConfig.manifestPaths) {
          // Reemplazar variables en el manifiesto
          const manifestContent = fs.readFileSync(manifestPath, 'utf8');
          let processedManifest = manifestContent;
          
          // Reemplazar variables de entorno
          if (this.environmentVariables.has(config.environment)) {
            const envVars = this.environmentVariables.get(config.environment);
            for (const [key, value] of envVars.entries()) {
              processedManifest = processedManifest.replace(new RegExp(`\\$\\{${key}\\}`, 'g'), value);
            }
          }
          
          // Guardar manifiesto procesado
          const tempManifestPath = path.join(path.dirname(manifestPath), `temp_${path.basename(manifestPath)}`);
          fs.writeFileSync(tempManifestPath, processedManifest, 'utf8');
          
          // Aplicar manifiesto
          const { stdout: applyOutput } = await execAsync(`kubectl apply -f ${tempManifestPath} -n ${namespace}`);
          deployOutput += applyOutput + '\n';
          
          // Eliminar manifiesto temporal
          fs.unlinkSync(tempManifestPath);
        }
        
        // Verificar despliegue
        if (k8sConfig.deploymentName) {
          await this.kubernetesService.waitForDeployment(k8sConfig.deploymentName, namespace);
          this.logger.debug(`Despliegue ${k8sConfig.deploymentName} completado correctamente`);
        }
        
        return `Despliegue en Kubernetes completado: ${deployOutput.trim()}`;
      } catch (error) {
        this.logger.error(`Error al desplegar en Kubernetes: ${error.message}`);
        throw error;
      }
    }
  
    private async deployToAWS(config: DeploymentConfig): Promise<string> {
      this.logger.info('Desplegando en AWS...');
      
      try {
        // Verificar si hay configuración de AWS
        if (!config.cloudConfig || config.cloudConfig.provider !== CloudProvider.AWS) {
          throw new Error('No se ha proporcionado configuración válida de AWS para despliegue');
        }
        
        const awsConfig = config.cloudConfig;
        
        // Verificar credenciales de AWS
        await execAsync('aws sts get-caller-identity');
        
        // Desplegar según el tipo de servicio
        let deployOutput = '';
        
        switch (awsConfig.serviceType) {
          case 'ec2':
            deployOutput = await this.deployToAWSEC2(config, awsConfig);
            break;
          case 'ecs':
            deployOutput = await this.deployToAWSECS(config, awsConfig);
            break;
          case 'lambda':
            deployOutput = await this.deployToAWSLambda(config, awsConfig);
            break;
          case 's3':
            deployOutput = await this.deployToAWSS3(config, awsConfig);
            break;
          case 'elasticbeanstalk':
            deployOutput = await this.deployToAWSElasticBeanstalk(config, awsConfig);
            break;
          default:
            throw new Error(`Tipo de servicio AWS no soportado: ${awsConfig.serviceType}`);
        }
        
        return `Despliegue en AWS completado: ${deployOutput.trim()}`;
      } catch (error) {
        this.logger.error(`Error al desplegar en AWS: ${error.message}`);
        throw error;
      }
    }
  
    private async deployToAWSEC2(config: DeploymentConfig, awsConfig: any): Promise<string> {
      // Implementación de despliegue en AWS EC2
      this.logger.info('Desplegando en AWS EC2...');
      
      // Verificar si hay una instancia existente
      const instanceId = awsConfig.instanceId;
      
      if (!instanceId) {
        throw new Error('No se ha proporcionado ID de instancia EC2 para despliegue');
      }
      
      // Verificar estado de la instancia
      const { stdout: instanceOutput } = await execAsync(`aws ec2 describe-instances --instance-ids ${instanceId}`);
      const instanceInfo = JSON.parse(instanceOutput);
      
      if (!instanceInfo.Reservations || instanceInfo.Reservations.length === 0) {
        throw new Error(`No se encontró la instancia EC2 con ID: ${instanceId}`);
      }
      
      // Obtener dirección IP pública
      const publicIp = instanceInfo.Reservations[0].Instances[0].PublicIpAddress;
      
      if (!publicIp) {
        throw new Error(`La instancia EC2 con ID ${instanceId} no tiene una dirección IP pública`);
      }
      
      // Crear archivo de despliegue
      const deployScriptPath = path.join(config.sourceCodePath, 'deploy.sh');
      
      fs.writeFileSync(deployScriptPath, `
  #!/bin/bash
  cd ${awsConfig.remotePath || '/var/www/app'}
  git pull
  npm install
  npm run build
  pm2 restart ${awsConfig.serviceName || 'app'}
      `, 'utf8');
      
      // Dar permisos de ejecución
      fs.chmodSync(deployScriptPath, '755');
      
      // Copiar archivo de despliegue a la instancia
      await execAsync(`scp -i ${awsConfig.keyPath} ${deployScriptPath} ec2-user@${publicIp}:/tmp/deploy.sh`);
      
      // Ejecutar script de despliegue
      const { stdout: sshOutput } = await execAsync(`ssh -i ${awsConfig.keyPath} ec2-user@${publicIp} "chmod +x /tmp/deploy.sh && /tmp/deploy.sh"`);
      
      // Eliminar archivo de despliegue local
      fs.unlinkSync(deployScriptPath);
      
      return `Despliegue en AWS EC2 completado: ${sshOutput.trim()}`;
    }
  
    private async deployToAWSECS(config: DeploymentConfig, awsConfig: any): Promise<string> {
      // Implementación de despliegue en AWS ECS
      this.logger.info('Desplegando en AWS ECS...');
      
      // Verificar parámetros necesarios
      if (!awsConfig.cluster || !awsConfig.service) {
        throw new Error('No se han proporcionado cluster y service de ECS para despliegue');
      }
      
      // Construir y subir imagen Docker a ECR
      const ecrRepository = awsConfig.ecrRepository;
      const imageTag = awsConfig.imageTag || 'latest';
      
      // Obtener token de autenticación para ECR
      const { stdout: ecrAuthOutput } = await execAsync(`aws ecr get-login-password --region ${awsConfig.region || 'us-east-1'}`);
      
      // Autenticar Docker con ECR
      await execAsync(`docker login --username AWS --password ${ecrAuthOutput.trim()} ${ecrRepository.split('/')[0]}`);
      
      // Construir imagen Docker
      await execAsync(`docker build -t ${ecrRepository}:${imageTag} -f ${config.containerConfig?.dockerfilePath || 'Dockerfile'} ${config.sourceCodePath}`);
      
      // Etiquetar imagen
      await execAsync(`docker tag ${ecrRepository}:${imageTag} ${ecrRepository}:${imageTag}`);
      
      // Subir imagen a ECR
      await execAsync(`docker push ${ecrRepository}:${imageTag}`);
      
      // Actualizar servicio ECS
      const { stdout: ecsOutput } = await execAsync(`aws ecs update-service --cluster ${awsConfig.cluster} --service ${awsConfig.service} --force-new-deployment`);
      
      // Esperar a que el despliegue se complete
      await execAsync(`aws ecs wait services-stable --cluster ${awsConfig.cluster} --services ${awsConfig.service}`);
      
      return `Despliegue en AWS ECS completado: Imagen ${ecrRepository}:${imageTag} desplegada en servicio ${awsConfig.service}`;
    }
  
    private async deployToAWSLambda(config: DeploymentConfig, awsConfig: any): Promise<string> {
      // Implementación de despliegue en AWS Lambda
      this.logger.info('Desplegando en AWS Lambda...');
      
      // Verificar parámetros necesarios
      if (!awsConfig.functionName) {
        throw new Error('No se ha proporcionado nombre de función Lambda para despliegue');
      }
      
      // Crear archivo ZIP para despliegue
      const zipPath = path.join(config.sourceCodePath, 'lambda-deploy.zip');
      
      // Ejecutar comando de empaquetado
      await execAsync(`cd ${config.sourceCodePath} && zip -r ${zipPath} . -x "*.git*" -x "node_modules/*"`);
      
      // Actualizar función Lambda
      const { stdout: lambdaOutput } = await execAsync(`aws lambda update-function-code --function-name ${awsConfig.functionName} --zip-file fileb://${zipPath}`);
      
      // Eliminar archivo ZIP
      fs.unlinkSync(zipPath);
      
      return `Despliegue en AWS Lambda completado: Función ${awsConfig.functionName} actualizada`;
    }
  
    private async deployToAWSS3(config: DeploymentConfig, awsConfig: any): Promise<string> {
      // Implementación de despliegue en AWS S3
      this.logger.info('Desplegando en AWS S3...');
      
      // Verificar parámetros necesarios
      if (!awsConfig.bucketName) {
        throw new Error('No se ha proporcionado nombre de bucket S3 para despliegue');
      }
      
      // Verificar directorio de construcción
      const buildDir = path.join(config.sourceCodePath, azureConfig.buildDir || 'dist');
      
      if (!fs.existsSync(buildDir)) {
        throw new Error(`El directorio de construcción no existe: ${buildDir}`);
      }
      
      // Desplegar en Azure Web App
      const { stdout: webAppOutput } = await execAsync(`az webapp deployment source config-zip --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.webAppName} --src ${buildDir}`);
      
      return `Despliegue en Azure Web App completado: ${webAppOutput.trim()}`;
    }
    
    private async deployToAzureFunction(config: DeploymentConfig, azureConfig: any): Promise<string> {
      // Implementación de despliegue en Azure Function
      this.logger.info('Desplegando en Azure Function...');
      
      // Verificar parámetros necesarios
      if (!azureConfig.resourceGroup || !azureConfig.functionAppName) {
        throw new Error('No se han proporcionado grupo de recursos y nombre de Function App para despliegue');
      }
      
      // Verificar directorio de construcción
      const buildDir = path.join(config.sourceCodePath, azureConfig.buildDir || 'dist');
      
      if (!fs.existsSync(buildDir)) {
        throw new Error(`El directorio de construcción no existe: ${buildDir}`);
      }
      
      // Crear archivo ZIP para despliegue
      const zipPath = path.join(config.sourceCodePath, 'function-deploy.zip');
      
      // Ejecutar comando de empaquetado
      await execAsync(`cd ${buildDir} && zip -r ${zipPath} .`);
      
      // Desplegar en Azure Function
      const { stdout: functionOutput } = await execAsync(`az functionapp deployment source config-zip --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.functionAppName} --src ${zipPath}`);
      
      // Eliminar archivo ZIP
      fs.unlinkSync(zipPath);
      
      return `Despliegue en Azure Function completado: ${functionOutput.trim()}`;
    }
    
    private async deployToAzureContainer(config: DeploymentConfig, azureConfig: any): Promise<string> {
      // Implementación de despliegue en Azure Container Instances
      this.logger.info('Desplegando en Azure Container Instances...');
      
      // Verificar parámetros necesarios
      if (!azureConfig.resourceGroup || !azureConfig.containerGroupName) {
        throw new Error('No se han proporcionado grupo de recursos y nombre de grupo de contenedores para despliegue');
      }
      
      // Verificar si hay configuración de contenedor
      if (!config.containerConfig) {
        throw new Error('No se ha proporcionado configuración de contenedor para despliegue en Azure Container Instances');
      }
      
      const containerConfig = config.containerConfig as ContainerConfig;
      
      // Construir imagen Docker
      const buildImageCommand = `docker build -t ${containerConfig.imageName}:${containerConfig.imageTag} -f ${containerConfig.dockerfilePath} ${config.sourceCodePath}`;
      const { stdout: buildOutput } = await execAsync(buildImageCommand);
      
      this.logger.debug(`Imagen Docker construida: ${buildOutput}`);
      
      // Etiquetar imagen para Azure Container Registry
      const acrLoginServer = azureConfig.acrLoginServer;
      const acrImageName = `${acrLoginServer}/${containerConfig.imageName}:${containerConfig.imageTag}`;
      
      await execAsync(`docker tag ${containerConfig.imageName}:${containerConfig.imageTag} ${acrImageName}`);
      
      // Iniciar sesión en Azure Container Registry
      await execAsync(`az acr login --name ${azureConfig.acrName}`);
      
      // Subir imagen a Azure Container Registry
      await execAsync(`docker push ${acrImageName}`);
      
      // Crear o actualizar grupo de contenedores
      let createCommand = `az container create --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.containerGroupName} --image ${acrImageName}`;
      
      // Añadir puertos
      if (containerConfig.ports && containerConfig.ports.length > 0) {
        const ports = containerConfig.ports.map(port => port.container).join(' ');
        createCommand += ` --ports ${ports}`;
      }
      
      // Añadir variables de entorno
      if (this.environmentVariables.has(config.environment)) {
        const envVars = this.environmentVariables.get(config.environment);
        let envString = '';
        
        for (const [key, value] of envVars.entries()) {
          envString += `${key}=${value} `;
        }
        
        if (envString) {
          createCommand += ` --environment-variables ${envString.trim()}`;
        }
      }
      
      // Ejecutar comando de creación
      const { stdout: containerOutput } = await execAsync(createCommand);
      
      return `Despliegue en Azure Container Instances completado: ${containerOutput.trim()}`;
    }
    
    private async deployToAzureStaticWebApp(config: DeploymentConfig, azureConfig: any): Promise<string> {
      // Implementación de despliegue en Azure Static Web App
      this.logger.info('Desplegando en Azure Static Web App...');
      
      // Verificar parámetros necesarios
      if (!azureConfig.resourceGroup || !azureConfig.staticWebAppName) {
        throw new Error('No se han proporcionado grupo de recursos y nombre de Static Web App para despliegue');
      }
      
      // Verificar directorio de construcción
      const buildDir = path.join(config.sourceCodePath, azureConfig.buildDir || 'dist');
      
      if (!fs.existsSync(buildDir)) {
        throw new Error(`El directorio de construcción no existe: ${buildDir}`);
      }
      
      // Obtener token de despliegue
      const { stdout: tokenOutput } = await execAsync(`az staticwebapp secrets list --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.staticWebAppName} --query "properties.apiKey" -o tsv`);
      const deployToken = tokenOutput.trim();
      
      // Crear archivo de configuración para el despliegue
      const configPath = path.join(config.sourceCodePath, 'staticwebapp.config.json');
      
      if (!fs.existsSync(configPath)) {
        const defaultConfig = {
          routes: [
            {
              route: "/*",
              serve: "/index.html",
              statusCode: 200
            }
          ],
          navigationFallback: {
            rewrite: "/index.html",
            exclude: ["/images/*.{png,jpg,gif}", "/css/*"]
          }
        };
        
        fs.writeFileSync(configPath, JSON.stringify(defaultConfig, null, 2), 'utf8');
      }
      
      // Desplegar en Azure Static Web App
      const { stdout: deployOutput } = await execAsync(`az staticwebapp deploy --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.staticWebAppName} --deployment-token "${deployToken}" --source ${buildDir}`);
      
      return `Despliegue en Azure Static Web App completado: ${deployOutput.trim()}`;
    }
    
    private async deployToGCP(config: DeploymentConfig): Promise<string> {
      this.logger.info('Desplegando en GCP...');
      
      try {
        // Verificar si hay configuración de GCP
        if (!config.cloudConfig || config.cloudConfig.provider !== CloudProvider.GCP) {
          throw new Error('No se ha proporcionado configuración válida de GCP para despliegue');
        }
        
        const gcpConfig = config.cloudConfig;
        
        // Verificar credenciales de GCP
        await execAsync('gcloud auth list');
        
        // Desplegar según el tipo de servicio
        let deployOutput = '';
        
        switch (gcpConfig.serviceType) {
          case 'appengine':
            deployOutput = await this.deployToGCPAppEngine(config, gcpConfig);
            break;
          case 'cloudrun':
            deployOutput = await this.deployToGCPCloudRun(config, gcpConfig);
            break;
          case 'functions':
            deployOutput = await this.deployToGCPFunctions(config, gcpConfig);
            break;
          case 'gke':
            deployOutput = await this.deployToGCPGKE(config, gcpConfig);
            break;
          default:
            throw new Error(`Tipo de servicio GCP no soportado: ${gcpConfig.serviceType}`);
        }
        
        return `Despliegue en GCP completado: ${deployOutput.trim()}`;
      } catch (error) {
        this.logger.error(`Error al desplegar en GCP: ${error.message}`);
        throw error;
      }
    }
    
    private async deployToGCPAppEngine(config: DeploymentConfig, gcpConfig: any): Promise<string> {
      // Implementación de despliegue en Google App Engine
      this.logger.info('Desplegando en Google App Engine...');
      
      // Verificar parámetros necesarios
      if (!gcpConfig.project) {
        throw new Error('No se ha proporcionado ID de proyecto GCP para despliegue');
      }
      
      // Verificar si existe app.yaml
      const appYamlPath = path.join(config.sourceCodePath, 'app.yaml');
      
      if (!fs.existsSync(appYamlPath)) {
        // Crear app.yaml básico si no existe
        const runtime = gcpConfig.runtime || 'nodejs14';
        
        const appYamlContent = `
runtime: ${runtime}
env: standard
instance_class: F1
automatic_scaling:
  min_idle_instances: 0
  max_idle_instances: 1
  min_pending_latency: 1000ms
  max_pending_latency: 5000ms
`;
        
        fs.writeFileSync(appYamlPath, appYamlContent, 'utf8');
        this.logger.debug(`Archivo app.yaml creado en: ${appYamlPath}`);
      }
      
      // Configurar proyecto GCP
      await execAsync(`gcloud config set project ${gcpConfig.project}`);
      
      // Desplegar en App Engine
      const { stdout: deployOutput } = await execAsync(`cd ${config.sourceCodePath} && gcloud app deploy --quiet`);
      
      return `Despliegue en Google App Engine completado: ${deployOutput.trim()}`;
    }
    
    private async deployToGCPCloudRun(config: DeploymentConfig, gcpConfig: any): Promise<string> {
      // Implementación de despliegue en Google Cloud Run
      this.logger.info('Desplegando en Google Cloud Run...');
      
      // Verificar parámetros necesarios
      if (!gcpConfig.project || !gcpConfig.serviceName) {
        throw new Error('No se han proporcionado ID de proyecto GCP y nombre de servicio para despliegue');
      }
      
      // Verificar si hay configuración de contenedor
      if (!config.containerConfig) {
        throw new Error('No se ha proporcionado configuración de contenedor para despliegue en Google Cloud Run');
      }
      
      const containerConfig = config.containerConfig as ContainerConfig;
      
      // Configurar proyecto GCP
      await execAsync(`gcloud config set project ${gcpConfig.project}`);
      
      // Construir imagen Docker
      const gcpImageName = `gcr.io/${gcpConfig.project}/${containerConfig.imageName}:${containerConfig.imageTag}`;
      
      await execAsync(`docker build -t ${gcpImageName} -f ${containerConfig.dockerfilePath} ${config.sourceCodePath}`);
      
      // Configurar Docker para usar gcloud como credencial helper
      await execAsync('gcloud auth configure-docker');
      
      // Subir imagen a Container Registry
      await execAsync(`docker push ${gcpImageName}`);
      
      // Desplegar en Cloud Run
      let deployCommand = `gcloud run deploy ${gcpConfig.serviceName} --image ${gcpImageName} --platform managed`;
      
      // Añadir región si está especificada
      if (gcpConfig.region) {
        deployCommand += ` --region ${gcpConfig.region}`;
      }
      
      // Añadir variables de entorno
      if (this.environmentVariables.has(config.environment)) {
        const envVars = this.environmentVariables.get(config.environment);
        let envString = '';
        
        for (const [key, value] of envVars.entries()) {
          envString += `${key}=${value},`;
        }
        
        if (envString) {
          deployCommand += ` --set-env-vars=${envString.slice(0, -1)}`;
        }
      }
      
      // Configurar memoria y CPU si están especificados
      if (gcpConfig.memory) {
        deployCommand += ` --memory ${gcpConfig.memory}`;
      }
      
      if (gcpConfig.cpu) {
        deployCommand += ` --cpu ${gcpConfig.cpu}`;
      }
      
      // Ejecutar comando de despliegue
      const { stdout: deployOutput } = await execAsync(deployCommand);
      
      return `Despliegue en Google Cloud Run completado: ${deployOutput.trim()}`;
    }
    
    private async deployToGCPFunctions(config: DeploymentConfig, gcpConfig: any): Promise<string> {
      // Implementación de despliegue en Google Cloud Functions
      this.logger.info('Desplegando en Google Cloud Functions...');
      
      // Verificar parámetros necesarios
      if (!gcpConfig.project || !gcpConfig.functionName) {
        throw new Error('No se han proporcionado ID de proyecto GCP y nombre de función para despliegue');
      }
      
      // Configurar proyecto GCP
      await execAsync(`gcloud config set project ${gcpConfig.project}`);
      
      // Desplegar en Cloud Functions
      let deployCommand = `gcloud functions deploy ${gcpConfig.functionName} --source=${config.sourceCodePath}`;
      
      // Añadir runtime
      const runtime = gcpConfig.runtime || 'nodejs14';
      deployCommand += ` --runtime=${runtime}`;
      
      // Añadir trigger
      if (gcpConfig.trigger === 'http') {
        deployCommand += ' --trigger-http';
      } else if (gcpConfig.trigger === 'event') {
        if (!gcpConfig.eventType) {
          throw new Error('No se ha proporcionado tipo de evento para trigger de Cloud Functions');
        }
        
        deployCommand += ` --trigger-event=${gcpConfig.eventType}`;
        
        if (gcpConfig.resource) {
          deployCommand += ` --trigger-resource=${gcpConfig.resource}`;
        }
      }
      
      // Añadir región si está especificada
      if (gcpConfig.region) {
        deployCommand += ` --region=${gcpConfig.region}`;
      }
      
      // Añadir punto de entrada
      if (gcpConfig.entryPoint) {
        deployCommand += ` --entry-point=${gcpConfig.entryPoint}`;
      }
      
      // Añadir variables de entorno
      if (this.environmentVariables.has(config.environment)) {
        const envVars = this.environmentVariables.get(config.environment);
        let envString = '';
        
        for (const [key, value] of envVars.entries()) {
          envString += `${key}=${value},`;
        }
        
        if (envString) {
          deployCommand += ` --set-env-vars=${envString.slice(0, -1)}`;
        }
      }
      
      // Ejecutar comando de despliegue
      const { stdout: deployOutput } = await execAsync(deployCommand);
      
      return `Despliegue en Google Cloud Functions completado: ${deployOutput.trim()}`;
    }
    
    private async deployToGCPGKE(config: DeploymentConfig, gcpConfig: any): Promise<string> {
      // Implementación de despliegue en Google Kubernetes Engine
      this.logger.info('Desplegando en Google Kubernetes Engine...');
      
      // Verificar parámetros necesarios
      if (!gcpConfig.project || !gcpConfig.cluster) {
        throw new Error('No se han proporcionado ID de proyecto GCP y nombre de cluster para despliegue');
      }
      
      // Verificar si hay configuración de Kubernetes
      if (!config.kubernetesConfig) {
        throw new Error('No se ha proporcionado configuración de Kubernetes para despliegue en GKE');
      }
      
      const k8sConfig = config.kubernetesConfig as KubernetesConfig;
      
      // Configurar proyecto GCP
      await execAsync(`gcloud config set project ${gcpConfig.project}`);
      
      // Obtener credenciales del cluster
      const region = gcpConfig.region || 'us-central1';
      await execAsync(`gcloud container clusters get-credentials ${gcpConfig.cluster} --region ${region}`);
      
      // Verificar namespace
      const namespace = k8sConfig.namespace || 'default';
      
      // Aplicar configuraciones de Kubernetes
      let deployOutput = '';
      
      for (const manifestPath of k8sConfig.manifestPaths) {
        // Reemplazar variables en el manifiesto
        const manifestContent = fs.readFileSync(manifestPath, 'utf8');
        let processedManifest = manifestContent;
        
        // Reemplazar variables de entorno
        if (this.environmentVariables.has(config.environment)) {
          const envVars = this.environmentVariables.get(config.environment);
          for (const [key, value] of envVars.entries()) {
            processedManifest = processedManifest.replace(new RegExp(`\\$\\{${key}\\}`, 'g'), value);
          }
        }
        
        // Guardar manifiesto procesado
        const tempManifestPath = path.join(path.dirname(manifestPath), `temp_${path.basename(manifestPath)}`);
        fs.writeFileSync(tempManifestPath, processedManifest, 'utf8');
        
        // Aplicar manifiesto
        const { stdout: applyOutput } = await execAsync(`kubectl apply -f ${tempManifestPath} -n ${namespace}`);
        deployOutput += applyOutput + '\n';
        
        // Eliminar manifiesto temporal
        fs.unlinkSync(tempManifestPath);
      }
      
      // Verificar despliegue
      if (k8sConfig.deploymentName) {
        await this.kubernetesService.waitForDeployment(k8sConfig.deploymentName, namespace);
        this.logger.debug(`Despliegue ${k8sConfig.deploymentName} completado correctamente`);
      }
      
      return `Despliegue en Google Kubernetes Engine completado: ${deployOutput.trim()}`;
    }
    
    private async verifyDeployment(config: DeploymentConfig): Promise<string> {
      this.logger.info(`Verificando despliegue en entorno ${config.environment}`);
      
      try {
        // Verificar según el tipo de infraestructura
        switch (config.infrastructureType) {
          case InfrastructureType.DOCKER:
            return await this.verifyDockerDeployment(config);
          case InfrastructureType.KUBERNETES:
            return await this.verifyKubernetesDeployment(config);
          case InfrastructureType.AWS:
            return await this.verifyAWSDeployment(config);
          case InfrastructureType.AZURE:
            return await this.verifyAzureDeployment(config);
          case InfrastructureType.GCP:
            return await this.verifyGCPDeployment(config);
          default:
            return `No se pudo verificar el despliegue para el tipo de infraestructura: ${config.infrastructureType}`;
        }
      } catch (error) {
        this.logger.error(`Error al verificar despliegue: ${error.message}`);
        throw error;
      }
    }
    
    private async verifyDockerDeployment(config: DeploymentConfig): Promise<string> {
      // Verificar despliegue en Docker
      if (!config.containerConfig) {
        throw new Error('No se ha proporcionado configuración de contenedor para verificar despliegue en Docker');
      }
      
      const containerConfig = config.containerConfig as ContainerConfig;
      
      // Verificar si el contenedor está en ejecución
      const { stdout: containerOutput } = await execAsync(`docker ps --filter "name=${containerConfig.containerName}" --format "{{.Status}}"`);
      
      if (!containerOutput.includes('Up')) {
        throw new Error(`El contenedor ${containerConfig.containerName} no está en ejecución`);
      }
      
      // Verificar logs del contenedor
      const { stdout: logsOutput } = await execAsync(`docker logs ${containerConfig.containerName} --tail 10`);
      
      // Verificar estado de salud si está configurado
      if (containerConfig.healthCheckEndpoint) {
        // Obtener puerto mapeado
        const { stdout: portOutput } = await execAsync(`docker port ${containerConfig.containerName}`);
        const portMapping = portOutput.split('\n')[0];
        const hostPort = portMapping.split(':')[1];
        
        // Verificar endpoint de salud
        const healthCheckUrl = `http://localhost:${hostPort}${containerConfig.healthCheckEndpoint}`;
        
        try {
          const { stdout: curlOutput } = await execAsync(`curl -s -o /dev/null -w "%{http_code}" ${healthCheckUrl}`);
          
          if (curlOutput.trim() !== '200') {
            throw new Error(`El endpoint de salud devolvió código ${curlOutput.trim()}`);
          }
        } catch (error) {
          throw new Error(`No se pudo acceder al endpoint de salud: ${error.message}`);
        }
      }
      
      return `Contenedor ${containerConfig.containerName} verificado correctamente. Últimos logs: ${logsOutput.substring(0, 200)}...`;
    }
    
    private async verifyKubernetesDeployment(config: DeploymentConfig): Promise<string> {
      // Verificar despliegue en Kubernetes
      if (!config.kubernetesConfig) {
        throw new Error('No se ha proporcionado configuración de Kubernetes para verificar despliegue');
      }
      
      const k8sConfig = config.kubernetesConfig as KubernetesConfig;
      const namespace = k8sConfig.namespace || 'default';
      
      if (!k8sConfig.deploymentName) {
        throw new Error('No se ha proporcionado nombre de despliegue para verificar en Kubernetes');
      }
      
      // Verificar estado del despliegue
      const { stdout: deploymentOutput } = await execAsync(`kubectl get deployment ${k8sConfig.deploymentName} -n ${namespace} -o json`);
      const deploymentInfo = JSON.parse(deploymentOutput);
      
      const availableReplicas = deploymentInfo.status.availableReplicas || 0;
      const desiredReplicas = deploymentInfo.status.replicas || 0;
      
      if (availableReplicas < desiredReplicas) {
        throw new Error(`El despliegue ${k8sConfig.deploymentName} no tiene todas las réplicas disponibles (${availableReplicas}/${desiredReplicas})`);
      }
      
      // Verificar pods
      const { stdout: podsOutput } = await execAsync(`kubectl get pods -n ${namespace} -l app=${k8sConfig.deploymentName} -o json`);
      const podsInfo = JSON.parse(podsOutput);
      
      if (!podsInfo.items || podsInfo.items.length === 0) {
        throw new Error(`No se encontraron pods para el despliegue ${k8sConfig.deploymentName}`);
      }
      
      // Verificar logs del primer pod
      const podName = podsInfo.items[0].metadata.name;
      const { stdout: logsOutput } = await execAsync(`kubectl logs ${podName} -n ${namespace} --tail=10`);
      
      return `Despliegue ${k8sConfig.deploymentName} verificado correctamente. Réplicas: ${availableReplicas}/${desiredReplicas}. Últimos logs: ${logsOutput.substring(0, 200)}...`;
    }
    
    private async verifyAWSDeployment(config: DeploymentConfig): Promise<string> {
      // Verificar despliegue en AWS
      if (!config.cloudConfig || config.cloudConfig.provider !== CloudProvider.AWS) {
        throw new Error('No se ha proporcionado configuración válida de AWS para verificar despliegue');
      }
      
      const awsConfig = config.cloudConfig;
      
      // Verificar según el tipo de servicio
      switch (awsConfig.serviceType) {
        case 'ec2':
          // Verificar instancia EC2
          const { stdout: instanceOutput } = await execAsync(`aws ec2 describe-instances --instance-ids ${awsConfig.instanceId} --query "Reservations[0].Instances[0].State.Name"`);
          
          if (!instanceOutput.includes('running')) {
            throw new Error(`La instancia EC2 ${awsConfig.instanceId} no está en ejecución`);
          }
          
          return `Instancia EC2 ${awsConfig.instanceId} verificada correctamente. Estado: ${instanceOutput.trim()}`;
          
        case 'ecs':
          // Verificar servicio ECS
          const { stdout: ecsOutput } = await execAsync(`aws ecs describe-services --cluster ${awsConfig.cluster} --services ${awsConfig.service} --query "services[0].runningCount"`);
          
          if (parseInt(ecsOutput.trim()) === 0) {
            throw new Error(`El servicio ECS ${awsConfig.service} no tiene tareas en ejecución`);
          }
          
          return `Servicio ECS ${awsConfig.service} verificado correctamente. Tareas en ejecución: ${ecsOutput.trim()}`;
          
        case 'lambda':
          // Verificar función Lambda
          const { stdout: lambdaOutput } = await execAsync(`aws lambda get-function --function-name ${awsConfig.functionName} --query "Configuration.State"`);
          
          if (!lambdaOutput.includes('Active')) {
            throw new Error(`La función Lambda ${awsConfig.functionName} no está activa`);
          }
          
          return `Función Lambda ${awsConfig.functionName} verificada correctamente. Estado: ${lambdaOutput.trim()}`;
          
        case 's3':
          // Verificar bucket S3
          const { stdout: s3Output } = await execAsync(`aws s3 ls s3://${awsConfig.bucketName} --recursive --summarize | grep "Total Objects"`);
          
          return `Bucket S3 ${awsConfig.bucketName} verificado correctamente. ${s3Output.trim()}`;
          
        case 'elasticbeanstalk':
          // Verificar entorno Elastic Beanstalk
          const { stdout: ebOutput } = await execAsync(`aws elasticbeanstalk describe-environments --environment-names ${awsConfig.environmentName} --query "Environments[0].Status"`);
          
          if (!ebOutput.includes('Ready')) {
            throw new Error(`El entorno Elastic Beanstalk ${awsConfig.environmentName} no está listo`);
          }
          
          return `Entorno Elastic Beanstalk ${awsConfig.environmentName} verificado correctamente. Estado: ${ebOutput.trim()}`;
          
        default:
          return `No se pudo verificar el despliegue para el tipo de servicio AWS: ${awsConfig.serviceType}`;
      }
    }
    
    private async verifyAzureDeployment(config: DeploymentConfig): Promise<string> {
      // Verificar despliegue en Azure
      if (!config.cloudConfig || config.cloudConfig.provider !== CloudProvider.AZURE) {
        throw new Error('No se ha proporcionado configuración válida de Azure para verificar despliegue');
      }
      
      const azureConfig = config.cloudConfig;
      
      // Verificar según el tipo de servicio
      switch (azureConfig.serviceType) {
        case 'webapp':
          // Verificar Web App
          const { stdout: webAppOutput } = await execAsync(`az webapp show --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.webAppName} --query "state"`);
          
          if (!webAppOutput.includes('Running')) {
            throw new Error(`La Web App ${azureConfig.webAppName} no está en ejecución`);
          }
          
          return `Web App ${azureConfig.webAppName} verificada correctamente. Estado: ${webAppOutput.trim()}`;
          
        case 'function':
          // Verificar Function App
          const { stdout: functionOutput } = await execAsync(`az functionapp show --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.functionAppName} --query "state"`);
          
          if (!functionOutput.includes('Running')) {
            throw new Error(`La Function App ${azureConfig.functionAppName} no está en ejecución`);
          }
          
          return `Function App ${azureConfig.functionAppName} verificada correctamente. Estado: ${functionOutput.trim()}`;
          
        case 'container':
          // Verificar Container Instance
          const { stdout: containerOutput } = await execAsync(`az container show --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.containerGroupName} --query "instanceView.state"`);
          
          if (!containerOutput.includes('Running')) {
            throw new Error(`El grupo de contenedores ${azureConfig.containerGroupName} no está en ejecución`);
          }
          
          return `Grupo de contenedores ${azureConfig.containerGroupName} verificado correctamente. Estado: ${containerOutput.trim()}`;
          
        case 'staticwebapp':
          // Verificar Static Web App
          const { stdout: staticWebAppOutput } = await execAsync(`az staticwebapp show --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.staticWebAppName} --query "status"`);
          
          if (!staticWebAppOutput.includes('Ready')) {
            throw new Error(`La Static Web App ${azureConfig.staticWebAppName} no está lista`);
          }
          
          return `Static Web App ${azureConfig.staticWebAppName} verificada correctamente. Estado: ${staticWebAppOutput.trim()}`;
          
        default:
          return `No se pudo verificar el despliegue para el tipo de servicio Azure: ${azureConfig.serviceType}`;
      }
    }
    
    private async verifyGCPDeployment(config: DeploymentConfig): Promise<string> {
      // Verificar despliegue en GCP
      if (!config.cloudConfig || config.cloudConfig.provider !== CloudProvider.GCP) {
        throw new Error('No se ha proporcionado configuración válida de GCP para verificar despliegue');
      }
      
      const gcpConfig = config.cloudConfig;
      
      // Verificar según el tipo de servicio
      switch (gcpConfig.serviceType) {
        case 'appengine':
          // Verificar App Engine
          const { stdout: appEngineOutput } = await execAsync(`gcloud app describe --project=${gcpConfig.project} --format="value(servingStatus)"`);
          
          if (!appEngineOutput.includes('SERVING')) {
            throw new Error(`La aplicación App Engine en el proyecto ${gcpConfig.project} no está sirviendo tráfico`);
          }
          
          return `Aplicación App Engine verificada correctamente. Estado: ${appEngineOutput.trim()}`;
          
        case 'cloudrun':
          // Verificar Cloud Run
          const { stdout: cloudRunOutput } = await execAsync(`gcloud run services describe ${gcpConfig.serviceName} --project=${gcpConfig.project} --region=${gcpConfig.region || 'us-central1'} --format="value(status.conditions[0].status)"`);
          
          if (!cloudRunOutput.includes('True')) {
            throw new Error(`El servicio Cloud Run ${gcpConfig.serviceName} no está listo`);
          }
          
          return `Servicio Cloud Run ${gcpConfig.serviceName} verificado correctamente. Estado: ${cloudRunOutput.trim()}`;
          
        case 'functions':
          // Verificar Cloud Functions
          const { stdout: functionsOutput } = await execAsync(`gcloud functions describe ${gcpConfig.functionName} --project=${gcpConfig.project} --region=${gcpConfig.region || 'us-central1'} --format="value(status)"`);
          
          if (!functionsOutput.includes('ACTIVE')) {
            throw new Error(`La función Cloud Functions ${gcpConfig.functionName} no está activa`);
          }
          
          return `Función Cloud Functions ${gcpConfig.functionName} verificada correctamente. Estado: ${functionsOutput.trim()}`;
          
        case 'gke':
          // Verificar GKE
          const { stdout: gkeOutput } = await execAsync(`gcloud container clusters describe ${gcpConfig.cluster} --project=${gcpConfig.project} --region=${gcpConfig.region || 'us-central1'} --format="value(status)"`);
          
          if (!gkeOutput.includes('RUNNING')) {
            throw new Error(`El cluster GKE ${gcpConfig.cluster} no está en ejecución`);
          }
          
          // Verificar despliegue en Kubernetes
          if (config.kubernetesConfig && config.kubernetesConfig.deploymentName) {
            return await this.verifyKubernetesDeployment(config);
          }
          
          return `Cluster GKE ${gcpConfig.cluster} verificado correctamente. Estado: ${gkeOutput.trim()}`;
          
        default:
          return `No se pudo verificar el despliegue para el tipo de servicio GCP: ${gcpConfig.serviceType}`;
      }
    }
    
    /**
     * Configura el monitoreo para un despliegue
     * @param config Configuración de despliegue
     * @returns Mensaje de confirmación
     */
    public async setupMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info(`Configurando monitoreo para ${config.name}`);
      
      try {
        // Verificar si ya existe configuración de monitoreo
        if (this.monitoringConfigs.has(config.name)) {
          this.logger.debug(`Actualizando configuración de monitoreo existente para ${config.name}`);
          // Actualizar configuración existente
          const existingConfig = this.monitoringConfigs.get(config.name);
          this.monitoringConfigs.set(config.name, { ...existingConfig, ...config });
        } else {
          // Crear nueva configuración
          this.monitoringConfigs.set(config.name, config);
        }
        
        // Configurar monitoreo según el tipo
        let setupOutput = '';
        
        switch (config.type) {
          case 'prometheus':
            setupOutput = await this.setupPrometheusMonitoring(config);
            break;
          case 'cloudwatch':
            setupOutput = await this.setupCloudWatchMonitoring(config);
            break;
          case 'stackdriver':
            setupOutput = await this.setupStackdriverMonitoring(config);
            break;
          case 'azure-monitor':
            setupOutput = await this.setupAzureMonitoring(config);
            break;
          case 'custom':
            setupOutput = await this.setupCustomMonitoring(config);
            break;
          default:
            throw new Error(`Tipo de monitoreo no soportado: ${config.type}`);
        }
        
        // Configurar alertas si están especificadas
        if (config.alerts && config.alerts.length > 0) {
          await this.setupAlerts(config);
        }
        
        // Configurar dashboards si están especificados
        if (config.dashboards && config.dashboards.length > 0) {
          await this.setupDashboards(config);
        }
        
        return `Monitoreo configurado correctamente para ${config.name}: ${setupOutput}`;
      } catch (error) {
        this.logger.error(`Error al configurar monitoreo: ${error.message}`);
        throw error;
      }
    }
    
    private async setupPrometheusMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo con Prometheus...');
      
      // Verificar si Prometheus está instalado
      try {
        await execAsync('prometheus --version');
      } catch (error) {
        this.logger.warn('Prometheus no está instalado. Intentando instalar...');
        
        // Instalar Prometheus según el sistema operativo
        const platform = process.platform;
        
        if (platform === 'linux') {
          await execAsync('sudo apt-get update && sudo apt-get install -y prometheus');
        } else if (platform === 'darwin') {
          await execAsync('brew install prometheus');
        } else if (platform === 'win32') {
          // En Windows, descargar y configurar manualmente
          this.logger.warn('En Windows, se recomienda descargar Prometheus manualmente desde https://prometheus.io/download/');
        } else {
          throw new Error(`Plataforma no soportada para instalación automática de Prometheus: ${platform}`);
        }
      }
      
      // Crear archivo de configuración de Prometheus
      const prometheusConfigPath = path.join(config.targetPath || process.cwd(), 'prometheus.yml');
      
      const prometheusConfig = `
global:
  scrape_interval: ${config.interval || '15s'}
  evaluation_interval: ${config.evaluationInterval || '15s'}

scrape_configs:
  - job_name: '${config.name}'
    static_configs:
      - targets: ['${config.endpoint || 'localhost:9090'}']
`;
      
      fs.writeFileSync(prometheusConfigPath, prometheusConfig, 'utf8');
      
      // Iniciar Prometheus con la configuración
      const prometheusCmd = `prometheus --config.file=${prometheusConfigPath}`;
      
      // Ejecutar en segundo plano
      const prometheusProcess = spawn(prometheusCmd, { shell: true, detached: true, stdio: 'ignore' });
      prometheusProcess.unref();
      
      return `Prometheus configurado y ejecutándose con configuración en ${prometheusConfigPath}`;
    }
    
    private async setupCloudWatchMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo con AWS CloudWatch...');
      
      // Verificar credenciales de AWS
      try {
        await execAsync('aws sts get-caller-identity');
      } catch (error) {
        throw new Error('No se han configurado credenciales de AWS válidas. Configure AWS CLI primero.');
      }
      
      // Crear grupo de logs si no existe
      const logGroupName = config.logGroupName || `${config.name}-logs`;
      
      try {
        await execAsync(`aws logs describe-log-groups --log-group-name-prefix ${logGroupName}`);
      } catch (error) {
        // Crear grupo de logs
        await execAsync(`aws logs create-log-group --log-group-name ${logGroupName}`);
        this.logger.debug(`Grupo de logs ${logGroupName} creado`);
      }
      
      // Configurar métricas
      if (config.metrics && config.metrics.length > 0) {
        for (const metric of config.metrics) {
          // Crear alarma para la métrica
          const alarmName = `${config.name}-${metric.name}-alarm`;
          const metricNamespace = metric.namespace || 'CJDevMind';
          
          const createAlarmCmd = `aws cloudwatch put-metric-alarm --alarm-name ${alarmName} --alarm-description "Alarma para ${metric.name}" --metric-name ${metric.name} --namespace ${metricNamespace} --statistic ${metric.statistic || 'Average'} --period ${metric.period || 60} --threshold ${metric.threshold} --comparison-operator ${metric.operator || 'GreaterThanThreshold'} --evaluation-periods ${metric.evaluationPeriods || 1}`;
          
          await execAsync(createAlarmCmd);
          this.logger.debug(`Alarma ${alarmName} creada para métrica ${metric.name}`);
        }
      }
      
      return `Monitoreo con CloudWatch configurado. Grupo de logs: ${logGroupName}`;
    }
    
    private async setupStackdriverMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo con Google Cloud Monitoring (Stackdriver)...');
      
      // Verificar credenciales de GCP
      try {
        await execAsync('gcloud auth list');
      } catch (error) {
        throw new Error('No se han configurado credenciales de GCP válidas. Configure gcloud CLI primero.');
      }
      
      // Verificar proyecto
      if (!config.projectId) {
        throw new Error('No se ha proporcionado ID de proyecto GCP para monitoreo');
      }
      
      // Configurar proyecto
      await execAsync(`gcloud config set project ${config.projectId}`);
      
      // Habilitar API de Monitoring si no está habilitada
      try {
        await execAsync(`gcloud services enable monitoring.googleapis.com --project=${config.projectId}`);
      } catch (error) {
        this.logger.warn(`Error al habilitar API de Monitoring: ${error.message}`);
      }
      
      // Crear políticas de alerta para métricas
      if (config.metrics && config.metrics.length > 0) {
        for (const metric of config.metrics) {
          const alertPolicyName = `${config.name}-${metric.name}-alert`;
          
          // Crear archivo de configuración de política
          const policyConfigPath = path.join(config.targetPath || process.cwd(), `${alertPolicyName}.json`);
          
          const policyConfig = {
            displayName: alertPolicyName,
            conditions: [
              {
                displayName: `${metric.name} condition`,
                conditionThreshold: {
                  filter: `metric.type="${metric.type}" AND resource.type="${metric.resourceType || 'global'}"`,
                  comparison: metric.operator || 'COMPARISON_GT',
                  thresholdValue: metric.threshold,
                  duration: { seconds: metric.duration || 60 },
                  trigger: { count: 1 }
                }
              }
            ],
            alertStrategy: {
              autoClose: '604800s'
            },
            combiner: 'OR'
          };
          
          fs.writeFileSync(policyConfigPath, JSON.stringify(policyConfig, null, 2), 'utf8');
          
          // Crear política de alerta
          await execAsync(`gcloud alpha monitoring policies create --policy-from-file=${policyConfigPath}`);
          
          this.logger.debug(`Política de alerta ${alertPolicyName} creada para métrica ${metric.name}`);
          
          // Eliminar archivo temporal
          fs.unlinkSync(policyConfigPath);
        }
      }
      
      return `Monitoreo con Google Cloud Monitoring configurado para proyecto ${config.projectId}`;
    }
    
    private async setupAzureMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo con Azure Monitor...');
      
      // Verificar credenciales de Azure
      try {
        await execAsync('az account show');
      } catch (error) {
        throw new Error('No se han configurado credenciales de Azure válidas. Configure Azure CLI primero.');
      }
      
      // Verificar grupo de recursos
      if (!config.resourceGroup) {
        throw new Error('No se ha proporcionado grupo de recursos para monitoreo en Azure');
      }
      
      // Crear grupo de acción para alertas si no existe
      const actionGroupName = `${config.name}-action-group`.replace(/[^a-zA-Z0-9]/g, '');
      
      try {
        await execAsync(`az monitor action-group show --resource-group ${config.resourceGroup} --name ${actionGroupName}`);
      } catch (error) {
        // Crear grupo de acción
        await execAsync(`az monitor action-group create --resource-group ${config.resourceGroup} --name ${actionGroupName} --short-name ${actionGroupName.substring(0, 12)}`);
        
        // Añadir notificaciones por email si están configuradas
        if (config.notificationEmail) {
          await execAsync(`az monitor action-group update --resource-group ${config.resourceGroup} --name ${actionGroupName} --add-email-receiver --email-receiver-name EmailNotification --email-address ${config.notificationEmail}`);
        }
        
        this.logger.debug(`Grupo de acción ${actionGroupName} creado`);
      }
      
      // Configurar reglas de alerta para métricas
      if (config.metrics && config.metrics.length > 0) {
        for (const metric of config.metrics) {
          const alertName = `${config.name}-${metric.name}-alert`.replace(/[^a-zA-Z0-9]/g, '');
          
          // Crear regla de alerta
          const createAlertCmd = `az monitor metrics alert create --resource-group ${config.resourceGroup} --name ${alertName} --scopes ${metric.resourceId} --condition "avg ${metric.name} > ${metric.threshold}" --window-size ${metric.windowSize || '5m'} --evaluation-frequency ${metric.evaluationFrequency || '1m'} --action ${actionGroupName}`;
          
          await execAsync(createAlertCmd);
          
          this.logger.debug(`Regla de alerta ${alertName} creada para métrica ${metric.name}`);
        }
      }
      
      return `Monitoreo con Azure Monitor configurado para grupo de recursos ${config.resourceGroup}`;
    }
    
    private async setupCustomMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo personalizado...');
      
      // Verificar script de monitoreo
      if (!config.scriptPath) {
        throw new Error('No se ha proporcionado ruta de script para monitoreo personalizado');
      }
      
      if (!fs.existsSync(config.scriptPath)) {
        throw new Error(`El script de monitoreo no existe: ${config.scriptPath}`);
      }
      
      // Verificar permisos de ejecución
      try {
        fs.accessSync(config.scriptPath, fs.constants.X_OK);
      } catch (error) {
        // Intentar dar permisos de ejecución
        if (process.platform !== 'win32') {
          await execAsync(`chmod +x ${config.scriptPath}`);
        }
      }
      
      // Configurar cron job para ejecutar el script periódicamente
      const cronExpression = config.cronExpression || '*/15 * * * *'; // Por defecto cada 15 minutos
      
      if (process.platform === 'win32') {
        // En Windows, usar Task Scheduler
        const taskName = `CJDevMind-Monitor-${config.name}`;
        const scriptExt = path.extname(config.scriptPath);
        let command = '';
        
        if (scriptExt === '.ps1') {
          command = `powershell -ExecutionPolicy Bypass -File "${config.scriptPath}"`;
        } else if (scriptExt === '.bat' || scriptExt === '.cmd') {
          command = `"${config.scriptPath}"`;
        } else {
          command = `node "${config.scriptPath}"`;
        }
        
        // Convertir expresión cron a formato de Task Scheduler
        const cronParts = cronExpression.split(' ');
        const minutes = cronParts[0] === '*' ? '*' : cronParts[0].replace('*/', '');
        const hours = cronParts[1] === '*' ? '*' : cronParts[1];
        
        let scheduleString = '';
        
        if (minutes === '*' && hours === '*') {
          scheduleString = '/SC MINUTE /MO 15'; // Cada 15 minutos
        } else if (minutes !== '*' && hours === '*') {
          scheduleString = `/SC HOURLY /MO 1 /ST 00:${minutes.padStart(2, '0')}`;
        } else {
          scheduleString = `/SC DAILY /ST ${hours.padStart(2, '0')}:${minutes.padStart(2, '0')}`;
        }
        
        await execAsync(`schtasks /Create /TN "${taskName}" /TR "${command}" ${scheduleString} /F`);
        
        return `Monitoreo personalizado configurado con Task Scheduler. Tarea: ${taskName}`;
      } else {
        // En sistemas Unix, usar crontab
        const cronCommand = `${cronExpression} ${config.scriptPath} >> ${config.logPath || '/tmp/cjdevmind-monitor.log'} 2>&1`;
        
        // Añadir a crontab
        const tempCronFile = path.join(os.tmpdir(), 'cjdevmind-crontab');
        
        // Obtener crontab actual
        const { stdout: currentCrontab } = await execAsync('crontab -l || echo ""');
        
        // Verificar si ya existe una entrada para este monitoreo
        const cronRegex = new RegExp(`.*${config.scriptPath.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}.*`);
        const newCrontab = cronRegex.test(currentCrontab)
          ? currentCrontab.replace(cronRegex, cronCommand)
          : `${currentCrontab}\n${cronCommand}`;
        
        // Escribir nuevo crontab
        fs.writeFileSync(tempCronFile, newCrontab, 'utf8');
        
        // Aplicar nuevo crontab
        await execAsync(`crontab ${tempCronFile}`);
        
        // Eliminar archivo temporal
        fs.unlinkSync(tempCronFile);
        
        return `Monitoreo personalizado configurado con crontab. Expresión: ${cronExpression}`;
      }
    }
    
    private async setupAlerts(config: MonitoringConfig): Promise<void> {
      this.logger.info(`Configurando alertas para ${config.name}...`);
      
      if (!config.alerts || config.alerts.length === 0) {
        return;
      }
      
      for (const alert of config.alerts) {
        this.logger.debug(`Configurando alerta ${alert.name}`);
        
        // Configurar alerta según el tipo de monitoreo
        switch (config.type) {
          case 'prometheus':
            await this.setupPrometheusAlert(config, alert);
            break;
          case 'cloudwatch':
            // Las alertas de CloudWatch ya se configuran en setupCloudWatchMonitoring
            break;
          case 'stackdriver':
            // Las alertas de Stackdriver ya se configuran en setupStackdriverMonitoring
            break;
          case 'azure-monitor':
            // Las alertas de Azure Monitor ya se configuran en setupAzureMonitoring
            break;
          case 'custom':
            await this.setupCustomAlert(config, alert);
            break;
        }
      }
    }
    
    private async setupPrometheusAlert(config: MonitoringConfig, alert: any): Promise<void> {
      // Verificar si Alertmanager está instalado
      try {
        await execAsync('alertmanager --version');
      } catch (error) {
        this.logger.warn('Alertmanager no está instalado. Intentando instalar...');
        
        // Instalar Alertmanager según el sistema operativo
        const platform = process.platform;
        
        if (platform === 'linux') {
          await execAsync('sudo apt-get update && sudo apt-get install -y prometheus-alertmanager');
        } else if (platform === 'darwin') {
          await execAsync('brew install alertmanager');
        } else if (platform === 'win32') {
          // En Windows, descargar y configurar manualmente
          this.logger.warn('En Windows, se recomienda descargar Alertmanager manualmente desde https://prometheus.io/download/');
        } else {
          throw new Error(`Plataforma no soportada para instalación automática de Alertmanager: ${platform}`);
        }
      }
      
      // Crear archivo de configuración de Alertmanager
      const alertmanagerConfigPath = path.join(config.targetPath || process.cwd(), 'alertmanager.yml');
      
      const receivers = [{
        name: 'default-receiver',
        email_configs: config.notificationEmail ? [{
          to: config.notificationEmail,
          send_resolved: true
        }] : undefined,
        webhook_configs: alert.webhookUrl ? [{
          url: alert.webhookUrl,
          send_resolved: true
        }] : undefined
      }];
      
      const alertmanagerConfig = {
        global: {
          resolve_timeout: '5m',
          smtp_smarthost: config.smtpServer || 'localhost:25',
          smtp_from: config.smtpFrom || 'alertmanager@localhost',
          smtp_require_tls: false
        },
        route: {
          group_by: ['alertname', 'job'],
          group_wait: '30s',
          group_interval: '5m',
          repeat_interval: '12h',
          receiver: 'default-receiver'
        },
        receivers
      };
      
      fs.writeFileSync(alertmanagerConfigPath, JSON.stringify(alertmanagerConfig, null, 2), 'utf8');
      
      // Crear regla de alerta para Prometheus
      const alertRulesPath = path.join(config.targetPath || process.cwd(), 'alert_rules.yml');
      
      const alertRule = {
        groups: [{
          name: `${config.name}-alerts`,
          rules: [{
            alert: alert.name,
            expr: alert.expression,
            for: alert.duration || '5m',
            labels: {
              severity: alert.severity || 'warning'
            },
            annotations: {
              summary: alert.summary || `Alerta: ${alert.name}`,
              description: alert.description || `Se ha activado la alerta ${alert.name}`
            }
          }]
        }]
      };
      
      fs.writeFileSync(alertRulesPath, JSON.stringify(alertRule, null, 2), 'utf8');
      
      // Actualizar configuración de Prometheus para incluir reglas de alerta
      const prometheusConfigPath = path.join(config.targetPath || process.cwd(), 'prometheus.yml');
      
      if (fs.existsSync(prometheusConfigPath)) {
        let prometheusConfig = fs.readFileSync(prometheusConfigPath, 'utf8');
        
        // Añadir configuración de reglas si no existe
        if (!prometheusConfig.includes('rule_files:')) {
          prometheusConfig += `\nrule_files:\n  - "${alertRulesPath}"\n`;
        } else if (!prometheusConfig.includes(alertRulesPath)) {
          prometheusConfig = prometheusConfig.replace(/rule_files:([^\n]*\n)(\s+- [^\n]*\n)*/, (match) => {
            return match + `  - "${alertRulesPath}"\n`;
          });
        }
        
        // Añadir configuración de Alertmanager si no existe
        if (!prometheusConfig.includes('alerting:')) {
          prometheusConfig += `\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets: ["localhost:9093"]\n`;
        }
        
        fs.writeFileSync(prometheusConfigPath, prometheusConfig, 'utf8');
      }
      
      // Iniciar Alertmanager con la configuración
      const alertmanagerCmd = `alertmanager --config.file=${alertmanagerConfigPath}`;
      
      // Ejecutar en segundo plano
      const alertmanagerProcess = spawn(alertmanagerCmd, { shell: true, detached: true, stdio: 'ignore' });
      alertmanagerProcess.unref();
      
      this.logger.debug(`Alerta ${alert.name} configurada con Prometheus Alertmanager`);
    }
    
    private async setupCustomAlert(config: MonitoringConfig, alert: any): Promise<void> {
      // Verificar script de alerta
      if (!alert.scriptPath) {
        this.logger.warn(`No se ha proporcionado script para la alerta personalizada ${alert.name}`);
        return;
      }
      
      if (!fs.existsSync(alert.scriptPath)) {
        throw new Error(`El script de alerta no existe: ${alert.scriptPath}`);
      }
      
      // Verificar permisos de ejecución
      try {
        fs.accessSync(alert.scriptPath, fs.constants.X_OK);
      } catch (error) {
        // Intentar dar permisos de ejecución
        if (process.platform !== 'win32') {
          await execAsync(`chmod +x ${alert.scriptPath}`);
        }
      }
      
      this.logger.debug(`Alerta personalizada ${alert.name} configurada con script ${alert.scriptPath}`);
    }
    
    private async setupDashboards(config: MonitoringConfig): Promise<void> {
      this.logger.info(`Configurando dashboards para ${config.name}...`);
      
      if (!config.dashboards || config.dashboards.length === 0) {
        return;
      }
      
      for (const dashboard of config.dashboards) {
        this.logger.debug(`Configurando dashboard ${dashboard.name}`);
        
        // Configurar dashboard según el tipo de monitoreo
        switch (config.type) {
          case 'prometheus':
            await this.setupGrafanaDashboard(config, dashboard);
            break;
          case 'cloudwatch':
            await this.setupCloudWatchDashboard(config, dashboard);
            break;
          case 'stackdriver':
            await this.setupStackdriverDashboard(config, dashboard);
            break;
          case 'azure-monitor':
            await this.setupAzureDashboard(config, dashboard);
            break;
          case 'custom':
            // No hay implementación estándar para dashboards personalizados
            break;
        }
      }
    }
    
    private async setupGrafanaDashboard(config: MonitoringConfig, dashboard: any): Promise<void> {
      // Verificar si Grafana está instalado
      try {
        await execAsync('grafana-server -v');
      } catch (error) {
        this.logger.warn('Grafana no está instalado. Los dashboards requieren Grafana para visualización.');
        return;
      }
      
      // Crear archivo JSON de dashboard
      const dashboardPath = path.join(config.targetPath || process.cwd(), `${dashboard.name}.json`);
      
      // Crear estructura básica de dashboard si no se proporciona una personalizada
      if (!dashboard.json) {
        const defaultDashboard = {
          dashboard: {
            id: null,
            title: dashboard.name,
            tags: [config.name, 'cjdevmind'],
            timezone: 'browser',
            schemaVersion: 16,
            version: 0,
            refresh: '10s',
            panels: []
          },
          overwrite: true
        };
        
        // Añadir paneles según las métricas configuradas
        if (config.metrics && config.metrics.length > 0) {
          let panelId = 1;
          
          for (const metric of config.metrics) {
            defaultDashboard.dashboard.panels.push({
              id: panelId++,
              title: metric.name,
              type: 'graph',
              datasource: 'Prometheus',
              targets: [{
                expr: `${metric.name}{job="${config.name}"}`,
                legendFormat: metric.name,
                refId: 'A'
              }],
              gridPos: {
                h: 8,
                w: 12,
                x: (panelId % 2) * 12,
                y: Math.floor(panelId / 2) * 8
              }
            });
          }
        }
        
        dashboard.json = defaultDashboard;
      }
      
      fs.writeFileSync(dashboardPath, JSON.stringify(dashboard.json, null, 2), 'utf8');
      
      this.logger.debug(`Dashboard Grafana ${dashboard.name} creado en ${dashboardPath}`);
      this.logger.info(`Para importar el dashboard en Grafana, vaya a Dashboards > Import y seleccione el archivo ${dashboardPath}`);
    }
    
    private async setupCloudWatchDashboard(config: MonitoringConfig, dashboard: any): Promise<void> {
      // Verificar credenciales de AWS
      try {
        await execAsync('aws sts get-caller-identity');
      } catch (error) {
        throw new Error('No se han configurado credenciales de AWS válidas. Configure AWS CLI primero.');
      }
      
      // Crear estructura de dashboard
      const dashboardBody: any = {
        widgets: []
      };
      
      // Añadir widgets según las métricas configuradas
      if (config.metrics && config.metrics.length > 0) {
        let row = 0;
        let col = 0;
        
        for (const metric of config.metrics) {
          dashboardBody.widgets.push({
            type: 'metric',
            x: col * 6,
            y: row * 6,
            width: 6,
            height: 6,
            properties: {
              metrics: [
                [metric.namespace || 'CJDevMind', metric.name]
              ],
              view: 'timeSeries',
              stacked: false,
              region: config.region || 'us-east-1',
              title: metric.name,
              period: metric.period || 300,
              stat: metric.statistic || 'Average'
            }
          });
          
          // Ajustar posición para el siguiente widget
          col = (col + 1) % 2;
          if (col === 0) row++;
        }
      }
      
      // Convertir a JSON para el comando de AWS CLI
      const dashboardBodyJson = JSON.stringify(dashboardBody);
      
      // Crear o actualizar dashboard
      await execAsync(`aws cloudwatch put-dashboard --dashboard-name ${dashboard.name} --dashboard-body '${dashboardBodyJson}'`);
      
      this.logger.debug(`Dashboard CloudWatch ${dashboard.name} creado correctamente`);
    }
    
    private async setupStackdriverDashboard(config: MonitoringConfig, dashboard: any): Promise<void> {
      // Verificar credenciales de GCP
      try {
        await execAsync('gcloud auth list');
      } catch (error) {
        throw new Error('No se han configurado credenciales de GCP válidas. Configure gcloud CLI primero.');
      }
      
      // Verificar proyecto
      if (!config.projectId) {
        throw new Error('No se ha proporcionado ID de proyecto GCP para dashboard');
      }
      
      this.logger.info(`Configurando dashboard en Google Cloud Monitoring para ${dashboard.name}`);
      
      // Crear archivo de configuración de dashboard
      const dashboardConfigPath = path.join(config.targetPath || process.cwd(), `${dashboard.name}-dashboard.json`);
      
      // Crear estructura básica de dashboard si no se proporciona una personalizada
      if (!dashboard.json) {
        const defaultDashboard = {
          displayName: dashboard.name,
          gridLayout: {
            columns: '2',
            widgets: []
          }
        };
        
        // Añadir widgets según las métricas configuradas
        if (config.metrics && config.metrics.length > 0) {
          for (const metric of config.metrics) {
            defaultDashboard.gridLayout.widgets.push({
              title: metric.name,
              xyChart: {
                dataSets: [{
                  timeSeriesQuery: {
                    timeSeriesFilter: {
                      filter: `metric.type="${metric.type}" AND resource.type="${metric.resourceType || 'global'}"`,
                      aggregation: {
                        perSeriesAligner: 'ALIGN_MEAN',
                        crossSeriesReducer: 'REDUCE_MEAN',
                        alignmentPeriod: metric.period || '60s'
                      }
                    }
                  },
                  plotType: 'LINE'
                }],
                timeshiftDuration: '0s',
                yAxis: {
                  label: metric.name,
                  scale: 'LINEAR'
                }
              }
            });
          }
        }
        
        dashboard.json = defaultDashboard;
      }
      
      fs.writeFileSync(dashboardConfigPath, JSON.stringify(dashboard.json, null, 2), 'utf8');
      
      // Crear dashboard en Google Cloud Monitoring
      await execAsync(`gcloud monitoring dashboards create --config-from-file=${dashboardConfigPath} --project=${config.projectId}`);
      
      this.logger.debug(`Dashboard Google Cloud Monitoring ${dashboard.name} creado correctamente`);
      
      // Eliminar archivo temporal
      fs.unlinkSync(dashboardConfigPath);
    }
    
    private async setupAzureDashboard(config: MonitoringConfig, dashboard: any): Promise<void> {
      // Verificar credenciales de Azure
      try {
        await execAsync('az account show');
      } catch (error) {
        throw new Error('No se han configurado credenciales de Azure válidas. Configure Azure CLI primero.');
      }
      
      // Verificar grupo de recursos
      if (!config.resourceGroup) {
        throw new Error('No se ha proporcionado grupo de recursos para dashboard en Azure');
      }
      
      this.logger.info(`Configurando dashboard en Azure para ${dashboard.name}`);
      
      // Crear archivo de configuración de dashboard
      const dashboardConfigPath = path.join(config.targetPath || process.cwd(), `${dashboard.name}-dashboard.json`);
      
      // Crear estructura básica de dashboard si no se proporciona una personalizada
      if (!dashboard.json) {
        const defaultDashboard = {
          properties: {
            lenses: {
              '0': {
                order: 0,
                parts: {}
              }
            },
            metadata: {
              model: {
                timeRange: {
                  value: {
                    relative: {
                      duration: 24,
                      timeUnit: 1
                    }
                  },
                  type: 'relative'
                }
              }
            }
          },
          name: dashboard.name,
          type: 'Microsoft.Portal/dashboards',
          location: config.location || 'westus',
          tags: {
            'hidden-title': dashboard.name
          }
        };
        
        // Añadir widgets según las métricas configuradas
        if (config.metrics && config.metrics.length > 0) {
          let partIndex = 0;
          
          for (const metric of config.metrics) {
            defaultDashboard.properties.lenses['0'].parts[partIndex.toString()] = {
              position: {
                x: (partIndex % 2) * 6,
                y: Math.floor(partIndex / 2) * 4,
                colSpan: 6,
                rowSpan: 4
              },
              metadata: {
                inputs: [
                  {
                    name: 'options',
                    value: {
                      chart: {
                        metrics: [
                          {
                            resourceMetadata: {
                              id: metric.resourceId
                            },
                            name: metric.name,
                            aggregationType: metric.aggregationType || 4,
                            namespace: metric.namespace,
                            metricVisualization: {
                              displayName: metric.displayName || metric.name
                            }
                          }
                        ],
                        title: metric.displayName || metric.name,
                        visualization: {
                          chartType: 2,
                          legendVisualization: {
                            isVisible: true,
                            position: 2,
                            hideSubtitle: false
                          },
                          axisVisualization: {
                            x: {
                              isVisible: true,
                              axisType: 2
                            },
                            y: {
                              isVisible: true,
                              axisType: 1
                            }
                          }
                        }
                      }
                    }
                  },
                  {
                    name: 'sharedTimeRange',
                    isOptional: true
                  }
                ],
                type: 'Extension/HubsExtension/PartType/MonitorChartPart'
              }
            };
            
            partIndex++;
          }
        }
        
        dashboard.json = defaultDashboard;
      }
      
      fs.writeFileSync(dashboardConfigPath, JSON.stringify(dashboard.json, null, 2), 'utf8');
      
      // Crear dashboard en Azure
      await execAsync(`az portal dashboard create --resource-group ${config.resourceGroup} --name ${dashboard.name} --location ${config.location || 'westus'} --input-path ${dashboardConfigPath}`);
      
      this.logger.debug(`Dashboard Azure ${dashboard.name} creado correctamente`);
      
      // Eliminar archivo temporal
      fs.unlinkSync(dashboardConfigPath);
    }
    
    /**
     * Configura el escalado automático para un despliegue
     * @param config Configuración de escalado
     * @returns Mensaje de confirmación
     */
    public async setupScaling(config: ScalingConfig): Promise<string> {
      this.logger.info(`Configurando escalado automático para ${config.name}`);
      
      try {
        // Verificar si ya existe configuración de escalado
        if (this.scalingConfigs.has(config.name)) {
          this.logger.debug(`Actualizando configuración de escalado existente para ${config.name}`);
          // Actualizar configuración existente
          const existingConfig = this.scalingConfigs.get(config.name);
          this.scalingConfigs.set(config.name, { ...existingConfig, ...config });
        } else {
          // Crear nueva configuración
          this.scalingConfigs.set(config.name, config);
        }
        
        // Configurar escalado según el tipo
        let setupOutput = '';
        
        switch (config.type) {
          case 'kubernetes':
            setupOutput = await this.setupKubernetesScaling(config);
            break;
          case 'aws':
            setupOutput = await this.setupAWSScaling(config);
            break;
          case 'gcp':
            setupOutput = await this.setupGCPScaling(config);
            break;
          case 'azure':
            setupOutput = await this.setupAzureScaling(config);
            break;
          case 'custom':
            setupOutput = await this.setupCustomScaling(config);
            break;
          default:
            throw new Error(`Tipo de escalado no soportado: ${config.type}`);
        }
        
        return `Escalado automático configurado correctamente para ${config.name}: ${setupOutput}`;
      } catch (error) {
        this.logger.error(`Error al configurar escalado automático: ${error.message}`);
        throw error;
      }
    }
    
    private async setupKubernetesScaling(config: ScalingConfig): Promise<string> {
      this.logger.info('Configurando escalado automático con Kubernetes HPA...');
      
      // Verificar configuración de Kubernetes
      if (!config.kubernetesConfig) {
        throw new Error('No se ha proporcionado configuración de Kubernetes para escalado automático');
      }
      
      const k8sConfig = config.kubernetesConfig;
      
      // Verificar si kubectl está instalado
      try {
        await execAsync('kubectl version --client');
      } catch (error) {
        throw new Error('kubectl no está instalado o no está en el PATH. Instale kubectl primero.');
      }
      
      // Verificar si el contexto de Kubernetes está configurado
      if (k8sConfig.context) {
        await execAsync(`kubectl config use-context ${k8sConfig.context}`);
      }
      
      // Verificar si el namespace existe
      const namespace = k8sConfig.namespace || 'default';
      
      try {
        await execAsync(`kubectl get namespace ${namespace}`);
      } catch (error) {
        // Crear namespace si no existe
        await execAsync(`kubectl create namespace ${namespace}`);
      }
      
      // Crear o actualizar HPA
      const hpaName = k8sConfig.hpaName || `${config.name}-hpa`;
      const deploymentName = k8sConfig.deploymentName;
      const minReplicas = config.minInstances || 1;
      const maxReplicas = config.maxInstances || 10;
      const cpuUtilization = config.cpuThreshold || 80;
      const memoryUtilization = config.memoryThreshold;
      
      let hpaCommand = `kubectl autoscale deployment ${deploymentName} --name=${hpaName} --namespace=${namespace} --min=${minReplicas} --max=${maxReplicas} --cpu-percent=${cpuUtilization}`;
      
      if (k8sConfig.dryRun) {
        hpaCommand += ' --dry-run=client -o yaml';
        const { stdout } = await execAsync(hpaCommand);
        
        // Guardar YAML para revisión
        const hpaYamlPath = path.join(config.targetPath || process.cwd(), `${hpaName}.yaml`);
        fs.writeFileSync(hpaYamlPath, stdout, 'utf8');
        
        this.logger.debug(`YAML de HPA generado en ${hpaYamlPath}`);
        return `Configuración de HPA generada en ${hpaYamlPath}. Ejecute 'kubectl apply -f ${hpaYamlPath}' para aplicar.`;
      } else {
        try {
          // Intentar crear HPA
          await execAsync(hpaCommand);
        } catch (error) {
          // Si ya existe, actualizar
          this.logger.debug(`HPA ${hpaName} ya existe, actualizando...`);
          
          // Crear YAML para HPA
          const hpaYaml = `
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ${hpaName}
  namespace: ${namespace}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ${deploymentName}
  minReplicas: ${minReplicas}
  maxReplicas: ${maxReplicas}
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: ${cpuUtilization}
${memoryUtilization ? `  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: ${memoryUtilization}` : ''}
`;
          
          const hpaYamlPath = path.join(config.targetPath || process.cwd(), `${hpaName}.yaml`);
          fs.writeFileSync(hpaYamlPath, hpaYaml, 'utf8');
          
          // Aplicar YAML
          await execAsync(`kubectl apply -f ${hpaYamlPath}`);
          
          // Eliminar archivo temporal
          fs.unlinkSync(hpaYamlPath);
        }
      }
      
      return `HPA ${hpaName} configurado correctamente para el despliegue ${deploymentName} en namespace ${namespace}`;
    }
    
    private async setupAWSScaling(config: ScalingConfig): Promise<string> {
      this.logger.info('Configurando escalado automático con AWS Auto Scaling...');
      
      // Verificar credenciales de AWS
      try {
        await execAsync('aws sts get-caller-identity');
      } catch (error) {
        throw new Error('No se han configurado credenciales de AWS válidas. Configure AWS CLI primero.');
      }
      
      // Verificar tipo de servicio AWS
      if (!config.awsConfig) {
        throw new Error('No se ha proporcionado configuración de AWS para escalado automático');
      }
      
      const awsConfig = config.awsConfig;
      const region = awsConfig.region || 'us-east-1';
      
      // Configurar región
      await execAsync(`aws configure set region ${region}`);
      
      switch (awsConfig.serviceType) {
        case 'ec2':
          return await this.setupEC2AutoScaling(config);
        case 'ecs':
          return await this.setupECSAutoScaling(config);
        case 'eks':
          return await this.setupEKSAutoScaling(config);
        case 'beanstalk':
          return await this.setupBeanstalkAutoScaling(config);
        default:
          throw new Error(`Tipo de servicio AWS no soportado para escalado automático: ${awsConfig.serviceType}`);
      }
    }
    
    private async setupEC2AutoScaling(config: ScalingConfig): Promise<string> {
      const awsConfig = config.awsConfig;
      const region = awsConfig.region || 'us-east-1';
      
      // Verificar si ya existe un grupo de Auto Scaling
      const asgName = awsConfig.asgName || `${config.name}-asg`;
      
      try {
        await execAsync(`aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${asgName} --region ${region}`);
        this.logger.debug(`Grupo de Auto Scaling ${asgName} ya existe, actualizando...`);
        
        // Actualizar configuración de escalado
        await execAsync(`aws autoscaling update-auto-scaling-group --auto-scaling-group-name ${asgName} --min-size ${config.minInstances || 1} --max-size ${config.maxInstances || 10} --region ${region}`);
      } catch (error) {
        // Crear nuevo grupo de Auto Scaling
        this.logger.debug(`Creando nuevo grupo de Auto Scaling ${asgName}...`);
        
        // Verificar si existe Launch Configuration o Launch Template
        if (!awsConfig.launchConfigName && !awsConfig.launchTemplateName) {
          throw new Error('Se requiere un Launch Configuration o Launch Template para crear un grupo de Auto Scaling');
        }
        
        let createCommand = `aws autoscaling create-auto-scaling-group --auto-scaling-group-name ${asgName} --min-size ${config.minInstances || 1} --max-size ${config.maxInstances || 10}`;
        
        if (awsConfig.launchConfigName) {
          createCommand += ` --launch-configuration-name ${awsConfig.launchConfigName}`;
        } else {
          createCommand += ` --launch-template LaunchTemplateName=${awsConfig.launchTemplateName}${awsConfig.launchTemplateVersion ? `,Version=${awsConfig.launchTemplateVersion}` : ''}`;
        }
        
        if (awsConfig.vpcZoneIdentifier) {
          createCommand += ` --vpc-zone-identifier "${awsConfig.vpcZoneIdentifier}"`;
        }
        
        createCommand += ` --region ${region}`;
        
        await execAsync(createCommand);
      }
      
      // Configurar políticas de escalado
      const cpuPolicyName = `${asgName}-cpu-policy`;
      
      // Política de escalado para CPU
      await execAsync(`aws autoscaling put-scaling-policy --auto-scaling-group-name ${asgName} --policy-name ${cpuPolicyName} --policy-type TargetTrackingScaling --target-tracking-configuration "{\\"PredefinedMetricSpecification\\":{\\"PredefinedMetricType\\":\\"ASGAverageCPUUtilization\\"},\\"TargetValue\\":${config.cpuThreshold || 70}}" --region ${region}`);
      
      // Si se especifica umbral de memoria, crear política para memoria
      if (config.memoryThreshold) {
        const memoryPolicyName = `${asgName}-memory-policy`;
        
        // Crear alarma de CloudWatch para memoria
        const alarmName = `${asgName}-high-memory-alarm`;
        
        await execAsync(`aws cloudwatch put-metric-alarm --alarm-name ${alarmName} --alarm-description "Alarm for high memory usage" --metric-name MemoryUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold ${config.memoryThreshold} --comparison-operator GreaterThanThreshold --dimensions "Name=AutoScalingGroupName,Value=${asgName}" --evaluation-periods 1 --alarm-actions ${awsConfig.scalingPolicyARN || `arn:aws:autoscaling:${region}:${awsConfig.accountId}:scalingPolicy:*:autoScalingGroupName/${asgName}:policyName/${memoryPolicyName}`} --region ${region}`);
        
        // Crear política de escalado simple para memoria
        await execAsync(`aws autoscaling put-scaling-policy --auto-scaling-group-name ${asgName} --policy-name ${memoryPolicyName} --scaling-adjustment 1 --adjustment-type ChangeInCapacity --cooldown 300 --region ${region}`);
      }
      
      return `Grupo de Auto Scaling ${asgName} configurado correctamente con políticas de escalado basadas en CPU${config.memoryThreshold ? ' y memoria' : ''}`;
    }
    
    private async setupECSAutoScaling(config: ScalingConfig): Promise<string> {
      const awsConfig = config.awsConfig;
      const region = awsConfig.region || 'us-east-1';
      
      // Verificar parámetros requeridos
      if (!awsConfig.clusterName || !awsConfig.serviceName) {
        throw new Error('Se requiere nombre de cluster y servicio ECS para configurar escalado automático');
      }
      
      const clusterName = awsConfig.clusterName;
      const serviceName = awsConfig.serviceName;
      
      // Registrar target para Application Auto Scaling
      try {
        await execAsync(`aws application-autoscaling register-scalable-target --service-namespace ecs --resource-id service/${clusterName}/${serviceName} --scalable-dimension ecs:service:DesiredCount --min-capacity ${config.minInstances || 1} --max-capacity ${config.maxInstances || 10} --region ${region}`);
      } catch (error) {
        this.logger.debug(`Error al registrar target: ${error.message}. Intentando actualizar target existente...`);
        
        // Actualizar target existente
        await execAsync(`aws application-autoscaling register-scalable-target --service-namespace ecs --resource-id service/${clusterName}/${serviceName} --scalable-dimension ecs:service:DesiredCount --min-capacity ${config.minInstances || 1} --max-capacity ${config.maxInstances || 10} --region ${region}`);
      }
      
      // Configurar política de escalado para CPU
      const cpuPolicyName = `${serviceName}-cpu-policy`;
      
      await execAsync(`aws application-autoscaling put-scaling-policy --service-namespace ecs --resource-id service/${clusterName}/${serviceName} --scalable-dimension ecs:service:DesiredCount --policy-name ${cpuPolicyName} --policy-type TargetTrackingScaling --target-tracking-scaling-policy-configuration "{\\"PredefinedMetricSpecification\\":{\\"PredefinedMetricType\\":\\"ECSServiceAverageCPUUtilization\\"},\\"TargetValue\\":${config.cpuThreshold || 70},\\"ScaleInCooldown\\":300,\\"ScaleOutCooldown\\":300}" --region ${region}`);
      
      // Si se especifica umbral de memoria, crear política para memoria
      if (config.memoryThreshold) {
        const memoryPolicyName = `${serviceName}-memory-policy`;
        
        await execAsync(`aws application-autoscaling put-scaling-policy --service-namespace ecs --resource-id service/${clusterName}/${serviceName} --scalable-dimension ecs:service:DesiredCount --policy-name ${memoryPolicyName} --policy-type TargetTrackingScaling --target-tracking-scaling-policy-configuration "{\\"PredefinedMetricSpecification\\":{\\"PredefinedMetricType\\":\\"ECSServiceAverageMemoryUtilization\\"},\\"TargetValue\\":${config.memoryThreshold},\\"ScaleInCooldown\\":300,\\"ScaleOutCooldown\\":300}" --region ${region}`);
      }
      
      return `Escalado automático configurado correctamente para el servicio ECS ${serviceName} en el cluster ${clusterName}`;
    }
    
    private async setupEKSAutoScaling(config: ScalingConfig): Promise<string> {
      const awsConfig = config.awsConfig;
      
      // Para EKS, utilizamos Kubernetes HPA
      if (!config.kubernetesConfig) {
        // Crear configuración de Kubernetes básica
        config.kubernetesConfig = {
          deploymentName: awsConfig.deploymentName || config.name,
          namespace: awsConfig.namespace || 'default',
          context: awsConfig.eksContext
        };
      }
      
      // Configurar kubectl para EKS
      if (awsConfig.clusterName) {
        await execAsync(`aws eks update-kubeconfig --name ${awsConfig.clusterName} --region ${awsConfig.region || 'us-east-1'}`);
      }
      
      // Usar la configuración de Kubernetes para HPA
      return await this.setupKubernetesScaling(config);
    }
    
    private async setupBeanstalkAutoScaling(config: ScalingConfig): Promise<string> {
      const awsConfig = config.awsConfig;
      const region = awsConfig.region || 'us-east-1';
      
      // Verificar parámetros requeridos
      if (!awsConfig.applicationName || !awsConfig.environmentName) {
        throw new Error('Se requiere nombre de aplicación y entorno Elastic Beanstalk para configurar escalado automático');
      }
      
      const applicationName = awsConfig.applicationName;
      const environmentName = awsConfig.environmentName;
      
      // Crear archivo de configuración para Auto Scaling
      const configPath = path.join(config.targetPath || process.cwd(), `${environmentName}-autoscaling.json`);
      
      const autoscalingConfig = {
        "AWSEBAutoScalingScaleDownPolicy.aws:autoscaling:trigger": {
          LowerBreachScaleIncrement: "-1"
        },
        "AWSEBAutoScalingScaleUpPolicy.aws:autoscaling:trigger": {
          UpperBreachScaleIncrement: "1"
        },
        "aws:autoscaling:asg": {
          MinSize: config.minInstances || 1,
          MaxSize: config.maxInstances || 10
        },
        "aws:autoscaling:trigger": {
          BreachDuration: 5,
          MeasureName: "CPUUtilization",
          Statistic: "Average",
          Unit: "Percent",
          UpperThreshold: config.cpuThreshold || 70,
          LowerThreshold: config.cpuLowerThreshold || 30,
          Period: 5
        }
      };
      
      // Si se especifica umbral de memoria, añadir configuración
      if (config.memoryThreshold) {
        autoscalingConfig["aws:autoscaling:trigger"] = {
          ...autoscalingConfig["aws:autoscaling:trigger"],
          MeasureName: "MemoryUtilization"
        };
      }
      
      fs.writeFileSync(configPath, JSON.stringify(autoscalingConfig, null, 2), 'utf8');
      
      // Aplicar configuración a Elastic Beanstalk
      await execAsync(`aws elasticbeanstalk update-environment --application-name ${applicationName} --environment-name ${environmentName} --option-settings file://${configPath} --region ${region}`);
      
      // Eliminar archivo temporal
      fs.unlinkSync(configPath);
      
      return `Escalado automático configurado correctamente para el entorno Elastic Beanstalk ${environmentName} de la aplicación ${applicationName}`;
    }
    
    private async setupGCPScaling(config: ScalingConfig): Promise<string> {
      this.logger.info('Configurando escalado automático con Google Cloud...');
      
      // Verificar credenciales de GCP
      try {
        await execAsync('gcloud auth list');
      } catch (error) {
        throw new Error('No se han configurado credenciales de GCP válidas. Configure gcloud CLI primero.');
      }
      
      // Verificar configuración de GCP
      if (!config.gcpConfig) {
        throw new Error('No se ha proporcionado configuración de GCP para escalado automático');
      }
      
      const gcpConfig = config.gcpConfig;
      
      // Verificar proyecto
      if (!gcpConfig.project) {
        throw new Error('No se ha proporcionado ID de proyecto GCP para escalado automático');
      }
      
      // Configurar proyecto
      await execAsync(`gcloud config set project ${gcpConfig.project}`);
      
      switch (gcpConfig.serviceType) {
        case 'gce':
          return await this.setupGCEAutoScaling(config);
        case 'gke':
          return await this.setupGKEAutoScaling(config);
        case 'appengine':
          return await this.setupAppEngineAutoScaling(config);
        case 'cloudrun':
          return await this.setupCloudRunAutoScaling(config);
        default:
          throw new Error(`Tipo de servicio GCP no soportado para escalado automático: ${gcpConfig.serviceType}`);
      }
    }
    
    private async setupGCEAutoScaling(config: ScalingConfig): Promise<string> {
      const gcpConfig = config.gcpConfig;
      const project = gcpConfig.project;
      const region = gcpConfig.region || 'us-central1';
      
      // Verificar parámetros requeridos
      if (!gcpConfig.instanceGroupName) {
        throw new Error('Se requiere nombre de grupo de instancias para configurar escalado automático en GCE');
      }
      
      const instanceGroupName = gcpConfig.instanceGroupName;
      
      // Verificar si ya existe un autoscaler
      try {
        await execAsync(`gcloud compute instance-groups managed describe ${instanceGroupName} --region=${region} --project=${project}`);
      } catch (error) {
        throw new Error(`El grupo de instancias ${instanceGroupName} no existe en la región ${region}`);
      }
      
      // Configurar autoscaler
      let autoscalerCommand = `gcloud compute instance-groups managed set-autoscaling ${instanceGroupName} --region=${region} --project=${project} --min-num-replicas=${config.minInstances || 1} --max-num-replicas=${config.maxInstances || 10} --target-cpu-utilization=${(config.cpuThreshold || 70) / 100}`;
      
      // Si se especifica umbral de memoria, añadir configuración
      if (config.memoryThreshold) {
        // Para memoria en GCE, necesitamos crear una política de escalado personalizada
        // Esto requiere configuración adicional que no se puede hacer directamente con gcloud
        this.logger.warn('El escalado basado en memoria para GCE requiere configuración adicional en la consola de Google Cloud');
      }
      
      // Si se especifica cooldown, añadir configuración
      if (config.cooldownPeriod) {
        autoscalerCommand += ` --cool-down-period=${config.cooldownPeriod}`;
      }
      
      await execAsync(autoscalerCommand);
      
      return `Escalado automático configurado correctamente para el grupo de instancias ${instanceGroupName} en la región ${region}`;
    }
    
    private async setupGKEAutoScaling(config: ScalingConfig): Promise<string> {
      const gcpConfig = config.gcpConfig;
      const project = gcpConfig.project;
      
      // Para GKE, utilizamos Kubernetes HPA
      if (!config.kubernetesConfig) {
        // Crear configuración de Kubernetes básica
        config.kubernetesConfig = {
          deploymentName: gcpConfig.deploymentName || config.name,
          namespace: gcpConfig.namespace || 'default'
        };
      }
      
      // Configurar kubectl para GKE
      if (gcpConfig.cluster) {
        await execAsync(`gcloud container clusters get-credentials ${gcpConfig.cluster} --region=${gcpConfig.region || 'us-central1'} --project=${project}`);
      }
      
      // Usar la configuración de Kubernetes para HPA
      return await this.setupKubernetesScaling(config);
    }
    
    private async setupAppEngineAutoScaling(config: ScalingConfig): Promise<string> {
      const gcpConfig = config.gcpConfig;
      const project = gcpConfig.project;
      
      // Verificar parámetros requeridos
      if (!gcpConfig.service) {
        throw new Error('Se requiere nombre de servicio App Engine para configurar escalado automático');
      }
      
      const service = gcpConfig.service;
      
      this.logger.info(`Configurando escalado automático para App Engine ${service}...`);
      
      // Crear archivo app.yaml con configuración de escalado
      const appYamlPath = path.join(config.targetPath || process.cwd(), `${service}-app.yaml`);
      
      // Configuración básica de App Engine
      let appYamlContent = `service: ${service}\nruntime: ${gcpConfig.runtime || 'nodejs16'}\n`;
      
      // Añadir configuración de escalado automático
      appYamlContent += `automatic_scaling:\n`;
      appYamlContent += `  min_instances: ${config.minInstances || 1}\n`;
      appYamlContent += `  max_instances: ${config.maxInstances || 10}\n`;
      
      // Configurar métricas de escalado
      if (config.cpuThreshold) {
        appYamlContent += `  cpu_utilization:\n`;
        appYamlContent += `    target_utilization: ${config.cpuThreshold / 100}\n`;
      }
      
      // Configurar cooldown si se especifica
      if (config.cooldownPeriod) {
        appYamlContent += `  min_pending_latency: ${config.cooldownPeriod}s\n`;
      }
      
      fs.writeFileSync(appYamlPath, appYamlContent, 'utf8');
      
      // Desplegar configuración
      if (gcpConfig.deploy) {
        await execAsync(`gcloud app deploy ${appYamlPath} --project=${project} --quiet`);
        
        // Eliminar archivo temporal
        fs.unlinkSync(appYamlPath);
        
        return `Escalado automático configurado y desplegado correctamente para el servicio App Engine ${service}`;
      } else {
        return `Configuración de escalado automático generada en ${appYamlPath}. Ejecute 'gcloud app deploy ${appYamlPath} --project=${project}' para aplicar.`;
      }
    }
    
    private async setupCloudRunAutoScaling(config: ScalingConfig): Promise<string> {
      const gcpConfig = config.gcpConfig;
      const project = gcpConfig.project;
      const region = gcpConfig.region || 'us-central1';
      
      // Verificar parámetros requeridos
      if (!gcpConfig.service) {
        throw new Error('Se requiere nombre de servicio Cloud Run para configurar escalado automático');
      }
      
      const service = gcpConfig.service;
      
      this.logger.info(`Configurando escalado automático para Cloud Run ${service}...`);
      
      // Actualizar configuración de servicio Cloud Run
      let updateCommand = `gcloud run services update ${service} --project=${project} --region=${region}`;
      
      // Configurar límites de instancias
      updateCommand += ` --min-instances=${config.minInstances || 0} --max-instances=${config.maxInstances || 100}`;
      
      // Configurar concurrencia si se especifica
      if (gcpConfig.concurrency) {
        updateCommand += ` --concurrency=${gcpConfig.concurrency}`;
      }
      
      // Configurar tiempo de CPU si se especifica
      if (gcpConfig.cpuThrottling === false) {
        updateCommand += ` --no-cpu-throttling`;
      }
      
      // Ejecutar comando
      await execAsync(updateCommand);
      
      return `Escalado automático configurado correctamente para el servicio Cloud Run ${service} en la región ${region}`;
    }
    
    private async setupAzureScaling(config: ScalingConfig): Promise<string> {
      this.logger.info('Configurando escalado automático con Azure...');
      
      // Verificar credenciales de Azure
      try {
        await execAsync('az account show');
      } catch (error) {
        throw new Error('No se han configurado credenciales de Azure válidas. Configure Azure CLI primero.');
      }
      
      // Verificar configuración de Azure
      if (!config.azureConfig) {
        throw new Error('No se ha proporcionado configuración de Azure para escalado automático');
      }
      
      const azureConfig = config.azureConfig;
      
      // Verificar grupo de recursos
      if (!azureConfig.resourceGroup) {
        throw new Error('No se ha proporcionado grupo de recursos para escalado automático en Azure');
      }
      
      switch (azureConfig.serviceType) {
        case 'appservice':
          return await this.setupAppServiceAutoScaling(config);
        case 'vmss':
          return await this.setupVMSSAutoScaling(config);
        case 'aks':
          return await this.setupAKSAutoScaling(config);
        case 'functions':
          return await this.setupFunctionsAutoScaling(config);
        default:
          throw new Error(`Tipo de servicio Azure no soportado para escalado automático: ${azureConfig.serviceType}`);
      }
    }
    
    private async setupAppServiceAutoScaling(config: ScalingConfig): Promise<string> {
      const azureConfig = config.azureConfig;
      const resourceGroup = azureConfig.resourceGroup;
      
      // Verificar parámetros requeridos
      if (!azureConfig.appName) {
        throw new Error('Se requiere nombre de App Service para configurar escalado automático');
      }
      
      const appName = azureConfig.appName;
      
      this.logger.info(`Configurando escalado automático para App Service ${appName}...`);
      
      // Configurar plan de App Service para escalado automático
      await execAsync(`az appservice plan update --resource-group ${resourceGroup} --name ${azureConfig.planName || appName + '-plan'} --sku ${azureConfig.sku || 'P1V2'} --number-of-workers ${config.minInstances || 1}`);
      
      // Crear reglas de escalado automático
      const autoScaleSettingName = `${appName}-autoscale`;
      
      // Crear configuración básica de escalado automático
      await execAsync(`az monitor autoscale create --resource-group ${resourceGroup} --resource ${azureConfig.planName || appName + '-plan'} --resource-type Microsoft.Web/serverfarms --name ${autoScaleSettingName} --min-count ${config.minInstances || 1} --max-count ${config.maxInstances || 10} --count ${config.minInstances || 1}`);
      
      // Añadir regla de escalado para CPU
      await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Percentage CPU > ${config.cpuThreshold || 70} avg 5m" --scale out 1`);
      
      // Añadir regla de reducción para CPU
      await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Percentage CPU < ${config.cpuLowerThreshold || 30} avg 5m" --scale in 1`);
      
      // Si se especifica umbral de memoria, añadir reglas para memoria
      if (config.memoryThreshold) {
        await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Memory Percentage > ${config.memoryThreshold} avg 5m" --scale out 1`);
        
        if (config.memoryLowerThreshold) {
          await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Memory Percentage < ${config.memoryLowerThreshold} avg 5m" --scale in 1`);
        }
      }
      
      return `Escalado automático configurado correctamente para App Service ${appName} en el grupo de recursos ${resourceGroup}`;
    }
    
    private async setupVMSSAutoScaling(config: ScalingConfig): Promise<string> {
      const azureConfig = config.azureConfig;
      const resourceGroup = azureConfig.resourceGroup;
      
      // Verificar parámetros requeridos
      if (!azureConfig.vmssName) {
        throw new Error('Se requiere nombre de Virtual Machine Scale Set para configurar escalado automático');
      }
      
      const vmssName = azureConfig.vmssName;
      
      this.logger.info(`Configurando escalado automático para VMSS ${vmssName}...`);
      
      // Configurar capacidad de VMSS
      await execAsync(`az vmss update --resource-group ${resourceGroup} --name ${vmssName} --set sku.capacity=${config.minInstances || 1}`);
      
      // Crear configuración de escalado automático
      const autoScaleSettingName = `${vmssName}-autoscale`;
      
      // Crear configuración básica de escalado automático
      await execAsync(`az monitor autoscale create --resource-group ${resourceGroup} --resource ${vmssName} --resource-type Microsoft.Compute/virtualMachineScaleSets --name ${autoScaleSettingName} --min-count ${config.minInstances || 1} --max-count ${config.maxInstances || 10} --count ${config.minInstances || 1}`);
      
      // Añadir regla de escalado para CPU
      await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Percentage CPU > ${config.cpuThreshold || 70} avg 5m" --scale out 1`);
      
      // Añadir regla de reducción para CPU
      await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Percentage CPU < ${config.cpuLowerThreshold || 30} avg 5m" --scale in 1`);
      
      // Si se especifica umbral de memoria, añadir reglas para memoria
      if (config.memoryThreshold) {
        await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Available Memory Bytes < ${azureConfig.memoryThresholdBytes || 1073741824} avg 5m" --scale out 1`);
        
        if (config.memoryLowerThreshold && azureConfig.memoryLowerThresholdBytes) {
          await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Available Memory Bytes > ${azureConfig.memoryLowerThresholdBytes} avg 5m" --scale in 1`);
        }
      }
      
      return `Escalado automático configurado correctamente para VMSS ${vmssName} en el grupo de recursos ${resourceGroup}`;
    }
    
    private async setupAKSAutoScaling(config: ScalingConfig): Promise<string> {
      const azureConfig = config.azureConfig;
      
      // Para AKS, utilizamos Kubernetes HPA
      if (!config.kubernetesConfig) {
        // Crear configuración de Kubernetes básica
        config.kubernetesConfig = {
          deploymentName: azureConfig.deploymentName || config.name,
          namespace: azureConfig.namespace || 'default'
        };
      }
      
      // Configurar kubectl para AKS
      if (azureConfig.clusterName) {
        await execAsync(`az aks get-credentials --resource-group ${azureConfig.resourceGroup} --name ${azureConfig.clusterName}`);
      }
      
      // Usar la configuración de Kubernetes para HPA
      return await this.setupKubernetesScaling(config);
    }
    
    private async setupFunctionsAutoScaling(config: ScalingConfig): Promise<string> {
      const azureConfig = config.azureConfig;
      const resourceGroup = azureConfig.resourceGroup;
      
      // Verificar parámetros requeridos
      if (!azureConfig.functionAppName) {
        throw new Error('Se requiere nombre de Function App para configurar escalado automático');
      }
      
      const functionAppName = azureConfig.functionAppName;
      
      this.logger.info(`Configurando escalado automático para Function App ${functionAppName}...`);
      
      // Configurar plan de consumo o premium
      if (azureConfig.planType === 'premium') {
        // Para plan premium, configurar escalado automático similar a App Service
        const planName = azureConfig.planName || `${functionAppName}-plan`;
        
        // Actualizar plan a premium si no lo es
        await execAsync(`az functionapp plan update --resource-group ${resourceGroup} --name ${planName} --sku EP1 --min-instances ${config.minInstances || 1} --max-burst ${config.maxInstances || 10}`);
        
        // Crear configuración de escalado automático
        const autoScaleSettingName = `${functionAppName}-autoscale`;
        
        // Crear configuración básica de escalado automático
        await execAsync(`az monitor autoscale create --resource-group ${resourceGroup} --resource ${planName} --resource-type Microsoft.Web/serverfarms --name ${autoScaleSettingName} --min-count ${config.minInstances || 1} --max-count ${config.maxInstances || 10} --count ${config.minInstances || 1}`);
        
        // Añadir regla de escalado para CPU
        await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Percentage CPU > ${config.cpuThreshold || 70} avg 5m" --scale out 1`);
        
        // Añadir regla de reducción para CPU
        await execAsync(`az monitor autoscale rule create --resource-group ${resourceGroup} --autoscale-name ${autoScaleSettingName} --condition "Percentage CPU < ${config.cpuLowerThreshold || 30} avg 5m" --scale in 1`);
        
        return `Escalado automático configurado correctamente para Function App ${functionAppName} en plan premium`;
      } else {
        // Para plan de consumo, configurar límites de escalado
        await execAsync(`az functionapp config appsettings set --resource-group ${resourceGroup} --name ${functionAppName} --settings WEBSITE_MAX_DYNAMIC_APPLICATION_SCALE_OUT=${config.maxInstances || 10}`);
        
        return `Límite de escalado configurado correctamente para Function App ${functionAppName} en plan de consumo`;
      }
    }
    
    private async setupCustomScaling(config: ScalingConfig): Promise<string> {
      this.logger.info('Configurando escalado automático personalizado...');
      
      // Verificar configuración personalizada
      if (!config.customConfig) {
        throw new Error('No se ha proporcionado configuración personalizada para escalado automático');
      }
      
      const customConfig = config.customConfig;
      
      // Verificar script personalizado
      if (!customConfig.scriptPath && !customConfig.commands) {
        throw new Error('Se requiere ruta de script o comandos para configuración personalizada de escalado automático');
      }
      
      // Ejecutar script personalizado si se proporciona
      if (customConfig.scriptPath) {
        const scriptPath = path.resolve(customConfig.scriptPath);
        
        // Verificar si el script existe
        if (!fs.existsSync(scriptPath)) {
          throw new Error(`El script personalizado no existe en la ruta: ${scriptPath}`);
        }
        
        // Ejecutar script
        const scriptArgs = customConfig.scriptArgs || [];
        const scriptEnv = {
          ...process.env,
          SCALING_MIN_INSTANCES: String(config.minInstances || 1),
          SCALING_MAX_INSTANCES: String(config.maxInstances || 10),
          SCALING_CPU_THRESHOLD: String(config.cpuThreshold || 70),
          SCALING_MEMORY_THRESHOLD: config.memoryThreshold ? String(config.memoryThreshold) : '',
          SCALING_NAME: config.name,
          SCALING_TARGET_PATH: config.targetPath || process.cwd(),
          ...customConfig.env
        };
        
        this.logger.debug(`Ejecutando script personalizado: ${scriptPath} ${scriptArgs.join(' ')}`);
        
        const { stdout } = await execAsync(`"${scriptPath}" ${scriptArgs.join(' ')}`, { env: scriptEnv });
        
        return `Escalado automático personalizado configurado correctamente: ${stdout}`;
      }
      
      // Ejecutar comandos personalizados si se proporcionan
      if (customConfig.commands && customConfig.commands.length > 0) {
        const results = [];
        
        for (const command of customConfig.commands) {
          // Reemplazar variables en el comando
          const processedCommand = command
            .replace('${MIN_INSTANCES}', String(config.minInstances || 1))
            .replace('${MAX_INSTANCES}', String(config.maxInstances || 10))
            .replace('${CPU_THRESHOLD}', String(config.cpuThreshold || 70))
            .replace('${MEMORY_THRESHOLD}', config.memoryThreshold ? String(config.memoryThreshold) : '')
            .replace('${NAME}', config.name)
            .replace('${TARGET_PATH}', config.targetPath || process.cwd());
          
          this.logger.debug(`Ejecutando comando personalizado: ${processedCommand}`);
          
          const { stdout } = await execAsync(processedCommand, { env: { ...process.env, ...customConfig.env } });
          results.push(stdout);
        }
        
        return `Escalado automático personalizado configurado correctamente: ${results.join('\n')}`;
      }
      
      return 'Configuración de escalado automático personalizado completada';
    }
    
    /**
     * Configura un sistema de monitoreo para un despliegue
     * @param config Configuración de monitoreo
     * @returns Mensaje de confirmación
     */
    public async setupMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info(`Configurando monitoreo para ${config.name}`);
      
      try {
        // Verificar si ya existe configuración de monitoreo
        if (this.monitoringConfigs.has(config.name)) {
          this.logger.debug(`Actualizando configuración de monitoreo existente para ${config.name}`);
          // Actualizar configuración existente
          const existingConfig = this.monitoringConfigs.get(config.name);
          this.monitoringConfigs.set(config.name, { ...existingConfig, ...config });
        } else {
          // Crear nueva configuración
          this.monitoringConfigs.set(config.name, config);
        }
        
        // Configurar monitoreo según el tipo
        let setupOutput = '';
        
        switch (config.type) {
          case 'prometheus':
            setupOutput = await this.setupPrometheusMonitoring(config);
            break;
          case 'cloudwatch':
            setupOutput = await this.setupCloudWatchMonitoring(config);
            break;
          case 'stackdriver':
            setupOutput = await this.setupStackdriverMonitoring(config);
            break;
          case 'azure':
            setupOutput = await this.setupAzureMonitoring(config);
            break;
          case 'custom':
            setupOutput = await this.setupCustomMonitoring(config);
            break;
          default:
            throw new Error(`Tipo de monitoreo no soportado: ${config.type}`);
        }
        
        return `Monitoreo configurado correctamente para ${config.name}: ${setupOutput}`;
      } catch (error) {
        this.logger.error(`Error al configurar monitoreo: ${error.message}`);
        throw error;
      }
    }
    
    private async setupPrometheusMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo con Prometheus...');
      
      // Verificar configuración de Prometheus
      if (!config.prometheusConfig) {
        throw new Error('No se ha proporcionado configuración de Prometheus para monitoreo');
      }
      
      const prometheusConfig = config.prometheusConfig;
      const targetPath = config.targetPath || process.cwd();
      
      // Crear directorio de configuración si no existe
      const configDir = path.join(targetPath, 'prometheus');
      if (!fs.existsSync(configDir)) {
        fs.mkdirSync(configDir, { recursive: true });
      }
      
      // Crear archivo de configuración de Prometheus
      const prometheusYamlPath = path.join(configDir, 'prometheus.yml');
      
      // Configuración básica de Prometheus
      let prometheusYaml = `
global:
  scrape_interval: ${prometheusConfig.scrapeInterval || '15s'}
  evaluation_interval: ${prometheusConfig.evaluationInterval || '15s'}

scrape_configs:
  - job_name: '${config.name}'
    static_configs:
      - targets: [${prometheusConfig.targets ? prometheusConfig.targets.map(t => `'${t}'`).join(', ') : "'localhost:9090'"}]
`;
      
      // Añadir configuraciones adicionales si se proporcionan
      if (prometheusConfig.additionalScrapeConfigs && prometheusConfig.additionalScrapeConfigs.length > 0) {
        for (const scrapeConfig of prometheusConfig.additionalScrapeConfigs) {
          prometheusYaml += `
  - job_name: '${scrapeConfig.jobName}'
    static_configs:
      - targets: [${scrapeConfig.targets.map(t => `'${t}'`).join(', ')}]
`;
        }
      }
      
      fs.writeFileSync(prometheusYamlPath, prometheusYaml, 'utf8');
      
      // Crear archivo docker-compose para Prometheus y Grafana si se solicita
      if (prometheusConfig.deployWithDocker) {
        const dockerComposePath = path.join(configDir, 'docker-compose.yml');
        
        let dockerComposeYaml = `
version: '3'
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - ${prometheusConfig.prometheusPort || '9090'}:9090
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
`;
        
        // Añadir Grafana si se solicita
        if (prometheusConfig.includeGrafana) {
          dockerComposeYaml += `
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - ${prometheusConfig.grafanaPort || '3000'}:3000
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus

volumes:
  grafana-data:
`;
        }
        
        fs.writeFileSync(dockerComposePath, dockerComposeYaml, 'utf8');
        
        // Iniciar contenedores si se solicita
        if (prometheusConfig.startContainers) {
          await execAsync(`docker-compose -f ${dockerComposePath} up -d`);
          
          this.logger.debug('Contenedores de Prometheus y Grafana iniciados correctamente');
        }
      }
      
      // Crear dashboards de Grafana si se solicita
      if (prometheusConfig.includeGrafana && prometheusConfig.grafanaDashboards && prometheusConfig.grafanaDashboards.length > 0) {
        const dashboardsDir = path.join(configDir, 'grafana', 'dashboards');
        if (!fs.existsSync(dashboardsDir)) {
          fs.mkdirSync(dashboardsDir, { recursive: true });
        }
        
        for (const dashboard of prometheusConfig.grafanaDashboards) {
          if (dashboard.json) {
            const dashboardPath = path.join(dashboardsDir, `${dashboard.name}.json`);
            fs.writeFileSync(dashboardPath, JSON.stringify(dashboard.json, null, 2), 'utf8');
          }
        }
        
        this.logger.debug(`Dashboards de Grafana generados en ${dashboardsDir}`);
      }
      
      return `Monitoreo con Prometheus configurado correctamente. Archivos de configuración generados en ${configDir}`;
    }
    
    private async setupCloudWatchMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo con AWS CloudWatch...');
      
      // Verificar credenciales de AWS
      try {
        await execAsync('aws sts get-caller-identity');
      } catch (error) {
        throw new Error('No se han configurado credenciales de AWS válidas. Configure AWS CLI primero.');
      }
      
      // Verificar configuración de CloudWatch
      if (!config.cloudwatchConfig) {
        throw new Error('No se ha proporcionado configuración de CloudWatch para monitoreo');
      }
      
      const cloudwatchConfig = config.cloudwatchConfig;
      const region = cloudwatchConfig.region || 'us-east-1';
      
      // Configurar región
      await execAsync(`aws configure set region ${region}`);
      
      // Crear grupo de logs si no existe
      const logGroupName = cloudwatchConfig.logGroupName || `/cjdevmind/${config.name}`;
      
      try {
        await execAsync(`aws logs describe-log-groups --log-group-name-prefix ${logGroupName} --region ${region}`);
      } catch (error) {
        // Crear grupo de logs si no existe
        await execAsync(`aws logs create-log-group --log-group-name ${logGroupName} --region ${region}`);
        
        // Configurar retención de logs si se especifica
        if (cloudwatchConfig.logRetentionDays) {
          await execAsync(`aws logs put-retention-policy --log-group-name ${logGroupName} --retention-in-days ${cloudwatchConfig.logRetentionDays} --region ${region}`);
        }
      }
      
      // Crear alarmas de CloudWatch si se especifican
      if (cloudwatchConfig.alarms && cloudwatchConfig.alarms.length > 0) {
        for (const alarm of cloudwatchConfig.alarms) {
          const alarmName = alarm.name || `${config.name}-${alarm.metric}-alarm`;
          
          // Crear comando de alarma
          let alarmCommand = `aws cloudwatch put-metric-alarm --alarm-name ${alarmName} --alarm-description "${alarm.description || `Alarm for ${alarm.metric}`}" --metric-name ${alarm.metric} --namespace ${alarm.namespace || 'AWS/EC2'} --statistic ${alarm.statistic || 'Average'} --period ${alarm.period || 300} --threshold ${alarm.threshold} --comparison-operator ${alarm.comparisonOperator || 'GreaterThanThreshold'} --evaluation-periods ${alarm.evaluationPeriods || 1}`;
          
          // Añadir dimensiones si se especifican
          if (alarm.dimensions && alarm.dimensions.length > 0) {
            const dimensionsJson = JSON.stringify(alarm.dimensions.map(d => ({ Name: d.name, Value: d.value })));
            alarmCommand += ` --dimensions '${dimensionsJson}'`;
          }
          
          // Añadir acciones de alarma si se especifican
          if (alarm.alarmActions && alarm.alarmActions.length > 0) {
            alarmCommand += ` --alarm-actions ${alarm.alarmActions.join(' ')}`;
          }
          
          // Añadir acciones de OK si se especifican
          if (alarm.okActions && alarm.okActions.length > 0) {
            alarmCommand += ` --ok-actions ${alarm.okActions.join(' ')}`;
          }
          
          alarmCommand += ` --region ${region}`;
          
          // Crear alarma
          await execAsync(alarmCommand);
          
          this.logger.debug(`Alarma CloudWatch ${alarmName} creada correctamente`);
        }
      }
      
      // Crear dashboards de CloudWatch si se especifican
      if (cloudwatchConfig.dashboards && cloudwatchConfig.dashboards.length > 0) {
        for (const dashboard of cloudwatchConfig.dashboards) {
          await this.setupCloudWatchDashboard(config, dashboard);
        }
      }
      
      return `Monitoreo con CloudWatch configurado correctamente. Grupo de logs: ${logGroupName}, Región: ${region}`;
    }
    
    private async setupStackdriverMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo con Google Cloud Monitoring (Stackdriver)...');
      
      // Verificar credenciales de GCP
      try {
        await execAsync('gcloud auth list');
      } catch (error) {
        throw new Error('No se han configurado credenciales de GCP válidas. Configure gcloud CLI primero.');
      }
      
      // Verificar configuración de Stackdriver
      if (!config.stackdriverConfig) {
        throw new Error('No se ha proporcionado configuración de Stackdriver para monitoreo');
      }
      
      const stackdriverConfig = config.stackdriverConfig;
      
      // Verificar proyecto
      if (!stackdriverConfig.projectId) {
        throw new Error('No se ha proporcionado ID de proyecto GCP para monitoreo');
      }
      
      const projectId = stackdriverConfig.projectId;
      
      // Configurar proyecto
      await execAsync(`gcloud config set project ${projectId}`);
      
      // Habilitar API de Monitoring si se solicita
      if (stackdriverConfig.enableApi) {
        await execAsync('gcloud services enable monitoring.googleapis.com');
      }
      
      // Crear políticas de alertas si se especifican
      if (stackdriverConfig.alertPolicies && stackdriverConfig.alertPolicies.length > 0) {
        for (const policy of stackdriverConfig.alertPolicies) {
          // Crear archivo de configuración de política
          const policyPath = path.join(config.targetPath || process.cwd(), `${policy.name}-policy.json`);
          
          // Crear JSON de política de alerta
          const policyJson = {
            displayName: policy.displayName || policy.name,
            documentation: {
              content: policy.description || `Política de alerta para ${config.name}`,
              mimeType: 'text/markdown'
            },
            conditions: policy.conditions.map(condition => ({
              displayName: condition.displayName || `Condición para ${condition.metric}`,
              conditionThreshold: {
                filter: condition.filter || `resource.type = "${condition.resourceType || 'gce_instance'}" AND metric.type = "${condition.metric}"`,
                aggregations: condition.aggregations || [{
                  alignmentPeriod: condition.alignmentPeriod || '60s',
                  perSeriesAligner: condition.perSeriesAligner || 'ALIGN_MEAN'
                }],
                comparison: condition.comparison || 'COMPARISON_GT',
                duration: condition.duration || '60s',
                trigger: {
                  count: condition.triggerCount || 1
                },
                thresholdValue: condition.threshold
              }
            })),
            alertStrategy: {
              autoClose: policy.autoCloseDuration || '86400s',
              notificationRateLimit: policy.notificationRateLimit ? {
                period: policy.notificationRateLimit
              } : undefined
            },
            notificationChannels: policy.notificationChannels || []
          };
          
          fs.writeFileSync(policyPath, JSON.stringify(policyJson, null, 2), 'utf8');
          
          // Crear política de alerta
          await execAsync(`gcloud alpha monitoring policies create --policy-from-file=${policyPath} --project=${projectId}`);
          
          // Eliminar archivo temporal
          fs.unlinkSync(policyPath);
          
          this.logger.debug(`Política de alerta ${policy.name} creada correctamente`);
        }
      }
      
      // Crear dashboards si se especifican
      if (stackdriverConfig.dashboards && stackdriverConfig.dashboards.length > 0) {
        for (const dashboard of stackdriverConfig.dashboards) {
          // Crear archivo de configuración de dashboard
          const dashboardPath = path.join(config.targetPath || process.cwd(), `${dashboard.name}-dashboard.json`);
          
          // Crear JSON de dashboard
          const dashboardJson = {
            displayName: dashboard.displayName || dashboard.name,
            gridLayout: {
              columns: dashboard.columns || 2,
              widgets: dashboard.widgets.map(widget => ({
                title: widget.title,
                xyChart: {
                  dataSets: widget.metrics.map(metric => ({
                    timeSeriesQuery: {
                      timeSeriesFilter: {
                        filter: widget.filter || `resource.type = "${widget.resourceType || 'gce_instance'}" AND metric.type = "${metric}"`,
                        aggregation: {
                          perSeriesAligner: widget.perSeriesAligner || 'ALIGN_MEAN',
                          alignmentPeriod: widget.alignmentPeriod || '60s'
                        }
                      }
                    },
                    plotType: widget.plotType || 'LINE'
                  }))
                }
              }))
            }
          };
          
          fs.writeFileSync(dashboardPath, JSON.stringify(dashboardJson, null, 2), 'utf8');
          
          // Crear dashboard
          await execAsync(`gcloud monitoring dashboards create --config-from-file=${dashboardPath} --project=${projectId}`);
          
          // Eliminar archivo temporal
          fs.unlinkSync(dashboardPath);
          
          this.logger.debug(`Dashboard ${dashboard.name} creado correctamente`);
        }
      }
      
      return `Monitoreo con Stackdriver configurado correctamente para el proyecto ${projectId}`;
    }
    
    private async setupAzureMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo con Azure Monitor...');
      
      // Verificar credenciales de Azure
      try {
        await execAsync('az account show');
      } catch (error) {
        throw new Error('No se han configurado credenciales de Azure válidas. Configure Azure CLI primero.');
      }
      
      // Verificar configuración de Azure Monitor
      if (!config.azureMonitorConfig) {
        throw new Error('No se ha proporcionado configuración de Azure Monitor para monitoreo');
      }
      
      const azureConfig = config.azureMonitorConfig;
      
      // Verificar grupo de recursos
      if (!azureConfig.resourceGroup) {
        throw new Error('No se ha proporcionado grupo de recursos para monitoreo en Azure');
      }
      
      const resourceGroup = azureConfig.resourceGroup;
      
      // Crear grupo de acción si se especifica
      let actionGroupId = azureConfig.actionGroupId;
      
      if (!actionGroupId && azureConfig.createActionGroup) {
        const actionGroupName = azureConfig.actionGroupName || `${config.name}-action-group`;
        
        // Crear grupo de acción
        await execAsync(`az monitor action-group create --resource-group ${resourceGroup} --name ${actionGroupName} --short-name ${azureConfig.actionGroupShortName || 'CJDevMind'}`);
        
        // Añadir receptores de correo si se especifican
        if (azureConfig.emailReceivers && azureConfig.emailReceivers.length > 0) {
          for (const receiver of azureConfig.emailReceivers) {
            await execAsync(`az monitor action-group email add --resource-group ${resourceGroup} --action-group ${actionGroupName} --name ${receiver.name} --email-address ${receiver.email}`);
          }
        }
        
        // Añadir receptores de webhook si se especifican
        if (azureConfig.webhookReceivers && azureConfig.webhookReceivers.length > 0) {
          for (const receiver of azureConfig.webhookReceivers) {
            await execAsync(`az monitor action-group webhook add --resource-group ${resourceGroup} --action-group ${actionGroupName} --name ${receiver.name} --uri ${receiver.uri}`);
          }
        }
        
        // Obtener ID del grupo de acción
        const { stdout } = await execAsync(`az monitor action-group show --resource-group ${resourceGroup} --name ${actionGroupName} --query id -o tsv`);
        actionGroupId = stdout.trim();
        
        this.logger.debug(`Grupo de acción ${actionGroupName} creado correctamente con ID: ${actionGroupId}`);
      }
      
      // Crear reglas de alerta si se especifican
      if (azureConfig.alertRules && azureConfig.alertRules.length > 0) {
        for (const rule of azureConfig.alertRules) {
          const ruleName = rule.name || `${config.name}-${rule.metric}-alert`;
          
          // Crear comando de regla de alerta
          let alertCommand = `az monitor metrics alert create --resource-group ${resourceGroup} --name ${ruleName}`;
          
          // Añadir recurso objetivo
          if (rule.resourceId) {
            alertCommand += ` --scopes ${rule.resourceId}`;
          } else if (rule.resourceName && rule.resourceType) {
            const { stdout } = await execAsync(`az resource show --resource-group ${resourceGroup} --name ${rule.resourceName} --resource-type ${rule.resourceType} --query id -o tsv`);
            alertCommand += ` --scopes ${stdout.trim()}`;
          } else {
            throw new Error(`Se requiere resourceId o resourceName+resourceType para la regla de alerta ${ruleName}`);
          }
          
          // Añadir condición
          alertCommand += ` --condition "avg ${rule.metric} ${rule.operator || '>'} ${rule.threshold} ${rule.timeAggregation || 'Average'} ${rule.windowSize || '5m'}"`;
          
          // Añadir grupo de acción si existe
          if (actionGroupId) {
            alertCommand += ` --action ${actionGroupId}`;
          }
          
          // Añadir descripción si se especifica
          if (rule.description) {
            alertCommand += ` --description "${rule.description}"`;
          }
          
          // Añadir severidad si se especifica
          if (rule.severity) {
            alertCommand += ` --severity ${rule.severity}`;
          }
          
          // Crear regla de alerta
          await execAsync(alertCommand);
          
          this.logger.debug(`Regla de alerta ${ruleName} creada correctamente`);
        }
      }
      
      // Configurar Application Insights si se especifica
      if (azureConfig.appInsights) {
        const appInsightsName = azureConfig.appInsights.name || `${config.name}-appinsights`;
        
        // Crear Application Insights si no existe
        try {
          await execAsync(`az monitor app-insights component show --resource-group ${resourceGroup} --app ${appInsightsName}`);
        } catch (error) {
          // Crear Application Insights
          await execAsync(`az monitor app-insights component create --resource-group ${resourceGroup} --app ${appInsightsName} --location ${azureConfig.appInsights.location || 'eastus'} --kind ${azureConfig.appInsights.kind || 'web'} --application-type ${azureConfig.appInsights.applicationType || 'web'}`);
          
          this.logger.debug(`Application Insights ${appInsightsName} creado correctamente`);
        }
        
        // Obtener clave de instrumentación
        const { stdout } = await execAsync(`az monitor app-insights component show --resource-group ${resourceGroup} --app ${appInsightsName} --query instrumentationKey -o tsv`);
        const instrumentationKey = stdout.trim();
        
        // Crear archivo de configuración para la aplicación
        if (azureConfig.appInsights.generateConfig) {
          const configPath = path.join(config.targetPath || process.cwd(), 'applicationinsights.config.js');
          
          const configContent = `
module.exports = {
  instrumentationKey: '${instrumentationKey}',
  connectionString: 'InstrumentationKey=${instrumentationKey}',
  disableAppInsights: false,
  enableAutoCollectConsole: true,
  enableAutoCollectExceptions: true,
  enableAutoCollectPerformance: true,
  enableAutoCollectRequests: true,
  enableAutoCollectDependencies: true,
  enableAutoCollectHeartbeat: true,
  enableUseDiskRetryCaching: true
};
`;
          
          fs.writeFileSync(configPath, configContent, 'utf8');
          
          this.logger.debug(`Archivo de configuración de Application Insights generado en ${configPath}`);
        }
        
        return `Monitoreo con Azure Monitor configurado correctamente. Application Insights: ${appInsightsName}, Clave de instrumentación: ${instrumentationKey}`;
      }
      
      return `Monitoreo con Azure Monitor configurado correctamente para el grupo de recursos ${resourceGroup}`;
    }
    
    private async setupCustomMonitoring(config: MonitoringConfig): Promise<string> {
      this.logger.info('Configurando monitoreo personalizado...');
      
      // Verificar configuración personalizada
      if (!config.customConfig) {
        throw new Error('No se ha proporcionado configuración personalizada para monitoreo');
      }
      
      const customConfig = config.customConfig;
      
      // Verificar script personalizado
      if (!customConfig.scriptPath && !customConfig.commands) {
        throw new Error('Se requiere ruta de script o comandos para configuración personalizada de monitoreo');
      }
      
      // Ejecutar script personalizado si se proporciona
      if (customConfig.scriptPath) {
        const scriptPath = path.resolve(customConfig.scriptPath);
        
        // Verificar si el script existe
        if (!fs.existsSync(scriptPath)) {
          throw new Error(`El script personalizado no existe en la ruta: ${scriptPath}`);
        }
        
        // Ejecutar script
        const scriptArgs = customConfig.scriptArgs || [];
        const scriptEnv = {
          ...process.env,
          MONITORING_NAME: config.name,
          MONITORING_TARGET_PATH: config.targetPath || process.cwd(),
          ...customConfig.env
        };
        
        this.logger.debug(`Ejecutando script personalizado: ${scriptPath} ${scriptArgs.join(' ')}`);
        
        const { stdout } = await execAsync(`"${scriptPath}" ${scriptArgs.join(' ')}`, { env: scriptEnv });
        
        return `Monitoreo personalizado configurado correctamente: ${stdout}`;
      }
      
      // Ejecutar comandos personalizados si se proporcionan
      if (customConfig.commands && customConfig.commands.length > 0) {
        const results = [];
        
        for (const command of customConfig.commands) {
          // Reemplazar variables en el comando
          const processedCommand = command
            .replace('${NAME}', config.name)
            .replace('${TARGET_PATH}', config.targetPath || process.cwd());
          
          this.logger.debug(`Ejecutando comando personalizado: ${processedCommand}`);
          
          const { stdout } = await execAsync(processedCommand, { env: { ...process.env, ...customConfig.env } });
          results.push(stdout);
        }
        
        return `Monitoreo personalizado configurado correctamente: ${results.join('\n')}`;
      }
      
      return 'Configuración de monitoreo personalizado completada';
    }
    
    private async setupCloudWatchDashboard(config: MonitoringConfig, dashboard: any): Promise<void> {
      const cloudwatchConfig = config.cloudwatchConfig;
      const region = cloudwatchConfig.region || 'us-east-1';
      
      // Crear archivo de configuración de dashboard
      const dashboardPath = path.join(config.targetPath || process.cwd(), `${dashboard.name}-dashboard.json`);
      
      // Crear JSON de dashboard
      const dashboardJson = {
        widgets: dashboard.widgets.map(widget => {
          const baseWidget = {
            type: widget.type || 'metric',
            x: widget.x || 0,
            y: widget.y || 0,
            width: widget.width || 6,
            height: widget.height || 6,
            properties: {
              title: widget.title,
              view: widget.view || 'timeSeries',
              stacked: widget.stacked || false,
              metrics: widget.metrics.map(metric => {
                if (Array.isArray(metric)) {
                  return metric;
                } else {
                  return [
                    metric.namespace || 'AWS/EC2',
                    metric.name,
                    ...(metric.dimensions ? Object.entries(metric.dimensions).flat() : [])
                  ];
                }
              }),
              region: region,
              period: widget.period || 300
            }
          };
          
          // Añadir propiedades específicas según el tipo de widget
          if (widget.type === 'text') {
            baseWidget.properties = {
              markdown: widget.markdown || `# ${widget.title}`
            };
          } else if (widget.type === 'alarm') {
            baseWidget.properties = {
              title: widget.title,
              alarms: widget.alarms
            };
          }
          
          return baseWidget;
        })
      };
      
      fs.writeFileSync(dashboardPath, JSON.stringify(dashboardJson, null, 2), 'utf8');
      
      // Crear dashboard
      await execAsync(`aws cloudwatch put-dashboard --dashboard-name ${dashboard.name} --dashboard-body file://${dashboardPath} --region ${region}`);
      
      // Eliminar archivo temporal
      fs.unlinkSync(dashboardPath);
      
      this.logger.debug(`Dashboard CloudWatch ${dashboard.name} creado correctamente`);
    }
    
    /**
     * Configura un pipeline de CI/CD para un proyecto
     * @param config Configuración del pipeline
     * @returns Mensaje de confirmación
     */
    public async setupCICDPipeline(config: any): Promise<string> {
      this.logger.info(`Configurando pipeline CI/CD para ${config.name}`);
      
      try {
        // Verificar si ya existe configuración de pipeline
        if (this.cicdPipelines.has(config.name)) {
          this.logger.debug(`Actualizando configuración de pipeline existente para ${config.name}`);
          // Actualizar configuración existente
          const existingConfig = this.cicdPipelines.get(config.name);
          this.cicdPipelines.set(config.name, { ...existingConfig, ...config });
        } else {
          // Crear nueva configuración
          this.cicdPipelines.set(config.name, config);
        }
        
        // Configurar pipeline según el tipo
        let setupOutput = '';
        
        switch (config.type) {
          case 'github':
            setupOutput = await this.setupGitHubActions(config);
            break;
          case 'gitlab':
            setupOutput = await this.setupGitLabCI(config);
            break;
          case 'jenkins':
            setupOutput = await this.setupJenkins(config);
            break;
          case 'azure-devops':
            setupOutput = await this.setupAzureDevOps(config);
            break;
          case 'aws-codepipeline':
            setupOutput = await this.setupAWSCodePipeline(config);
            break;
          case 'gcp-cloudbuild':
            setupOutput = await this.setupGCPCloudBuild(config);
            break;
          case 'custom':
            setupOutput = await this.setupCustomCICD(config);
            break;
          default:
            throw new Error(`Tipo de pipeline CI/CD no soportado: ${config.type}`);
        }
        
        return `Pipeline CI/CD configurado correctamente para ${config.name}: ${setupOutput}`;
      } catch (error) {
        this.logger.error(`Error al configurar pipeline CI/CD: ${error.message}`);
        throw error;
      }
    }
    
    private async setupGitHubActions(config: any): Promise<string> {
      this.logger.info('Configurando GitHub Actions...');
      
      // Verificar configuración de GitHub Actions
      if (!config.githubConfig) {
        throw new Error('No se ha proporcionado configuración de GitHub Actions para el pipeline CI/CD');
      }
      
      const githubConfig = config.githubConfig;
      const targetPath = config.targetPath || process.cwd();
      
      // Crear directorio de GitHub Actions si no existe
      const actionsDir = path.join(targetPath, '.github', 'workflows');
      if (!fs.existsSync(actionsDir)) {
        fs.mkdirSync(actionsDir, { recursive: true });
      }
      
      // Crear archivo de workflow
      const workflowName = githubConfig.workflowName || `${config.name}-workflow`;
      const workflowPath = path.join(actionsDir, `${workflowName}.yml`);
      
      // Generar contenido del workflow
      let workflowContent = `name: ${githubConfig.displayName || workflowName}\n\n`;
      
      // Configurar triggers
      workflowContent += 'on:\n';
      
      if (githubConfig.triggers) {
        if (githubConfig.triggers.push) {
          workflowContent += '  push:\n';
          if (githubConfig.triggers.push.branches) {
            workflowContent += '    branches:\n';
            for (const branch of githubConfig.triggers.push.branches) {
              workflowContent += `      - ${branch}\n`;
            }
          }
          if (githubConfig.triggers.push.tags) {
            workflowContent += '    tags:\n';
            for (const tag of githubConfig.triggers.push.tags) {
              workflowContent += `      - ${tag}\n`;
            }
          }
        }
        
        if (githubConfig.triggers.pullRequest) {
          workflowContent += '  pull_request:\n';
          if (githubConfig.triggers.pullRequest.branches) {
            workflowContent += '    branches:\n';
            for (const branch of githubConfig.triggers.pullRequest.branches) {
              workflowContent += `      - ${branch}\n`;
            }
          }
          if (githubConfig.triggers.pullRequest.types) {
            workflowContent += '    types:\n';
            for (const type of githubConfig.triggers.pullRequest.types) {
              workflowContent += `      - ${type}\n`;
            }
          }
        }
        
        if (githubConfig.triggers.schedule) {
          workflowContent += '  schedule:\n';
          for (const schedule of githubConfig.triggers.schedule) {
            workflowContent += `    - cron: '${schedule}'\n`;
          }
        }
        
        if (githubConfig.triggers.workflow_dispatch) {
          workflowContent += '  workflow_dispatch:\n';
        }
      } else {
        // Configuración por defecto
        workflowContent += '  push:\n';
        workflowContent += '    branches: [ main, master ]\n';
        workflowContent += '  pull_request:\n';
        workflowContent += '    branches: [ main, master ]\n';
      }
      
      // Configurar entorno
      workflowContent += '\nenv:\n';
      if (githubConfig.env) {
        for (const [key, value] of Object.entries(githubConfig.env)) {
          workflowContent += `  ${key}: ${value}\n`;
        }
      }
      
      // Configurar jobs
      workflowContent += '\njobs:\n';
      
      // Job de build
      workflowContent += '  build:\n';
      workflowContent += `    runs-on: ${githubConfig.runner || 'ubuntu-latest'}\n`;
      
      // Configurar estrategia de matriz si se especifica
      if (githubConfig.matrix) {
        workflowContent += '    strategy:\n';
        workflowContent += '      matrix:\n';
        for (const [key, values] of Object.entries(githubConfig.matrix)) {
          workflowContent += `        ${key}: ${JSON.stringify(values)}\n`;
        }
      }
      
      // Configurar pasos
      workflowContent += '    steps:\n';
      
      // Paso de checkout
      workflowContent += '    - name: Checkout code\n';
      workflowContent += '      uses: actions/checkout@v3\n';
      
      // Configurar pasos adicionales
      if (githubConfig.steps) {
        for (const step of githubConfig.steps) {
          workflowContent += `    - name: ${step.name}\n`;
          
          if (step.uses) {
            workflowContent += `      uses: ${step.uses}\n`;
          } else if (step.run) {
            workflowContent += `      run: ${step.run}\n`;
          }
          
          if (step.with) {
            workflowContent += '      with:\n';
            for (const [key, value] of Object.entries(step.with)) {
              workflowContent += `        ${key}: ${value}\n`;
            }
          }
          
          if (step.env) {
            workflowContent += '      env:\n';
            for (const [key, value] of Object.entries(step.env)) {
              workflowContent += `        ${key}: ${value}\n`;
            }
          }
        }
      } else {
        // Pasos por defecto según el tipo de proyecto
        if (githubConfig.projectType === 'node') {
          workflowContent += '    - name: Setup Node.js\n';
          workflowContent += '      uses: actions/setup-node@v3\n';
          workflowContent += '      with:\n';
          workflowContent += `        node-version: ${githubConfig.nodeVersion || '16'}\n`;
          workflowContent += '        cache: npm\n';
          
          workflowContent += '    - name: Install dependencies\n';
          workflowContent += '      run: npm ci\n';
          
          workflowContent += '    - name: Run tests\n';
          workflowContent += '      run: npm test\n';
          
          workflowContent += '    - name: Build\n';
          workflowContent += '      run: npm run build\n';
        } else if (githubConfig.projectType === 'python') {
          workflowContent += '    - name: Setup Python\n';
          workflowContent += '      uses: actions/setup-python@v4\n';
          workflowContent += '      with:\n';
          workflowContent += `        python-version: ${githubConfig.pythonVersion || '3.9'}\n`;
          
          workflowContent += '    - name: Install dependencies\n';
          workflowContent += '      run: |\n';
          workflowContent += '        python -m pip install --upgrade pip\n';
          workflowContent += '        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n';
          
          workflowContent += '    - name: Run tests\n';
          workflowContent += '      run: pytest\n';
        } else if (githubConfig.projectType === 'docker') {
          workflowContent += '    - name: Set up Docker Buildx\n';
          workflowContent += '      uses: docker/setup-buildx-action@v2\n';
          
          workflowContent += '    - name: Build and push Docker image\n';
          workflowContent += '      uses: docker/build-push-action@v4\n';
          workflowContent += '      with:\n';
          workflowContent += '        context: .\n';
          workflowContent += '        push: false\n';
          workflowContent += `        tags: ${githubConfig.dockerImage || config.name}:latest\n`;
        }
      }
      
      // Configurar job de despliegue si se especifica
      if (githubConfig.deploy) {
        workflowContent += '\n  deploy:\n';
        workflowContent += '    needs: build\n';
        workflowContent += `    runs-on: ${githubConfig.deployRunner || 'ubuntu-latest'}\n`;
        
        // Configurar entorno de despliegue si se especifica
        if (githubConfig.deployEnvironment) {
          workflowContent += `    environment: ${githubConfig.deployEnvironment}\n`;
        }
        
        // Configurar pasos de despliegue
        workflowContent += '    steps:\n';
        workflowContent += '    - name: Checkout code\n';
        workflowContent += '      uses: actions/checkout@v3\n';
        
        if (githubConfig.deploySteps) {
          for (const step of githubConfig.deploySteps) {
            workflowContent += `    - name: ${step.name}\n`;
            
            if (step.uses) {
              workflowContent += `      uses: ${step.uses}\n`;
            } else if (step.run) {
              workflowContent += `      run: ${step.run}\n`;
            }
            
            if (step.with) {
              workflowContent += '      with:\n';
              for (const [key, value] of Object.entries(step.with)) {
                workflowContent += `        ${key}: ${value}\n`;
              }
            }
            
            if (step.env) {
              workflowContent += '      env:\n';
              for (const [key, value] of Object.entries(step.env)) {
                workflowContent += `        ${key}: ${value}\n`;
              }
            }
          }
        } else {
          // Pasos de despliegue por defecto según el tipo de despliegue
          if (githubConfig.deployType === 'aws') {
            workflowContent += '    - name: Configure AWS credentials\n';
            workflowContent += '      uses: aws-actions/configure-aws-credentials@v1\n';
            workflowContent += '      with:\n';
            workflowContent += '        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
            workflowContent += '        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
            workflowContent += `        aws-region: ${githubConfig.awsRegion || 'us-east-1'}\n`;
            
            if (githubConfig.deployTarget === 's3') {
              workflowContent += '    - name: Deploy to S3\n';
              workflowContent += '      run: |\n';
              workflowContent += `        aws s3 sync ./build s3://${githubConfig.s3Bucket}/\n`;
            } else if (githubConfig.deployTarget === 'elasticbeanstalk') {
              workflowContent += '    - name: Generate deployment package\n';
              workflowContent += '      run: zip -r deploy.zip .\n';
              
              workflowContent += '    - name: Deploy to Elastic Beanstalk\n';
              workflowContent += '      run: |\n';
              workflowContent += `        aws elasticbeanstalk create-application-version --application-name ${githubConfig.ebApplication} --version-label ${{ github.sha }} --source-bundle S3Bucket="${githubConfig.s3Bucket}",S3Key="deploy.zip"\n`;
              workflowContent += `        aws elasticbeanstalk update-environment --application-name ${githubConfig.ebApplication} --environment-name ${githubConfig.ebEnvironment} --version-label ${{ github.sha }}\n`;
            }
          } else if (githubConfig.deployType === 'azure') {
            workflowContent += '    - name: Azure Login\n';
            workflowContent += '      uses: azure/login@v1\n';
            workflowContent += '      with:\n';
            workflowContent += '        creds: ${{ secrets.AZURE_CREDENTIALS }}\n';
            
            workflowContent += '    - name: Deploy to Azure Web App\n';
            workflowContent += '      uses: azure/webapps-deploy@v2\n';
            workflowContent += '      with:\n';
            workflowContent += `        app-name: ${githubConfig.azureWebApp}\n`;
            workflowContent += '        package: ./build\n';
          } else if (githubConfig.deployType === 'gcp') {
            workflowContent += '    - name: Google Auth\n';
            workflowContent += '      uses: google-github-actions/auth@v1\n';
            workflowContent += '      with:\n';
            workflowContent += '        credentials_json: ${{ secrets.GCP_SA_KEY }}\n';
            
            workflowContent += '    - name: Deploy to App Engine\n';
            workflowContent += '      uses: google-github-actions/deploy-appengine@v1\n';
            workflowContent += '      with:\n';
            workflowContent += `        project_id: ${githubConfig.gcpProjectId}\n`;
            workflowContent += '        deliverables: app.yaml\n';
          } else if (githubConfig.deployType === 'heroku') {
            workflowContent += '    - name: Deploy to Heroku\n';
            workflowContent += '      uses: akhileshns/heroku-deploy@v3\n';
            workflowContent += '      with:\n';
            workflowContent += '        heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n';
            workflowContent += `        heroku_app_name: ${githubConfig.herokuApp}\n`;
            workflowContent += `        heroku_email: ${githubConfig.herokuEmail || '${{ secrets.HEROKU_EMAIL }}'}\n`;
          }
        }
      }
      
      // Escribir archivo de workflow
      fs.writeFileSync(workflowPath, workflowContent, 'utf8');
      
      this.logger.debug(`Archivo de workflow GitHub Actions creado en: ${workflowPath}`);
      
      return `Pipeline CI/CD con GitHub Actions configurado correctamente: ${workflowPath}`;
    }
    
    private async setupGitLabCI(config: any): Promise<string> {
      this.logger.info('Configurando GitLab CI...');
      
      // Verificar configuración de GitLab CI
      if (!config.gitlabConfig) {
        throw new Error('No se ha proporcionado configuración de GitLab CI para el pipeline CI/CD');
      }
      
      const gitlabConfig = config.gitlabConfig;
      const targetPath = config.targetPath || process.cwd();
      
      // Crear archivo de configuración de GitLab CI
      const ciConfigPath = path.join(targetPath, '.gitlab-ci.yml');
      
      // Generar contenido del archivo de configuración
      let ciContent = '';
      
      // Configurar variables
      if (gitlabConfig.variables) {
        ciContent += 'variables:\n';
        for (const [key, value] of Object.entries(gitlabConfig.variables)) {
          ciContent += `  ${key}: ${value}\n`;
        }
        ciContent += '\n';
      }
      
      // Configurar stages
      const stages = gitlabConfig.stages || ['build', 'test', 'deploy'];
      ciContent += 'stages:\n';
      for (const stage of stages) {
        ciContent += `  - ${stage}\n`;
      }
      ciContent += '\n';
      
      // Configurar cache
      if (gitlabConfig.cache) {
        ciContent += 'cache:\n';
        if (gitlabConfig.cache.key) {
          ciContent += `  key: ${gitlabConfig.cache.key}\n`;
        }
        if (gitlabConfig.cache.paths) {
          ciContent += '  paths:\n';
          for (const path of gitlabConfig.cache.paths) {
            ciContent += `    - ${path}\n`;
          }
        }
        ciContent += '\n';
      }
      
      // Configurar jobs
      if (gitlabConfig.jobs) {
        for (const [jobName, job] of Object.entries(gitlabConfig.jobs)) {
          ciContent += `${jobName}:\n`;
          
          // Stage
          if (job.stage) {
            ciContent += `  stage: ${job.stage}\n`;
          }
          
          // Image
          if (job.image) {
            ciContent += `  image: ${job.image}\n`;
          }
          
          // Tags
          if (job.tags) {
            ciContent += '  tags:\n';
            for (const tag of job.tags) {
              ciContent += `    - ${tag}\n`;
            }
          }
          
          // Only
          if (job.only) {
            ciContent += '  only:\n';
            if (Array.isArray(job.only)) {
              for (const only of job.only) {
                ciContent += `    - ${only}\n`;
              }
            } else {
              for (const [key, value] of Object.entries(job.only)) {
                ciContent += `    ${key}:\n`;
                if (Array.isArray(value)) {
                  for (const item of value) {
                    ciContent += `      - ${item}\n`;
                  }
                } else {
                  ciContent += `      - ${value}\n`;
                }
              }
            }
          }
          
          // Except
          if (job.except) {
            ciContent += '  except:\n';
            if (Array.isArray(job.except)) {
              for (const except of job.except) {
                ciContent += `    - ${except}\n`;
              }
            } else {
              for (const [key, value] of Object.entries(job.except)) {
                ciContent += `    ${key}:\n`;
                if (Array.isArray(value)) {
                  for (const item of value) {
                    ciContent += `      - ${item}\n`;
                  }
                } else {
                  ciContent += `      - ${value}\n`;
                }
              }
            }
          }
          
          // Variables
          if (job.variables) {
            ciContent += '  variables:\n';
            for (const [key, value] of Object.entries(job.variables)) {
              ciContent += `    ${key}: ${value}\n`;
            }
          }
          
          // Before script
          if (job.before_script) {
            ciContent += '  before_script:\n';
            for (const script of job.before_script) {
              ciContent += `    - ${script}\n`;
            }
          }
          
          // Script
          if (job.script) {
            ciContent += '  script:\n';
            for (const script of job.script) {
              ciContent += `    - ${script}\n`;
            }
          }
          
          // After script
          if (job.after_script) {
            ciContent += '  after_script:\n';
            for (const script of job.after_script) {
              ciContent += `    - ${script}\n`;
            }
          }
          
          // Artifacts
          if (job.artifacts) {
            ciContent += '  artifacts:\n';
            if (job.artifacts.paths) {
              ciContent += '    paths:\n';
              for (const artifactPath of job.artifacts.paths) {
                ciContent += `      - ${artifactPath}\n`;
              }
            }
            if (job.artifacts.expire_in) {
              ciContent += `    expire_in: ${job.artifacts.expire_in}\n`;
            }
          }
          
          // Dependencies
          if (job.dependencies) {
            ciContent += '  dependencies:\n';
            for (const dependency of job.dependencies) {
              ciContent += `    - ${dependency}\n`;
            }
          }
          
          // Environment
          if (job.environment) {
            ciContent += '  environment:\n';
            if (typeof job.environment === 'string') {
              ciContent += `    name: ${job.environment}\n`;
            } else {
              if (job.environment.name) {
                ciContent += `    name: ${job.environment.name}\n`;
              }
              if (job.environment.url) {
                ciContent += `    url: ${job.environment.url}\n`;
              }
              if (job.environment.on_stop) {
                ciContent += `    on_stop: ${job.environment.on_stop}\n`;
              }
              if (job.environment.action) {
                ciContent += `    action: ${job.environment.action}\n`;
              }
            }
          }
          
          // When
          if (job.when) {
            ciContent += `  when: ${job.when}\n`;
          }
          
          // Allow failure
          if (job.allow_failure) {
            ciContent += `  allow_failure: ${job.allow_failure}\n`;
          }
          
          // Retry
          if (job.retry) {
            ciContent += '  retry:\n';
            if (typeof job.retry === 'number') {
              ciContent += `    max: ${job.retry}\n`;
            } else {
              if (job.retry.max) {
                ciContent += `    max: ${job.retry.max}\n`;
              }
              if (job.retry.when) {
                ciContent += '    when:\n';
                for (const when of job.retry.when) {
                  ciContent += `      - ${when}\n`;
                }
              }
            }
          }
          
          ciContent += '\n';
        }
      } else {
        // Configuración por defecto según el tipo de proyecto
        if (gitlabConfig.projectType === 'node') {
          // Job de build
          ciContent += 'build:\n';
          ciContent += '  stage: build\n';
          ciContent += '  image: node:16\n';
          ciContent += '  script:\n';
          ciContent += '    - npm ci\n';
          ciContent += '    - npm run build\n';
          ciContent += '  artifacts:\n';
          ciContent += '    paths:\n';
          ciContent += '      - build/\n';
          ciContent += '      - dist/\n';
          ciContent += '    expire_in: 1 week\n';
          ciContent += '\n';
          
          // Job de test
          ciContent += 'test:\n';
          ciContent += '  stage: test\n';
          ciContent += '  image: node:16\n';
          ciContent += '  script:\n';
          ciContent += '    - npm ci\n';
          ciContent += '    - npm test\n';
          ciContent += '\n';
          
          // Job de deploy
          if (gitlabConfig.deployType) {
            ciContent += 'deploy:\n';
            ciContent += '  stage: deploy\n';
            ciContent += '  image: node:16\n';
            
            if (gitlabConfig.deployType === 'aws') {
              ciContent += '  image: amazon/aws-cli\n';
              ciContent += '  script:\n';
              ciContent += '    - aws s3 sync ./build s3://$S3_BUCKET/\n';
              ciContent += '  variables:\n';
              ciContent += '    S3_BUCKET: ' + (gitlabConfig.s3Bucket || '${S3_BUCKET}') + '\n';
            } else if (gitlabConfig.deployType === 'azure') {
              ciContent += '  image: mcr.microsoft.com/azure-cli\n';
              ciContent += '  script:\n';
              ciContent += '    - az login --service-principal -u $AZURE_SP_ID -p $AZURE_SP_PASSWORD --tenant $AZURE_TENANT_ID\n';
              ciContent += '    - az webapp deployment source config-zip --resource-group $AZURE_RESOURCE_GROUP --name $AZURE_WEBAPP_NAME --src ./build.zip\n';
            } else if (gitlabConfig.deployType === 'gcp') {
              ciContent += '  image: google/cloud-sdk\n';
              ciContent += '  script:\n';
              ciContent += '    - echo $GCP_SERVICE_ACCOUNT > /tmp/service-account.json\n';
              ciContent += '    - gcloud auth activate-service-account --key-file=/tmp/service-account.json\n';
              ciContent += '    - gcloud app deploy --project=$GCP_PROJECT_ID\n';
            } else if (gitlabConfig.deployType === 'heroku') {
              ciContent += '  script:\n';
              ciContent += '    - apt-get update -qy\n';
              ciContent += '    - apt-get install -y ruby-dev\n';
              ciContent += '    - gem install dpl\n';
              ciContent += '    - dpl --provider=heroku --app=$HEROKU_APP_NAME --api-key=$HEROKU_API_KEY\n';
            }
            
            ciContent += '  only:\n';
            ciContent += '    - main\n';
            ciContent += '    - master\n';
            ciContent += '\n';
          }
        } else if (gitlabConfig.projectType === 'python') {
          // Job de build
          ciContent += 'build:\n';
          ciContent += '  stage: build\n';
          ciContent += '  image: python:3.9\n';
          ciContent += '  script:\n';
          ciContent += '    - pip install -r requirements.txt\n';
          ciContent += '    - python setup.py build\n';
          ciContent += '  artifacts:\n';
          ciContent += '    paths:\n';
          ciContent += '      - dist/\n';
          ciContent += '    expire_in: 1 week\n';
          ciContent += '\n';
          
          // Job de test
          ciContent += 'test:\n';
          ciContent += '  stage: test\n';
          ciContent += '  image: python:3.9\n';
          ciContent += '  script:\n';
          ciContent += '    - pip install -r requirements.txt\n';
          ciContent += '    - pip install pytest\n';
          ciContent += '    - pytest\n';
          ciContent += '\n';
          
          // Job de deploy
          if (gitlabConfig.deployType) {
            ciContent += 'deploy:\n';
            ciContent += '  stage: deploy\n';
            
            if (gitlabConfig.deployType === 'aws') {
              ciContent += '  image: amazon/aws-cli\n';
              ciContent += '  script:\n';
              ciContent += '    - aws s3 sync ./dist s3://$S3_BUCKET/\n';
              ciContent += '  variables:\n';
              ciContent += '    S3_BUCKET: ' + (gitlabConfig.s3Bucket || '${S3_BUCKET}') + '\n';
            } else if (gitlabConfig.deployType === 'azure') {
              ciContent += '  image: mcr.microsoft.com/azure-cli\n';
              ciContent += '  script:\n';
              ciContent += '    - az login --service-principal -u $AZURE_SP_ID -p $AZURE_SP_PASSWORD --tenant $AZURE_TENANT_ID\n';
              ciContent += '    - az webapp deployment source config-zip --resource-group $AZURE_RESOURCE_GROUP --name $AZURE_WEBAPP_NAME --src ./dist.zip\n';
            } else if (gitlabConfig.deployType === 'gcp') {
              ciContent += '  image: google/cloud-sdk\n';
              ciContent += '  script:\n';
              ciContent += '    - echo $GCP_SERVICE_ACCOUNT > /tmp/service-account.json\n';
              ciContent += '    - gcloud auth activate-service-account --key-file=/tmp/service-account.json\n';
              ciContent += '    - gcloud app deploy --project=$GCP_PROJECT_ID\n';
            } else if (gitlabConfig.deployType === 'heroku') {
              ciContent += '  script:\n';
              ciContent += '    - apt-get update -qy\n';
              ciContent += '    - apt-get install -y ruby-dev\n';
              ciContent += '    - gem install dpl\n';
              ciContent += '    - dpl --provider=heroku --app=$HEROKU_APP_NAME --api-key=$HEROKU_API_KEY\n';
            }
            
            ciContent += '  only:\n';
            ciContent += '    - main\n';
            ciContent += '    - master\n';
            ciContent += '\n';
          }
        } else if (gitlabConfig.projectType === 'docker') {
          // Job de build
          ciContent += 'build:\n';
          ciContent += '  stage: build\n';
          ciContent += '  image: docker:20.10.16\n';
          ciContent += '  services:\n';
          ciContent += '    - docker:20.10.16-dind\n';
          ciContent += '  variables:\n';
          ciContent += '    DOCKER_TLS_CERTDIR: "/certs"\n';
          ciContent += '  script:\n';
          ciContent += '    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG .\n';
          ciContent += '    - docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG $CI_REGISTRY_IMAGE:latest\n';
          ciContent += '  only:\n';
          ciContent += '    - main\n';
          ciContent += '    - master\n';
          ciContent += '\n';
          
          // Job de push
          ciContent += 'push:\n';
          ciContent += '  stage: deploy\n';
          ciContent += '  image: docker:20.10.16\n';
          ciContent += '  services:\n';
          ciContent += '    - docker:20.10.16-dind\n';
          ciContent += '  variables:\n';
          ciContent += '    DOCKER_TLS_CERTDIR: "/certs"\n';
          ciContent += '  script:\n';
          ciContent += '    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n';
          ciContent += '    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG\n';
          ciContent += '    - docker push $CI_REGISTRY_IMAGE:latest\n';
          ciContent += '  only:\n';
          ciContent += '    - main\n';
          ciContent += '    - master\n';
          ciContent += '\n';
        }
      }
      
      // Escribir archivo de configuración
      fs.writeFileSync(ciConfigPath, ciContent, 'utf8');
      
      this.logger.debug(`Archivo de configuración GitLab CI creado en: ${ciConfigPath}`);
      
      return `Pipeline CI/CD con GitLab CI configurado correctamente: ${ciConfigPath}`;
    }
    
    private async setupJenkins(config: any): Promise<string> {
      this.logger.info('Configurando Jenkins...');
      
      // Verificar configuración de Jenkins
      if (!config.jenkinsConfig) {
        throw new Error('No se ha proporcionado configuración de Jenkins para el pipeline CI/CD');
      }
      
      const jenkinsConfig = config.jenkinsConfig;
      const targetPath = config.targetPath || process.cwd();
      
      // Crear archivo Jenkinsfile
      const jenkinsfilePath = path.join(targetPath, 'Jenkinsfile');
      
      // Generar contenido del Jenkinsfile
      let jenkinsfileContent = '';
      
      // Configurar pipeline
      jenkinsfileContent += 'pipeline {\n';
      
      // Configurar agent
      jenkinsfileContent += '  agent {\n';
      if (jenkinsConfig.agent && jenkinsConfig.agent.type) {
        if (jenkinsConfig.agent.type === 'any') {
          jenkinsfileContent += '    any\n';
        } else if (jenkinsConfig.agent.type === 'label') {
          jenkinsfileContent += `    label '${jenkinsConfig.agent.label}'\n`;
        } else if (jenkinsConfig.agent.type === 'docker') {
          jenkinsfileContent += '    docker {\n';
          jenkinsfileContent += `      image '${jenkinsConfig.agent.image}'\n`;
          if (jenkinsConfig.agent.args) {
            jenkinsfileContent += `      args '${jenkinsConfig.agent.args}'\n`;
          }
          jenkinsfileContent += '    }\n';
        } else if (jenkinsConfig.agent.type === 'kubernetes') {
          jenkinsfileContent += '    kubernetes {\n';
          jenkinsfileContent += `      yaml '''${jenkinsConfig.agent.yaml}'''\n`;
          jenkinsfileContent += '    }\n';
        }
      } else {
        // Agent por defecto
        jenkinsfileContent += '    any\n';
      }
      jenkinsfileContent += '  }\n\n';
      
      // Configurar options
      if (jenkinsConfig.options) {
        jenkinsfileContent += '  options {\n';
        for (const [option, value] of Object.entries(jenkinsConfig.options)) {
          if (typeof value === 'boolean' && value) {
            jenkinsfileContent += `    ${option}()\n`;
          } else if (typeof value === 'string') {
            jenkinsfileContent += `    ${option}('${value}')\n`;
          } else if (typeof value === 'number') {
            jenkinsfileContent += `    ${option}(${value})\n`;
          }
        }
        jenkinsfileContent += '  }\n\n';
      }
      
      // Configurar triggers
      if (jenkinsConfig.triggers) {
        jenkinsfileContent += '  triggers {\n';
        for (const [trigger, value] of Object.entries(jenkinsConfig.triggers)) {
          if (trigger === 'cron' && typeof value === 'string') {
            jenkinsfileContent += `    cron('${value}')\n`;
          } else if (trigger === 'pollSCM' && typeof value === 'string') {
            jenkinsfileContent += `    pollSCM('${value}')\n`;
          } else if (trigger === 'upstream' && typeof value === 'string') {
            jenkinsfileContent += `    upstream('${value}')\n`;
          } else if (typeof value === 'boolean' && value) {
            jenkinsfileContent += `    ${trigger}()\n`;
          }
        }
        jenkinsfileContent += '  }\n\n';
      }
      
      // Configurar parameters
      if (jenkinsConfig.parameters && jenkinsConfig.parameters.length > 0) {
        jenkinsfileContent += '  parameters {\n';
        for (const param of jenkinsConfig.parameters) {
          if (param.type === 'string') {
            jenkinsfileContent += `    string(name: '${param.name}', defaultValue: '${param.defaultValue || ''}', description: '${param.description || ''}')\n`;
          } else if (param.type === 'text') {
            jenkinsfileContent += `    text(name: '${param.name}', defaultValue: '${param.defaultValue || ''}', description: '${param.description || ''}')\n`;
          } else if (param.type === 'booleanParam') {
            jenkinsfileContent += `    booleanParam(name: '${param.name}', defaultValue: ${param.defaultValue || false}, description: '${param.description || ''}')\n`;
          } else if (param.type === 'choice') {
            jenkinsfileContent += `    choice(name: '${param.name}', choices: [${param.choices.map(c => `'${c}'`).join(', ')}], description: '${param.description || ''}')\n`;
          } else if (param.type === 'password') {
            jenkinsfileContent += `    password(name: '${param.name}', defaultValue: '${param.defaultValue || ''}', description: '${param.description || ''}')\n`;
          }
        }
        jenkinsfileContent += '  }\n\n';
      }
      
      // Configurar environment
      if (jenkinsConfig.environment) {
        jenkinsfileContent += '  environment {\n';
        for (const [key, value] of Object.entries(jenkinsConfig.environment)) {
          jenkinsfileContent += `    ${key} = '${value}'\n`;
        }
        jenkinsfileContent += '  }\n\n';
      }
      
      // Configurar stages
      jenkinsfileContent += '  stages {\n';
      
      if (jenkinsConfig.stages && jenkinsConfig.stages.length > 0) {
        for (const stage of jenkinsConfig.stages) {
          jenkinsfileContent += `    stage('${stage.name}') {\n`;
          
          // Configurar when
          if (stage.when) {
            jenkinsfileContent += '      when {\n';
            for (const [condition, value] of Object.entries(stage.when)) {
              if (condition === 'branch' && typeof value === 'string') {
                jenkinsfileContent += `        branch '${value}'\n`;
              } else if (condition === 'expression' && typeof value === 'string') {
                jenkinsfileContent += `        expression { return ${value} }\n`;
              } else if (condition === 'environment' && typeof value === 'object') {
                jenkinsfileContent += `        environment name: '${value.name}', value: '${value.value}'\n`;
              } else if (typeof value === 'boolean' && value) {
                jenkinsfileContent += `        ${condition}()\n`;
              }
            }
            jenkinsfileContent += '      }\n';
          }
          
          // Configurar agent
          if (stage.agent) {
            jenkinsfileContent += '      agent {\n';
            if (stage.agent.type === 'any') {
              jenkinsfileContent += '        any\n';
            } else if (stage.agent.type === 'label') {
              jenkinsfileContent += `        label '${stage.agent.label}'\n`;
            } else if (stage.agent.type === 'docker') {
              jenkinsfileContent += '        docker {\n';
              jenkinsfileContent += `          image '${stage.agent.image}'\n`;
              if (stage.agent.args) {
                jenkinsfileContent += `          args '${stage.agent.args}'\n`;
              }
              jenkinsfileContent += '        }\n';
            }
            jenkinsfileContent += '      }\n';
          }
          
          // Configurar environment
          if (stage.environment) {
            jenkinsfileContent += '      environment {\n';
            for (const [key, value] of Object.entries(stage.environment)) {
              jenkinsfileContent += `        ${key} = '${value}'\n`;
            }
            jenkinsfileContent += '      }\n';
          }
          
          // Configurar steps
          jenkinsfileContent += '      steps {\n';
          if (stage.steps && stage.steps.length > 0) {
            for (const step of stage.steps) {
              if (typeof step === 'string') {
                jenkinsfileContent += `        sh '${step}'\n`;
              } else if (step.sh) {
                jenkinsfileContent += `        sh '${step.sh}'\n`;
              } else if (step.bat) {
                jenkinsfileContent += `        bat '${step.bat}'\n`;
              } else if (step.echo) {
                jenkinsfileContent += `        echo '${step.echo}'\n`;
              } else if (step.script) {
                jenkinsfileContent += '        script {\n';
                jenkinsfileContent += `          ${step.script}\n`;
                jenkinsfileContent += '        }\n';
              } else if (step.dir) {
                jenkinsfileContent += `        dir('${step.dir.path}') {\n`;
                for (const dirStep of step.dir.steps) {
                  if (typeof dirStep === 'string') {
                    jenkinsfileContent += `          sh '${dirStep}'\n`;
                  } else if (dirStep.sh) {
                    jenkinsfileContent += `          sh '${dirStep.sh}'\n`;
                  } else if (dirStep.bat) {
                    jenkinsfileContent += `          bat '${dirStep.bat}'\n`;
                  } else if (dirStep.echo) {
                    jenkinsfileContent += `          echo '${dirStep.echo}'\n`;
                  }
                }
                jenkinsfileContent += '        }\n';
              } else if (step.withCredentials) {
                jenkinsfileContent += '        withCredentials([\n';
                for (const cred of step.withCredentials.credentials) {
                  if (cred.type === 'string') {
                    jenkinsfileContent += `          string(credentialsId: '${cred.id}', variable: '${cred.variable}')\n`;
                  } else if (cred.type === 'usernamePassword') {
                    jenkinsfileContent += `          usernamePassword(credentialsId: '${cred.id}', usernameVariable: '${cred.usernameVariable}', passwordVariable: '${cred.passwordVariable}')\n`;
                  } else if (cred.type === 'file') {
                    jenkinsfileContent += `          file(credentialsId: '${cred.id}', variable: '${cred.variable}')\n`;
                  }
                }
                jenkinsfileContent += '        ]) {\n';
                for (const credStep of step.withCredentials.steps) {
                  if (typeof credStep === 'string') {
                    jenkinsfileContent += `          sh '${credStep}'\n`;
                  } else if (credStep.sh) {
                    jenkinsfileContent += `          sh '${credStep.sh}'\n`;
                  } else if (credStep.bat) {
                    jenkinsfileContent += `          bat '${credStep.bat}'\n`;
                  } else if (credStep.echo) {
                    jenkinsfileContent += `          echo '${credStep.echo}'\n`;
                  }
                }
                jenkinsfileContent += '        }\n';
              }
            }
          } else {
            // Pasos por defecto según el tipo de proyecto
            if (jenkinsConfig.projectType === 'node') {
              jenkinsfileContent += '        sh \'npm ci\'\n';
              jenkinsfileContent += '        sh \'npm test\'\n';
              jenkinsfileContent += '        sh \'npm run build\'\n';
            } else if (jenkinsConfig.projectType === 'python') {
              jenkinsfileContent += '        sh \'pip install -r requirements.txt\'\n';
              jenkinsfileContent += '        sh \'pytest\'\n';
            } else if (jenkinsConfig.projectType === 'java') {
              jenkinsfileContent += '        sh \'./mvnw clean package\'\n';
            } else if (jenkinsConfig.projectType === 'docker') {
              jenkinsfileContent += '        sh \'docker build -t ${IMAGE_NAME}:${BUILD_NUMBER} .\'\n';
            }
          }
          jenkinsfileContent += '      }\n';
          
          // Configurar post
          if (stage.post) {
            jenkinsfileContent += '      post {\n';
            for (const [condition, steps] of Object.entries(stage.post)) {
              jenkinsfileContent += `        ${condition} {\n`;
              for (const step of steps) {
                if (typeof step === 'string') {
                  jenkinsfileContent += `          sh '${step}'\n`;
                } else if (step.sh) {
                  jenkinsfileContent += `          sh '${step.sh}'\n`;
                } else if (step.bat) {
                  jenkinsfileContent += `          bat '${step.bat}'\n`;
                } else if (step.echo) {
                  jenkinsfileContent += `          echo '${step.echo}'\n`;
                } else if (step.echo) {
                  jenkinsfileContent += `          echo '${step.echo}'\n`;
                } else if (step.script) {
                  jenkinsfileContent += '          script {\n';
                  jenkinsfileContent += `            ${step.script}\n`;
                  jenkinsfileContent += '          }\n';
                }
              }
              jenkinsfileContent += `        ${condition} {\n`;
            }
            jenkinsfileContent += '      }\n';
          }
          
          jenkinsfileContent += '    }\n';
        }
      } else {
        // Stages por defecto según el tipo de proyecto
        if (jenkinsConfig.projectType === 'node') {
          // Stage de build
          jenkinsfileContent += '    stage(\'Build\') {\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        sh \'npm ci\'\n';
          jenkinsfileContent += '        sh \'npm run build\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de test
          jenkinsfileContent += '    stage(\'Test\') {\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        sh \'npm test\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de deploy
          if (jenkinsConfig.deployType) {
            jenkinsfileContent += '    stage(\'Deploy\') {\n';
            jenkinsfileContent += '      when {\n';
            jenkinsfileContent += '        branch \'main\'\n';
            jenkinsfileContent += '      }\n';
            jenkinsfileContent += '      steps {\n';
            
            if (jenkinsConfig.deployType === 'aws') {
              jenkinsfileContent += '        withAWS(credentials: \'aws-credentials\') {\n';
              jenkinsfileContent += '          sh \'aws s3 sync ./build s3://${S3_BUCKET}/\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'azure') {
              jenkinsfileContent += '        withCredentials([azureServicePrincipal(\'azure-credentials\')]) {\n';
              jenkinsfileContent += '          sh \'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET --tenant $AZURE_TENANT_ID\'\n';
              jenkinsfileContent += '          sh \'az webapp deployment source config-zip --resource-group ${AZURE_RESOURCE_GROUP} --name ${AZURE_WEBAPP_NAME} --src ./build.zip\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'gcp') {
              jenkinsfileContent += '        withCredentials([file(credentialsId: \'gcp-credentials\', variable: \'GOOGLE_APPLICATION_CREDENTIALS\')]) {\n';
              jenkinsfileContent += '          sh \'gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS\'\n';
              jenkinsfileContent += '          sh \'gcloud app deploy --project=${GCP_PROJECT_ID}\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'heroku') {
              jenkinsfileContent += '        withCredentials([string(credentialsId: \'heroku-api-key\', variable: \'HEROKU_API_KEY\')]) {\n';
              jenkinsfileContent += '          sh \'heroku container:login\'\n';
              jenkinsfileContent += '          sh \'heroku container:push web --app=${HEROKU_APP_NAME}\'\n';
              jenkinsfileContent += '          sh \'heroku container:release web --app=${HEROKU_APP_NAME}\'\n';
              jenkinsfileContent += '        }\n';
            }
            
            jenkinsfileContent += '      }\n';
            jenkinsfileContent += '    }\n';
          }
        } else if (jenkinsConfig.projectType === 'python') {
          // Stage de build
          jenkinsfileContent += '    stage(\'Build\') {\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        sh \'pip install -r requirements.txt\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de test
          jenkinsfileContent += '    stage(\'Test\') {\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        sh \'pytest\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de deploy
          if (jenkinsConfig.deployType) {
            jenkinsfileContent += '    stage(\'Deploy\') {\n';
            jenkinsfileContent += '      when {\n';
            jenkinsfileContent += '        branch \'main\'\n';
            jenkinsfileContent += '      }\n';
            jenkinsfileContent += '      steps {\n';
            
            if (jenkinsConfig.deployType === 'aws') {
              jenkinsfileContent += '        withAWS(credentials: \'aws-credentials\') {\n';
              jenkinsfileContent += '          sh \'aws s3 sync ./dist s3://${S3_BUCKET}/\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'azure') {
              jenkinsfileContent += '        withCredentials([azureServicePrincipal(\'azure-credentials\')]) {\n';
              jenkinsfileContent += '          sh \'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET --tenant $AZURE_TENANT_ID\'\n';
              jenkinsfileContent += '          sh \'az webapp deployment source config-zip --resource-group ${AZURE_RESOURCE_GROUP} --name ${AZURE_WEBAPP_NAME} --src ./dist.zip\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'gcp') {
              jenkinsfileContent += '        withCredentials([file(credentialsId: \'gcp-credentials\', variable: \'GOOGLE_APPLICATION_CREDENTIALS\')]) {\n';
              jenkinsfileContent += '          sh \'gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS\'\n';
              jenkinsfileContent += '          sh \'gcloud app deploy --project=${GCP_PROJECT_ID}\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'heroku') {
              jenkinsfileContent += '        withCredentials([string(credentialsId: \'heroku-api-key\', variable: \'HEROKU_API_KEY\')]) {\n';
              jenkinsfileContent += '          sh \'heroku container:login\'\n';
              jenkinsfileContent += '          sh \'heroku container:push web --app=${HEROKU_APP_NAME}\'\n';
              jenkinsfileContent += '          sh \'heroku container:release web --app=${HEROKU_APP_NAME}\'\n';
              jenkinsfileContent += '        }\n';
            }
            
            jenkinsfileContent += '      }\n';
            jenkinsfileContent += '    }\n';
          }
        } else if (jenkinsConfig.projectType === 'java') {
          // Stage de build
          jenkinsfileContent += '    stage(\'Build\') {\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        sh \'./mvnw clean package\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de test
          jenkinsfileContent += '    stage(\'Test\') {\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        sh \'./mvnw test\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de deploy
          if (jenkinsConfig.deployType) {
            jenkinsfileContent += '    stage(\'Deploy\') {\n';
            jenkinsfileContent += '      when {\n';
            jenkinsfileContent += '        branch \'main\'\n';
            jenkinsfileContent += '      }\n';
            jenkinsfileContent += '      steps {\n';
            
            if (jenkinsConfig.deployType === 'aws') {
              jenkinsfileContent += '        withAWS(credentials: \'aws-credentials\') {\n';
              jenkinsfileContent += '          sh \'aws s3 cp ./target/*.jar s3://${S3_BUCKET}/\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'azure') {
              jenkinsfileContent += '        withCredentials([azureServicePrincipal(\'azure-credentials\')]) {\n';
              jenkinsfileContent += '          sh \'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET --tenant $AZURE_TENANT_ID\'\n';
              jenkinsfileContent += '          sh \'az webapp deploy --resource-group ${AZURE_RESOURCE_GROUP} --name ${AZURE_WEBAPP_NAME} --src-path ./target/*.jar\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'gcp') {
              jenkinsfileContent += '        withCredentials([file(credentialsId: \'gcp-credentials\', variable: \'GOOGLE_APPLICATION_CREDENTIALS\')]) {\n';
              jenkinsfileContent += '          sh \'gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS\'\n';
              jenkinsfileContent += '          sh \'gcloud app deploy --project=${GCP_PROJECT_ID}\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'heroku') {
              jenkinsfileContent += '        withCredentials([string(credentialsId: \'heroku-api-key\', variable: \'HEROKU_API_KEY\')]) {\n';
              jenkinsfileContent += '          sh \'heroku plugins:install java\'\n';
              jenkinsfileContent += '          sh \'heroku deploy:jar ./target/*.jar --app=${HEROKU_APP_NAME}\'\n';
              jenkinsfileContent += '        }\n';
            }
            
            jenkinsfileContent += '      }\n';
            jenkinsfileContent += '    }\n';
          }
        } else if (jenkinsConfig.projectType === 'docker') {
          // Stage de build
          jenkinsfileContent += '    stage(\'Build\') {\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        sh \'docker build -t ${IMAGE_NAME}:${BUILD_NUMBER} .\'\n';
          jenkinsfileContent += '        sh \'docker tag ${IMAGE_NAME}:${BUILD_NUMBER} ${IMAGE_NAME}:latest\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de test
          jenkinsfileContent += '    stage(\'Test\') {\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        sh \'docker run --rm ${IMAGE_NAME}:${BUILD_NUMBER} test\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de push
          jenkinsfileContent += '    stage(\'Push\') {\n';
          jenkinsfileContent += '      when {\n';
          jenkinsfileContent += '        branch \'main\'\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '      steps {\n';
          jenkinsfileContent += '        withCredentials([usernamePassword(credentialsId: \'docker-registry-credentials\', usernameVariable: \'DOCKER_USERNAME\', passwordVariable: \'DOCKER_PASSWORD\')]) {\n';
          jenkinsfileContent += '          sh \'echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin ${DOCKER_REGISTRY}\'\n';
          jenkinsfileContent += '          sh \'docker tag ${IMAGE_NAME}:${BUILD_NUMBER} ${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\'\n';
          jenkinsfileContent += '          sh \'docker tag ${IMAGE_NAME}:${BUILD_NUMBER} ${DOCKER_REGISTRY}/${IMAGE_NAME}:latest\'\n';
          jenkinsfileContent += '          sh \'docker push ${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\'\n';
          jenkinsfileContent += '          sh \'docker push ${DOCKER_REGISTRY}/${IMAGE_NAME}:latest\'\n';
          jenkinsfileContent += '        }\n';
          jenkinsfileContent += '      }\n';
          jenkinsfileContent += '    }\n';
          
          // Stage de deploy
          if (jenkinsConfig.deployType) {
            jenkinsfileContent += '    stage(\'Deploy\') {\n';
            jenkinsfileContent += '      when {\n';
            jenkinsfileContent += '        branch \'main\'\n';
            jenkinsfileContent += '      }\n';
            jenkinsfileContent += '      steps {\n';
            
            if (jenkinsConfig.deployType === 'kubernetes') {
              jenkinsfileContent += '        withKubeConfig([credentialsId: \'kubernetes-config\']) {\n';
              jenkinsfileContent += '          sh \'kubectl set image deployment/${DEPLOYMENT_NAME} ${CONTAINER_NAME}=${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\'\n';
              jenkinsfileContent += '          sh \'kubectl rollout status deployment/${DEPLOYMENT_NAME}\'\n';
              jenkinsfileContent += '        }\n';
            } else if (jenkinsConfig.deployType === 'aws-ecs') {
              jenkinsfileContent += '        withAWS(credentials: \'aws-credentials\') {\n';
              jenkinsfileContent += '          sh \'aws ecs update-service --cluster ${ECS_CLUSTER} --service ${ECS_SERVICE} --force-new-deployment\'\n';
              jenkinsfileContent += '        }\n';
            }
            
            jenkinsfileContent += '      }\n';
            jenkinsfileContent += '    }\n';
          }
        }
      }
      
      // Configurar post
      if (jenkinsConfig.post) {
        jenkinsfileContent += '  post {\n';
        for (const [condition, steps] of Object.entries(jenkinsConfig.post)) {
          jenkinsfileContent += `    ${condition} {\n`;
          for (const step of steps) {
            if (typeof step === 'string') {
              jenkinsfileContent += `      sh '${step}'\n`;
            } else if (step.sh) {
              jenkinsfileContent += `      sh '${step.sh}'\n`;
            } else if (step.bat) {
              jenkinsfileContent += `      bat '${step.bat}'\n`;
            } else if (step.echo) {
              jenkinsfileContent += `      echo '${step.echo}'\n`;
            } else if (step.script) {
              jenkinsfileContent += '      script {\n';
              jenkinsfileContent += `        ${step.script}\n`;
              jenkinsfileContent += '      }\n';
            } else if (step.mail) {
              jenkinsfileContent += `      mail to: '${step.mail.to}',\n`;
              jenkinsfileContent += `           subject: '${step.mail.subject}',\n`;
              jenkinsfileContent += `           body: '${step.mail.body}'\n`;
            } else if (step.slackSend) {
              jenkinsfileContent += `      slackSend channel: '${step.slackSend.channel}',\n`;
              jenkinsfileContent += `                color: '${step.slackSend.color}',\n`;
              jenkinsfileContent += `                message: '${step.slackSend.message}'\n`;
            }
          }
          jenkinsfileContent += '    }\n';
        }
        jenkinsfileContent += '  }\n';
      } else {
        // Post por defecto
        jenkinsfileContent += '  post {\n';
        jenkinsfileContent += '    success {\n';
        jenkinsfileContent += '      echo \'Pipeline ejecutado con éxito\'\n';
        jenkinsfileContent += '    }\n';
        jenkinsfileContent += '    failure {\n';
        jenkinsfileContent += '      echo \'Pipeline falló\'\n';
        jenkinsfileContent += '    }\n';
        jenkinsfileContent += '  }\n';
      }
      
      jenkinsfileContent += '}\n';
      
      // Escribir archivo Jenkinsfile
      fs.writeFileSync(jenkinsfilePath, jenkinsfileContent, 'utf8');
      
      this.logger.debug(`Archivo Jenkinsfile creado en: ${jenkinsfilePath}`);
      
      return `Pipeline CI/CD con Jenkins configurado correctamente: ${jenkinsfilePath}`;
    }
    
    private async setupCircleCI(config: any): Promise<string> {
      this.logger.info('Configurando CircleCI...');
      
      // Verificar configuración de CircleCI
      if (!config.circleCIConfig) {
        throw new Error('No se ha proporcionado configuración de CircleCI para el pipeline CI/CD');
      }
      
      const circleCIConfig = config.circleCIConfig;
      const targetPath = config.targetPath || process.cwd();
      
      // Crear directorio .circleci si no existe
      const circleCIDir = path.join(targetPath, '.circleci');
      if (!fs.existsSync(circleCIDir)) {
        fs.mkdirSync(circleCIDir, { recursive: true });
      }
      
      // Crear archivo de configuración de CircleCI
      const configPath = path.join(circleCIDir, 'config.yml');
      
      // Generar contenido del archivo de configuración
      let configContent = 'version: 2.1\n\n';
      
      // Configurar orbs
      if (circleCIConfig.orbs && Object.keys(circleCIConfig.orbs).length > 0) {
        configContent += 'orbs:\n';
        for (const [orbName, orbVersion] of Object.entries(circleCIConfig.orbs)) {
          configContent += `  ${orbName}: ${orbVersion}\n`;
        }
        configContent += '\n';
      }
      
      // Configurar executors
      if (circleCIConfig.executors && Object.keys(circleCIConfig.executors).length > 0) {
        configContent += 'executors:\n';
        for (const [executorName, executor] of Object.entries(circleCIConfig.executors)) {
          configContent += `  ${executorName}:\n`;
          if (executor.docker) {
            configContent += '    docker:\n';
            for (const image of executor.docker) {
              configContent += `      - image: ${image.image}\n`;
              if (image.auth) {
                configContent += '        auth:\n';
                configContent += `          username: ${image.auth.username}\n`;
                configContent += `          password: ${image.auth.password}\n`;
              }
            }
          }
          if (executor.resource_class) {
            configContent += `    resource_class: ${executor.resource_class}\n`;
          }
          if (executor.working_directory) {
            configContent += `    working_directory: ${executor.working_directory}\n`;
          }
          if (executor.environment) {
            configContent += '    environment:\n';
            for (const [key, value] of Object.entries(executor.environment)) {
              configContent += `      ${key}: ${value}\n`;
            }
          }
        }
        configContent += '\n';
      }
      
      // Configurar commands
      if (circleCIConfig.commands && Object.keys(circleCIConfig.commands).length > 0) {
        configContent += 'commands:\n';
        for (const [commandName, command] of Object.entries(circleCIConfig.commands)) {
          configContent += `  ${commandName}:\n`;
          if (command.description) {
            configContent += `    description: ${command.description}\n`;
          }
          if (command.parameters) {
            configContent += '    parameters:\n';
            for (const [paramName, param] of Object.entries(command.parameters)) {
              configContent += `      ${paramName}:\n`;
              configContent += `        type: ${param.type}\n`;
              if (param.default) {
                configContent += `        default: ${param.default}\n`;
              }
              if (param.description) {
                configContent += `        description: ${param.description}\n`;
              }
            }
          }
          if (command.steps) {
            configContent += '    steps:\n';
            for (const step of command.steps) {
              for (const [stepType, stepConfig] of Object.entries(step)) {
                configContent += `      - ${stepType}:\n`;
                for (const [key, value] of Object.entries(stepConfig)) {
                  configContent += `          ${key}: ${value}\n`;
                }
              }
            }
          }
        }
        configContent += '\n';
      }
      
      // Configurar jobs
      configContent += 'jobs:\n';
      
      if (circleCIConfig.jobs && Object.keys(circleCIConfig.jobs).length > 0) {
        for (const [jobName, job] of Object.entries(circleCIConfig.jobs)) {
          configContent += `  ${jobName}:\n`;
          
          // Executor
          if (job.executor) {
            configContent += `    executor: ${job.executor}\n`;
          } else if (job.docker) {
            configContent += '    docker:\n';
            for (const image of job.docker) {
              configContent += `      - image: ${image.image}\n`;
              if (image.auth) {
                configContent += '        auth:\n';
                configContent += `          username: ${image.auth.username}\n`;
                configContent += `          password: ${image.auth.password}\n`;
              }
            }
          } else if (job.machine) {
            configContent += '    machine:\n';
            configContent += `      image: ${job.machine.image}\n`;
          }
          
          // Resource class
          if (job.resource_class) {
            configContent += `    resource_class: ${job.resource_class}\n`;
          }
          
          // Working directory
          if (job.working_directory) {
            configContent += `    working_directory: ${job.working_directory}\n`;
          }
          
          // Environment
          if (job.environment) {
            configContent += '    environment:\n';
            for (const [key, value] of Object.entries(job.environment)) {
              configContent += `      ${key}: ${value}\n`;
            }
          }
          
          // Steps
          if (job.steps) {
            configContent += '    steps:\n';
            for (const step of job.steps) {
              if (typeof step === 'string') {
                configContent += `      - ${step}\n`;
              } else {
                for (const [stepType, stepConfig] of Object.entries(step)) {
                  if (typeof stepConfig === 'string') {
                    configContent += `      - ${stepType}: ${stepConfig}\n`;
                  } else {
                    configContent += `      - ${stepType}:\n`;
                    for (const [key, value] of Object.entries(stepConfig)) {
                      if (typeof value === 'object' && !Array.isArray(value)) {
                        configContent += `          ${key}:\n`;
                        for (const [subKey, subValue] of Object.entries(value)) {
                          configContent += `            ${subKey}: ${subValue}\n`;
                        }
                      } else if (Array.isArray(value)) {
                        configContent += `          ${key}:\n`;
                        for (const item of value) {
                          configContent += `            - ${item}\n`;
                        }
                      } else {
                        configContent += `          ${key}: ${value}\n`;
                      }
                    }
                  }
                }
              }
            }
          }
        }
      } else {
        // Jobs por defecto según el tipo de proyecto
        if (circleCIConfig.projectType === 'node') {
          // Job de build
          configContent += '  build:\n';
          configContent += '    docker:\n';
          configContent += '      - image: cimg/node:16.13\n';
          configContent += '    steps:\n';
          configContent += '      - checkout\n';
          configContent += '      - restore_cache:\n';
          configContent += '          keys:\n';
          configContent += '            - v1-dependencies-{{ checksum "package.json" }}\n';
          configContent += '            - v1-dependencies-\n';
          configContent += '      - run: npm ci\n';
          configContent += '      - save_cache:\n';
          configContent += '          paths:\n';
          configContent += '            - node_modules\n';
          configContent += '          key: v1-dependencies-{{ checksum "package.json" }}\n';
          configContent += '      - run: npm run build\n';
          configContent += '      - persist_to_workspace:\n';
          configContent += '          root: .\n';
          configContent += '          paths:\n';
          configContent += '            - build\n';
          configContent += '            - dist\n';
          configContent += '            - node_modules\n';
          configContent += '\n';
          
          // Job de test
          configContent += '  test:\n';
          configContent += '    docker:\n';
          configContent += '      - image: cimg/node:16.13\n';
          configContent += '    steps:\n';
          configContent += '      - checkout\n';
          configContent += '      - restore_cache:\n';
          configContent += '          keys:\n';
          configContent += '            - v1-dependencies-{{ checksum "package.json" }}\n';
          configContent += '            - v1-dependencies-\n';
          configContent += '      - run: npm ci\n';
          configContent += '      - run: npm test\n';
          configContent += '\n';
          
          // Job de deploy
          if (circleCIConfig.deployType) {
            configContent += '  deploy:\n';
            configContent += '    docker:\n';
            
            if (circleCIConfig.deployType === 'aws') {
              configContent += '      - image: amazon/aws-cli\n';
              configContent += '    steps:\n';
              configContent += '      - attach_workspace:\n';
              configContent += '          at: .\n';
              configContent += '      - run:\n';
              configContent += '          name: Deploy to S3\n';
              configContent += '          command: aws s3 sync ./build s3://${S3_BUCKET}/\n';
            } else if (circleCIConfig.deployType === 'azure') {
              configContent += '      - image: mcr.microsoft.com/azure-cli\n';
              configContent += '    steps:\n';
              configContent += '      - attach_workspace:\n';
              configContent += '          at: .\n';
              configContent += '      - run:\n';
              configContent += '          name: Deploy to Azure\n';
              configContent += '          command: |\n';
              configContent += '            az login --service-principal -u $AZURE_SP_ID -p $AZURE_SP_PASSWORD --tenant $AZURE_TENANT_ID\n';
              configContent += '            az webapp deployment source config-zip --resource-group $AZURE_RESOURCE_GROUP --name $AZURE_WEBAPP_NAME --src ./build.zip\n';
            } else if (circleCIConfig.deployType === 'gcp') {
              configContent += '      - image: google/cloud-sdk\n';
              configContent += '    steps:\n';
              configContent += '      - attach_workspace:\n';
              configContent += '          at: .\n';
              configContent += '      - run:\n';
              configContent += '          name: Deploy to GCP\n';
              configContent += '          command: |\n';
              configContent += '            echo $GCLOUD_SERVICE_KEY | gcloud auth activate-service-account --key-file=-\n';
              configContent += '            gcloud app deploy --project=$GOOGLE_PROJECT_ID\n';
            } else if (circleCIConfig.deployType === 'heroku') {
              configContent += '      - image: cimg/node:16.13\n';
              configContent += '    steps:\n';
              configContent += '      - attach_workspace:\n';
              configContent += '          at: .\n';
              configContent += '      - run:\n';
              configContent += '          name: Deploy to Heroku\n';
              configContent += '          command: |\n';
              configContent += '            sudo curl https://cli-assets.heroku.com/install.sh | sh\n';
              configContent += '            heroku container:login\n';
              configContent += '            heroku container:push web --app=$HEROKU_APP_NAME\n';
              configContent += '            heroku container:release web --app=$HEROKU_APP_NAME\n';
            }
            
            configContent += '\n';
          }
        } else if (circleCIConfig.projectType === 'python') {
          // Job de build
          configContent += '  build:\n';
      configContent += '    docker:\n';
      configContent += '      - image: cimg/openjdk:17.0\n';
      configContent += '    steps:\n';
      configContent += '      - checkout\n';
      configContent += '      - restore_cache:\n';
      configContent += '          keys:\n';
      configContent += '            - v1-dependencies-{{ checksum "pom.xml" }}\n';
      configContent += '            - v1-dependencies-\n';
      configContent += '      - run: ./mvnw dependency:go-offline\n';
      configContent += '      - save_cache:\n';
      configContent += '          paths:\n';
      configContent += '            - ~/.m2\n';
      configContent += '          key: v1-dependencies-{{ checksum "pom.xml" }}\n';
      configContent += '      - run: ./mvnw package\n';
      configContent += '      - persist_to_workspace:\n';
      configContent += '          root: .\n';
      configContent += '          paths:\n';
      configContent += '            - target\n';
      configContent += '\n';
      
      // Job de test
      configContent += '  test:\n';
      configContent += '    docker:\n';
      configContent += '      - image: cimg/openjdk:17.0\n';
      configContent += '    steps:\n';
      configContent += '      - checkout\n';
      configContent += '      - restore_cache:\n';
      configContent += '          keys:\n';
      configContent += '            - v1-dependencies-{{ checksum "pom.xml" }}\n';
      configContent += '            - v1-dependencies-\n';
      configContent += '      - run: ./mvnw test\n';
      configContent += '\n';
      
      // Job de deploy
      if (circleCIConfig.deployType) {
        configContent += '  deploy:\n';
        configContent += '    docker:\n';
        
        if (circleCIConfig.deployType === 'aws') {
          configContent += '      - image: amazon/aws-cli\n';
          configContent += '    steps:\n';
          configContent += '      - attach_workspace:\n';
          configContent += '          at: .\n';
          configContent += '      - run:\n';
          configContent += '          name: Deploy to AWS\n';
          configContent += '          command: aws s3 cp ./target/*.jar s3://${S3_BUCKET}/\n';
        } else if (circleCIConfig.deployType === 'azure') {
          configContent += '      - image: mcr.microsoft.com/azure-cli\n';
          configContent += '    steps:\n';
          configContent += '      - attach_workspace:\n';
          configContent += '          at: .\n';
          configContent += '      - run:\n';
          configContent += '          name: Deploy to Azure\n';
          configContent += '          command: |\n';
          configContent += '            az login --service-principal -u $AZURE_SP_ID -p $AZURE_SP_PASSWORD --tenant $AZURE_TENANT_ID\n';
          configContent += '            az webapp deploy --resource-group $AZURE_RESOURCE_GROUP --name $AZURE_WEBAPP_NAME --src-path ./target/*.jar\n';
        } else if (circleCIConfig.deployType === 'gcp') {
          configContent += '      - image: google/cloud-sdk\n';
          configContent += '    steps:\n';
          configContent += '      - attach_workspace:\n';
          configContent += '          at: .\n';
          configContent += '      - run:\n';
          configContent += '          name: Deploy to GCP\n';
          configContent += '          command: |\n';
          configContent += '            echo $GCLOUD_SERVICE_KEY | gcloud auth activate-service-account --key-file=-\n';
          configContent += '            gcloud app deploy --project=$GOOGLE_PROJECT_ID\n';
        } else if (circleCIConfig.deployType === 'heroku') {
          configContent += '      - image: cimg/openjdk:17.0\n';
          configContent += '    steps:\n';
          configContent += '      - attach_workspace:\n';
          configContent += '          at: .\n';
          configContent += '      - run:\n';
          configContent += '          name: Deploy to Heroku\n';
          configContent += '          command: |\n';
          configContent += '            curl https://cli-assets.heroku.com/install.sh | sh\n';
          configContent += '            heroku plugins:install java\n';
          configContent += '            heroku deploy:jar ./target/*.jar --app=$HEROKU_APP_NAME\n';
        }
        
        configContent += '\n';
      }
    } else if (circleCIConfig.projectType === 'docker') {
      // Job de build
      configContent += '  build:\n';
      configContent += '    machine:\n';
      configContent += '      image: ubuntu-2004:202010-01\n';
      configContent += '    steps:\n';
      configContent += '      - checkout\n';
      configContent += '      - run:\n';
      configContent += '          name: Build Docker image\n';
      configContent += '          command: |\n';
      configContent += '            docker build -t ${IMAGE_NAME}:${CIRCLE_SHA1} .\n';
      configContent += '            docker tag ${IMAGE_NAME}:${CIRCLE_SHA1} ${IMAGE_NAME}:latest\n';
      configContent += '      - run:\n';
      configContent += '          name: Save Docker image\n';
      configContent += '          command: |\n';
      configContent += '            mkdir -p /tmp/docker-images\n';
      configContent += '            docker save -o /tmp/docker-images/${IMAGE_NAME}.tar ${IMAGE_NAME}:${CIRCLE_SHA1}\n';
      configContent += '      - persist_to_workspace:\n';
      configContent += '          root: /tmp/docker-images\n';
      configContent += '          paths:\n';
      configContent += '            - ${IMAGE_NAME}.tar\n';
      configContent += '\n';
      
      // Job de test
      configContent += '  test:\n';
      configContent += '    machine:\n';
      configContent += '      image: ubuntu-2004:202010-01\n';
      configContent += '    steps:\n';
      configContent += '      - checkout\n';
      configContent += '      - attach_workspace:\n';
      configContent += '          at: /tmp/docker-images\n';
      configContent += '      - run:\n';
      configContent += '          name: Load Docker image\n';
      configContent += '          command: docker load -i /tmp/docker-images/${IMAGE_NAME}.tar\n';
      configContent += '      - run:\n';
      configContent += '          name: Run tests\n';
      configContent += '          command: docker run --rm ${IMAGE_NAME}:${CIRCLE_SHA1} test\n';
      configContent += '\n';
      
      // Job de push
      configContent += '  push:\n';
      configContent += '    machine:\n';
      configContent += '      image: ubuntu-2004:202010-01\n';
      configContent += '    steps:\n';
      configContent += '      - attach_workspace:\n';
      configContent += '          at: /tmp/docker-images\n';
      configContent += '      - run:\n';
      configContent += '          name: Load Docker image\n';
      configContent += '          command: docker load -i /tmp/docker-images/${IMAGE_NAME}.tar\n';
      configContent += '      - run:\n';
      configContent += '          name: Push Docker image\n';
      configContent += '          command: |\n';
      configContent += '            echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin ${DOCKER_REGISTRY}\n';
      configContent += '            docker tag ${IMAGE_NAME}:${CIRCLE_SHA1} ${DOCKER_REGISTRY}/${IMAGE_NAME}:${CIRCLE_SHA1}\n';
      configContent += '            docker tag ${IMAGE_NAME}:${CIRCLE_SHA1} ${DOCKER_REGISTRY}/${IMAGE_NAME}:latest\n';
      configContent += '            docker push ${DOCKER_REGISTRY}/${IMAGE_NAME}:${CIRCLE_SHA1}\n';
      configContent += '            docker push ${DOCKER_REGISTRY}/${IMAGE_NAME}:latest\n';
      configContent += '\n';
      
      // Job de deploy
      if (circleCIConfig.deployType) {
        configContent += '  deploy:\n';
        configContent += '    machine:\n';
        configContent += '      image: ubuntu-2004:202010-01\n';
        configContent += '    steps:\n';
        
        if (circleCIConfig.deployType === 'kubernetes') {
          configContent += '      - checkout\n';
          configContent += '      - run:\n';
          configContent += '          name: Install kubectl\n';
          configContent += '          command: |\n';
          configContent += '            curl -LO "https://dl.k8s.io/release/stable.txt"\n';
          configContent += '            curl -LO "https://dl.k8s.io/release/$(cat stable.txt)/bin/linux/amd64/kubectl"\n';
          configContent += '            chmod +x kubectl\n';
          configContent += '            sudo mv kubectl /usr/local/bin/\n';
          configContent += '      - run:\n';
          configContent += '          name: Setup kubeconfig\n';
          configContent += '          command: |\n';
          configContent += '            echo $KUBECONFIG_DATA | base64 -d > kubeconfig.yaml\n';
          configContent += '            export KUBECONFIG=kubeconfig.yaml\n';
          configContent += '      - run:\n';
          configContent += '          name: Deploy to Kubernetes\n';
          configContent += '          command: |\n';
          configContent += '            kubectl set image deployment/${DEPLOYMENT_NAME} ${CONTAINER_NAME}=${DOCKER_REGISTRY}/${IMAGE_NAME}:${CIRCLE_SHA1}\n';
          configContent += '            kubectl rollout status deployment/${DEPLOYMENT_NAME}\n';
        } else if (circleCIConfig.deployType === 'aws-ecs') {
          configContent += '      - run:\n';
          configContent += '          name: Install AWS CLI\n';
          configContent += '          command: |\n';
          configContent += '            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"\n';
          configContent += '            unzip awscliv2.zip\n';
          configContent += '            sudo ./aws/install\n';
          configContent += '      - run:\n';
          configContent += '          name: Deploy to AWS ECS\n';
          configContent += '          command: |\n';
          configContent += '            aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID\n';
          configContent += '            aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY\n';
          configContent += '            aws configure set default.region $AWS_REGION\n';
          configContent += '            aws ecs update-service --cluster ${ECS_CLUSTER} --service ${ECS_SERVICE} --force-new-deployment\n';
        }
        
        configContent += '\n';
      }
    }
  }
  
  // Configurar workflows
  configContent += 'workflows:\n';
  configContent += '  version: 2\n';
  
  if (circleCIConfig.workflows && Object.keys(circleCIConfig.workflows).length > 0) {
    for (const [workflowName, workflow] of Object.entries(circleCIConfig.workflows)) {
      configContent += `  ${workflowName}:\n`;
      
      if (workflow.triggers) {
        configContent += '    triggers:\n';
        for (const trigger of workflow.triggers) {
          configContent += '      - schedule:\n';
          configContent += `          cron: "${trigger.cron}"\n`;
          configContent += '          filters:\n';
          configContent += '            branches:\n';
          configContent += '              only:\n';
          for (const branch of trigger.branches) {
            configContent += `                - ${branch}\n`;
          }
        }
      }
      
      configContent += '    jobs:\n';
      for (const job of workflow.jobs) {
        if (typeof job === 'string') {
          configContent += `      - ${job}\n`;
        } else {
          for (const [jobName, jobConfig] of Object.entries(job)) {
            configContent += `      - ${jobName}:\n`;
            
            if (jobConfig.context) {
              configContent += '          context:\n';
              for (const context of jobConfig.context) {
                configContent += `            - ${context}\n`;
              }
            }
            
            if (jobConfig.requires) {
              configContent += '          requires:\n';
              for (const req of jobConfig.requires) {
                configContent += `            - ${req}\n`;
              }
            }
            
            if (jobConfig.filters) {
              configContent += '          filters:\n';
              
              if (jobConfig.filters.branches) {
                configContent += '            branches:\n';
                if (jobConfig.filters.branches.only) {
                  configContent += '              only:\n';
                  for (const branch of jobConfig.filters.branches.only) {
                    configContent += `                - ${branch}\n`;
                  }
                }
                if (jobConfig.filters.branches.ignore) {
                  configContent += '              ignore:\n';
                  for (const branch of jobConfig.filters.branches.ignore) {
                    configContent += `                - ${branch}\n`;
                  }
                }
              }
              
              if (jobConfig.filters.tags) {
                configContent += '            tags:\n';
                if (jobConfig.filters.tags.only) {
                  configContent += '              only:\n';
                  for (const tag of jobConfig.filters.tags.only) {
                    configContent += `                - ${tag}\n`;
                  }
                }
                if (jobConfig.filters.tags.ignore) {
                  configContent += '              ignore:\n';
                  for (const tag of jobConfig.filters.tags.ignore) {
                    configContent += `                - ${tag}\n`;
                  }
                }
              }
            }
          }
        }
      }
    }
  } else {
    // Workflow por defecto
    configContent += '  main:\n';
    configContent += '    jobs:\n';
    configContent += '      - build\n';
    configContent += '      - test:\n';
    configContent += '          requires:\n';
    configContent += '            - build\n';
    
    if (circleCIConfig.projectType === 'docker') {
      configContent += '      - push:\n';
      configContent += '          requires:\n';
      configContent += '            - test\n';
      configContent += '          filters:\n';
      configContent += '            branches:\n';
      configContent += '              only: main\n';
      
      if (circleCIConfig.deployType) {
        configContent += '      - deploy:\n';
        configContent += '          requires:\n';
        configContent += '            - push\n';
        configContent += '          filters:\n';
        configContent += '            branches:\n';
        configContent += '              only: main\n';
      }
    } else if (circleCIConfig.deployType) {
      configContent += '      - deploy:\n';
      configContent += '          requires:\n';
      configContent += '            - test\n';
      configContent += '          filters:\n';
      configContent += '            branches:\n';
      configContent += '              only: main\n';
    }
  }
  
  // Escribir archivo de configuración
  fs.writeFileSync(configPath, configContent, 'utf8');
  
  this.logger.debug(`Archivo de configuración de CircleCI creado en: ${configPath}`);
  
  return `Pipeline CI/CD con CircleCI configurado correctamente: ${configPath}`;
}

private async setupGitHubActions(config: any): Promise<string> {
  this.logger.info('Configurando GitHub Actions...');
  
  // Verificar configuración de GitHub Actions
  if (!config.githubActionsConfig) {
    throw new Error('No se ha proporcionado configuración de GitHub Actions para el pipeline CI/CD');
  }
  
  const githubActionsConfig = config.githubActionsConfig;
  const targetPath = config.targetPath || process.cwd();
  
  // Crear directorio .github/workflows si no existe
  const workflowsDir = path.join(targetPath, '.github', 'workflows');
  if (!fs.existsSync(workflowsDir)) {
    fs.mkdirSync(workflowsDir, { recursive: true });
  }
  
  // Crear archivo de workflow
  const workflowName = githubActionsConfig.name || 'ci-cd';
  const workflowPath = path.join(workflowsDir, `${workflowName}.yml`);
  
  // Generar contenido del archivo de workflow
  let workflowContent = '';
  
  // Nombre del workflow
  workflowContent += `name: ${githubActionsConfig.displayName || 'CI/CD Pipeline'}\n\n`;
  
  // Eventos que disparan el workflow
  workflowContent += 'on:\n';
  if (githubActionsConfig.on) {
    for (const [event, config] of Object.entries(githubActionsConfig.on)) {
      workflowContent += `  ${event}:\n`;
      
      if (event === 'push' || event === 'pull_request') {
        if (config.branches) {
          workflowContent += '    branches:\n';
          for (const branch of config.branches) {
            workflowContent += `      - ${branch}\n`;
          }
        }
        if (config.paths) {
          workflowContent += '    paths:\n';
          for (const path of config.paths) {
            workflowContent += `      - '${path}'\n`;
          }
        }
        if (config['paths-ignore']) {
          workflowContent += '    paths-ignore:\n';
          for (const path of config['paths-ignore']) {
            workflowContent += `      - '${path}'\n`;
          }
        }
      } else if (event === 'schedule') {
        workflowContent += '    - cron: ';
        if (typeof config === 'string') {
          workflowContent += `'${config}'\n`;
        } else if (Array.isArray(config)) {
          for (const cron of config) {
            workflowContent += `'${cron}'\n`;
          }
        }
      } else if (event === 'workflow_dispatch') {
        if (config.inputs) {
          workflowContent += '    inputs:\n';
          for (const [inputName, inputConfig] of Object.entries(config.inputs)) {
            workflowContent += `      ${inputName}:\n`;
            workflowContent += `        description: '${inputConfig.description}'\n`;
            workflowContent += `        required: ${inputConfig.required}\n`;
            if (inputConfig.default) {
              workflowContent += `        default: '${inputConfig.default}'\n`;
            }
            if (inputConfig.type) {
              workflowContent += `        type: ${inputConfig.type}\n`;
            }
          }
        }
      }
    }
  } else {
    // Eventos por defecto
    workflowContent += '  push:\n';
    workflowContent += '    branches: [ main, master ]\n';
    workflowContent += '  pull_request:\n';
    workflowContent += '    branches: [ main, master ]\n';
  }
  
  workflowContent += '\n';
  
  // Variables de entorno
  if (githubActionsConfig.env) {
    workflowContent += 'env:\n';
    for (const [key, value] of Object.entries(githubActionsConfig.env)) {
      workflowContent += `  ${key}: ${value}\n`;
    }
    workflowContent += '\n';
  }
  
  // Jobs
  workflowContent += 'jobs:\n';
  
  if (githubActionsConfig.jobs && Object.keys(githubActionsConfig.jobs).length > 0) {
    for (const [jobName, job] of Object.entries(githubActionsConfig.jobs)) {
      workflowContent += `  ${jobName}:\n`;
      
      // Runs-on
      workflowContent += `    runs-on: ${job.runsOn || 'ubuntu-latest'}\n`;
      
      // Needs
      if (job.needs) {
        workflowContent += '    needs: ';
        if (Array.isArray(job.needs)) {
          workflowContent += '[ ';
          workflowContent += job.needs.join(', ');
          workflowContent += ' ]\n';
        } else {
          workflowContent += `${job.needs}\n`;
        }
      }
      
      // Environment
      if (job.environment) {
        if (typeof job.environment === 'string') {
          workflowContent += `    environment: ${job.environment}\n`;
        } else {
          workflowContent += '    environment:\n';
          workflowContent += `      name: ${job.environment.name}\n`;
          if (job.environment.url) {
            workflowContent += `      url: ${job.environment.url}\n`;
          }
        }
      }
      
      // Concurrency
      if (job.concurrency) {
        workflowContent += `    concurrency: ${job.concurrency}\n`;
      }
      
      // Timeout
      if (job.timeout) {
        workflowContent += `    timeout-minutes: ${job.timeout}\n`;
      }
      
      // Strategy
      if (job.strategy) {
        workflowContent += '    strategy:\n';
        
        if (job.strategy.matrix) {
          workflowContent += '      matrix:\n';
          for (const [key, value] of Object.entries(job.strategy.matrix)) {
            if (Array.isArray(value)) {
              workflowContent += `        ${key}: [ `;
              workflowContent += value.map(v => typeof v === 'string' ? `'${v}'` : v).join(', ');
              workflowContent += ' ]\n';
            } else if (typeof value === 'object') {
              workflowContent += `        ${key}:\n`;
              for (const [subKey, subValue] of Object.entries(value)) {
                workflowContent += `          ${subKey}: ${subValue}\n`;
              }
            } else {
              workflowContent += `        ${key}: ${value}\n`;
            }
          }
        }
        
        if (job.strategy['fail-fast'] !== undefined) {
          workflowContent += `      fail-fast: ${job.strategy['fail-fast']}\n`;
        }
        
        if (job.strategy['max-parallel'] !== undefined) {
          workflowContent += `      max-parallel: ${job.strategy['max-parallel']}\n`;
        }
      }
      
      // Container
      if (job.container) {
        if (typeof job.container === 'string') {
          workflowContent += `    container: ${job.container}\n`;
        } else {
          workflowContent += '    container:\n';
          workflowContent += `      image: ${job.container.image}\n`;
          
          if (job.container.env) {
            workflowContent += '      env:\n';
            for (const [key, value] of Object.entries(job.container.env)) {
              workflowContent += `        ${key}: ${value}\n`;
            }
          }
          
          if (job.container.ports) {
            workflowContent += '      ports:\n';
            for (const port of job.container.ports) {
              workflowContent += `        - ${port}\n`;
            }
          }
          
          if (job.container.volumes) {
            workflowContent += '      volumes:\n';
            for (const volume of job.container.volumes) {
              workflowContent += `        - ${volume}\n`;
            }
          }
          
          if (job.container.options) {
            workflowContent += `      options: ${job.container.options}\n`;
          }
        }
      }
      
      // Services
      if (job.services) {
        workflowContent += '    services:\n';
        for (const [serviceName, service] of Object.entries(job.services)) {
          workflowContent += `      ${serviceName}:\n`;
          workflowContent += `        image: ${service.image}\n`;
          
          if (service.env) {
            workflowContent += '        env:\n';
            for (const [key, value] of Object.entries(service.env)) {
              workflowContent += `          ${key}: ${value}\n`;
            }
          }
          
          if (service.ports) {
            workflowContent += '        ports:\n';
            for (const port of service.ports) {
              workflowContent += `          - ${port}\n`;
            }
          }
          
          if (service.volumes) {
            workflowContent += '        volumes:\n';
            for (const volume of service.volumes) {
              workflowContent += `          - ${volume}\n`;
            }
          }
          
          if (service.options) {
            workflowContent += `        options: ${service.options}\n`;
          }
        }
      }
      
      // Steps
      workflowContent += '    steps:\n';
      for (const step of job.steps) {
        workflowContent += '      - ';
        
        if (step.name) {
          workflowContent += `name: ${step.name}\n`;
          workflowContent += '        ';
        }
        
        if (step.uses) {
          workflowContent += `uses: ${step.uses}\n`;
          
          if (step.with) {
            workflowContent += '        with:\n';
            for (const [key, value] of Object.entries(step.with)) {
              workflowContent += `          ${key}: ${value}\n`;
            }
          }
        } else if (step.run) {
          workflowContent += 'run: ';
          
          if (step.run.includes('\n')) {
            workflowContent += '|\n';
            for (const line of step.run.split('\n')) {
              workflowContent += `          ${line}\n`;
            }
          } else {
            workflowContent += `${step.run}\n`;
          }
          
          if (step.shell) {
            workflowContent += `        shell: ${step.shell}\n`;
          }
        }
        
        if (step.id) {
          workflowContent += `        id: ${step.id}\n`;
        }
        
        if (step.if) {
          workflowContent += `        if: ${step.if}\n`;
        }
        
        if (step.env) {
          workflowContent += '        env:\n';
          for (const [key, value] of Object.entries(step.env)) {
            workflowContent += `          ${key}: ${value}\n`;
          }
        }
        
        if (step['continue-on-error'] !== undefined) {
          workflowContent += `        continue-on-error: ${step['continue-on-error']}\n`;
        }
        
        if (step['timeout-minutes'] !== undefined) {
          workflowContent += `        timeout-minutes: ${step['timeout-minutes']}\n`;
        }
      }
    }
  } else {
    // Jobs por defecto según el tipo de proyecto
    if (githubActionsConfig.projectType === 'node') {
      // Job de build
      workflowContent += '  build:\n';
      workflowContent += '    runs-on: ubuntu-latest\n';
      workflowContent += '    steps:\n';
      workflowContent += '      - uses: actions/checkout@v3\n';
      workflowContent += '      - name: Set up Node.js\n';
      workflowContent += '        uses: actions/setup-node@v3\n';
      workflowContent += '        with:\n';
      workflowContent += '          node-version: 18\n';
      workflowContent += '          cache: npm\n';
      workflowContent += '      - name: Install dependencies\n';
      workflowContent += '        run: npm ci\n';
      workflowContent += '      - name: Build\n';
      workflowContent += '        run: npm run build --if-present\n';
      workflowContent += '      - name: Upload build artifacts\n';
      workflowContent += '        uses: actions/upload-artifact@v3\n';
      workflowContent += '        with:\n';
      workflowContent += '          name: build-artifacts\n';
      workflowContent += '          path: dist/\n';
      workflowContent += '\n';
      
      // Job de test
      workflowContent += '  test:\n';
      workflowContent += '    needs: build\n';
      workflowContent += '    runs-on: ubuntu-latest\n';
      workflowContent += '    steps:\n';
      workflowContent += '      - uses: actions/checkout@v3\n';
      workflowContent += '      - name: Set up Node.js\n';
      workflowContent += '        uses: actions/setup-node@v3\n';
      workflowContent += '        with:\n';
      workflowContent += '          node-version: 18\n';
      workflowContent += '          cache: npm\n';
      workflowContent += '      - name: Install dependencies\n';
      workflowContent += '        run: npm ci\n';
      workflowContent += '      - name: Run tests\n';
      workflowContent += '        run: npm test\n';
      workflowContent += '\n';
      
      // Job de deploy
      if (githubActionsConfig.deployType) {
        workflowContent += '  deploy:\n';
        workflowContent += '    needs: test\n';
        workflowContent += '    runs-on: ubuntu-latest\n';
        workflowContent += '    if: github.ref == \'refs/heads/main\' || github.ref == \'refs/heads/master\'\n';
        workflowContent += '    steps:\n';
        workflowContent += '      - uses: actions/checkout@v3\n';
        workflowContent += '      - name: Download build artifacts\n';
        workflowContent += '        uses: actions/download-artifact@v3\n';
        workflowContent += '        with:\n';
        workflowContent += '          name: build-artifacts\n';
        workflowContent += '          path: dist/\n';
        
        if (githubActionsConfig.deployType === 'aws') {
          workflowContent += '      - name: Configure AWS credentials\n';
          workflowContent += '        uses: aws-actions/configure-aws-credentials@v1\n';
          workflowContent += '        with:\n';
          workflowContent += '          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
          workflowContent += '          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
          workflowContent += '          aws-region: ${{ secrets.AWS_REGION }}\n';
          workflowContent += '      - name: Deploy to AWS S3\n';
          workflowContent += '        run: aws s3 sync dist/ s3://${{ secrets.S3_BUCKET }}/\n';
          workflowContent += '      - name: Invalidate CloudFront cache\n';
          workflowContent += '        run: aws cloudfront create-invalidation --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} --paths "/*"\n';
        } else if (githubActionsConfig.deployType === 'azure') {
          workflowContent += '      - name: Deploy to Azure Web App\n';
          workflowContent += '        uses: azure/webapps-deploy@v2\n';
          workflowContent += '        with:\n';
          workflowContent += '          app-name: ${{ secrets.AZURE_WEBAPP_NAME }}\n';
          workflowContent += '          publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE }}\n';
          workflowContent += '          package: dist/\n';
        } else if (githubActionsConfig.deployType === 'gcp') {
          workflowContent += '      - name: Setup Google Cloud SDK\n';
          workflowContent += '        uses: google-github-actions/setup-gcloud@v0\n';
          workflowContent += '        with:\n';
          workflowContent += '          project_id: ${{ secrets.GCP_PROJECT_ID }}\n';
          workflowContent += '          service_account_key: ${{ secrets.GCP_SA_KEY }}\n';
          workflowContent += '      - name: Deploy to Google App Engine\n';
          workflowContent += '        run: gcloud app deploy --quiet\n';
        } else if (githubActionsConfig.deployType === 'heroku') {
          workflowContent += '      - name: Deploy to Heroku\n';
          workflowContent += '        uses: akhileshns/heroku-deploy@v3.12.12\n';
          workflowContent += '        with:\n';
          workflowContent += '          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n';
          workflowContent += '          heroku_app_name: ${{ secrets.HEROKU_APP_NAME }}\n';
          workflowContent += '          heroku_email: ${{ secrets.HEROKU_EMAIL }}\n';
        } else if (githubActionsConfig.deployType === 'vercel') {
          workflowContent += '      - name: Deploy to Vercel\n';
          workflowContent += '        uses: amondnet/vercel-action@v20\n';
          workflowContent += '        with:\n';
          workflowContent += '          vercel-token: ${{ secrets.VERCEL_TOKEN }}\n';
          workflowContent += '          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}\n';
          workflowContent += '          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}\n';
          workflowContent += '          vercel-args: --prod\n';
        } else if (githubActionsConfig.deployType === 'netlify') {
          workflowContent += '      - name: Deploy to Netlify\n';
          workflowContent += '        uses: nwtgck/actions-netlify@v1.2\n';
          workflowContent += '        with:\n';
          workflowContent += '          publish-dir: ./dist\n';
          workflowContent += '          production-branch: main\n';
          workflowContent += '          github-token: ${{ secrets.GITHUB_TOKEN }}\n';
          workflowContent += '          deploy-message: "Deploy from GitHub Actions"\n';
          workflowContent += '        env:\n';
          workflowContent += '          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n';
          workflowContent += '          NETLIFY_SITE_ID: ${{ secrets.NETLIFY_SITE_ID }}\n';
        }
        
        workflowContent += '\n';
      }
    } else if (githubActionsConfig.projectType === 'python') {
      // Job de build
      workflowContent += '  build:\n';
      workflowContent += '    runs-on: ubuntu-latest\n';
      workflowContent += '    steps:\n';
      workflowContent += '      - uses: actions/checkout@v3\n';
      workflowContent += '      - name: Set up Python\n';
      workflowContent += '        uses: actions/setup-python@v4\n';
      workflowContent += '        with:\n';
      workflowContent += '          python-version: 3.9\n';
      workflowContent += '          cache: pip\n';
      workflowContent += '      - name: Install dependencies\n';
      workflowContent += '        run: |\n';
      workflowContent += '          python -m pip install --upgrade pip\n';
      workflowContent += '          pip install -r requirements.txt\n';
      workflowContent += '      - name: Build package\n';
      workflowContent += '        run: |\n';
      workflowContent += '          pip install build\n';
      workflowContent += '          python -m build\n';
      workflowContent += '      - name: Upload build artifacts\n';
      workflowContent += '        uses: actions/upload-artifact@v3\n';
      workflowContent += '        with:\n';
      workflowContent += '          name: python-package\n';
      workflowContent += '          path: dist/\n';
      workflowContent += '\n';
      
      // Job de test
      workflowContent += '  test:\n';
      workflowContent += '    runs-on: ubuntu-latest\n';
      workflowContent += '    steps:\n';
      workflowContent += '      - uses: actions/checkout@v3\n';
      workflowContent += '      - name: Set up Python\n';
      workflowContent += '        uses: actions/setup-python@v4\n';
      workflowContent += '        with:\n';
      workflowContent += '          python-version: 3.9\n';
      workflowContent += '          cache: pip\n';
      workflowContent += '      - name: Install dependencies\n';
      workflowContent += '        run: |\n';
      workflowContent += '          python -m pip install --upgrade pip\n';
      workflowContent += '          pip install -r requirements.txt\n';
      workflowContent += '          pip install pytest pytest-cov\n';
      workflowContent += '      - name: Run tests\n';
      workflowContent += '        run: pytest --cov=./ --cov-report=xml\n';
      workflowContent += '      - name: Upload coverage report\n';
      workflowContent += '        uses: codecov/codecov-action@v3\n';
      workflowContent += '        with:\n';
      workflowContent += '          file: ./coverage.xml\n';
      workflowContent += '\n';
      
      // Job de deploy
      if (githubActionsConfig.deployType) {
        workflowContent += '  deploy:\n';
        workflowContent += '    needs: [build, test]\n';
        workflowContent += '    runs-on: ubuntu-latest\n';
        workflowContent += '    if: github.ref == \'refs/heads/main\' || github.ref == \'refs/heads/master\'\n';
        workflowContent += '    steps:\n';
        workflowContent += '      - uses: actions/checkout@v3\n';
        workflowContent += '      - name: Download build artifacts\n';
        workflowContent += '        uses: actions/download-artifact@v3\n';
        workflowContent += '        with:\n';
        workflowContent += '          name: python-package\n';
        workflowContent += '          path: dist/\n';
        
        if (githubActionsConfig.deployType === 'pypi') {
          workflowContent += '      - name: Publish to PyPI\n';
          workflowContent += '        uses: pypa/gh-action-pypi-publish@release/v1\n';
          workflowContent += '        with:\n';
          workflowContent += '          user: __token__\n';
          workflowContent += '          password: ${{ secrets.PYPI_API_TOKEN }}\n';
        } else if (githubActionsConfig.deployType === 'aws-lambda') {
          workflowContent += '      - name: Configure AWS credentials\n';
          workflowContent += '        uses: aws-actions/configure-aws-credentials@v1\n';
          workflowContent += '        with:\n';
          workflowContent += '          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
          workflowContent += '          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
          workflowContent += '          aws-region: ${{ secrets.AWS_REGION }}\n';
          workflowContent += '      - name: Deploy to AWS Lambda\n';
          workflowContent += '        run: |\n';
          workflowContent += '          zip -j lambda_function.zip lambda_function.py\n';
          workflowContent += '          aws lambda update-function-code --function-name ${{ secrets.LAMBDA_FUNCTION_NAME }} --zip-file fileb://lambda_function.zip\n';
        } else if (githubActionsConfig.deployType === 'heroku') {
          workflowContent += '      - name: Deploy to Heroku\n';
          workflowContent += '        uses: akhileshns/heroku-deploy@v3.12.12\n';
          workflowContent += '        with:\n';
          workflowContent += '          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n';
          workflowContent += '          heroku_app_name: ${{ secrets.HEROKU_APP_NAME }}\n';
          workflowContent += '          heroku_email: ${{ secrets.HEROKU_EMAIL }}\n';
        }
        
        workflowContent += '\n';
      }
    } else if (githubActionsConfig.projectType === 'java') {
      // Job de build
      workflowContent += '  build:\n';
      workflowContent += '    runs-on: ubuntu-latest\n';
      workflowContent += '    steps:\n';
      workflowContent += '      - uses: actions/checkout@v3\n';
      workflowContent += '      - name: Set up JDK\n';
      workflowContent += '        uses: actions/setup-java@v3\n';
      workflowContent += '        with:\n';
      workflowContent += '          java-version: 17\n';
      workflowContent += '          distribution: temurin\n';
      workflowContent += '          cache: maven\n';
      workflowContent += '      - name: Build with Maven\n';
      workflowContent += '        run: mvn -B package --file pom.xml\n';
      workflowContent += '      - name: Upload build artifacts\n';
      workflowContent += '        uses: actions/upload-artifact@v3\n';
      workflowContent += '        with:\n';
      workflowContent += '          name: java-package\n';
      workflowContent += '          path: target/*.jar\n';
      workflowContent += '\n';
      
      // Job de test
      workflowContent += '  test:\n';
      workflowContent += '    runs-on: ubuntu-latest\n';
      workflowContent += '    steps:\n';
      workflowContent += '      - uses: actions/checkout@v3\n';
      workflowContent += '      - name: Set up JDK\n';
      workflowContent += '        uses: actions/setup-java@v3\n';
      workflowContent += '        with:\n';
      workflowContent += '          java-version: 17\n';
      workflowContent += '          distribution: temurin\n';
      workflowContent += '          cache: maven\n';
      workflowContent += '      - name: Test with Maven\n';
      workflowContent += '        run: mvn -B test --file pom.xml\n';
      workflowContent += '\n';
      
      // Job de deploy
      if (githubActionsConfig.deployType) {
        workflowContent += '  deploy:\n';
        workflowContent += '    needs: [build, test]\n';
        workflowContent += '    runs-on: ubuntu-latest\n';
        workflowContent += '    if: github.ref == \'refs/heads/main\' || github.ref == \'refs/heads/master\'\n';
        workflowContent += '    steps:\n';
        workflowContent += '      - uses: actions/checkout@v3\n';
        workflowContent += '      - name: Download build artifacts\n';
        workflowContent += '        uses: actions/download-artifact@v3\n';
        workflowContent += '        with:\n';
        workflowContent += '          name: java-package\n';
        workflowContent += '          path: target/\n';
        
        if (githubActionsConfig.deployType === 'aws-elastic-beanstalk') {
          workflowContent += '      - name: Deploy to AWS Elastic Beanstalk\n';
          workflowContent += '        uses: einaregilsson/beanstalk-deploy@v21\n';
          workflowContent += '        with:\n';
          workflowContent += '          aws_access_key: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
          workflowContent += '          aws_secret_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
          workflowContent += '          application_name: ${{ secrets.EB_APPLICATION_NAME }}\n';
          workflowContent += '          environment_name: ${{ secrets.EB_ENVIRONMENT_NAME }}\n';
          workflowContent += '          version_label: ${{ github.sha }}\n';
          workflowContent += '          region: ${{ secrets.AWS_REGION }}\n';
          workflowContent += '          deployment_package: target/*.jar\n';
        } else if (githubActionsConfig.deployType === 'azure') {
          workflowContent += '      - name: Deploy to Azure Web App\n';
          workflowContent += '        uses: azure/webapps-deploy@v2\n';
          workflowContent += '        with:\n';
          workflowContent += '          app-name: ${{ secrets.AZURE_WEBAPP_NAME }}\n';
          workflowContent += '          publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE }}\n';
          workflowContent += '          package: target/*.jar\n';
        } else if (githubActionsConfig.deployType === 'heroku') {
          workflowContent += '      - name: Deploy to Heroku\n';
          workflowContent += '        uses: akhileshns/heroku-deploy@v3.12.12\n';
          workflowContent += '        with:\n';
          workflowContent += '          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n';
          workflowContent += '          heroku_app_name: ${{ secrets.HEROKU_APP_NAME }}\n';
          workflowContent += '          heroku_email: ${{ secrets.HEROKU_EMAIL }}\n';
          workflowContent += '          justlogin: true\n';
          workflowContent += '      - name: Deploy JAR to Heroku\n';
          workflowContent += '        run: |\n';
          workflowContent += '          heroku plugins:install java\n';
          workflowContent += '          heroku deploy:jar target/*.jar --app ${{ secrets.HEROKU_APP_NAME }}\n';
        }
        
        workflowContent += '\n';
      }
    } else if (githubActionsConfig.projectType === 'docker') {
      // Job de build y push
      workflowContent += '  build-and-push:\n';
      workflowContent += '    runs-on: ubuntu-latest\n';
      workflowContent += '    steps:\n';
      workflowContent += '      - uses: actions/checkout@v3\n';
      workflowContent += '      - name: Set up Docker Buildx\n';
      workflowContent += '        uses: docker/setup-buildx-action@v2\n';
      workflowContent += '      - name: Login to DockerHub\n';
      workflowContent += '        uses: docker/login-action@v2\n';
      workflowContent += '        with:\n';
      workflowContent += '          username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
      workflowContent += '          password: ${{ secrets.DOCKERHUB_TOKEN }}\n';
      workflowContent += '      - name: Build and push\n';
      workflowContent += '        uses: docker/build-push-action@v4\n';
      workflowContent += '        with:\n';
      workflowContent += '          context: .\n';
      workflowContent += '          push: ${{ github.ref == \'refs/heads/main\' || github.ref == \'refs/heads/master\' }}\n';
      workflowContent += '          tags: ${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.IMAGE_NAME }}:latest,${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.IMAGE_NAME }}:${{ github.sha }}\n';
      workflowContent += '          cache-from: type=registry,ref=${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.IMAGE_NAME }}:buildcache\n';
      workflowContent += '          cache-to: type=registry,ref=${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.IMAGE_NAME }}:buildcache,mode=max\n';
      workflowContent += '\n';
      
      // Job de deploy
      if (githubActionsConfig.deployType) {
        workflowContent += '  deploy:\n';
        workflowContent += '    needs: build-and-push\n';
        workflowContent += '    runs-on: ubuntu-latest\n';
        workflowContent += '    if: github.ref == \'refs/heads/main\' || github.ref == \'refs/heads/master\'\n';
        workflowContent += '    steps:\n';
        
        if (githubActionsConfig.deployType === 'kubernetes') {
          workflowContent += '      - uses: actions/checkout@v3\n';
          workflowContent += '      - name: Set up kubectl\n';
          workflowContent += '        uses: azure/setup-kubectl@v3\n';
          workflowContent += '      - name: Set Kubernetes context\n';
          workflowContent += '        uses: azure/k8s-set-context@v3\n';
          workflowContent += '        with:\n';
          workflowContent += '          kubeconfig: ${{ secrets.KUBECONFIG }}\n';
          workflowContent += '      - name: Deploy to Kubernetes\n';
          workflowContent += '        run: |\n';
          workflowContent += '          kubectl set image deployment/${{ secrets.DEPLOYMENT_NAME }} ${{ secrets.CONTAINER_NAME }}=${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.IMAGE_NAME }}:${{ github.sha }}\n';
          workflowContent += '          kubectl rollout status deployment/${{ secrets.DEPLOYMENT_NAME }}\n';
        } else if (githubActionsConfig.deployType === 'aws-ecs') {
          workflowContent += '      - name: Configure AWS credentials\n';
          workflowContent += '        uses: aws-actions/configure-aws-credentials@v1\n';
          workflowContent += '        with:\n';
          workflowContent += '          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
          workflowContent += '          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
          workflowContent += '          aws-region: ${{ secrets.AWS_REGION }}\n';
          workflowContent += '      - name: Deploy to Amazon ECS\n';
          workflowContent += '        uses: aws-actions/amazon-ecs-deploy-task-definition@v1\n';
          workflowContent += '        with:\n';
          workflowContent += '          task-definition: ${{ secrets.ECS_TASK_DEFINITION }}\n';
          workflowContent += '          service: ${{ secrets.ECS_SERVICE }}\n';
          workflowContent += '          cluster: ${{ secrets.ECS_CLUSTER }}\n';
          workflowContent += '          wait-for-service-stability: true\n';
        } else if (githubActionsConfig.deployType === 'azure-container-apps') {
          workflowContent += '      - name: Azure Login\n';
          workflowContent += '        uses: azure/login@v1\n';
          workflowContent += '        with:\n';
          workflowContent += '          creds: ${{ secrets.AZURE_CREDENTIALS }}\n';
          workflowContent += '      - name: Deploy to Azure Container Apps\n';
          workflowContent += '        uses: azure/container-apps-deploy-action@v1\n';
          workflowContent += '        with:\n';
          workflowContent += '          containerAppName: ${{ secrets.CONTAINER_APP_NAME }}\n';
          workflowContent += '          resourceGroup: ${{ secrets.RESOURCE_GROUP }}\n';
          workflowContent += '          imageToDeploy: ${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.IMAGE_NAME }}:${{ github.sha }}\n';
        }
        
        workflowContent += '\n';
      }
    }
  }
  
  // Escribir archivo de workflow
  fs.writeFileSync(workflowPath, workflowContent, 'utf8');
  
  this.logger.debug(`Archivo de workflow de GitHub Actions creado en: ${workflowPath}`);
  
  return `Pipeline CI/CD con GitHub Actions configurado correctamente: ${workflowPath}`;
}

private async setupJenkins(config: any): Promise<string> {
  this.logger.info('Configurando Jenkins...');
  
  // Verificar configuración de Jenkins
  if (!config.jenkinsConfig) {
    throw new Error('No se ha proporcionado configuración de Jenkins para el pipeline CI/CD');
  }
  
  const jenkinsConfig = config.jenkinsConfig;
  const targetPath = config.targetPath || process.cwd();
  
  // Crear archivo Jenkinsfile
  const jenkinsfilePath = path.join(targetPath, 'Jenkinsfile');
  
  // Generar contenido del Jenkinsfile
  let jenkinsfileContent = '';
  
  // Pipeline
  jenkinsfileContent += 'pipeline {\n';
  
  // Agent
  jenkinsfileContent += '  agent {\n';
  if (jenkinsConfig.agent && jenkinsConfig.agent.type) {
    if (jenkinsConfig.agent.type === 'any') {
      jenkinsfileContent += '    any\n';
    } else if (jenkinsConfig.agent.type === 'none') {
      jenkinsfileContent += '    none\n';
    } else if (jenkinsConfig.agent.type === 'label') {
      jenkinsfileContent += `    label '${jenkinsConfig.agent.label}'\n`;
    } else if (jenkinsConfig.agent.type === 'docker') {
      jenkinsfileContent += '    docker {\n';
      jenkinsfileContent += `      image '${jenkinsConfig.agent.image}'\n`;
      if (jenkinsConfig.agent.args) {
        jenkinsfileContent += `      args '${jenkinsConfig.agent.args}'\n`;
      }
      jenkinsfileContent += '    }\n';
    } else if (jenkinsConfig.agent.type === 'kubernetes') {
      jenkinsfileContent += '    kubernetes {\n';
      jenkinsfileContent += `      yaml '''\n${jenkinsConfig.agent.yaml}\n'''\n`;
      jenkinsfileContent += '    }\n';
    }
  } else {
    jenkinsfileContent += '    any\n';
  }
  jenkinsfileContent += '  }\n\n';
  
  // Options
  if (jenkinsConfig.options) {
    jenkinsfileContent += '  options {\n';
    
    if (jenkinsConfig.options.timeout) {
      jenkinsfileContent += `    timeout(time: ${jenkinsConfig.options.timeout.time}, unit: '${jenkinsConfig.options.timeout.unit}')\n`;
    }
    
    if (jenkinsConfig.options.disableConcurrentBuilds) {
      jenkinsfileContent += '    disableConcurrentBuilds()\n';
    }
    
    if (jenkinsConfig.options.buildDiscarder) {
      jenkinsfileContent += `    buildDiscarder(logRotator(numToKeepStr: '${jenkinsConfig.options.buildDiscarder.numToKeepStr}'))\n`;
    }
    
    if (jenkinsConfig.options.timestamps) {
      jenkinsfileContent += '    timestamps()\n';
    }
    
    jenkinsfileContent += '  }\n\n';
  }
  
  // Triggers
  if (jenkinsConfig.triggers) {
    jenkinsfileContent += '  triggers {\n';
    
    if (jenkinsConfig.triggers.cron) {
      jenkinsfileContent += `    cron('${jenkinsConfig.triggers.cron}')\n`;
    }
    
    if (jenkinsConfig.triggers.pollSCM) {
      jenkinsfileContent += `    pollSCM('${jenkinsConfig.triggers.pollSCM}')\n`;
    }
    
    if (jenkinsConfig.triggers.upstream) {
      jenkinsfileContent += `    upstream(upstreamProjects: '${jenkinsConfig.triggers.upstream.upstreamProjects}', threshold: ${jenkinsConfig.triggers.upstream.threshold})\n`;
    }
    
    jenkinsfileContent += '  }\n\n';
  }
  
  // Parameters
  if (jenkinsConfig.parameters && jenkinsConfig.parameters.length > 0) {
    jenkinsfileContent += '  parameters {\n';
    
    for (const param of jenkinsConfig.parameters) {
      if (param.type === 'string') {
        jenkinsfileContent += `    string(name: '${param.name}', defaultValue: '${param.defaultValue}', description: '${param.description}')\n`;
      } else if (param.type === 'text') {
        jenkinsfileContent += `    text(name: '${param.name}', defaultValue: '${param.defaultValue}', description: '${param.description}')\n`;
      } else if (param.type === 'booleanParam') {
        jenkinsfileContent += `    booleanParam(name: '${param.name}', defaultValue: ${param.defaultValue}, description: '${param.description}')\n`;
      } else if (param.type === 'choice') {
        jenkinsfileContent += `    choice(name: '${param.name}', choices: ${JSON.stringify(param.choices)}, description: '${param.description}')\n`;
      } else if (param.type === 'password') {
        jenkinsfileContent += `    password(name: '${param.name}', defaultValue: '${param.defaultValue}', description: '${param.description}')\n`;
      }
    }
    
    jenkinsfileContent += '  }\n\n';
  }
  
  // Environment
  if (jenkinsConfig.environment && Object.keys(jenkinsConfig.environment).length > 0) {
    jenkinsfileContent += '  environment {\n';
    
    for (const [key, value] of Object.entries(jenkinsConfig.environment)) {
      jenkinsfileContent += `    ${key} = '${value}'\n`;
    }
    
    jenkinsfileContent += '  }\n\n';
  }
  
  // Stages
  jenkinsfileContent += '  stages {\n';
  
  if (jenkinsConfig.stages && jenkinsConfig.stages.length > 0) {
    // Usar las etapas definidas en la configuración
    for (const stage of jenkinsConfig.stages) {
      jenkinsfileContent += `    stage('${stage.name}') {\n`;
      
      if (stage.agent) {
        jenkinsfileContent += '      agent {\n';
        if (stage.agent.type === 'any') {
          jenkinsfileContent += '        any\n';
        } else if (stage.agent.type === 'none') {
          jenkinsfileContent += '        none\n';
        } else if (stage.agent.type === 'label') {
          jenkinsfileContent += `        label '${stage.agent.label}'\n`;
        } else if (stage.agent.type === 'docker') {
          jenkinsfileContent += '        docker {\n';
          jenkinsfileContent += `          image '${stage.agent.image}'\n`;
          if (stage.agent.args) {
            jenkinsfileContent += `          args '${stage.agent.args}'\n`;
          }
          jenkinsfileContent += '        }\n';
        }
        jenkinsfileContent += '      }\n';
      }
      
      if (stage.when) {
        jenkinsfileContent += '      when {\n';
        if (stage.when.branch) {
          jenkinsfileContent += `        branch '${stage.when.branch}'\n`;
        }
        if (stage.when.expression) {
          jenkinsfileContent += `        expression { return ${stage.when.expression} }\n`;
        }
        jenkinsfileContent += '      }\n';
      }
      
      jenkinsfileContent += '      steps {\n';
      for (const step of stage.steps) {
        jenkinsfileContent += `        ${step}\n`;
      }
      jenkinsfileContent += '      }\n';
      
      if (stage.post) {
        jenkinsfileContent += '      post {\n';
        if (stage.post.success) {
          jenkinsfileContent += '        success {\n';
          for (const step of stage.post.success) {
            jenkinsfileContent += `          ${step}\n`;
          }
          jenkinsfileContent += '        }\n';
        }
        if (stage.post.failure) {
          jenkinsfileContent += '        failure {\n';
          for (const step of stage.post.failure) {
            jenkinsfileContent += `          ${step}\n`;
          }
          jenkinsfileContent += '        }\n';
        }
        if (stage.post.always) {
          jenkinsfileContent += '        always {\n';
          for (const step of stage.post.always) {
            jenkinsfileContent += `          ${step}\n`;
          }
          jenkinsfileContent += '        }\n';
        }
        jenkinsfileContent += '      }\n';
      }
      
      jenkinsfileContent += '    }\n\n';
    }
  } else {
    // Etapas por defecto según el tipo de proyecto
    if (jenkinsConfig.projectType === 'node') {
      // Etapa de checkout
      jenkinsfileContent += '    stage(\'Checkout\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        checkout scm\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de instalación de dependencias
      jenkinsfileContent += '    stage(\'Install Dependencies\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'npm ci\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de linting
      jenkinsfileContent += '    stage(\'Lint\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'npm run lint\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de pruebas
      jenkinsfileContent += '    stage(\'Test\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'npm test\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '      post {\n';
      jenkinsfileContent += '        always {\n';
      jenkinsfileContent += '          junit \'**/test-results.xml\'\n';
      jenkinsfileContent += '        }\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de construcción
      jenkinsfileContent += '    stage(\'Build\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'npm run build\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de despliegue
      if (jenkinsConfig.deployType) {
        jenkinsfileContent += '    stage(\'Deploy\') {\n';
        jenkinsfileContent += '      when {\n';
        jenkinsfileContent += '        branch \'main\'\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '      steps {\n';
        
        if (jenkinsConfig.deployType === 'aws') {
          jenkinsfileContent += '        withAWS(credentials: \'aws-credentials\', region: \'us-east-1\') {\n';
          jenkinsfileContent += '          sh \'aws s3 sync dist/ s3://my-bucket/\'\n';
          jenkinsfileContent += '          sh \'aws cloudfront create-invalidation --distribution-id DISTRIBUTION_ID --paths "/*"\'\n';
          jenkinsfileContent += '        }\n';
        } else if (jenkinsConfig.deployType === 'azure') {
          jenkinsfileContent += '        withCredentials([azureServicePrincipal(\'azure-credentials\')]) {\n';
          jenkinsfileContent += '          sh \'az webapp deployment source config-zip --resource-group my-resource-group --name my-app-name --src dist.zip\'\n';
          jenkinsfileContent += '        }\n';
        } else if (jenkinsConfig.deployType === 'heroku') {
          jenkinsfileContent += '        withCredentials([string(credentialsId: \'heroku-api-key\', variable: \'HEROKU_API_KEY\')]) {\n';
          jenkinsfileContent += '          sh \'heroku container:push web -a my-heroku-app\'\n';
          jenkinsfileContent += '          sh \'heroku container:release web -a my-heroku-app\'\n';
          jenkinsfileContent += '        }\n';
        }
        
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '    }\n\n';
      }
    } else if (jenkinsConfig.projectType === 'python') {
      // Etapa de checkout
      jenkinsfileContent += '    stage(\'Checkout\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        checkout scm\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de configuración del entorno
      jenkinsfileContent += '    stage(\'Setup Environment\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'python -m venv venv\'\n';
      jenkinsfileContent += '        sh \'source venv/bin/activate && pip install -r requirements.txt\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de linting
      jenkinsfileContent += '    stage(\'Lint\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'source venv/bin/activate && flake8\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de pruebas
      jenkinsfileContent += '    stage(\'Test\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'source venv/bin/activate && pytest --junitxml=test-results.xml\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '      post {\n';
      jenkinsfileContent += '        always {\n';
      jenkinsfileContent += '          junit \'test-results.xml\'\n';
      jenkinsfileContent += '        }\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de construcción
      jenkinsfileContent += '    stage(\'Build\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'source venv/bin/activate && python setup.py sdist bdist_wheel\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de despliegue
      if (jenkinsConfig.deployType) {
        jenkinsfileContent += '    stage(\'Deploy\') {\n';
        jenkinsfileContent += '      when {\n';
        jenkinsfileContent += '        branch \'main\'\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '      steps {\n';
        
        if (jenkinsConfig.deployType === 'pypi') {
          jenkinsfileContent += '        withCredentials([string(credentialsId: \'pypi-token\', variable: \'PYPI_TOKEN\')]) {\n';
          jenkinsfileContent += '          sh \'source venv/bin/activate && twine upload --username __token__ --password $PYPI_TOKEN dist/*\'\n';
          jenkinsfileContent += '        }\n';
        } else if (jenkinsConfig.deployType === 'aws-lambda') {
          jenkinsfileContent += '        withAWS(credentials: \'aws-credentials\', region: \'us-east-1\') {\n';
          jenkinsfileContent += '          sh \'zip -r lambda_function.zip lambda_function.py\'\n';
          jenkinsfileContent += '          sh \'aws lambda update-function-code --function-name my-lambda-function --zip-file fileb://lambda_function.zip\'\n';
          jenkinsfileContent += '        }\n';
        } else if (jenkinsConfig.deployType === 'heroku') {
          jenkinsfileContent += '        withCredentials([string(credentialsId: \'heroku-api-key\', variable: \'HEROKU_API_KEY\')]) {\n';
          jenkinsfileContent += '          sh \'git push https://heroku:$HEROKU_API_KEY@git.heroku.com/my-heroku-app.git HEAD:main\'\n';
          jenkinsfileContent += '        }\n';
        }
        
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '    }\n\n';
      }
    } else if (jenkinsConfig.projectType === 'java') {
      // Etapa de checkout
      jenkinsfileContent += '    stage(\'Checkout\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        checkout scm\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de compilación
      jenkinsfileContent += '    stage(\'Compile\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'./mvnw compile\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de pruebas
      jenkinsfileContent += '    stage(\'Test\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'./mvnw test\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '      post {\n';
      jenkinsfileContent += '        always {\n';
      jenkinsfileContent += '          junit \'**/target/surefire-reports/TEST-*.xml\'\n';
      jenkinsfileContent += '        }\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de empaquetado
      jenkinsfileContent += '    stage(\'Package\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'./mvnw package -DskipTests\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de despliegue
      if (jenkinsConfig.deployType) {
        jenkinsfileContent += '    stage(\'Deploy\') {\n';
        jenkinsfileContent += '      when {\n';
        jenkinsfileContent += '        branch \'main\'\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '      steps {\n';
        
        if (jenkinsConfig.deployType === 'aws-elastic-beanstalk') {
          jenkinsfileContent += '        withAWS(credentials: \'aws-credentials\', region: \'us-east-1\') {\n';
          jenkinsfileContent += '          sh \'aws s3 cp target/*.jar s3://elasticbeanstalk-deployment-bucket/\'\n';
          jenkinsfileContent += '          sh \'aws elasticbeanstalk create-application-version --application-name my-app --version-label $BUILD_NUMBER --source-bundle S3Bucket=elasticbeanstalk-deployment-bucket,S3Key=my-app.jar\'\n';
          jenkinsfileContent += '          sh \'aws elasticbeanstalk update-environment --environment-name my-env --version-label $BUILD_NUMBER\'\n';
          jenkinsfileContent += '        }\n';
        } else if (jenkinsConfig.deployType === 'azure') {
          jenkinsfileContent += '        withCredentials([azureServicePrincipal(\'azure-credentials\')]) {\n';
          jenkinsfileContent += '          sh \'az webapp deploy --resource-group my-resource-group --name my-app-name --src-path target/*.jar\'\n';
          jenkinsfileContent += '        }\n';
        } else if (jenkinsConfig.deployType === 'heroku') {
          jenkinsfileContent += '        withCredentials([string(credentialsId: \'heroku-api-key\', variable: \'HEROKU_API_KEY\')]) {\n';
          jenkinsfileContent += '          sh \'heroku plugins:install java\'\n';
          jenkinsfileContent += '          sh \'heroku deploy:jar target/*.jar --app my-heroku-app\'\n';
          jenkinsfileContent += '        }\n';
        }
        
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '    }\n\n';
      }
    } else if (jenkinsConfig.projectType === 'docker') {
      // Etapa de checkout
      jenkinsfileContent += '    stage(\'Checkout\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        checkout scm\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de construcción de imagen
      jenkinsfileContent += '    stage(\'Build Image\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'docker build -t my-image:$BUILD_NUMBER .\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de pruebas
      jenkinsfileContent += '    stage(\'Test\') {\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        sh \'docker run --rm my-image:$BUILD_NUMBER npm test\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de publicación de imagen
      jenkinsfileContent += '    stage(\'Publish Image\') {\n';
      jenkinsfileContent += '      when {\n';
      jenkinsfileContent += '        branch \'main\'\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '      steps {\n';
      jenkinsfileContent += '        withCredentials([usernamePassword(credentialsId: \'docker-hub-credentials\', usernameVariable: \'DOCKER_USERNAME\', passwordVariable: \'DOCKER_PASSWORD\')]) {\n';
      jenkinsfileContent += '          sh \'echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin\'\n';
      jenkinsfileContent += '          sh \'docker tag my-image:$BUILD_NUMBER $DOCKER_USERNAME/my-image:latest\'\n';
      jenkinsfileContent += '          sh \'docker tag my-image:$BUILD_NUMBER $DOCKER_USERNAME/my-image:$BUILD_NUMBER\'\n';
      jenkinsfileContent += '          sh \'docker push $DOCKER_USERNAME/my-image:latest\'\n';
      jenkinsfileContent += '          sh \'docker push $DOCKER_USERNAME/my-image:$BUILD_NUMBER\'\n';
      jenkinsfileContent += '        }\n';
      jenkinsfileContent += '      }\n';
      jenkinsfileContent += '    }\n\n';
      
      // Etapa de despliegue
      if (jenkinsConfig.deployType) {
        jenkinsfileContent += '    stage(\'Deploy\') {\n';
        jenkinsfileContent += '      when {\n';
        jenkinsfileContent += '        branch \'main\'\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '      steps {\n';
        
        if (jenkinsConfig.deployType === 'kubernetes') {
          jenkinsfileContent += '        withKubeConfig([credentialsId: \'kubeconfig\']) {\n';
          jenkinsfileContent += '          sh \'kubectl set image deployment/my-deployment my-container=$DOCKER_USERNAME/my-image:$BUILD_NUMBER\'\n';
          jenkinsfileContent += '          sh \'kubectl rollout status deployment/my-deployment\'\n';
          jenkinsfileContent += '        }\n';
        } else if (jenkinsConfig.deployType === 'aws-ecs') {
          jenkinsfileContent += '        withAWS(credentials: \'aws-credentials\', region: \'us-east-1\') {\n';
          jenkinsfileContent += '          sh \'aws ecs update-service --cluster my-cluster --service my-service --force-new-deployment\'\n';
          jenkinsfileContent += '        }\n';
        } else if (jenkinsConfig.deployType === 'azure-container-apps') {
          jenkinsfileContent += '        withCredentials([azureServicePrincipal(\'azure-credentials\')]) {\n';
          jenkinsfileContent += '          sh \'az containerapp update --name my-container-app --resource-group my-resource-group --image $DOCKER_USERNAME/my-image:$BUILD_NUMBER\'\n';
          jenkinsfileContent += '        }\n';
        }
        
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '    }\n\n';
      }
    }
  }
  
  jenkinsfileContent += '  }\n\n';
  
  // Post
  if (jenkinsConfig.post) {
    jenkinsfileContent += '  post {\n';
    
    if (jenkinsConfig.post.success) {
      jenkinsfileContent += '    success {\n';
      for (const step of jenkinsConfig.post.success) {
        jenkinsfileContent += `      ${step}\n`;
      }
      jenkinsfileContent += '    }\n';
    }
    
    if (jenkinsConfig.post.failure) {
      jenkinsfileContent += '    failure {\n';
      for (const step of jenkinsConfig.post.failure) {
        jenkinsfileContent += `      ${step}\n`;
      }
      jenkinsfileContent += '    }\n';
    }
    
    if (jenkinsConfig.post.always) {
      jenkinsfileContent += '    always {\n';
      for (const step of jenkinsConfig.post.always) {
        jenkinsfileContent += `      ${step}\n`;
      }
      jenkinsfileContent += '    }\n';
    }
    
    jenkinsfileContent += '  }\n';
  } else {
    // Post por defecto
    jenkinsfileContent += '  post {\n';
    jenkinsfileContent += '    success {\n';
    jenkinsfileContent += '      echo \'Pipeline ejecutado con éxito\'\n';
    jenkinsfileContent += '    }\n';
    jenkinsfileContent += '    failure {\n';
    jenkinsfileContent += '      echo \'Pipeline fallido\'\n';
    jenkinsfileContent += '    }\n';
    jenkinsfileContent += '    always {\n';
    jenkinsfileContent += '      cleanWs()\n';
    jenkinsfileContent += '    }\n';
    jenkinsfileContent += '  }\n';
  }
  
  jenkinsfileContent += '}\n';
  
  // Escribir archivo Jenkinsfile
  fs.writeFileSync(jenkinsfilePath, jenkinsfileContent, 'utf8');
  
  this.logger.debug(`Archivo Jenkinsfile creado en: ${jenkinsfilePath}`);
  
  return `Pipeline CI/CD con Jenkins configurado correctamente: ${jenkinsfilePath}`;
}

private async setupAzureDevOps(config: any): Promise<string> {
  this.logger.info('Configurando Azure DevOps...');
  
  // Verificar configuración de Azure DevOps
  if (!config.azureDevOpsConfig) {
    throw new Error('No se ha proporcionado configuración de Azure DevOps para el pipeline CI/CD');
  }
  
  const azureDevOpsConfig = config.azureDevOpsConfig;
  const targetPath = config.targetPath || process.cwd();
  
  // Crear directorio .azure-pipelines si no existe
  const azurePipelinesDir = path.join(targetPath, '.azure-pipelines');
  if (!fs.existsSync(azurePipelinesDir)) {
    fs.mkdirSync(azurePipelinesDir, { recursive: true });
  }
  
  // Crear archivo de pipeline principal
  const pipelinePath = path.join(targetPath, 'azure-pipelines.yml');
  
  // Generar contenido del pipeline
  let pipelineContent = '';
  
  // Trigger
  pipelineContent += 'trigger:\n';
  if (azureDevOpsConfig.trigger && azureDevOpsConfig.trigger.branches) {
    pipelineContent += '  branches:\n';
    pipelineContent += '    include:\n';
    for (const branch of azureDevOpsConfig.trigger.branches.include || ['main']) {
      pipelineContent += `    - ${branch}\n`;
    }
    if (azureDevOpsConfig.trigger.branches.exclude) {
      pipelineContent += '    exclude:\n';
      for (const branch of azureDevOpsConfig.trigger.branches.exclude) {
        pipelineContent += `    - ${branch}\n`;
      }
    }
  } else {
    pipelineContent += '  branches:\n';
    pipelineContent += '    include:\n';
    pipelineContent += '    - main\n';
  }
  pipelineContent += '\n';
  
  // PR trigger
  if (azureDevOpsConfig.pr) {
    pipelineContent += 'pr:\n';
    if (azureDevOpsConfig.pr.branches) {
      pipelineContent += '  branches:\n';
      pipelineContent += '    include:\n';
      for (const branch of azureDevOpsConfig.pr.branches.include || ['main']) {
        pipelineContent += `    - ${branch}\n`;
      }
      if (azureDevOpsConfig.pr.branches.exclude) {
        pipelineContent += '    exclude:\n';
        for (const branch of azureDevOpsConfig.pr.branches.exclude) {
          pipelineContent += `    - ${branch}\n`;
        }
      }
    } else {
      pipelineContent += '  branches:\n';
      pipelineContent += '    include:\n';
      pipelineContent += '    - main\n';
    }
    pipelineContent += '\n';
  }
  
  // Pool
  pipelineContent += 'pool:\n';
  if (azureDevOpsConfig.pool) {
    if (azureDevOpsConfig.pool.vmImage) {
      pipelineContent += `  vmImage: '${azureDevOpsConfig.pool.vmImage}'\n`;
    } else if (azureDevOpsConfig.pool.name) {
      pipelineContent += `  name: '${azureDevOpsConfig.pool.name}'\n`;
      if (azureDevOpsConfig.pool.demands) {
        pipelineContent += '  demands:\n';
        for (const demand of azureDevOpsConfig.pool.demands) {
          pipelineContent += `  - ${demand}\n`;
        }
      }
    }
  } else {
    pipelineContent += "  vmImage: 'ubuntu-latest'\n";
  }
  pipelineContent += '\n';
  
  // Variables
  if (azureDevOpsConfig.variables && Object.keys(azureDevOpsConfig.variables).length > 0) {
    pipelineContent += 'variables:\n';
    for (const [key, value] of Object.entries(azureDevOpsConfig.variables)) {
      pipelineContent += `  ${key}: '${value}'\n`;
    }
    pipelineContent += '\n';
  }
  
  // Stages
  pipelineContent += 'stages:\n';
  
  if (azureDevOpsConfig.stages && azureDevOpsConfig.stages.length > 0) {
    // Usar las etapas definidas en la configuración
    for (const stage of azureDevOpsConfig.stages) {
      pipelineContent += `- stage: ${stage.name}\n`;
      pipelineContent += '  displayName: ' + (stage.displayName || stage.name) + '\n';
      
      if (stage.condition) {
        pipelineContent += `  condition: ${stage.condition}\n`;
      }
      
      if (stage.dependsOn) {
        pipelineContent += '  dependsOn:\n';
        for (const dependency of stage.dependsOn) {
          pipelineContent += `  - ${dependency}\n`;
        }
      }
      
      pipelineContent += '  jobs:\n';
      
      for (const job of stage.jobs) {
        pipelineContent += `  - job: ${job.name}\n`;
        pipelineContent += '    displayName: ' + (job.displayName || job.name) + '\n';
        
        if (job.condition) {
          pipelineContent += `    condition: ${job.condition}\n`;
        }
        
        if (job.dependsOn) {
          pipelineContent += '    dependsOn:\n';
          for (const dependency of job.dependsOn) {
            pipelineContent += `    - ${dependency}\n`;
          }
        }
        
        if (job.pool) {
          pipelineContent += '    pool:\n';
          if (job.pool.vmImage) {
            pipelineContent += `      vmImage: '${job.pool.vmImage}'\n`;
          } else if (job.pool.name) {
            pipelineContent += `      name: '${job.pool.name}'\n`;
            if (job.pool.demands) {
              pipelineContent += '      demands:\n';
              for (const demand of job.pool.demands) {
                pipelineContent += `      - ${demand}\n`;
              }
            }
          }
        }
        
        if (job.variables && Object.keys(job.variables).length > 0) {
          pipelineContent += '    variables:\n';
          for (const [key, value] of Object.entries(job.variables)) {
            pipelineContent += `      ${key}: '${value}'\n`;
          }
        }
        
        pipelineContent += '    steps:\n';
        for (const step of job.steps) {
          pipelineContent += `    - ${step.task}:\n`;
          for (const [key, value] of Object.entries(step.inputs)) {
            pipelineContent += `        ${key}: '${value}'\n`;
          }
          if (step.displayName) {
            pipelineContent += `      displayName: '${step.displayName}'\n`;
          }
          if (step.condition) {
            pipelineContent += `      condition: ${step.condition}\n`;
          }
        }
      }
      
      pipelineContent += '\n';
    }
  } else {
        // Etapas por defecto según el tipo
        if (azureDevOpsConfig.projectType === 'node') {
          // Etapa de construcción
          pipelineContent += '- stage: Build\n';
          pipelineContent += '  displayName: Build and Test\n';
          pipelineContent += '  jobs:\n';
          pipelineContent += '  - job: BuildJob\n';
          pipelineContent += '    displayName: Build and Test\n';
          pipelineContent += '    steps:\n';
          pipelineContent += '    - task: NodeTool@0\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        versionSpec: \'16.x\'\n';
          pipelineContent += '      displayName: \'Install Node.js\'\n';
          pipelineContent += '    - script: npm ci\n';
          pipelineContent += '      displayName: \'Install dependencies\'\n';
          pipelineContent += '    - script: npm run lint\n';
          pipelineContent += '      displayName: \'Run linting\'\n';
          pipelineContent += '    - script: npm test\n';
          pipelineContent += '      displayName: \'Run tests\'\n';
          pipelineContent += '    - script: npm run build\n';
          pipelineContent += '      displayName: \'Build\'\n';
          pipelineContent += '    - task: PublishTestResults@2\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        testResultsFormat: \'JUnit\'\n';
          pipelineContent += '        testResultsFiles: \'**/test-results.xml\'\n';
          pipelineContent += '      displayName: \'Publish test results\'\n';
          pipelineContent += '      condition: succeededOrFailed()\n';
          pipelineContent += '    - task: PublishBuildArtifacts@1\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        pathToPublish: \'$(System.DefaultWorkingDirectory)/dist\'\n';
          pipelineContent += '        artifactName: \'drop\'\n';
          pipelineContent += '        publishLocation: \'Container\'\n';
          pipelineContent += '      displayName: \'Publish build artifacts\'\n';
          
          // Etapa de despliegue
          if (azureDevOpsConfig.deployType) {
            pipelineContent += '- stage: Deploy\n';
            pipelineContent += '  displayName: Deploy\n';
            pipelineContent += '  dependsOn: Build\n';
            pipelineContent += '  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\n';
            pipelineContent += '  jobs:\n';
            pipelineContent += '  - job: DeployJob\n';
            pipelineContent += '    displayName: Deploy\n';
            pipelineContent += '    steps:\n';
            
            if (azureDevOpsConfig.deployType === 'azure-web-app') {
              pipelineContent += '    - task: AzureWebApp@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        azureSubscription: \'$(AZURE_SUBSCRIPTION)\'\n';
              pipelineContent += '        appType: \'webAppLinux\'\n';
              pipelineContent += '        appName: \'$(WEB_APP_NAME)\'\n';
              pipelineContent += '        package: \'$(Pipeline.Workspace)/drop\'\n';
              pipelineContent += '      displayName: \'Deploy to Azure Web App\'\n';
            } else if (azureDevOpsConfig.deployType === 'aws-s3') {
              pipelineContent += '    - task: AWSCLIInstall@1\n';
              pipelineContent += '      displayName: \'Install AWS CLI\'\n';
              pipelineContent += '    - task: S3Upload@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        awsCredentials: \'$(AWS_CREDENTIALS)\'\n';
              pipelineContent += '        regionName: \'$(AWS_REGION)\'\n';
              pipelineContent += '        bucketName: \'$(S3_BUCKET)\'\n';
              pipelineContent += '        sourceFolder: \'$(Pipeline.Workspace)/drop\'\n';
              pipelineContent += '        globExpressions: \'**\'\n';
              pipelineContent += '      displayName: \'Upload to S3\'\n';
              pipelineContent += '    - task: AWSCLI@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        awsCredentials: \'$(AWS_CREDENTIALS)\'\n';
              pipelineContent += '        regionName: \'$(AWS_REGION)\'\n';
              pipelineContent += '        awsCommand: \'cloudfront\'\n';
              pipelineContent += '        awsSubCommand: \'create-invalidation\'\n';
              pipelineContent += '        awsArguments: \'--distribution-id $(CLOUDFRONT_DISTRIBUTION_ID) --paths "/*"\'\n';
              pipelineContent += '      displayName: \'Invalidate CloudFront cache\'\n';
            } else if (azureDevOpsConfig.deployType === 'heroku') {
              pipelineContent += '    - script: |\n';
              pipelineContent += '        curl https://cli-assets.heroku.com/install.sh | sh\n';
              pipelineContent += '        heroku container:login\n';
              pipelineContent += '        heroku container:push web -a $(HEROKU_APP_NAME)\n';
              pipelineContent += '        heroku container:release web -a $(HEROKU_APP_NAME)\n';
              pipelineContent += '      env:\n';
              pipelineContent += '        HEROKU_API_KEY: $(HEROKU_API_KEY)\n';
              pipelineContent += '      displayName: \'Deploy to Heroku\'\n';
            }
          }
        } else if (azureDevOpsConfig.projectType === 'python') {
          // Etapa de construcción
          pipelineContent += '- stage: Build\n';
          pipelineContent += '  displayName: Build and Test\n';
          pipelineContent += '  jobs:\n';
          pipelineContent += '  - job: BuildJob\n';
          pipelineContent += '    displayName: Build and Test\n';
          pipelineContent += '    steps:\n';
          pipelineContent += '    - task: UsePythonVersion@0\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        versionSpec: \'3.9\'\n';
          pipelineContent += '        addToPath: true\n';
          pipelineContent += '      displayName: \'Install Python\'\n';
          pipelineContent += '    - script: |\n';
          pipelineContent += '        python -m pip install --upgrade pip\n';
          pipelineContent += '        pip install -r requirements.txt\n';
          pipelineContent += '      displayName: \'Install dependencies\'\n';
          pipelineContent += '    - script: |\n';
          pipelineContent += '        pip install flake8\n';
          pipelineContent += '        flake8 .\n';
          pipelineContent += '      displayName: \'Run linting\'\n';
          pipelineContent += '    - script: |\n';
          pipelineContent += '        pip install pytest pytest-azurepipelines\n';
          pipelineContent += '        pytest\n';
          pipelineContent += '      displayName: \'Run tests\'\n';
          pipelineContent += '    - script: |\n';
          pipelineContent += '        pip install wheel\n';
          pipelineContent += '        python setup.py sdist bdist_wheel\n';
          pipelineContent += '      displayName: \'Build package\'\n';
          pipelineContent += '    - task: PublishBuildArtifacts@1\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        pathToPublish: \'$(System.DefaultWorkingDirectory)/dist\'\n';
          pipelineContent += '        artifactName: \'dist\'\n';
          pipelineContent += '        publishLocation: \'Container\'\n';
          pipelineContent += '      displayName: \'Publish build artifacts\'\n';
          
          // Etapa de despliegue
          if (azureDevOpsConfig.deployType) {
            pipelineContent += '- stage: Deploy\n';
            pipelineContent += '  displayName: Deploy\n';
            pipelineContent += '  dependsOn: Build\n';
            pipelineContent += '  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\n';
            pipelineContent += '  jobs:\n';
            pipelineContent += '  - job: DeployJob\n';
            pipelineContent += '    displayName: Deploy\n';
            pipelineContent += '    steps:\n';
            
            if (azureDevOpsConfig.deployType === 'pypi') {
              pipelineContent += '    - task: UsePythonVersion@0\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        versionSpec: \'3.9\'\n';
              pipelineContent += '        addToPath: true\n';
              pipelineContent += '      displayName: \'Install Python\'\n';
              pipelineContent += '    - task: TwineAuthenticate@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        pythonUploadServiceConnection: \'pypi-connection\'\n';
              pipelineContent += '      displayName: \'Authenticate with PyPI\'\n';
              pipelineContent += '    - script: |\n';
              pipelineContent += '        pip install twine\n';
              pipelineContent += '        python -m twine upload -r "pypi-connection" --config-file $(PYPIRC_PATH) $(Pipeline.Workspace)/dist/*\n';
              pipelineContent += '      displayName: \'Upload to PyPI\'\n';
            } else if (azureDevOpsConfig.deployType === 'aws-lambda') {
              pipelineContent += '    - task: AWSLambdaDeployFunction@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        awsCredentials: \'$(AWS_CREDENTIALS)\'\n';
              pipelineContent += '        regionName: \'$(AWS_REGION)\'\n';
              pipelineContent += '        deploymentMode: \'codeonly\'\n';
              pipelineContent += '        functionName: \'$(LAMBDA_FUNCTION_NAME)\'\n';
              pipelineContent += '        zipFile: \'$(Pipeline.Workspace)/dist/*.whl\'\n';
              pipelineContent += '      displayName: \'Deploy to AWS Lambda\'\n';
            } else if (azureDevOpsConfig.deployType === 'azure-functions') {
              pipelineContent += '    - task: AzureFunctionApp@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        azureSubscription: \'$(AZURE_SUBSCRIPTION)\'\n';
              pipelineContent += '        appType: \'functionAppLinux\'\n';
              pipelineContent += '        appName: \'$(FUNCTION_APP_NAME)\'\n';
              pipelineContent += '        package: \'$(Pipeline.Workspace)/dist\'\n';
              pipelineContent += '      displayName: \'Deploy to Azure Functions\'\n';
            }
          }
        } else if (azureDevOpsConfig.projectType === 'java') {
          // Etapa de construcción
          pipelineContent += '- stage: Build\n';
          pipelineContent += '  displayName: Build and Test\n';
          pipelineContent += '  jobs:\n';
          pipelineContent += '  - job: BuildJob\n';
          pipelineContent += '    displayName: Build and Test\n';
          pipelineContent += '    steps:\n';
          pipelineContent += '    - task: JavaToolInstaller@0\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        versionSpec: \'11\'\n';
          pipelineContent += '        jdkArchitectureOption: \'x64\'\n';
          pipelineContent += '        jdkSourceOption: \'PreInstalled\'\n';
          pipelineContent += '      displayName: \'Install Java\'\n';
          pipelineContent += '    - task: Maven@3\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        mavenPomFile: \'pom.xml\'\n';
          pipelineContent += '        goals: \'clean package\'\n';
          pipelineContent += '        publishJUnitResults: true\n';
          pipelineContent += '        testResultsFiles: \'**/surefire-reports/TEST-*.xml\'\n';
          pipelineContent += '        javaHomeOption: \'JDKVersion\'\n';
          pipelineContent += '        mavenVersionOption: \'Default\'\n';
          pipelineContent += '        mavenOptions: \'-Xmx3072m\'\n';
          pipelineContent += '        mavenAuthenticateFeed: false\n';
          pipelineContent += '        effectivePomSkip: false\n';
          pipelineContent += '        sonarQubeRunAnalysis: false\n';
          pipelineContent += '      displayName: \'Build and test\'\n';
          pipelineContent += '    - task: PublishBuildArtifacts@1\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        pathToPublish: \'$(System.DefaultWorkingDirectory)/target\'\n';
          pipelineContent += '        artifactName: \'target\'\n';
          pipelineContent += '        publishLocation: \'Container\'\n';
          pipelineContent += '      displayName: \'Publish build artifacts\'\n';
          
          // Etapa de despliegue
          if (azureDevOpsConfig.deployType) {
            pipelineContent += '- stage: Deploy\n';
            pipelineContent += '  displayName: Deploy\n';
            pipelineContent += '  dependsOn: Build\n';
            pipelineContent += '  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\n';
            pipelineContent += '  jobs:\n';
            pipelineContent += '  - job: DeployJob\n';
            pipelineContent += '    displayName: Deploy\n';
            pipelineContent += '    steps:\n';
            
            if (azureDevOpsConfig.deployType === 'azure-web-app') {
              pipelineContent += '    - task: AzureWebApp@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        azureSubscription: \'$(AZURE_SUBSCRIPTION)\'\n';
              pipelineContent += '        appType: \'webAppLinux\'\n';
              pipelineContent += '        appName: \'$(WEB_APP_NAME)\'\n';
              pipelineContent += '        package: \'$(Pipeline.Workspace)/target/*.jar\'\n';
              pipelineContent += '      displayName: \'Deploy to Azure Web App\'\n';
            } else if (azureDevOpsConfig.deployType === 'aws-elastic-beanstalk') {
              pipelineContent += '    - task: AWSCLI@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        awsCredentials: \'$(AWS_CREDENTIALS)\'\n';
              pipelineContent += '        regionName: \'$(AWS_REGION)\'\n';
              pipelineContent += '        awsCommand: \'s3\'\n';
              pipelineContent += '        awsSubCommand: \'cp\'\n';
              pipelineContent += '        awsArguments: \'$(Pipeline.Workspace)/target/*.jar s3://$(S3_BUCKET)/$(Build.BuildNumber).jar\'\n';
              pipelineContent += '      displayName: \'Upload to S3\'\n';
              pipelineContent += '    - task: AWSCLI@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        awsCredentials: \'$(AWS_CREDENTIALS)\'\n';
              pipelineContent += '        regionName: \'$(AWS_REGION)\'\n';
              pipelineContent += '        awsCommand: \'elasticbeanstalk\'\n';
              pipelineContent += '        awsSubCommand: \'create-application-version\'\n';
              pipelineContent += '        awsArguments: \'--application-name $(EB_APP_NAME) --version-label $(Build.BuildNumber) --source-bundle S3Bucket=$(S3_BUCKET),S3Key=$(Build.BuildNumber).jar\'\n';
              pipelineContent += '      displayName: \'Create application version\'\n';
              pipelineContent += '    - task: AWSCLI@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        awsCredentials: \'$(AWS_CREDENTIALS)\'\n';
              pipelineContent += '        regionName: \'$(AWS_REGION)\'\n';
              pipelineContent += '        awsCommand: \'elasticbeanstalk\'\n';
              pipelineContent += '        awsSubCommand: \'update-environment\'\n';
              pipelineContent += '        awsArguments: \'--environment-name $(EB_ENV_NAME) --version-label $(Build.BuildNumber)\'\n';
              pipelineContent += '      displayName: \'Update environment\'\n';
            }
          }
        } else if (azureDevOpsConfig.projectType === 'docker') {
          // Etapa de construcción
          pipelineContent += '- stage: Build\n';
          pipelineContent += '  displayName: Build and Test\n';
          pipelineContent += '  jobs:\n';
          pipelineContent += '  - job: BuildJob\n';
          pipelineContent += '    displayName: Build and Test\n';
          pipelineContent += '    steps:\n';
          pipelineContent += '    - task: Docker@2\n';
          pipelineContent += '      inputs:\n';
          pipelineContent += '        containerRegistry: \'$(DOCKER_REGISTRY_SERVICE_CONNECTION)\'\n';
          pipelineContent += '        repository: \'$(DOCKER_REPOSITORY)\'\n';
          pipelineContent += '        command: \'buildAndPush\'\n';
          pipelineContent += '        Dockerfile: \'**/Dockerfile\'\n';
          pipelineContent += '        tags: |\n';
          pipelineContent += '          $(Build.BuildId)\n';
          pipelineContent += '          latest\n';
          pipelineContent += '      displayName: \'Build and push Docker image\'\n';
          
          // Etapa de despliegue
          if (azureDevOpsConfig.deployType) {
            pipelineContent += '- stage: Deploy\n';
            pipelineContent += '  displayName: Deploy\n';
            pipelineContent += '  dependsOn: Build\n';
            pipelineContent += '  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\n';
            pipelineContent += '  jobs:\n';
            pipelineContent += '  - job: DeployJob\n';
            pipelineContent += '    displayName: Deploy\n';
            pipelineContent += '    steps:\n';
            
            if (azureDevOpsConfig.deployType === 'kubernetes') {
              pipelineContent += '    - task: KubernetesManifest@0\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        action: \'deploy\'\n';
              pipelineContent += '        kubernetesServiceConnection: \'$(KUBERNETES_SERVICE_CONNECTION)\'\n';
              pipelineContent += '        namespace: \'$(KUBERNETES_NAMESPACE)\'\n';
              pipelineContent += '        manifests: \'$(System.DefaultWorkingDirectory)/kubernetes/*.yml\'\n';
              pipelineContent += '        containers: \'$(DOCKER_REPOSITORY):$(Build.BuildId)\'\n';
              pipelineContent += '      displayName: \'Deploy to Kubernetes\'\n';
            } else if (azureDevOpsConfig.deployType === 'azure-container-apps') {
              pipelineContent += '    - task: AzureCLI@2\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        azureSubscription: \'$(AZURE_SUBSCRIPTION)\'\n';
              pipelineContent += '        scriptType: \'bash\'\n';
              pipelineContent += '        scriptLocation: \'inlineScript\'\n';
              pipelineContent += '        inlineScript: |\n';
              pipelineContent += '          az containerapp update \\\n';
              pipelineContent += '            --name $(CONTAINER_APP_NAME) \\\n';
              pipelineContent += '            --resource-group $(RESOURCE_GROUP) \\\n';
              pipelineContent += '            --image $(DOCKER_REPOSITORY):$(Build.BuildId)\n';
              pipelineContent += '      displayName: \'Deploy to Azure Container Apps\'\n';
            } else if (azureDevOpsConfig.deployType === 'aws-ecs') {
              pipelineContent += '    - task: AWSCLI@1\n';
              pipelineContent += '      inputs:\n';
              pipelineContent += '        awsCredentials: \'$(AWS_CREDENTIALS)\'\n';
              pipelineContent += '        regionName: \'$(AWS_REGION)\'\n';
              pipelineContent += '        awsCommand: \'ecs\'\n';
              pipelineContent += '        awsSubCommand: \'update-service\'\n';
              pipelineContent += '        awsArguments: \'--cluster $(ECS_CLUSTER) --service $(ECS_SERVICE) --force-new-deployment\'\n';
              pipelineContent += '      displayName: \'Deploy to AWS ECS\'\n';
            }
          }
        }
      }
      
      // Escribir archivo de pipeline
      fs.writeFileSync(pipelinePath, pipelineContent, 'utf8');
      
      this.logger.debug(`Archivo de pipeline de Azure DevOps creado en: ${pipelinePath}`);
      
      return `Pipeline CI/CD con Azure DevOps configurado correctamente: ${pipelinePath}`;
    }
    
    private async setupGitHubActions(config: any): Promise<string> {
      this.logger.info('Configurando GitHub Actions...');
      
      // Verificar configuración de GitHub Actions
      if (!config.githubActionsConfig) {
        throw new Error('No se ha proporcionado configuración de GitHub Actions para el pipeline CI/CD');
      }
      
      const githubActionsConfig = config.githubActionsConfig;
      const targetPath = config.targetPath || process.cwd();
      
      // Crear directorio .github/workflows si no existe
      const workflowsDir = path.join(targetPath, '.github', 'workflows');
      if (!fs.existsSync(workflowsDir)) {
        fs.mkdirSync(workflowsDir, { recursive: true });
      }
      
      // Crear archivo de workflow principal
      const workflowName = githubActionsConfig.workflowName || 'ci-cd';
      const workflowPath = path.join(workflowsDir, `${workflowName}.yml`);
      
      // Generar contenido del workflow
      let workflowContent = '';
      
      // Nombre del workflow
      workflowContent += `name: ${githubActionsConfig.workflowDisplayName || 'CI/CD Pipeline'}\n\n`;
      
      // Triggers
      workflowContent += 'on:\n';
      if (githubActionsConfig.triggers && githubActionsConfig.triggers.push) {
        workflowContent += '  push:\n';
        workflowContent += '    branches:\n';
        for (const branch of githubActionsConfig.triggers.push.branches || ['main']) {
          workflowContent += `      - ${branch}\n`;
        }
        if (githubActionsConfig.triggers.push.paths) {
          workflowContent += '    paths:\n';
          for (const path of githubActionsConfig.triggers.push.paths) {
            workflowContent += `      - '${path}'\n`;
          }
        }
        if (githubActionsConfig.triggers.push.tags) {
          workflowContent += '    tags:\n';
          for (const tag of githubActionsConfig.triggers.push.tags) {
            workflowContent += `      - ${tag}\n`;
          }
        }
      } else {
        workflowContent += '  push:\n';
        workflowContent += '    branches: [ main ]\n';
      }
      
      if (githubActionsConfig.triggers && githubActionsConfig.triggers.pullRequest) {
        workflowContent += '  pull_request:\n';
        workflowContent += '    branches:\n';
        for (const branch of githubActionsConfig.triggers.pullRequest.branches || ['main']) {
          workflowContent += `      - ${branch}\n`;
        }
        if (githubActionsConfig.triggers.pullRequest.paths) {
          workflowContent += '    paths:\n';
          for (const path of githubActionsConfig.triggers.pullRequest.paths) {
            workflowContent += `      - '${path}'\n`;
          }
        }
      } else {
        workflowContent += '  pull_request:\n';
        workflowContent += '    branches: [ main ]\n';
      }
      
      if (githubActionsConfig.triggers && githubActionsConfig.triggers.schedule) {
        workflowContent += '  schedule:\n';
        for (const schedule of githubActionsConfig.triggers.schedule) {
          workflowContent += `    - cron: '${schedule}'\n`;
        }
      }
      
      if (githubActionsConfig.triggers && githubActionsConfig.triggers.workflow_dispatch) {
        workflowContent += '  workflow_dispatch:\n';
        if (githubActionsConfig.triggers.workflow_dispatch.inputs) {
          workflowContent += '    inputs:\n';
          for (const [key, input] of Object.entries(githubActionsConfig.triggers.workflow_dispatch.inputs)) {
            workflowContent += `      ${key}:\n`;
            workflowContent += `        description: '${input.description}'\n`;
            workflowContent += `        required: ${input.required || false}\n`;
            if (input.default) {
              workflowContent += `        default: '${input.default}'\n`;
            }
            if (input.type === 'choice' && input.options) {
              workflowContent += '        type: choice\n';
              workflowContent += '        options:\n';
              for (const option of input.options) {
                workflowContent += `          - ${option}\n`;
              }
            } else if (input.type) {
              workflowContent += `        type: ${input.type}\n`;
            }
          }
        }
      }
      
      workflowContent += '\n';
      
      // Entorno
      if (githubActionsConfig.env && Object.keys(githubActionsConfig.env).length > 0) {
        workflowContent += 'env:\n';
        for (const [key, value] of Object.entries(githubActionsConfig.env)) {
          workflowContent += `  ${key}: ${value}\n`;
        }
        workflowContent += '\n';
      }
      
      // Jobs
      workflowContent += 'jobs:\n';
      
      if (githubActionsConfig.jobs && githubActionsConfig.jobs.length > 0) {
        // Usar los jobs definidos en la configuración
        for (const job of githubActionsConfig.jobs) {
          workflowContent += `  ${job.name}:\n`;
          workflowContent += `    name: ${job.displayName || job.name}\n`;
          
          if (job.runsOn) {
            workflowContent += `    runs-on: ${job.runsOn}\n`;
          } else {
            workflowContent += '    runs-on: ubuntu-latest\n';
          }
          
          if (job.needs && job.needs.length > 0) {
            workflowContent += '    needs: [';
            workflowContent += job.needs.join(', ');
            workflowContent += ']\n';
          }
          
          if (job.if) {
            workflowContent += `    if: ${job.if}\n`;
          }
          
          if (job.env && Object.keys(job.env).length > 0) {
            workflowContent += '    env:\n';
            for (const [key, value] of Object.entries(job.env)) {
              workflowContent += `      ${key}: ${value}\n`;
            }
          }
          
          if (job.strategy) {
            workflowContent += '    strategy:\n';
            if (job.strategy.matrix) {
              workflowContent += '      matrix:\n';
              for (const [key, values] of Object.entries(job.strategy.matrix)) {
                workflowContent += `        ${key}: [${values.join(', ')}]\n`;
              }
            }
            if (job.strategy.failFast !== undefined) {
              workflowContent += `      fail-fast: ${job.strategy.failFast}\n`;
            }
            if (job.strategy.maxParallel !== undefined) {
              workflowContent += `      max-parallel: ${job.strategy.maxParallel}\n`;
            }
          }
          
          workflowContent += '    steps:\n';
          for (const step of job.steps) {
            workflowContent += '      - ';
            if (step.name) {
              workflowContent += `name: ${step.name}\n`;
              workflowContent += '        ';
            }
            
            if (step.uses) {
              workflowContent += `uses: ${step.uses}\n`;
              if (step.with && Object.keys(step.with).length > 0) {
                workflowContent += '        with:\n';
                for (const [key, value] of Object.entries(step.with)) {
                  workflowContent += `          ${key}: ${value}\n`;
                }
              }
            } else if (step.run) {
              workflowContent += `run: ${step.run}\n`;
              if (step.shell) {
                workflowContent += `        shell: ${step.shell}\n`;
              }
              if (step.workingDirectory) {
                workflowContent += `        working-directory: ${step.workingDirectory}\n`;
              }
            }
            
            if (step.env && Object.keys(step.env).length > 0) {
              workflowContent += '        env:\n';
              for (const [key, value] of Object.entries(step.env)) {
                workflowContent += `          ${key}: ${value}\n`;
              }
            }
            
            if (step.continueOnError !== undefined) {
              workflowContent += `        continue-on-error: ${step.continueOnError}\n`;
            }
            
            if (step.if) {
              workflowContent += `        if: ${step.if}\n`;
            }
            
            if (step.timeout) {
              workflowContent += `        timeout-minutes: ${step.timeout}\n`;
            }
          }
        }
      } else {
        // Crear jobs por defecto según el tipo de proyecto
        if (githubActionsConfig.projectType === 'node') {
          // Job de construcción
          workflowContent += '  build:\n';
          workflowContent += '    name: Build and Test\n';
          workflowContent += '    runs-on: ubuntu-latest\n';
          workflowContent += '    steps:\n';
          workflowContent += '      - uses: actions/checkout@v3\n';
          workflowContent += '      - name: Set up Node.js\n';
          workflowContent += '        uses: actions/setup-node@v3\n';
          workflowContent += '        with:\n';
          workflowContent += '          node-version: 16\n';
          workflowContent += '          cache: \'npm\'\n';
          workflowContent += '      - name: Install dependencies\n';
          workflowContent += '        run: npm ci\n';
          workflowContent += '      - name: Lint\n';
          workflowContent += '        run: npm run lint --if-present\n';
          workflowContent += '      - name: Test\n';
          workflowContent += '        run: npm test --if-present\n';
          workflowContent += '      - name: Build\n';
          workflowContent += '        run: npm run build --if-present\n';
          workflowContent += '      - name: Upload build artifacts\n';
          workflowContent += '        uses: actions/upload-artifact@v3\n';
          workflowContent += '        with:\n';
          workflowContent += '          name: build-artifacts\n';
          workflowContent += '          path: dist/\n';
          
          // Job de despliegue
          if (githubActionsConfig.deployType) {
            workflowContent += '  deploy:\n';
            workflowContent += '    name: Deploy\n';
            workflowContent += '    needs: build\n';
            workflowContent += '    runs-on: ubuntu-latest\n';
            workflowContent += '    if: github.ref == \'refs/heads/main\'\n';
            workflowContent += '    steps:\n';
            workflowContent += '      - uses: actions/checkout@v3\n';
            workflowContent += '      - name: Download build artifacts\n';
            workflowContent += '        uses: actions/download-artifact@v3\n';
            workflowContent += '        with:\n';
            workflowContent += '          name: build-artifacts\n';
            workflowContent += '          path: dist/\n';
            
            if (githubActionsConfig.deployType === 'azure-web-app') {
              workflowContent += '      - name: Deploy to Azure Web App\n';
              workflowContent += '        uses: azure/webapps-deploy@v2\n';
              workflowContent += '        with:\n';
              workflowContent += '          app-name: ${{ secrets.AZURE_WEBAPP_NAME }}\n';
              workflowContent += '          publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE }}\n';
              workflowContent += '          package: dist/\n';
            } else if (githubActionsConfig.deployType === 'aws-s3') {
              workflowContent += '      - name: Configure AWS credentials\n';
              workflowContent += '        uses: aws-actions/configure-aws-credentials@v1\n';
              workflowContent += '        with:\n';
              workflowContent += '          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
              workflowContent += '          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
              workflowContent += '          aws-region: ${{ secrets.AWS_REGION }}\n';
              workflowContent += '      - name: Deploy to S3\n';
              workflowContent += '        run: aws s3 sync dist/ s3://${{ secrets.S3_BUCKET }} --delete\n';
              workflowContent += '      - name: Invalidate CloudFront cache\n';
              workflowContent += '        run: aws cloudfront create-invalidation --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} --paths "/*"\n';
            } else if (githubActionsConfig.deployType === 'heroku') {
              workflowContent += '      - name: Deploy to Heroku\n';
              workflowContent += '        uses: akhileshns/heroku-deploy@v3.12.12\n';
              workflowContent += '        with:\n';
              workflowContent += '          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n';
              workflowContent += '          heroku_app_name: ${{ secrets.HEROKU_APP_NAME }}\n';
              workflowContent += '          heroku_email: ${{ secrets.HEROKU_EMAIL }}\n';
              workflowContent += '          appdir: dist\n';
            } else if (githubActionsConfig.deployType === 'github-pages') {
              workflowContent += '      - name: Deploy to GitHub Pages\n';
              workflowContent += '        uses: JamesIves/github-pages-deploy-action@v4.3.3\n';
              workflowContent += '        with:\n';
              workflowContent += '          branch: gh-pages\n';
              workflowContent += '          folder: dist\n';
              workflowContent += '          clean: true\n';
            }
          }
        } else if (githubActionsConfig.projectType === 'python') {
          // Job de construcción
          workflowContent += '  build:\n';
          workflowContent += '    name: Build and Test\n';
          workflowContent += '    runs-on: ubuntu-latest\n';
          workflowContent += '    steps:\n';
          workflowContent += '      - uses: actions/checkout@v3\n';
          workflowContent += '      - name: Set up Python\n';
          workflowContent += '        uses: actions/setup-python@v4\n';
          workflowContent += '        with:\n';
          workflowContent += '          python-version: 3.9\n';
          workflowContent += '          cache: \'pip\'\n';
          workflowContent += '      - name: Install dependencies\n';
          workflowContent += '        run: |\n';
          workflowContent += '          python -m pip install --upgrade pip\n';
          workflowContent += '          pip install flake8 pytest\n';
          workflowContent += '          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n';
          workflowContent += '        shell: bash\n';
          workflowContent += '      - name: Lint with flake8\n';
          workflowContent += '        run: |\n';
          workflowContent += '          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n';
          workflowContent += '          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics\n';
          workflowContent += '        shell: bash\n';
          workflowContent += '      - name: Test with pytest\n';
          workflowContent += '        run: pytest\n';
          workflowContent += '      - name: Build package\n';
          workflowContent += '        run: |\n';
          workflowContent += '          pip install wheel\n';
          workflowContent += '          python setup.py sdist bdist_wheel\n';
          workflowContent += '        shell: bash\n';
          workflowContent += '      - name: Upload build artifacts\n';
          workflowContent += '        uses: actions/upload-artifact@v3\n';
          workflowContent += '        with:\n';
          workflowContent += '          name: dist-artifacts\n';
          workflowContent += '          path: dist/\n';
          
          // Job de despliegue
          if (githubActionsConfig.deployType) {
            workflowContent += '  deploy:\n';
            workflowContent += '    name: Deploy\n';
            workflowContent += '    needs: build\n';
            workflowContent += '    runs-on: ubuntu-latest\n';
            workflowContent += '    if: github.ref == \'refs/heads/main\'\n';
            workflowContent += '    steps:\n';
            workflowContent += '      - uses: actions/checkout@v3\n';
            workflowContent += '      - name: Set up Python\n';
            workflowContent += '        uses: actions/setup-python@v4\n';
            workflowContent += '        with:\n';
            workflowContent += '          python-version: 3.9\n';
            workflowContent += '      - name: Download build artifacts\n';
            workflowContent += '        uses: actions/download-artifact@v3\n';
            workflowContent += '        with:\n';
            workflowContent += '          name: dist-artifacts\n';
            workflowContent += '          path: dist/\n';
            
            if (githubActionsConfig.deployType === 'pypi') {
              workflowContent += '      - name: Publish to PyPI\n';
              workflowContent += '        uses: pypa/gh-action-pypi-publish@release/v1\n';
              workflowContent += '        with:\n';
              workflowContent += '          user: ${{ secrets.PYPI_USERNAME }}\n';
              workflowContent += '          password: ${{ secrets.PYPI_PASSWORD }}\n';
            } else if (githubActionsConfig.deployType === 'aws-lambda') {
              workflowContent += '      - name: Configure AWS credentials\n';
              workflowContent += '        uses: aws-actions/configure-aws-credentials@v1\n';
              workflowContent += '        with:\n';
              workflowContent += '          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
              workflowContent += '          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
              workflowContent += '          aws-region: ${{ secrets.AWS_REGION }}\n';
              workflowContent += '      - name: Deploy to AWS Lambda\n';
              workflowContent += '        run: |\n';
              workflowContent += '          aws lambda update-function-code \\\n';
              workflowContent += '            --function-name ${{ secrets.LAMBDA_FUNCTION_NAME }} \\\n';
              workflowContent += '            --zip-file fileb://dist/*.whl\n';
              workflowContent += '        shell: bash\n';
            } else if (githubActionsConfig.deployType === 'azure-functions') {
              workflowContent += '      - name: Deploy to Azure Functions\n';
              workflowContent += '        uses: Azure/functions-action@v1\n';
              workflowContent += '        with:\n';
              workflowContent += '          app-name: ${{ secrets.AZURE_FUNCTIONAPP_NAME }}\n';
              workflowContent += '          package: dist/\n';
              workflowContent += '          publish-profile: ${{ secrets.AZURE_FUNCTIONAPP_PUBLISH_PROFILE }}\n';
            }
          }
        } else if (githubActionsConfig.projectType === 'java') {
          // Job de construcción
          workflowContent += '  build:\n';
          workflowContent += '    name: Build and Test\n';
          workflowContent += '    runs-on: ubuntu-latest\n';
          workflowContent += '    steps:\n';
          workflowContent += '      - uses: actions/checkout@v3\n';
          workflowContent += '      - name: Set up JDK\n';
          workflowContent += '        uses: actions/setup-java@v3\n';
          workflowContent += '        with:\n';
          workflowContent += '          java-version: 11\n';
          workflowContent += '          distribution: \'temurin\'\n';
          workflowContent += '          cache: maven\n';
          workflowContent += '      - name: Build with Maven\n';
          workflowContent += '        run: mvn -B package --file pom.xml\n';
          workflowContent += '      - name: Upload build artifacts\n';
          workflowContent += '        uses: actions/upload-artifact@v3\n';
          workflowContent += '        with:\n';
          workflowContent += '          name: target-artifacts\n';
          workflowContent += '          path: target/*.jar\n';
          
          // Job de despliegue
          if (githubActionsConfig.deployType) {
            workflowContent += '  deploy:\n';
            workflowContent += '    name: Deploy\n';
            workflowContent += '    needs: build\n';
            workflowContent += '    runs-on: ubuntu-latest\n';
            workflowContent += '    if: github.ref == \'refs/heads/main\'\n';
            workflowContent += '    steps:\n';
            workflowContent += '      - uses: actions/checkout@v3\n';
            workflowContent += '      - name: Download build artifacts\n';
            workflowContent += '        uses: actions/download-artifact@v3\n';
            workflowContent += '        with:\n';
            workflowContent += '          name: target-artifacts\n';
            workflowContent += '          path: target/\n';
            
            if (githubActionsConfig.deployType === 'azure-web-app') {
              workflowContent += '      - name: Deploy to Azure Web App\n';
              workflowContent += '        uses: azure/webapps-deploy@v2\n';
              workflowContent += '        with:\n';
              workflowContent += '          app-name: ${{ secrets.AZURE_WEBAPP_NAME }}\n';
              workflowContent += '          publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE }}\n';
              workflowContent += '          package: target/*.jar\n';
            } else if (githubActionsConfig.deployType === 'aws-elastic-beanstalk') {
              workflowContent += '      - name: Configure AWS credentials\n';
              workflowContent += '        uses: aws-actions/configure-aws-credentials@v1\n';
              workflowContent += '        with:\n';
              workflowContent += '          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
              workflowContent += '          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
              workflowContent += '          aws-region: ${{ secrets.AWS_REGION }}\n';
              workflowContent += '      - name: Upload to S3\n';
              workflowContent += '        run: aws s3 cp target/*.jar s3://${{ secrets.S3_BUCKET }}/${{ github.sha }}.jar\n';
              workflowContent += '      - name: Create application version\n';
              workflowContent += '        run: |\n';
              workflowContent += '          aws elasticbeanstalk create-application-version \\\n';
              workflowContent += '            --application-name ${{ secrets.EB_APPLICATION_NAME }} \\\n';
              workflowContent += '            --version-label ${{ github.sha }} \\\n';
              workflowContent += '            --source-bundle S3Bucket="${{ secrets.S3_BUCKET }}",S3Key="${{ github.sha }}.jar"\n';
              workflowContent += '        shell: bash\n';
              workflowContent += '      - name: Update environment\n';
              workflowContent += '        run: |\n';
              workflowContent += '          aws elasticbeanstalk update-environment \\\n';
              workflowContent += '            --environment-name ${{ secrets.EB_ENVIRONMENT_NAME }} \\\n';
              workflowContent += '            --version-label ${{ github.sha }}\n';
              workflowContent += '        shell: bash\n';
            }
          }
        } else if (githubActionsConfig.projectType === 'docker') {
          // Job de construcción
          workflowContent += '  build:\n';
          workflowContent += '    name: Build and Push Docker Image\n';
          workflowContent += '    runs-on: ubuntu-latest\n';
          workflowContent += '    steps:\n';
          workflowContent += '      - uses: actions/checkout@v3\n';
          workflowContent += '      - name: Set up Docker Buildx\n';
          workflowContent += '        uses: docker/setup-buildx-action@v2\n';
          workflowContent += '      - name: Login to DockerHub\n';
          workflowContent += '        uses: docker/login-action@v2\n';
          workflowContent += '        with:\n';
          workflowContent += '          username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
          workflowContent += '          password: ${{ secrets.DOCKERHUB_TOKEN }}\n';
          workflowContent += '      - name: Build and push\n';
          workflowContent += '        uses: docker/build-push-action@v3\n';
          workflowContent += '        with:\n';
          workflowContent += '          context: .\n';
          workflowContent += '          push: true\n';
          workflowContent += '          tags: ${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.DOCKER_REPOSITORY }}:latest,${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.DOCKER_REPOSITORY }}:${{ github.sha }}\n';
          
          // Job de despliegue
          if (githubActionsConfig.deployType) {
            workflowContent += '  deploy:\n';
            workflowContent += '    name: Deploy\n';
            workflowContent += '    needs: build\n';
            workflowContent += '    runs-on: ubuntu-latest\n';
            workflowContent += '    if: github.ref == \'refs/heads/main\'\n';
            workflowContent += '    steps:\n';
            workflowContent += '      - uses: actions/checkout@v3\n';
            
            if (githubActionsConfig.deployType === 'kubernetes') {
              workflowContent += '      - name: Set up kubectl\n';
              workflowContent += '        uses: azure/setup-kubectl@v3\n';
              workflowContent += '      - name: Set Kubernetes context\n';
              workflowContent += '        uses: azure/k8s-set-context@v3\n';
              workflowContent += '        with:\n';
              workflowContent += '          kubeconfig: ${{ secrets.KUBE_CONFIG }}\n';
              workflowContent += '      - name: Deploy to Kubernetes\n';
              workflowContent += '        run: |\n';
              workflowContent += '          sed -i \'s|{{IMAGE_TAG}}|${{ github.sha }}|g\' kubernetes/*.yml\n';
              workflowContent += '          kubectl apply -f kubernetes/\n';
              workflowContent += '        shell: bash\n';
            } else if (githubActionsConfig.deployType === 'azure-container-apps') {
              workflowContent += '      - name: Azure Login\n';
              workflowContent += '        uses: azure/login@v1\n';
              workflowContent += '        with:\n';
              workflowContent += '          creds: ${{ secrets.AZURE_CREDENTIALS }}\n';
              workflowContent += '      - name: Deploy to Azure Container Apps\n';
              workflowContent += '        run: |\n';
              workflowContent += '          az containerapp update \\\n';
              workflowContent += '            --name ${{ secrets.CONTAINER_APP_NAME }} \\\n';
              workflowContent += '            --resource-group ${{ secrets.RESOURCE_GROUP }} \\\n';
              workflowContent += '            --image ${{ secrets.DOCKERHUB_USERNAME }}/${{ secrets.DOCKER_REPOSITORY }}:${{ github.sha }}\n';
              workflowContent += '        shell: bash\n';
            } else if (githubActionsConfig.deployType === 'aws-ecs') {
              workflowContent += '      - name: Configure AWS credentials\n';
              workflowContent += '        uses: aws-actions/configure-aws-credentials@v1\n';
              workflowContent += '        with:\n';
              workflowContent += '          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
              workflowContent += '          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
              workflowContent += '          aws-region: ${{ secrets.AWS_REGION }}\n';
              workflowContent += '      - name: Deploy to Amazon ECS\n';
              workflowContent += '        run: |\n';
              workflowContent += '          aws ecs update-service \\\n';
              workflowContent += '            --cluster ${{ secrets.ECS_CLUSTER }} \\\n';
              workflowContent += '            --service ${{ secrets.ECS_SERVICE }} \\\n';
              workflowContent += '            --force-new-deployment\n';
              workflowContent += '        shell: bash\n';
            }
          }
        }
      }
    }
    
    // Escribir archivo de workflow
    fs.writeFileSync(workflowPath, workflowContent, 'utf8');
    
    this.logger.debug(`Archivo de workflow de GitHub Actions creado en: ${workflowPath}`);
    
    return `Pipeline CI/CD con GitHub Actions configurado correctamente: ${workflowPath}`;
  }

  private async setupTerraform(config: TerraformConfig): Promise<string> {
    this.logger.info('Configurando Terraform...');
    
    const targetPath = config.targetPath || process.cwd();
    const provider = config.provider || 'aws';
    const region = config.region || 'us-west-2';
    const resourcePrefix = config.resourcePrefix || 'cjdevmind';
    
    // Crear directorio para Terraform si no existe
    const terraformDir = path.join(targetPath, 'terraform');
    if (!fs.existsSync(terraformDir)) {
      fs.mkdirSync(terraformDir, { recursive: true });
    }
    
    // Crear archivo main.tf
    let mainTfContent = '';
    
    // Configuración del proveedor
    if (provider === 'aws') {
      mainTfContent += 'provider "aws" {\n';
      mainTfContent += `  region = "${region}"\n`;
      mainTfContent += '}\n\n';
    } else if (provider === 'azure') {
      mainTfContent += 'provider "azurerm" {\n';
      mainTfContent += '  features {}\n';
      mainTfContent += '}\n\n';
    } else if (provider === 'gcp') {
      mainTfContent += 'provider "google" {\n';
      mainTfContent += `  region = "${region}"\n`;
      mainTfContent += `  project = "${config.projectId || 'my-project'}"\n`;
      mainTfContent += '}\n\n';
    }
    
    // Configuración del backend
    if (config.backend) {
      mainTfContent += 'terraform {\n';
      mainTfContent += '  backend "' + config.backend.type + '" {\n';
      
      if (config.backend.type === 's3') {
        mainTfContent += `    bucket = "${config.backend.bucket || `${resourcePrefix}-terraform-state`}"\n`;
        mainTfContent += `    key    = "${config.backend.key || 'terraform.tfstate'}"\n`;
        mainTfContent += `    region = "${config.backend.region || region}"\n`;
        
        if (config.backend.dynamodbTable) {
          mainTfContent += `    dynamodb_table = "${config.backend.dynamodbTable}"\n`;
        }
      } else if (config.backend.type === 'azurerm') {
        mainTfContent += `    resource_group_name  = "${config.backend.resourceGroupName || `${resourcePrefix}-terraform-state`}"\n`;
        mainTfContent += `    storage_account_name = "${config.backend.storageAccountName || `${resourcePrefix}tfstate`}"\n`;
        mainTfContent += `    container_name       = "${config.backend.containerName || 'tfstate'}"\n`;
        mainTfContent += `    key                  = "${config.backend.key || 'terraform.tfstate'}"\n`;
      } else if (config.backend.type === 'gcs') {
        mainTfContent += `    bucket = "${config.backend.bucket || `${resourcePrefix}-terraform-state`}"\n`;
        mainTfContent += `    prefix = "${config.backend.prefix || 'terraform/state'}"\n`;
      }
      
      mainTfContent += '  }\n';
      mainTfContent += '}\n\n';
    }
    
    // Recursos según el tipo de infraestructura
    if (config.infrastructureType === InfrastructureType.SERVERLESS) {
      if (provider === 'aws') {
        // AWS Lambda y API Gateway
        mainTfContent += '# Lambda Function\n';
        mainTfContent += 'resource "aws_lambda_function" "app" {\n';
        mainTfContent += `  function_name = "${resourcePrefix}-lambda"\n`;
        mainTfContent += '  handler       = "index.handler"\n';
        mainTfContent += '  runtime       = "nodejs14.x"\n';
        mainTfContent += '  filename      = "lambda.zip"\n';
        mainTfContent += '  role          = aws_iam_role.lambda_role.arn\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# IAM Role para Lambda\n';
        mainTfContent += 'resource "aws_iam_role" "lambda_role" {\n';
        mainTfContent += `  name = "${resourcePrefix}-lambda-role"\n`;
        mainTfContent += '  assume_role_policy = jsonencode({\n';
        mainTfContent += '    Version = "2012-10-17"\n';
        mainTfContent += '    Statement = [{\n';
        mainTfContent += '      Action = "sts:AssumeRole"\n';
        mainTfContent += '      Effect = "Allow"\n';
        mainTfContent += '      Principal = {\n';
        mainTfContent += '        Service = "lambda.amazonaws.com"\n';
        mainTfContent += '      }\n';
        mainTfContent += '    }]\n';
        mainTfContent += '  })\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# API Gateway\n';
        mainTfContent += 'resource "aws_apigatewayv2_api" "api" {\n';
        mainTfContent += `  name          = "${resourcePrefix}-api"\n`;
        mainTfContent += '  protocol_type = "HTTP"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_apigatewayv2_stage" "default" {\n';
        mainTfContent += '  api_id      = aws_apigatewayv2_api.api.id\n';
        mainTfContent += '  name        = "$default"\n';
        mainTfContent += '  auto_deploy = true\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_apigatewayv2_integration" "lambda" {\n';
        mainTfContent += '  api_id           = aws_apigatewayv2_api.api.id\n';
        mainTfContent += '  integration_type = "AWS_PROXY"\n';
        mainTfContent += '  integration_uri  = aws_lambda_function.app.invoke_arn\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_apigatewayv2_route" "default" {\n';
        mainTfContent += '  api_id    = aws_apigatewayv2_api.api.id\n';
        mainTfContent += '  route_key = "ANY /"\n';
        mainTfContent += '  target    = "integrations/${aws_apigatewayv2_integration.lambda.id}"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_lambda_permission" "api_gw" {\n';
        mainTfContent += '  statement_id  = "AllowExecutionFromAPIGateway"\n';
        mainTfContent += '  action        = "lambda:InvokeFunction"\n';
        mainTfContent += '  function_name = aws_lambda_function.app.function_name\n';
        mainTfContent += '  principal     = "apigateway.amazonaws.com"\n';
        mainTfContent += '  source_arn    = "${aws_apigatewayv2_api.api.execution_arn}/*/*"\n';
        mainTfContent += '}\n\n';
      } else if (provider === 'azure') {
        // Azure Functions
        mainTfContent += '# Resource Group\n';
        mainTfContent += 'resource "azurerm_resource_group" "main" {\n';
        mainTfContent += `  name     = "${resourcePrefix}-rg"\n`;
        mainTfContent += `  location = "${config.region || 'West Europe'}"\n`;
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Storage Account\n';
        mainTfContent += 'resource "azurerm_storage_account" "main" {\n';
        mainTfContent += `  name                     = "${resourcePrefix}storage"\n`;
        mainTfContent += '  resource_group_name      = azurerm_resource_group.main.name\n';
        mainTfContent += '  location                 = azurerm_resource_group.main.location\n';
        mainTfContent += '  account_tier             = "Standard"\n';
        mainTfContent += '  account_replication_type = "LRS"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Function App\n';
        mainTfContent += 'resource "azurerm_app_service_plan" "main" {\n';
        mainTfContent += `  name                = "${resourcePrefix}-app-service-plan"\n`;
        mainTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        mainTfContent += '  location            = azurerm_resource_group.main.location\n';
        mainTfContent += '  kind                = "FunctionApp"\n';
        mainTfContent += '  reserved            = true\n';
        mainTfContent += '  sku {\n';
        mainTfContent += '    tier = "Dynamic"\n';
        mainTfContent += '    size = "Y1"\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "azurerm_function_app" "main" {\n';
        mainTfContent += `  name                       = "${resourcePrefix}-function-app"\n`;
        mainTfContent += '  resource_group_name        = azurerm_resource_group.main.name\n';
        mainTfContent += '  location                   = azurerm_resource_group.main.location\n';
        mainTfContent += '  app_service_plan_id        = azurerm_app_service_plan.main.id\n';
        mainTfContent += '  storage_account_name       = azurerm_storage_account.main.name\n';
        mainTfContent += '  storage_account_access_key = azurerm_storage_account.main.primary_access_key\n';
        mainTfContent += '  os_type                    = "linux"\n';
        mainTfContent += '  version                    = "~3"\n';
        mainTfContent += '  site_config {\n';
        mainTfContent += '    linux_fx_version = "python|3.9"\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
      } else if (provider === 'gcp') {
        // Google Cloud Functions
        mainTfContent += '# Cloud Function\n';
        mainTfContent += 'resource "google_storage_bucket" "function_bucket" {\n';
        mainTfContent += `  name     = "${resourcePrefix}-function-bucket"\n`;
        mainTfContent += '  location = "US"\n';
        mainTfContent += '  uniform_bucket_level_access = true\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "google_storage_bucket_object" "function_archive" {\n';
        mainTfContent += '  name   = "function-source.zip"\n';
        mainTfContent += '  bucket = google_storage_bucket.function_bucket.name\n';
        mainTfContent += '  source = "function-source.zip"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "google_cloudfunctions_function" "function" {\n';
        mainTfContent += `  name        = "${resourcePrefix}-function"\n`;
        mainTfContent += `  region      = "${region}"\n`;
        mainTfContent += '  runtime     = "nodejs14"\n';
        mainTfContent += '  entry_point = "handler"\n';
        mainTfContent += '  source_archive_bucket = google_storage_bucket.function_bucket.name\n';
        mainTfContent += '  source_archive_object = google_storage_bucket_object.function_archive.name\n';
        mainTfContent += '  trigger_http = true\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# IAM\n';
        mainTfContent += 'resource "google_cloudfunctions_function_iam_member" "invoker" {\n';
        mainTfContent += '  project        = google_cloudfunctions_function.function.project\n';
        mainTfContent += '  region         = google_cloudfunctions_function.function.region\n';
        mainTfContent += '  cloud_function = google_cloudfunctions_function.function.name\n';
        mainTfContent += '  role           = "roles/cloudfunctions.invoker"\n';
        mainTfContent += '  member         = "allUsers"\n';
        mainTfContent += '}\n\n';
      }
    } else if (config.infrastructureType === InfrastructureType.CONTAINER) {
      if (provider === 'aws') {
        // AWS ECS
        mainTfContent += '# VPC\n';
        mainTfContent += 'resource "aws_vpc" "main" {\n';
        mainTfContent += '  cidr_block = "10.0.0.0/16"\n';
        mainTfContent += '  enable_dns_support = true\n';
        mainTfContent += '  enable_dns_hostnames = true\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-vpc"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Subnets\n';
        mainTfContent += 'resource "aws_subnet" "public_a" {\n';
        mainTfContent += '  vpc_id            = aws_vpc.main.id\n';
        mainTfContent += '  cidr_block        = "10.0.1.0/24"\n';
        mainTfContent += `  availability_zone = "${region}a"\n`;
        mainTfContent += '  map_public_ip_on_launch = true\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-public-a"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_subnet" "public_b" {\n';
        mainTfContent += '  vpc_id            = aws_vpc.main.id\n';
        mainTfContent += '  cidr_block        = "10.0.2.0/24"\n';
        mainTfContent += `  availability_zone = "${region}b"\n`;
        mainTfContent += '  map_public_ip_on_launch = true\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-public-b"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Internet Gateway\n';
        mainTfContent += 'resource "aws_internet_gateway" "main" {\n';
        mainTfContent += '  vpc_id = aws_vpc.main.id\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-igw"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Route Table\n';
        mainTfContent += 'resource "aws_route_table" "public" {\n';
        mainTfContent += '  vpc_id = aws_vpc.main.id\n';
        mainTfContent += '  route {\n';
        mainTfContent += '    cidr_block = "0.0.0.0/0"\n';
        mainTfContent += '    gateway_id = aws_internet_gateway.main.id\n';
        mainTfContent += '  }\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-public-rt"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Route Table Association\n';
        mainTfContent += 'resource "aws_route_table_association" "public_a" {\n';
        mainTfContent += '  subnet_id      = aws_subnet.public_a.id\n';
        mainTfContent += '  route_table_id = aws_route_table.public.id\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_route_table_association" "public_b" {\n';
        mainTfContent += '  subnet_id      = aws_subnet.public_b.id\n';
        mainTfContent += '  route_table_id = aws_route_table.public.id\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Security Group\n';
        mainTfContent += 'resource "aws_security_group" "ecs" {\n';
        mainTfContent += `  name        = "${resourcePrefix}-ecs-sg"\n`;
        mainTfContent += '  description = "Allow inbound traffic"\n';
        mainTfContent += '  vpc_id      = aws_vpc.main.id\n';
        mainTfContent += '  ingress {\n';
        mainTfContent += '    from_port   = 80\n';
        mainTfContent += '    to_port     = 80\n';
        mainTfContent += '    protocol    = "tcp"\n';
        mainTfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
        mainTfContent += '  }\n';
        mainTfContent += '  egress {\n';
        mainTfContent += '    from_port   = 0\n';
        mainTfContent += '    to_port     = 0\n';
        mainTfContent += '    protocol    = "-1"\n';
        mainTfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
        mainTfContent += '  }\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-ecs-sg"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# ECS Cluster\n';
        mainTfContent += 'resource "aws_ecs_cluster" "main" {\n';
        mainTfContent += `  name = "${resourcePrefix}-cluster"\n`;
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Task Definition\n';
        mainTfContent += 'resource "aws_ecs_task_definition" "app" {\n';
        mainTfContent += `  family                   = "${resourcePrefix}-app"\n`;
        mainTfContent += '  network_mode             = "awsvpc"\n';
        mainTfContent += '  requires_compatibilities = ["FARGATE"]\n';
        mainTfContent += '  cpu                      = 256\n';
        mainTfContent += '  memory                   = 512\n';
        mainTfContent += '  execution_role_arn       = aws_iam_role.ecs_execution_role.arn\n';
        mainTfContent += '  container_definitions    = jsonencode([\n';
        mainTfContent += '    {\n';
        mainTfContent += `      name      = "${resourcePrefix}-app"\n`;
        mainTfContent += '      image     = "nginx:latest"\n';
        mainTfContent += '      essential = true\n';
        mainTfContent += '      portMappings = [\n';
        mainTfContent += '        {\n';
        mainTfContent += '          containerPort = 80\n';
        mainTfContent += '          hostPort      = 80\n';
        mainTfContent += '        }\n';
        mainTfContent += '      ]\n';
        mainTfContent += '    }\n';
        mainTfContent += '  ])\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# IAM Role for ECS\n';
        mainTfContent += 'resource "aws_iam_role" "ecs_execution_role" {\n';
        mainTfContent += `  name = "${resourcePrefix}-ecs-execution-role"\n`;
        mainTfContent += '  assume_role_policy = jsonencode({\n';
        mainTfContent += '    Version = "2012-10-17"\n';
        mainTfContent += '    Statement = [\n';
        mainTfContent += '      {\n';
        mainTfContent += '        Action = "sts:AssumeRole"\n';
        mainTfContent += '        Effect = "Allow"\n';
        mainTfContent += '        Principal = {\n';
        mainTfContent += '          Service = "ecs-tasks.amazonaws.com"\n';
        mainTfContent += '        }\n';
        mainTfContent += '      }\n';
        mainTfContent += '    ]\n';
        mainTfContent += '  })\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_iam_role_policy_attachment" "ecs_execution_role_policy" {\n';
        mainTfContent += '  role       = aws_iam_role.ecs_execution_role.name\n';
        mainTfContent += '  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# ECS Service\n';
        mainTfContent += 'resource "aws_ecs_service" "app" {\n';
        mainTfContent += `  name            = "${resourcePrefix}-service"\n`;
        mainTfContent += '  cluster         = aws_ecs_cluster.main.id\n';
        mainTfContent += '  task_definition = aws_ecs_task_definition.app.arn\n';
        mainTfContent += '  desired_count   = 1\n';
        mainTfContent += '  launch_type     = "FARGATE"\n';
        mainTfContent += '  network_configuration {\n';
        mainTfContent += '    subnets          = [aws_subnet.public_a.id, aws_subnet.public_b.id]\n';
        mainTfContent += '    security_groups  = [aws_security_group.ecs.id]\n';
        mainTfContent += '    assign_public_ip = true\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
      } else if (provider === 'azure') {
        // Azure Container Instances
        mainTfContent += '# Resource Group\n';
        mainTfContent += 'resource "azurerm_resource_group" "main" {\n';
        mainTfContent += `  name     = "${resourcePrefix}-rg"\n`;
        mainTfContent += `  location = "${config.region || 'West Europe'}"\n`;
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Container Group\n';
        mainTfContent += 'resource "azurerm_container_group" "main" {\n';
        mainTfContent += `  name                = "${resourcePrefix}-container-group"\n`;
        mainTfContent += '  location            = azurerm_resource_group.main.location\n';
        mainTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        mainTfContent += '  ip_address_type     = "Public"\n';
        mainTfContent += '  dns_name_label      = "${resourcePrefix}-container"\n';
        mainTfContent += '  os_type             = "Linux"\n';
        mainTfContent += '  container {\n';
        mainTfContent += `    name   = "${resourcePrefix}-app"\n`;
        mainTfContent += '    image  = "nginx:latest"\n';
        mainTfContent += '    cpu    = "0.5"\n';
        mainTfContent += '    memory = "1.5"\n';
        mainTfContent += '    ports {\n';
        mainTfContent += '      port     = 80\n';
        mainTfContent += '      protocol = "TCP"\n';
        mainTfContent += '    }\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
      } else if (provider === 'gcp') {
        // Google Cloud Run
        mainTfContent += '# Cloud Run Service\n';
        mainTfContent += 'resource "google_cloud_run_service" "main" {\n';
        mainTfContent += `  name     = "${resourcePrefix}-service"\n`;
        mainTfContent += `  location = "${region}"\n`;
        mainTfContent += '  template {\n';
        mainTfContent += '    spec {\n';
        mainTfContent += '      containers {\n';
        mainTfContent += '        image = "gcr.io/cloudrun/hello"\n';
        mainTfContent += '        resources {\n';
        mainTfContent += '          limits = {\n';
        mainTfContent += '            cpu    = "1000m"\n';
        mainTfContent += '            memory = "512Mi"\n';
        mainTfContent += '          }\n';
        mainTfContent += '        }\n';
        mainTfContent += '      }\n';
        mainTfContent += '    }\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# IAM\n';
        mainTfContent += 'resource "google_cloud_run_service_iam_member" "public" {\n';
        mainTfContent += '  service  = google_cloud_run_service.main.name\n';
        mainTfContent += '  location = google_cloud_run_service.main.location\n';
        mainTfContent += '  role     = "roles/run.invoker"\n';
        mainTfContent += '  member   = "allUsers"\n';
        mainTfContent += '}\n\n';
      }
    } else if (config.infrastructureType === InfrastructureType.KUBERNETES) {
      if (provider === 'aws') {
        // AWS EKS
        mainTfContent += '# VPC\n';
        mainTfContent += 'resource "aws_vpc" "main" {\n';
        mainTfContent += '  cidr_block = "10.0.0.0/16"\n';
        mainTfContent += '  enable_dns_support = true\n';
        mainTfContent += '  enable_dns_hostnames = true\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-vpc"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Subnets\n';
        mainTfContent += 'resource "aws_subnet" "private_a" {\n';
        mainTfContent += '  vpc_id            = aws_vpc.main.id\n';
        mainTfContent += '  cidr_block        = "10.0.1.0/24"\n';
        mainTfContent += `  availability_zone = "${region}a"\n`;
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-private-a"\n`;
        mainTfContent += '    "kubernetes.io/cluster/${aws_eks_cluster.main.name}" = "shared"\n';
        mainTfContent += '    "kubernetes.io/role/internal-elb" = "1"\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_subnet" "private_b" {\n';
        mainTfContent += '  vpc_id            = aws_vpc.main.id\n';
        mainTfContent += '  cidr_block        = "10.0.2.0/24"\n';
        mainTfContent += `  availability_zone = "${region}b"\n`;
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-private-b"\n`;
        mainTfContent += '    "kubernetes.io/cluster/${aws_eks_cluster.main.name}" = "shared"\n';
        mainTfContent += '    "kubernetes.io/role/internal-elb" = "1"\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_subnet" "public_a" {\n';
        mainTfContent += '  vpc_id            = aws_vpc.main.id\n';
        mainTfContent += '  cidr_block        = "10.0.3.0/24"\n';
        mainTfContent += `  availability_zone = "${region}a"\n`;
        mainTfContent += '  map_public_ip_on_launch = true\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-public-a"\n`;
        mainTfContent += '    "kubernetes.io/cluster/${aws_eks_cluster.main.name}" = "shared"\n';
        mainTfContent += '    "kubernetes.io/role/elb" = "1"\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_subnet" "public_b" {\n';
        mainTfContent += '  vpc_id            = aws_vpc.main.id\n';
        mainTfContent += '  cidr_block        = "10.0.4.0/24"\n';
        mainTfContent += `  availability_zone = "${region}b"\n`;
        mainTfContent += '  map_public_ip_on_launch = true\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-public-b"\n`;
        mainTfContent += '    "kubernetes.io/cluster/${aws_eks_cluster.main.name}" = "shared"\n';
        mainTfContent += '    "kubernetes.io/role/elb" = "1"\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Internet Gateway\n';
        mainTfContent += 'resource "aws_internet_gateway" "main" {\n';
        mainTfContent += '  vpc_id = aws_vpc.main.id\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-igw"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# NAT Gateway\n';
        mainTfContent += 'resource "aws_eip" "nat" {\n';
        mainTfContent += '  vpc = true\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-nat-eip"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_nat_gateway" "main" {\n';
        mainTfContent += '  allocation_id = aws_eip.nat.id\n';
        mainTfContent += '  subnet_id     = aws_subnet.public_a.id\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-nat-gw"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Route Tables\n';
        mainTfContent += 'resource "aws_route_table" "public" {\n';
        mainTfContent += '  vpc_id = aws_vpc.main.id\n';
        mainTfContent += '  route {\n';
        mainTfContent += '    cidr_block = "0.0.0.0/0"\n';
        mainTfContent += '    gateway_id = aws_internet_gateway.main.id\n';
        mainTfContent += '  }\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-public-rt"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_route_table" "private" {\n';
        mainTfContent += '  vpc_id = aws_vpc.main.id\n';
        mainTfContent += '  route {\n';
        mainTfContent += '    cidr_block = "0.0.0.0/0"\n';
        mainTfContent += '    nat_gateway_id = aws_nat_gateway.main.id\n';
        mainTfContent += '  }\n';
        mainTfContent += '  tags = {\n';
        mainTfContent += `    Name = "${resourcePrefix}-private-rt"\n`;
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Route Table Associations\n';
        mainTfContent += 'resource "aws_route_table_association" "public_a" {\n';
        mainTfContent += '  subnet_id      = aws_subnet.public_a.id\n';
        mainTfContent += '  route_table_id = aws_route_table.public.id\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_route_table_association" "public_b" {\n';
        mainTfContent += '  subnet_id      = aws_subnet.public_b.id\n';
        mainTfContent += '  route_table_id = aws_route_table.public.id\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_route_table_association" "private_a" {\n';
        mainTfContent += '  subnet_id      = aws_subnet.private_a.id\n';
        mainTfContent += '  route_table_id = aws_route_table.private.id\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_route_table_association" "private_b" {\n';
        mainTfContent += '  subnet_id      = aws_subnet.private_b.id\n';
        mainTfContent += '  route_table_id = aws_route_table.private.id\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# EKS Cluster IAM Role\n';
        mainTfContent += 'resource "aws_iam_role" "eks_cluster" {\n';
        mainTfContent += `  name = "${resourcePrefix}-eks-cluster-role"\n`;
        mainTfContent += '  assume_role_policy = jsonencode({\n';
        mainTfContent += '    Version = "2012-10-17"\n';
        mainTfContent += '    Statement = [\n';
        mainTfContent += '      {\n';
        mainTfContent += '        Action = "sts:AssumeRole"\n';
        mainTfContent += '        Effect = "Allow"\n';
        mainTfContent += '        Principal = {\n';
        mainTfContent += '          Service = "eks.amazonaws.com"\n';
        mainTfContent += '        }\n';
        mainTfContent += '      }\n';
        mainTfContent += '    ]\n';
        mainTfContent += '  })\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_iam_role_policy_attachment" "eks_cluster_policy" {\n';
        mainTfContent += '  role       = aws_iam_role.eks_cluster.name\n';
        mainTfContent += '  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# EKS Node Group IAM Role\n';
        mainTfContent += 'resource "aws_iam_role" "eks_node_group" {\n';
        mainTfContent += `  name = "${resourcePrefix}-eks-node-group-role"\n`;
        mainTfContent += '  assume_role_policy = jsonencode({\n';
        mainTfContent += '    Version = "2012-10-17"\n';
        mainTfContent += '    Statement = [\n';
        mainTfContent += '      {\n';
        mainTfContent += '        Action = "sts:AssumeRole"\n';
        mainTfContent += '        Effect = "Allow"\n';
        mainTfContent += '        Principal = {\n';
        mainTfContent += '          Service = "ec2.amazonaws.com"\n';
        mainTfContent += '        }\n';
        mainTfContent += '      }\n';
        mainTfContent += '    ]\n';
        mainTfContent += '  })\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_iam_role_policy_attachment" "eks_worker_node_policy" {\n';
        mainTfContent += '  role       = aws_iam_role.eks_node_group.name\n';
        mainTfContent += '  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_iam_role_policy_attachment" "eks_cni_policy" {\n';
        mainTfContent += '  role       = aws_iam_role.eks_node_group.name\n';
        mainTfContent += '  policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'resource "aws_iam_role_policy_attachment" "eks_container_registry" {\n';
        mainTfContent += '  role       = aws_iam_role.eks_node_group.name\n';
        mainTfContent += '  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# EKS Cluster\n';
        mainTfContent += 'resource "aws_eks_cluster" "main" {\n';
        mainTfContent += `  name     = "${resourcePrefix}-cluster"\n`;
        mainTfContent += '  role_arn = aws_iam_role.eks_cluster.arn\n';
        mainTfContent += '  vpc_config {\n';
        mainTfContent += '    subnet_ids = [\n';
        mainTfContent += '      aws_subnet.private_a.id,\n';
        mainTfContent += '      aws_subnet.private_b.id,\n';
        mainTfContent += '      aws_subnet.public_a.id,\n';
        mainTfContent += '      aws_subnet.public_b.id\n';
        mainTfContent += '    ]\n';
        mainTfContent += '    endpoint_private_access = true\n';
        mainTfContent += '    endpoint_public_access  = true\n';
        mainTfContent += '  }\n';
        mainTfContent += '  depends_on = [\n';
        mainTfContent += '    aws_iam_role_policy_attachment.eks_cluster_policy\n';
        mainTfContent += '  ]\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# EKS Node Group\n';
        mainTfContent += 'resource "aws_eks_node_group" "main" {\n';
        mainTfContent += `  cluster_name    = aws_eks_cluster.main.name\n`;
        mainTfContent += `  node_group_name = "${resourcePrefix}-node-group"\n`;
        mainTfContent += '  node_role_arn   = aws_iam_role.eks_node_group.arn\n';
        mainTfContent += '  subnet_ids      = [\n';
        mainTfContent += '    aws_subnet.private_a.id,\n';
        mainTfContent += '    aws_subnet.private_b.id\n';
        mainTfContent += '  ]\n';
        mainTfContent += '  scaling_config {\n';
        mainTfContent += '    desired_size = 2\n';
        mainTfContent += '    max_size     = 3\n';
        mainTfContent += '    min_size     = 1\n';
        mainTfContent += '  }\n';
        mainTfContent += '  instance_types = ["t3.medium"]\n';
        mainTfContent += '  depends_on = [\n';
        mainTfContent += '    aws_iam_role_policy_attachment.eks_worker_node_policy,\n';
        mainTfContent += '    aws_iam_role_policy_attachment.eks_cni_policy,\n';
        mainTfContent += '    aws_iam_role_policy_attachment.eks_container_registry\n';
        mainTfContent += '  ]\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Outputs\n';
        mainTfContent += 'output "eks_cluster_endpoint" {\n';
        mainTfContent += '  value = aws_eks_cluster.main.endpoint\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'output "eks_cluster_name" {\n';
        mainTfContent += '  value = aws_eks_cluster.main.name\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'output "kubeconfig_certificate_authority_data" {\n';
        mainTfContent += '  value = aws_eks_cluster.main.certificate_authority[0].data\n';
        mainTfContent += '}\n\n';
      } else if (provider === 'azure') {
        // Azure AKS
        mainTfContent += '# Resource Group\n';
        mainTfContent += 'resource "azurerm_resource_group" "main" {\n';
        mainTfContent += `  name     = "${resourcePrefix}-rg"\n`;
        mainTfContent += `  location = "${config.region || 'West Europe'}"\n`;
        mainTfContent += '}\n\n';
        
        mainTfContent += '# AKS Cluster\n';
        mainTfContent += 'resource "azurerm_kubernetes_cluster" "main" {\n';
        mainTfContent += `  name                = "${resourcePrefix}-aks"\n`;
        mainTfContent += '  location            = azurerm_resource_group.main.location\n';
        mainTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        mainTfContent += '  dns_prefix          = "${resourcePrefix}-k8s"\n';
        mainTfContent += '  kubernetes_version  = "1.24.9"\n';
        mainTfContent += '  default_node_pool {\n';
        mainTfContent += `    name       = "default"\n`;
        mainTfContent += '    node_count = 2\n';
        mainTfContent += '    vm_size    = "Standard_D2_v2"\n';
        mainTfContent += '  }\n';
        mainTfContent += '  identity {\n';
        mainTfContent += '    type = "SystemAssigned"\n';
        mainTfContent += '  }\n';
        mainTfContent += '  network_profile {\n';
        mainTfContent += '    network_plugin    = "kubenet"\n';
        mainTfContent += '    load_balancer_sku = "standard"\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Outputs\n';
        mainTfContent += 'output "kube_config" {\n';
        mainTfContent += '  value     = azurerm_kubernetes_cluster.main.kube_config_raw\n';
        mainTfContent += '  sensitive = true\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'output "host" {\n';
        mainTfContent += '  value = azurerm_kubernetes_cluster.main.kube_config[0].host\n';
        mainTfContent += '}\n\n';
      } else if (provider === 'gcp') {
        // Google GKE
        mainTfContent += '# GKE Cluster\n';
        mainTfContent += 'resource "google_container_cluster" "main" {\n';
        mainTfContent += `  name     = "${resourcePrefix}-gke"\n`;
        mainTfContent += `  location = "${region}"\n`;
        mainTfContent += '  remove_default_node_pool = true\n';
        mainTfContent += '  initial_node_count       = 1\n';
        mainTfContent += '  network    = "default"\n';
        mainTfContent += '  subnetwork = "default"\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# GKE Node Pool\n';
        mainTfContent += 'resource "google_container_node_pool" "main" {\n';
        mainTfContent += `  name       = "${resourcePrefix}-node-pool"\n`;
        mainTfContent += '  location   = google_container_cluster.main.location\n';
        mainTfContent += '  cluster    = google_container_cluster.main.name\n';
        mainTfContent += '  node_count = 2\n';
        mainTfContent += '  node_config {\n';
        mainTfContent += '    preemptible  = false\n';
        mainTfContent += '    machine_type = "e2-medium"\n';
        mainTfContent += '    oauth_scopes = [\n';
        mainTfContent += '      "https://www.googleapis.com/auth/logging.write",\n';
        mainTfContent += '      "https://www.googleapis.com/auth/monitoring",\n';
        mainTfContent += '      "https://www.googleapis.com/auth/devstorage.read_only"\n';
        mainTfContent += '    ]\n';
        mainTfContent += '  }\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += '# Outputs\n';
        mainTfContent += 'output "kubernetes_cluster_name" {\n';
        mainTfContent += '  value = google_container_cluster.main.name\n';
        mainTfContent += '}\n\n';
        
        mainTfContent += 'output "kubernetes_cluster_host" {\n';
        mainTfContent += '  value = google_container_cluster.main.endpoint\n';
        mainTfContent += '}\n\n';
      }
    }

    // Outputs
    mainTfContent += '# General Outputs\n';
    mainTfContent += 'output "resource_prefix" {\n';
    mainTfContent += `  value = "${resourcePrefix}"\n`;
    mainTfContent += '}\n\n';
    
    mainTfContent += 'output "provider" {\n';
    mainTfContent += `  value = "${provider}"\n`;
    mainTfContent += '}\n\n';
    
    mainTfContent += 'output "region" {\n';
    mainTfContent += `  value = "${region}"\n`;
    mainTfContent += '}\n\n';

    // Write main.tf file
    fs.writeFileSync(path.join(terraformDir, 'main.tf'), mainTfContent);

    // Create variables.tf
    let variablesTfContent = '# Variables\n\n';
    
    variablesTfContent += 'variable "project_name" {\n';
    variablesTfContent += '  description = "The name of the project"\n';
    variablesTfContent += `  default     = "${config.projectName || 'my-project'}"\n`;
    variablesTfContent += '}\n\n';
    
    variablesTfContent += 'variable "environment" {\n';
    variablesTfContent += '  description = "The deployment environment (dev, staging, prod)"\n';
    variablesTfContent += `  default     = "${config.environment || 'dev'}"\n`;
    variablesTfContent += '}\n\n';
    
    if (provider === 'aws') {
      variablesTfContent += 'variable "aws_region" {\n';
      variablesTfContent += '  description = "The AWS region to deploy to"\n';
      variablesTfContent += `  default     = "${region}"\n`;
      variablesTfContent += '}\n\n';
      
      variablesTfContent += 'variable "aws_access_key" {\n';
      variablesTfContent += '  description = "AWS access key"\n';
      variablesTfContent += '  sensitive   = true\n';
      variablesTfContent += '}\n\n';
      
      variablesTfContent += 'variable "aws_secret_key" {\n';
      variablesTfContent += '  description = "AWS secret key"\n';
      variablesTfContent += '  sensitive   = true\n';
      variablesTfContent += '}\n\n';
    } else if (provider === 'azure') {
      variablesTfContent += 'variable "azure_location" {\n';
      variablesTfContent += '  description = "The Azure location to deploy to"\n';
      variablesTfContent += `  default     = "${config.region || 'West Europe'}"\n`;
      variablesTfContent += '}\n\n';
      
      variablesTfContent += 'variable "azure_subscription_id" {\n';
      variablesTfContent += '  description = "Azure subscription ID"\n';
      variablesTfContent += '  sensitive   = true\n';
      variablesTfContent += '}\n\n';
      
      variablesTfContent += 'variable "azure_tenant_id" {\n';
      variablesTfContent += '  description = "Azure tenant ID"\n';
      variablesTfContent += '  sensitive   = true\n';
      variablesTfContent += '}\n\n';
      
      variablesTfContent += 'variable "azure_client_id" {\n';
      variablesTfContent += '  description = "Azure client ID"\n';
      variablesTfContent += '  sensitive   = true\n';
      variablesTfContent += '}\n\n';
      
      variablesTfContent += 'variable "azure_client_secret" {\n';
      variablesTfContent += '  description = "Azure client secret"\n';
      variablesTfContent += '  sensitive   = true\n';
      variablesTfContent += '}\n\n';
    } else if (provider === 'gcp') {
      variablesTfContent += 'variable "gcp_region" {\n';
      variablesTfContent += '  description = "The GCP region to deploy to"\n';
      variablesTfContent += `  default     = "${region}"\n`;
      variablesTfContent += '}\n\n';
      
      variablesTfContent += 'variable "gcp_project" {\n';
      variablesTfContent += '  description = "GCP project ID"\n';
      variablesTfContent += '}\n\n';
      
      variablesTfContent += 'variable "gcp_credentials" {\n';
      variablesTfContent += '  description = "GCP credentials JSON file path"\n';
      variablesTfContent += '  sensitive   = true\n';
      variablesTfContent += '}\n\n';
    }

    // Write variables.tf file
    fs.writeFileSync(path.join(terraformDir, 'variables.tf'), variablesTfContent);

    // Create outputs.tf
    let outputsTfContent = '# Outputs\n\n';
    
    outputsTfContent += 'output "deployment_id" {\n';
    outputsTfContent += '  description = "Unique identifier for this deployment"\n';
    outputsTfContent += '  value       = "${var.project_name}-${var.environment}"\n';
    outputsTfContent += '}\n\n';
    
    outputsTfContent += 'output "deployment_timestamp" {\n';
    outputsTfContent += '  description = "Timestamp of when this deployment was created"\n';
    outputsTfContent += '  value       = timestamp()\n';
    outputsTfContent += '}\n\n';

    // Write outputs.tf file
    fs.writeFileSync(path.join(terraformDir, 'outputs.tf'), outputsTfContent);

    // Create terraform.tfvars
    let tfvarsContent = '# Terraform Variables\n\n';
    
    tfvarsContent += `project_name = "${config.projectName || 'my-project'}"\n`;
    tfvarsContent += `environment = "${config.environment || 'dev'}"\n\n`;
    
    if (provider === 'aws') {
      tfvarsContent += `aws_region = "${region}"\n`;
      tfvarsContent += '# aws_access_key = "your-access-key"\n';
      tfvarsContent += '# aws_secret_key = "your-secret-key"\n\n';
    } else if (provider === 'azure') {
      tfvarsContent += `azure_location = "${config.region || 'West Europe'}"\n`;
      tfvarsContent += '# azure_subscription_id = "your-subscription-id"\n';
      tfvarsContent += '# azure_tenant_id = "your-tenant-id"\n';
      tfvarsContent += '# azure_client_id = "your-client-id"\n';
      tfvarsContent += '# azure_client_secret = "your-client-secret"\n\n';
    } else if (provider === 'gcp') {
      tfvarsContent += `gcp_region = "${region}"\n`;
      tfvarsContent += '# gcp_project = "your-project-id"\n';
      tfvarsContent += '# gcp_credentials = "path/to/your/credentials.json"\n\n';
    }

    // Write terraform.tfvars file
    fs.writeFileSync(path.join(terraformDir, 'terraform.tfvars'), tfvarsContent);

    // Create README.md
    let readmeContent = `# Terraform Configuration for ${config.projectName || 'My Project'}\n\n`;
    
    readmeContent += '## Overview\n\n';
    readmeContent += `This Terraform configuration sets up the infrastructure for ${config.projectName || 'my project'} on ${provider.toUpperCase()}.\n\n`;
    
    readmeContent += '## Prerequisites\n\n';
    readmeContent += '- Terraform v1.0.0 or newer\n';
    
    if (provider === 'aws') {
      readmeContent += '- AWS CLI configured with appropriate credentials\n';
      readmeContent += '- AWS account with necessary permissions\n\n';
    } else if (provider === 'azure') {
      readmeContent += '- Azure CLI installed and configured\n';
      readmeContent += '- Azure account with necessary permissions\n\n';
    } else if (provider === 'gcp') {
      readmeContent += '- Google Cloud SDK installed and configured\n';
      readmeContent += '- GCP account with necessary permissions\n\n';
    }
    
    readmeContent += '## Usage\n\n';
    readmeContent += '1. Update the `terraform.tfvars` file with your specific values\n';
    readmeContent += '2. Initialize Terraform:\n   ```\n   terraform init\n   ```\n';
    readmeContent += '3. Plan the deployment:\n   ```\n   terraform plan\n   ```\n';
    readmeContent += '4. Apply the configuration:\n   ```\n   terraform apply\n   ```\n\n';
    
    readmeContent += '## Resources Created\n\n';
    
    if (config.infrastructureType === InfrastructureType.SERVERLESS) {
      if (provider === 'aws') {
        readmeContent += '- AWS Lambda Function\n';
        readmeContent += '- API Gateway\n';
        readmeContent += '- IAM Roles and Policies\n';
        readmeContent += '- CloudWatch Log Group\n';
      } else if (provider === 'azure') {
        readmeContent += '- Azure Function App\n';
        readmeContent += '- App Service Plan\n';
        readmeContent += '- Storage Account\n';
      } else if (provider === 'gcp') {
        readmeContent += '- Google Cloud Function\n';
        readmeContent += '- Cloud Storage Bucket\n';
        readmeContent += '- IAM Roles\n';
      }
    } else if (config.infrastructureType === InfrastructureType.CONTAINER) {
      if (provider === 'aws') {
        readmeContent += '- AWS ECS Cluster\n';
        readmeContent += '- ECS Task Definition\n';
        readmeContent += '- ECS Service\n';
        readmeContent += '- VPC, Subnets, Security Groups\n';
        readmeContent += '- IAM Roles and Policies\n';
      } else if (provider === 'azure') {
        readmeContent += '- Azure Container Instance\n';
        readmeContent += '- Resource Group\n';
      } else if (provider === 'gcp') {
        readmeContent += '- Google Cloud Run Service\n';
        readmeContent += '- IAM Roles\n';
      }
    } else if (config.infrastructureType === InfrastructureType.KUBERNETES) {
      if (provider === 'aws') {
        readmeContent += '- AWS EKS Cluster\n';
        readmeContent += '- EKS Node Group\n';
        readmeContent += '- VPC, Subnets, Security Groups\n';
        readmeContent += '- IAM Roles and Policies\n';
      } else if (provider === 'azure') {
        readmeContent += '- Azure Kubernetes Service (AKS) Cluster\n';
        readmeContent += '- Resource Group\n';
      } else if (provider === 'gcp') {
        readmeContent += '- Google Kubernetes Engine (GKE) Cluster\n';
        readmeContent += '- GKE Node Pool\n';
      }
    }
    
    readmeContent += '\n## Cleanup\n\n';
    readmeContent += 'To destroy all resources created by this configuration:\n';
    readmeContent += '```\n';
    readmeContent += 'terraform destroy\n';
    readmeContent += '```\n\n';
    
    readmeContent += '## Notes\n\n';
    readmeContent += '- This configuration is intended for demonstration purposes\n';
    readmeContent += '- Review and customize the configuration before using in production\n';
    readmeContent += '- Ensure you have appropriate permissions and quotas in your cloud provider account\n';

    // Write README.md file
    fs.writeFileSync(path.join(terraformDir, 'README.md'), readmeContent);

    // Create .gitignore
    let gitignoreContent = '# Terraform .gitignore\n\n';
    gitignoreContent += '# Local .terraform directories\n';
    gitignoreContent += '**/.terraform/*\n\n';
    gitignoreContent += '# .tfstate files\n';
    gitignoreContent += '*.tfstate\n';
    gitignoreContent += '*.tfstate.*\n\n';
    gitignoreContent += '# Crash log files\n';
    gitignoreContent += 'crash.log\n\n';
    gitignoreContent += '# Exclude all .tfvars files, which are likely to contain sensitive data\n';
    gitignoreContent += '*.tfvars\n';
    gitignoreContent += '*.tfvars.json\n\n';
    gitignoreContent += '# Ignore override files as they are usually used for local dev\n';
    gitignoreContent += 'override.tf\n';
    gitignoreContent += 'override.tf.json\n';
    gitignoreContent += '*_override.tf\n';
    gitignoreContent += '*_override.tf.json\n\n';
    gitignoreContent += '# Ignore CLI configuration files\n';
    gitignoreContent += '.terraformrc\n';
    gitignoreContent += 'terraform.rc\n';

    // Write .gitignore file
    fs.writeFileSync(path.join(terraformDir, '.gitignore'), gitignoreContent);

    this.logger.info(`Terraform configuration created in ${terraformDir}`);
    return terraformDir;
  }

  /**
   * Sets up Docker configuration for the project
   * @param config Docker configuration
   * @returns Path to the Docker configuration directory
   */
  private async setupDocker(config: ContainerConfig): Promise<string> {
    const dockerDir = path.join(process.cwd(), 'docker');
    
    // Create docker directory if it doesn't exist
    if (!fs.existsSync(dockerDir)) {
      fs.mkdirSync(dockerDir, { recursive: true });
    }

    // Create Dockerfile
    let dockerfileContent = '';
    
    if (config.baseImage) {
      dockerfileContent += `FROM ${config.baseImage}\n\n`;
    } else {
      // Default to Node.js if no base image is specified
      dockerfileContent += 'FROM node:16-alpine\n\n';
    }
    
    dockerfileContent += 'WORKDIR /app\n\n';
    
    if (config.dependencies && config.dependencies.length > 0) {
      if (config.baseImage && config.baseImage.includes('node')) {
        // Node.js dependencies
        dockerfileContent += 'COPY package*.json ./\n';
        dockerfileContent += 'RUN npm install\n\n';
      } else if (config.baseImage && config.baseImage.includes('python')) {
        // Python dependencies
        dockerfileContent += 'COPY requirements.txt ./\n';
        dockerfileContent += 'RUN pip install --no-cache-dir -r requirements.txt\n\n';
      }
    }
    
    dockerfileContent += 'COPY . .\n\n';
    
    if (config.exposedPorts && config.exposedPorts.length > 0) {
      config.exposedPorts.forEach(port => {
        dockerfileContent += `EXPOSE ${port}\n`;
      });
      dockerfileContent += '\n';
    }
    
    if (config.command) {
      dockerfileContent += `CMD ${config.command}\n`;
    } else {
      // Default command based on base image
      if (config.baseImage && config.baseImage.includes('node')) {
        dockerfileContent += 'CMD ["npm", "start"]\n';
      } else if (config.baseImage && config.baseImage.includes('python')) {
        dockerfileContent += 'CMD ["python", "app.py"]\n';
      } else {
        dockerfileContent += 'CMD ["sh", "-c", "echo No command specified"]\n';
      }
    }

    // Write Dockerfile
    fs.writeFileSync(path.join(dockerDir, 'Dockerfile'), dockerfileContent);

    // Create .dockerignore
    let dockerignoreContent = 'node_modules\n';
    dockerignoreContent += 'npm-debug.log\n';
    dockerignoreContent += '.git\n';
    dockerignoreContent += '.gitignore\n';
    dockerignoreContent += '.env\n';
    dockerignoreContent += '*.md\n';
    dockerignoreContent += 'docker-compose*.yml\n';

    // Write .dockerignore
    fs.writeFileSync(path.join(dockerDir, '.dockerignore'), dockerignoreContent);

    // Create docker-compose.yml if needed
    if (config.createDockerCompose) {
      let dockerComposeContent = 'version: "3.8"\n\n';
      dockerComposeContent += 'services:\n';
      dockerComposeContent += '  app:\n';
      dockerComposeContent += '    build:\n';
      dockerComposeContent += '      context: ..\n';
      dockerComposeContent += '      dockerfile: docker/Dockerfile\n';
      dockerComposeContent += '    container_name: app\n';
      
      if (config.exposedPorts && config.exposedPorts.length > 0) {
        dockerComposeContent += '    ports:\n';
        config.exposedPorts.forEach(port => {
          dockerComposeContent += `      - "${port}:${port}"\n`;
        });
      }
      
      if (config.volumes && config.volumes.length > 0) {
        dockerComposeContent += '    volumes:\n';
        config.volumes.forEach(volume => {
          dockerComposeContent += `      - ${volume}\n`;
        });
      }
      
      if (config.environmentVariables && Object.keys(config.environmentVariables).length > 0) {
        dockerComposeContent += '    environment:\n';
        Object.entries(config.environmentVariables).forEach(([key, value]) => {
          dockerComposeContent += `      - ${key}=${value}\n`;
        });
      }
      
      if (config.dependsOn && config.dependsOn.length > 0) {
        dockerComposeContent += '    depends_on:\n';
        config.dependsOn.forEach(dependency => {
          dockerComposeContent += `      - ${dependency}\n`;
        });
      }
      
      // Add database service if needed
      if (config.includeDatabase) {
        dockerComposeContent += '\n  db:\n';
        dockerComposeContent += '    image: postgres:13\n';
        dockerComposeContent += '    container_name: db\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "5432:5432"\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - POSTGRES_USER=postgres\n';
        dockerComposeContent += '      - POSTGRES_PASSWORD=postgres\n';
        dockerComposeContent += '      - POSTGRES_DB=app\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - postgres_data:/var/lib/postgresql/data\n';
      }
      
      // Add volumes section if database is included
      if (config.includeDatabase) {
        dockerComposeContent += '\nvolumes:\n';
        dockerComposeContent += '  postgres_data:\n';
      }

      // Write docker-compose.yml
      fs.writeFileSync(path.join(dockerDir, 'docker-compose.yml'), dockerComposeContent);
      
      // Create docker-compose.prod.yml with production settings
      let dockerComposeProdContent = 'version: "3.8"\n\n';
      dockerComposeProdContent += 'services:\n';
      dockerComposeProdContent += '  app:\n';
      dockerComposeProdContent += '    build:\n';
      dockerComposeProdContent += '      context: ..\n';
      dockerComposeProdContent += '      dockerfile: docker/Dockerfile\n';
      dockerComposeProdContent += '    container_name: app\n';
      dockerComposeProdContent += '    restart: always\n';
      
      if (config.exposedPorts && config.exposedPorts.length > 0) {
        dockerComposeProdContent += '    ports:\n';
        config.exposedPorts.forEach(port => {
          dockerComposeProdContent += `      - "${port}:${port}"\n`;
        });
      }
      
      if (config.volumes && config.volumes.length > 0) {
        dockerComposeProdContent += '    volumes:\n';
        config.volumes.forEach(volume => {
          dockerComposeProdContent += `      - ${volume}\n`;
        });
      }
      
      if (config.environmentVariables && Object.keys(config.environmentVariables).length > 0) {
        dockerComposeProdContent += '    environment:\n';
        dockerComposeProdContent += '      - NODE_ENV=production\n';
        
        if (config.environmentVariables && Object.keys(config.environmentVariables).length > 0) {
          Object.entries(config.environmentVariables).forEach(([key, value]) => {
            if (key !== 'NODE_ENV') { // Evitar duplicar NODE_ENV
              dockerComposeProdContent += `      - ${key}=${value}\n`;
            }
          });
        }
        
        if (config.dependsOn && config.dependsOn.length > 0) {
          dockerComposeProdContent += '    depends_on:\n';
          config.dependsOn.forEach(dependency => {
            dockerComposeProdContent += `      - ${dependency}\n`;
          });
        }
        
        // Add database service if needed for production
        if (config.includeDatabase) {
          dockerComposeProdContent += '\n  db:\n';
          dockerComposeProdContent += '    image: postgres:13\n';
          dockerComposeProdContent += '    container_name: db\n';
          dockerComposeProdContent += '    restart: always\n';
          dockerComposeProdContent += '    ports:\n';
          dockerComposeProdContent += '      - "5432:5432"\n';
          dockerComposeProdContent += '    environment:\n';
          dockerComposeProdContent += '      - POSTGRES_USER=postgres\n';
          dockerComposeProdContent += '      - POSTGRES_PASSWORD=${DB_PASSWORD}\n';
          dockerComposeProdContent += '      - POSTGRES_DB=app\n';
          dockerComposeProdContent += '    volumes:\n';
          dockerComposeProdContent += '      - postgres_data:/var/lib/postgresql/data\n';
        }
        
        // Add volumes section if database is included
        if (config.includeDatabase) {
          dockerComposeProdContent += '\nvolumes:\n';
          dockerComposeProdContent += '  postgres_data:\n';
        }

        // Write docker-compose.prod.yml
        fs.writeFileSync(path.join(dockerDir, 'docker-compose.prod.yml'), dockerComposeProdContent);
      }
    }

    // Create README.md for Docker
    let dockerReadmeContent = '# Docker Configuration\n\n';
    dockerReadmeContent += `This directory contains Docker configuration for ${config.projectName || 'the project'}.\n\n`;
    
    dockerReadmeContent += '## Files\n\n';
    dockerReadmeContent += '- `Dockerfile`: Main Docker configuration for building the application image\n';
    dockerReadmeContent += '- `.dockerignore`: Specifies files to exclude from the Docker build context\n';
    
    if (config.createDockerCompose) {
      dockerReadmeContent += '- `docker-compose.yml`: Docker Compose configuration for local development\n';
      dockerReadmeContent += '- `docker-compose.prod.yml`: Docker Compose configuration for production deployment\n';
    }
    
    dockerReadmeContent += '\n## Usage\n\n';
    dockerReadmeContent += '### Building the Docker Image\n\n';
    dockerReadmeContent += '```bash\n';
    dockerReadmeContent += 'docker build -t myapp:latest -f docker/Dockerfile .\n';
    dockerReadmeContent += '```\n\n';
    
    dockerReadmeContent += '### Running the Container\n\n';
    dockerReadmeContent += '```bash\n';
    dockerReadmeContent += 'docker run -p 3000:3000 myapp:latest\n';
    dockerReadmeContent += '```\n\n';
    
    if (config.createDockerCompose) {
      dockerReadmeContent += '### Using Docker Compose for Development\n\n';
      dockerReadmeContent += '```bash\n';
      dockerReadmeContent += 'docker-compose -f docker/docker-compose.yml up\n';
      dockerReadmeContent += '```\n\n';
      
      dockerReadmeContent += '### Using Docker Compose for Production\n\n';
      dockerReadmeContent += '```bash\n';
      dockerReadmeContent += 'docker-compose -f docker/docker-compose.prod.yml up -d\n';
      dockerReadmeContent += '```\n';
    }

    // Write Docker README.md
    fs.writeFileSync(path.join(dockerDir, 'README.md'), dockerReadmeContent);

    this.logger.info(`Docker configuration created in ${dockerDir}`);
    return dockerDir;
  }

  /**
   * Sets up Kubernetes configuration for the project
   * @param config Kubernetes configuration
   * @returns Path to the Kubernetes configuration directory
   */
  private async setupKubernetes(config: KubernetesConfig): Promise<string> {
    const k8sDir = path.join(process.cwd(), 'kubernetes');
    
    // Create kubernetes directory if it doesn't exist
    if (!fs.existsSync(k8sDir)) {
      fs.mkdirSync(k8sDir, { recursive: true });
    }

    // Create namespace.yaml
    const namespace = config.namespace || 'default';
    let namespaceYaml = '';
    
    if (namespace !== 'default') {
      namespaceYaml = 'apiVersion: v1\n';
      namespaceYaml += 'kind: Namespace\n';
      namespaceYaml += 'metadata:\n';
      namespaceYaml += `  name: ${namespace}\n`;
      
      // Write namespace.yaml
      fs.writeFileSync(path.join(k8sDir, 'namespace.yaml'), namespaceYaml);
    }

    // Create deployment.yaml
    let deploymentYaml = 'apiVersion: apps/v1\n';
    deploymentYaml += 'kind: Deployment\n';
    deploymentYaml += 'metadata:\n';
    deploymentYaml += `  name: ${config.appName || 'app'}\n`;
    
    if (namespace !== 'default') {
      deploymentYaml += `  namespace: ${namespace}\n`;
    }
    
    deploymentYaml += 'spec:\n';
    deploymentYaml += `  replicas: ${config.replicas || 1}\n`;
    deploymentYaml += '  selector:\n';
    deploymentYaml += '    matchLabels:\n';
    deploymentYaml += `      app: ${config.appName || 'app'}\n`;
    deploymentYaml += '  template:\n';
    deploymentYaml += '    metadata:\n';
    deploymentYaml += '      labels:\n';
    deploymentYaml += `        app: ${config.appName || 'app'}\n`;
    deploymentYaml += '    spec:\n';
    
    // Add init containers if needed
    if (config.initContainers && config.initContainers.length > 0) {
      deploymentYaml += '      initContainers:\n';
      config.initContainers.forEach(container => {
        deploymentYaml += `      - name: ${container.name}\n`;
        deploymentYaml += `        image: ${container.image}\n`;
        
        if (container.command) {
          deploymentYaml += '        command:\n';
          container.command.forEach(cmd => {
            deploymentYaml += `        - ${cmd}\n`;
          });
        }
        
        if (container.env && container.env.length > 0) {
          deploymentYaml += '        env:\n';
          container.env.forEach(env => {
            deploymentYaml += `        - name: ${env.name}\n`;
            if (env.value) {
              deploymentYaml += `          value: "${env.value}"\n`;
            } else if (env.valueFrom) {
              deploymentYaml += '          valueFrom:\n';
              if (env.valueFrom.configMapKeyRef) {
                deploymentYaml += '            configMapKeyRef:\n';
                deploymentYaml += `              name: ${env.valueFrom.configMapKeyRef.name}\n`;
                deploymentYaml += `              key: ${env.valueFrom.configMapKeyRef.key}\n`;
              } else if (env.valueFrom.secretKeyRef) {
                deploymentYaml += '            secretKeyRef:\n';
                deploymentYaml += `              name: ${env.valueFrom.secretKeyRef.name}\n`;
                deploymentYaml += `              key: ${env.valueFrom.secretKeyRef.key}\n`;
              }
            }
          });
        }
      });
    }
    
    // Add containers
    deploymentYaml += '      containers:\n';
    deploymentYaml += `      - name: ${config.appName || 'app'}\n`;
    deploymentYaml += `        image: ${config.image || 'myapp:latest'}\n`;
    
    if (config.containerPorts && config.containerPorts.length > 0) {
      deploymentYaml += '        ports:\n';
      config.containerPorts.forEach(port => {
        deploymentYaml += `        - containerPort: ${port}\n`;
      });
    }
    
    if (config.env && config.env.length > 0) {
      deploymentYaml += '        env:\n';
      config.env.forEach(env => {
        deploymentYaml += `        - name: ${env.name}\n`;
        if (env.value) {
          deploymentYaml += `          value: "${env.value}"\n`;
        } else if (env.valueFrom) {
          deploymentYaml += '          valueFrom:\n';
          if (env.valueFrom.configMapKeyRef) {
            deploymentYaml += '            configMapKeyRef:\n';
            deploymentYaml += `              name: ${env.valueFrom.configMapKeyRef.name}\n`;
            deploymentYaml += `              key: ${env.valueFrom.configMapKeyRef.key}\n`;
          } else if (env.valueFrom.secretKeyRef) {
            deploymentYaml += '            secretKeyRef:\n';
            deploymentYaml += `              name: ${env.valueFrom.secretKeyRef.name}\n`;
            deploymentYaml += `              key: ${env.valueFrom.secretKeyRef.key}\n`;
          }
        }
      });
    }
    
    // Add resources if specified
    if (config.resources) {
      deploymentYaml += '        resources:\n';
      if (config.resources.limits) {
        deploymentYaml += '          limits:\n';
        if (config.resources.limits.cpu) {
          deploymentYaml += `            cpu: "${config.resources.limits.cpu}"\n`;
        }
        if (config.resources.limits.memory) {
          deploymentYaml += `            memory: "${config.resources.limits.memory}"\n`;
        }
      }
      if (config.resources.requests) {
        deploymentYaml += '          requests:\n';
        if (config.resources.requests.cpu) {
          deploymentYaml += `            cpu: "${config.resources.requests.cpu}"\n`;
        }
        if (config.resources.requests.memory) {
          deploymentYaml += `            memory: "${config.resources.requests.memory}"\n`;
        }
      }
    }
    
    // Add liveness probe if specified
    if (config.livenessProbe) {
      deploymentYaml += '        livenessProbe:\n';
      if (config.livenessProbe.httpGet) {
        deploymentYaml += '          httpGet:\n';
        deploymentYaml += `            path: ${config.livenessProbe.httpGet.path}\n`;
        deploymentYaml += `            port: ${config.livenessProbe.httpGet.port}\n`;
      } else if (config.livenessProbe.exec) {
        deploymentYaml += '          exec:\n';
        deploymentYaml += '            command:\n';
        config.livenessProbe.exec.command.forEach(cmd => {
          deploymentYaml += `            - ${cmd}\n`;
        });
      } else if (config.livenessProbe.tcpSocket) {
        deploymentYaml += '          tcpSocket:\n';
        deploymentYaml += `            port: ${config.livenessProbe.tcpSocket.port}\n`;
      }
      if (config.livenessProbe.initialDelaySeconds) {
        deploymentYaml += `          initialDelaySeconds: ${config.livenessProbe.initialDelaySeconds}\n`;
      }
      if (config.livenessProbe.periodSeconds) {
        deploymentYaml += `          periodSeconds: ${config.livenessProbe.periodSeconds}\n`;
      }
    }
    
    // Add readiness probe if specified
    if (config.readinessProbe) {
      deploymentYaml += '        readinessProbe:\n';
      if (config.readinessProbe.httpGet) {
        deploymentYaml += '          httpGet:\n';
        deploymentYaml += `            path: ${config.readinessProbe.httpGet.path}\n`;
        deploymentYaml += `            port: ${config.readinessProbe.httpGet.port}\n`;
      } else if (config.readinessProbe.exec) {
        deploymentYaml += '          exec:\n';
        deploymentYaml += '            command:\n';
        config.readinessProbe.exec.command.forEach(cmd => {
          deploymentYaml += `            - ${cmd}\n`;
        });
      } else if (config.readinessProbe.tcpSocket) {
        deploymentYaml += '          tcpSocket:\n';
        deploymentYaml += `            port: ${config.readinessProbe.tcpSocket.port}\n`;
      }
      if (config.readinessProbe.initialDelaySeconds) {
        deploymentYaml += `          initialDelaySeconds: ${config.readinessProbe.initialDelaySeconds}\n`;
      }
      if (config.readinessProbe.periodSeconds) {
        deploymentYaml += `          periodSeconds: ${config.readinessProbe.periodSeconds}\n`;
      }
    }
    
    // Add volume mounts if specified
    if (config.volumeMounts && config.volumeMounts.length > 0) {
      deploymentYaml += '        volumeMounts:\n';
      config.volumeMounts.forEach(mount => {
        deploymentYaml += `        - name: ${mount.name}\n`;
        deploymentYaml += `          mountPath: ${mount.mountPath}\n`;
        if (mount.subPath) {
          deploymentYaml += `          subPath: ${mount.subPath}\n`;
        }
        if (mount.readOnly) {
          deploymentYaml += '          readOnly: true\n';
        }
      });
    }
    
    // Add volumes if specified
    if (config.volumes && config.volumes.length > 0) {
      deploymentYaml += '      volumes:\n';
      config.volumes.forEach(volume => {
        deploymentYaml += `      - name: ${volume.name}\n`;
        if (volume.configMap) {
          deploymentYaml += '        configMap:\n';
          deploymentYaml += `          name: ${volume.configMap.name}\n`;
        } else if (volume.secret) {
          deploymentYaml += '        secret:\n';
          deploymentYaml += `          secretName: ${volume.secret.secretName}\n`;
        } else if (volume.persistentVolumeClaim) {
          deploymentYaml += '        persistentVolumeClaim:\n';
          deploymentYaml += `          claimName: ${volume.persistentVolumeClaim.claimName}\n`;
        } else if (volume.emptyDir) {
          deploymentYaml += '        emptyDir: {}\n';
        }
      });
    }

    // Write deployment.yaml
    fs.writeFileSync(path.join(k8sDir, 'deployment.yaml'), deploymentYaml);

    // Create service.yaml
    let serviceYaml = 'apiVersion: v1\n';
    serviceYaml += 'kind: Service\n';
    serviceYaml += 'metadata:\n';
    serviceYaml += `  name: ${config.appName || 'app'}\n`;
    
    if (namespace !== 'default') {
      serviceYaml += `  namespace: ${namespace}\n`;
    }
    
    serviceYaml += 'spec:\n';
    serviceYaml += `  type: ${config.serviceType || 'ClusterIP'}\n`;
    serviceYaml += '  selector:\n';
    serviceYaml += `    app: ${config.appName || 'app'}\n`;
    serviceYaml += '  ports:\n';
    
    if (config.servicePorts && config.servicePorts.length > 0) {
      config.servicePorts.forEach(port => {
        serviceYaml += '  - port: ' + port.port + '\n';
        if (port.targetPort) {
          serviceYaml += '    targetPort: ' + port.targetPort + '\n';
        }
        if (port.nodePort && config.serviceType === 'NodePort') {
          serviceYaml += '    nodePort: ' + port.nodePort + '\n';
        }
        if (port.name) {
          serviceYaml += '    name: ' + port.name + '\n';
        }
        if (port.protocol) {
          serviceYaml += '    protocol: ' + port.protocol + '\n';
        }
      });
    } else {
      // Default port configuration
      serviceYaml += '  - port: 80\n';
      serviceYaml += '    targetPort: 3000\n';
    }

    // Write service.yaml
    fs.writeFileSync(path.join(k8sDir, 'service.yaml'), serviceYaml);

    // Create ingress.yaml if needed
    if (config.createIngress) {
      let ingressYaml = 'apiVersion: networking.k8s.io/v1\n';
      ingressYaml += 'kind: Ingress\n';
      ingressYaml += 'metadata:\n';
      ingressYaml += `  name: ${config.appName || 'app'}-ingress\n`;
      
      if (namespace !== 'default') {
        ingressYaml += `  namespace: ${namespace}\n`;
      }
      
      ingressYaml += '  annotations:\n';
      ingressYaml += '    kubernetes.io/ingress.class: nginx\n';
      
      if (config.ingressAnnotations) {
        Object.entries(config.ingressAnnotations).forEach(([key, value]) => {
          ingressYaml += `    ${key}: ${value}\n`;
        });
      }
      
      ingressYaml += 'spec:\n';
      ingressYaml += '  rules:\n';
      
      if (config.ingressHosts && config.ingressHosts.length > 0) {
        config.ingressHosts.forEach(host => {
          ingressYaml += `  - host: ${host.host}\n`;
          ingressYaml += '    http:\n';
          ingressYaml += '      paths:\n';
          
          if (host.paths && host.paths.length > 0) {
            host.paths.forEach(p => {
              ingressYaml += `      - path: ${p.path}\n`;
              ingressYaml += '        pathType: Prefix\n';
              ingressYaml += '        backend:\n';
              ingressYaml += '          service:\n';
              ingressYaml += `            name: ${p.serviceName || config.appName || 'app'}\n`;
              ingressYaml += '            port:\n';
              ingressYaml += `              number: ${p.servicePort || 80}\n`;
            });
          } else {
            // Default path configuration
            ingressYaml += '      - path: /\n';
            ingressYaml += '        pathType: Prefix\n';
            ingressYaml += '        backend:\n';
            ingressYaml += '          service:\n';
            ingressYaml += `            name: ${config.appName || 'app'}\n`;
            ingressYaml += '            port:\n';
            ingressYaml += '              number: 80\n';
          }
        });
      } else {
        // Default host configuration
        ingressYaml += '  - http:\n';
        ingressYaml += '      paths:\n';
        ingressYaml += '      - path: /\n';
        ingressYaml += '        pathType: Prefix\n';
        ingressYaml += '        backend:\n';
        ingressYaml += '          service:\n';
        ingressYaml += `            name: ${config.appName || 'app'}\n`;
        ingressYaml += '            port:\n';
        ingressYaml += '              number: 80\n';
      }
      
      // Add TLS configuration if needed
      if (config.ingressTls && config.ingressTls.length > 0) {
        ingressYaml += '  tls:\n';
        config.ingressTls.forEach(tls => {
          ingressYaml += '  - hosts:\n';
          tls.hosts.forEach(host => {
            ingressYaml += `    - ${host}\n`;
          });
          if (tls.secretName) {
            ingressYaml += `    secretName: ${tls.secretName}\n`;
          }
        });
      }

      // Write ingress.yaml
      fs.writeFileSync(path.join(k8sDir, 'ingress.yaml'), ingressYaml);
    }

    // Create configmap.yaml if needed
    if (config.configMapData && Object.keys(config.configMapData).length > 0) {
      let configMapYaml = 'apiVersion: v1\n';
      configMapYaml += 'kind: ConfigMap\n';
      configMapYaml += 'metadata:\n';
      configMapYaml += `  name: ${config.appName || 'app'}-config\n`;
      
      if (namespace !== 'default') {
        configMapYaml += `  namespace: ${namespace}\n`;
      }
      
      configMapYaml += 'data:\n';
      
      Object.entries(config.configMapData).forEach(([key, value]) => {
        configMapYaml += `  ${key}: |\n`;
        value.split('\n').forEach(line => {
          configMapYaml += `    ${line}\n`;
        });
      });

      // Write configmap.yaml
      fs.writeFileSync(path.join(k8sDir, 'configmap.yaml'), configMapYaml);
    }

    // Create secret.yaml if needed
    if (config.secretData && Object.keys(config.secretData).length > 0) {
      let secretYaml = 'apiVersion: v1\n';
      secretYaml += 'kind: Secret\n';
      secretYaml += 'metadata:\n';
      secretYaml += `  name: ${config.appName || 'app'}-secret\n`;
      
      if (namespace !== 'default') {
        secretYaml += `  namespace: ${namespace}\n`;
      }
      
      secretYaml += 'type: Opaque\n';
      secretYaml += 'data:\n';
      
      Object.entries(config.secretData).forEach(([key, value]) => {
        // Convert to base64
        const base64Value = Buffer.from(value).toString('base64');
        secretYaml += `  ${key}: ${base64Value}\n`;
      });

      // Write secret.yaml
      fs.writeFileSync(path.join(k8sDir, 'secret.yaml'), secretYaml);
    }

    // Create persistent volume claim if needed
    if (config.createPvc) {
      let pvcYaml = 'apiVersion: v1\n';
      pvcYaml += 'kind: PersistentVolumeClaim\n';
      pvcYaml += 'metadata:\n';
      pvcYaml += `  name: ${config.appName || 'app'}-pvc\n`;
      
      if (namespace !== 'default') {
        pvcYaml += `  namespace: ${namespace}\n`;
      }
      
      pvcYaml += 'spec:\n';
      pvcYaml += '  accessModes:\n';
      pvcYaml += '    - ReadWriteOnce\n';
      pvcYaml += '  resources:\n';
      pvcYaml += '    requests:\n';
      pvcYaml += `      storage: ${config.pvcSize || '1Gi'}\n`;
      
      if (config.storageClassName) {
        pvcYaml += `  storageClassName: ${config.storageClassName}\n`;
      }

      // Write pvc.yaml
      fs.writeFileSync(path.join(k8sDir, 'pvc.yaml'), pvcYaml);
    }

    // Create horizontal pod autoscaler if needed
    if (config.createHpa) {
      let hpaYaml = 'apiVersion: autoscaling/v2\n';
      hpaYaml += 'kind: HorizontalPodAutoscaler\n';
      hpaYaml += 'metadata:\n';
      hpaYaml += `  name: ${config.appName || 'app'}-hpa\n`;
      
      if (namespace !== 'default') {
        hpaYaml += `  namespace: ${namespace}\n`;
      }
      
      hpaYaml += 'spec:\n';
      hpaYaml += '  scaleTargetRef:\n';
      hpaYaml += '    apiVersion: apps/v1\n';
      hpaYaml += '    kind: Deployment\n';
      hpaYaml += `    name: ${config.appName || 'app'}\n`;
      hpaYaml += `  minReplicas: ${config.hpaMinReplicas || 1}\n`;
      hpaYaml += `  maxReplicas: ${config.hpaMaxReplicas || 10}\n`;
      hpaYaml += '  metrics:\n';
      hpaYaml += '  - type: Resource\n';
      hpaYaml += '    resource:\n';
      hpaYaml += '      name: cpu\n';
      hpaYaml += '      target:\n';
      hpaYaml += '        type: Utilization\n';
      hpaYaml += `        averageUtilization: ${config.hpaCpuUtilization || 80}\n`;

      // Write hpa.yaml
      fs.writeFileSync(path.join(k8sDir, 'hpa.yaml'), hpaYaml);
    }

    // Create kustomization.yaml
    let kustomizationYaml = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
    kustomizationYaml += 'kind: Kustomization\n';
    kustomizationYaml += '\n';
    
    if (namespace !== 'default') {
      kustomizationYaml += `namespace: ${namespace}\n\n`;
    }
    
    kustomizationYaml += 'resources:\n';
    
    if (namespace !== 'default') {
      kustomizationYaml += '- namespace.yaml\n';
    }
    
    kustomizationYaml += '- deployment.yaml\n';
    kustomizationYaml += '- service.yaml\n';
    
    if (config.createIngress) {
      kustomizationYaml += '- ingress.yaml\n';
    }
    
    if (config.configMapData && Object.keys(config.configMapData).length > 0) {
      kustomizationYaml += '- configmap.yaml\n';
    }
    
    if (config.secretData && Object.keys(config.secretData).length > 0) {
      kustomizationYaml += '- secret.yaml\n';
    }
    
    if (config.createPvc) {
      kustomizationYaml += '- pvc.yaml\n';
    }
    
    if (config.createHpa) {
      kustomizationYaml += '- hpa.yaml\n';
    }

    // Write kustomization.yaml
    fs.writeFileSync(path.join(k8sDir, 'kustomization.yaml'), kustomizationYaml);

    // Create README.md for Kubernetes
    let k8sReadmeContent = '# Kubernetes Configuration\n\n';
    k8sReadmeContent += `This directory contains Kubernetes configuration for ${config.appName || 'the application'}.\n\n`;
    
    k8sReadmeContent += '## Files\n\n';
    
    if (namespace !== 'default') {
      k8sReadmeContent += '- `namespace.yaml`: Defines the Kubernetes namespace\n';
    }
    
    k8sReadmeContent += '- `deployment.yaml`: Defines the Kubernetes deployment\n';
    k8sReadmeContent += '- `service.yaml`: Defines the Kubernetes service\n';
    
    if (config.createIngress) {
      k8sReadmeContent += '- `ingress.yaml`: Defines the Kubernetes ingress for external access\n';
    }
    
    if (config.configMapData && Object.keys(config.configMapData).length > 0) {
      k8sReadmeContent += '- `configmap.yaml`: Defines configuration data\n';
    }
    
    if (config.secretData && Object.keys(config.secretData).length > 0) {
      k8sReadmeContent += '- `secret.yaml`: Defines secret data (base64 encoded)\n';
    }
    
    if (config.createPvc) {
      k8sReadmeContent += '- `pvc.yaml`: Defines persistent volume claim\n';
    }
    
    if (config.createHpa) {
      k8sReadmeContent += '- `hpa.yaml`: Defines horizontal pod autoscaler\n';
    }
    
    k8sReadmeContent += '- `kustomization.yaml`: Kustomize configuration for managing resources\n\n';
    
    k8sReadmeContent += '## Usage\n\n';
    k8sReadmeContent += '### Applying the Configuration\n\n';
    k8sReadmeContent += '```bash\n';
    k8sReadmeContent += 'kubectl apply -k .\n';
    k8sReadmeContent += '```\n\n';
    
    k8sReadmeContent += '### Viewing Resources\n\n';
    k8sReadmeContent += '```bash\n';
    k8sReadmeContent += `kubectl get all -n ${namespace}\n`;
    k8sReadmeContent += '```\n\n';
    
    k8sReadmeContent += '### Deleting Resources\n\n';
    k8sReadmeContent += '```bash\n';
    k8sReadmeContent += 'kubectl delete -k .\n';
    k8sReadmeContent += '```\n';

    // Write Kubernetes README.md
    fs.writeFileSync(path.join(k8sDir, 'README.md'), k8sReadmeContent);

    this.logger.info(`Kubernetes configuration created in ${k8sDir}`);
    return k8sDir;
  }

  /**
   * Sets up Terraform configuration for the project
   * @param config Terraform configuration
   * @returns Path to the Terraform configuration directory
   */
  private async setupTerraform(config: TerraformConfig): Promise<string> {
    const terraformDir = path.join(process.cwd(), 'terraform');
    
    // Create terraform directory if it doesn't exist
    if (!fs.existsSync(terraformDir)) {
      fs.mkdirSync(terraformDir, { recursive: true });
    }

    // Create main.tf
    let mainTfContent = '';
    
    // Add terraform block
    mainTfContent += 'terraform {\n';
    mainTfContent += '  required_version = ">= 1.0.0"\n';
    mainTfContent += '  required_providers {\n';
    
    // Add AWS provider if needed
    if (config.cloudProvider === CloudProvider.AWS) {
      mainTfContent += '    aws = {\n';
      mainTfContent += '      source  = "hashicorp/aws"\n';
      mainTfContent += '      version = "~> 4.0"\n';
      mainTfContent += '    }\n';
    }
    
    // Add Azure provider if needed
    if (config.cloudProvider === CloudProvider.AZURE) {
      mainTfContent += '    azurerm = {\n';
      mainTfContent += '      source  = "hashicorp/azurerm"\n';
      mainTfContent += '      version = "~> 3.0"\n';
      mainTfContent += '    }\n';
    }
    
    // Add GCP provider if needed
    if (config.cloudProvider === CloudProvider.GCP) {
      mainTfContent += '    google = {\n';
      mainTfContent += '      source  = "hashicorp/google"\n';
      mainTfContent += '      version = "~> 4.0"\n';
      mainTfContent += '    }\n';
    }
    
    // Add Digital Ocean provider if needed
    if (config.cloudProvider === CloudProvider.DIGITAL_OCEAN) {
      mainTfContent += '    digitalocean = {\n';
      mainTfContent += '      source  = "digitalocean/digitalocean"\n';
      mainTfContent += '      version = "~> 2.0"\n';
      mainTfContent += '    }\n';
    }
    
    mainTfContent += '  }\n';
    
    // Add backend configuration if specified
    if (config.backendType) {
      mainTfContent += '  backend "' + config.backendType + '" {\n';
      
      if (config.backendConfig) {
        Object.entries(config.backendConfig).forEach(([key, value]) => {
          mainTfContent += `    ${key} = "${value}"\n`;
        });
      }
      
      mainTfContent += '  }\n';
    }
    
    mainTfContent += '}\n\n';
    
    // Add provider configuration
    if (config.cloudProvider === CloudProvider.AWS) {
      mainTfContent += 'provider "aws" {\n';
      mainTfContent += '  region = "' + (config.region || 'us-west-2') + '"\n';
      
      if (config.providerConfig && config.providerConfig.profile) {
        mainTfContent += '  profile = "' + config.providerConfig.profile + '"\n';
      }
      
      mainTfContent += '}\n\n';
    } else if (config.cloudProvider === CloudProvider.AZURE) {
      mainTfContent += 'provider "azurerm" {\n';
      mainTfContent += '  features {}\n';
      
      if (config.providerConfig) {
        if (config.providerConfig.subscriptionId) {
          mainTfContent += '  subscription_id = "' + config.providerConfig.subscriptionId + '"\n';
        }
        if (config.providerConfig.tenantId) {
          mainTfContent += '  tenant_id = "' + config.providerConfig.tenantId + '"\n';
        }
      }
      
      mainTfContent += '}\n\n';
    } else if (config.cloudProvider === CloudProvider.GCP) {
      mainTfContent += 'provider "google" {\n';
      mainTfContent += '  project = "' + (config.providerConfig?.project || 'my-project') + '"\n';
      mainTfContent += '  region  = "' + (config.region || 'us-central1') + '"\n';
      mainTfContent += '}\n\n';
    } else if (config.cloudProvider === CloudProvider.DIGITAL_OCEAN) {
      mainTfContent += 'provider "digitalocean" {\n';
      
      if (config.providerConfig && config.providerConfig.token) {
        mainTfContent += '  token = var.do_token\n';
      }
      
      mainTfContent += '}\n\n';
    }
    
    // Add variables
    if (config.cloudProvider === CloudProvider.DIGITAL_OCEAN && config.providerConfig && config.providerConfig.token) {
      mainTfContent += 'variable "do_token" {\n';
      mainTfContent += '  description = "DigitalOcean API Token"\n';
      mainTfContent += '  type        = string\n';
      mainTfContent += '  sensitive   = true\n';
      mainTfContent += '}\n\n';
    }

    // Write main.tf
    fs.writeFileSync(path.join(terraformDir, 'main.tf'), mainTfContent);

    // Create variables.tf
    let variablesTfContent = '';
    
    if (config.variables && Object.keys(config.variables).length > 0) {
      Object.entries(config.variables).forEach(([name, variable]) => {
        variablesTfContent += `variable "${name}" {\n`;
        
        if (variable.description) {
          variablesTfContent += `  description = "${variable.description}"\n`;
        }
        
        if (variable.type) {
          variablesTfContent += `  type        = ${variable.type}\n`;
        }
        
        if (variable.default !== undefined) {
          if (typeof variable.default === 'string') {
            variablesTfContent += `  default     = "${variable.default}"\n`;
          } else if (Array.isArray(variable.default)) {
            variablesTfContent += '  default     = [\n';
            variable.default.forEach(item => {
              if (typeof item === 'string') {
                variablesTfContent += `    "${item}",\n`;
              } else {
                variablesTfContent += `    ${item},\n`;
              }
            });
            variablesTfContent += '  ]\n';
          } else if (typeof variable.default === 'object') {
            variablesTfContent += '  default     = {\n';
            Object.entries(variable.default).forEach(([k, v]) => {
              if (typeof v === 'string') {
                variablesTfContent += `    ${k} = "${v}"\n`;
              } else {
                variablesTfContent += `    ${k} = ${v}\n`;
              }
            });
            variablesTfContent += '  }\n';
          } else {
            variablesTfContent += `  default     = ${variable.default}\n`;
          }
        }
        
        if (variable.sensitive) {
          variablesTfContent += '  sensitive   = true\n';
        }
        
        variablesTfContent += '}\n\n';
      });
    }

    // Add common variables if not defined
    if (!config.variables || !config.variables.environment) {
      variablesTfContent += 'variable "environment" {\n';
      variablesTfContent += '  description = "Environment (dev, staging, prod)"\n';
      variablesTfContent += '  type        = string\n';
      variablesTfContent += '  default     = "dev"\n';
      variablesTfContent += '}\n\n';
    }
    
    if (!config.variables || !config.variables.project_name) {
      variablesTfContent += 'variable "project_name" {\n';
      variablesTfContent += '  description = "Name of the project"\n';
      variablesTfContent += '  type        = string\n';
      variablesTfContent += `  default     = "${config.projectName || 'my-project'}"\n`;
      variablesTfContent += '}\n\n';
    }

    // Write variables.tf
    fs.writeFileSync(path.join(terraformDir, 'variables.tf'), variablesTfContent);

    // Create outputs.tf
    let outputsTfContent = '';
    
    if (config.outputs && config.outputs.length > 0) {
      config.outputs.forEach(output => {
        outputsTfContent += `output "${output.name}" {\n`;
        outputsTfContent += `  value       = ${output.value}\n`;
        
        if (output.description) {
          outputsTfContent += `  description = "${output.description}"\n`;
        }
        
        if (output.sensitive) {
          outputsTfContent += '  sensitive   = true\n';
        }
        
        outputsTfContent += '}\n\n';
      });
    }

    // Write outputs.tf
    fs.writeFileSync(path.join(terraformDir, 'outputs.tf'), outputsTfContent);

    // Create infrastructure files based on cloud provider
    if (config.cloudProvider === CloudProvider.AWS) {
      this.createAwsInfrastructure(terraformDir, config);
    } else if (config.cloudProvider === CloudProvider.AZURE) {
      this.createAzureInfrastructure(terraformDir, config);
    } else if (config.cloudProvider === CloudProvider.GCP) {
      this.createGcpInfrastructure(terraformDir, config);
    } else if (config.cloudProvider === CloudProvider.DIGITAL_OCEAN) {
      this.createDigitalOceanInfrastructure(terraformDir, config);
    }

    // Create terraform.tfvars
    let tfvarsContent = '';
    
    if (config.tfvars && Object.keys(config.tfvars).length > 0) {
      Object.entries(config.tfvars).forEach(([key, value]) => {
        if (typeof value === 'string') {
          tfvarsContent += `${key} = "${value}"\n`;
        } else if (Array.isArray(value)) {
          tfvarsContent += `${key} = [\n`;
          value.forEach(item => {
            if (typeof item === 'string') {
              tfvarsContent += `  "${item}",\n`;
            } else {
              tfvarsContent += `  ${item},\n`;
            }
          });
          tfvarsContent += ']\n';
        } else if (typeof value === 'object') {
          tfvarsContent += `${key} = {\n`;
          Object.entries(value).forEach(([k, v]) => {
            if (typeof v === 'string') {
              tfvarsContent += `  ${k} = "${v}"\n`;
            } else {
              tfvarsContent += `  ${k} = ${v}\n`;
            }
          });
          tfvarsContent += '}\n';
        } else {
          tfvarsContent += `${key} = ${value}\n`;
        }
      });
    }

    // Add common tfvars
    if (!config.tfvars || !config.tfvars.environment) {
      tfvarsContent += 'environment = "dev"\n';
    }
    
    if (!config.tfvars || !config.tfvars.project_name) {
      tfvarsContent += `project_name = "${config.projectName || 'my-project'}"\n`;
    }

    // Write terraform.tfvars
    fs.writeFileSync(path.join(terraformDir, 'terraform.tfvars'), tfvarsContent);

    // Create README.md for Terraform
    let terraformReadmeContent = '# Terraform Configuration\n\n';
    terraformReadmeContent += `This directory contains Terraform configuration for ${config.projectName || 'the project'}.\n\n`;
    
    terraformReadmeContent += '## Files\n\n';
    terraformReadmeContent += '- `main.tf`: Main Terraform configuration file\n';
    terraformReadmeContent += '- `variables.tf`: Variable definitions\n';
    terraformReadmeContent += '- `outputs.tf`: Output definitions\n';
    terraformReadmeContent += '- `terraform.tfvars`: Variable values\n';
    
    if (config.cloudProvider === CloudProvider.AWS) {
      terraformReadmeContent += '- `vpc.tf`: AWS VPC configuration\n';
      terraformReadmeContent += '- `ec2.tf`: AWS EC2 configuration\n';
      terraformReadmeContent += '- `rds.tf`: AWS RDS configuration\n';
      terraformReadmeContent += '- `s3.tf`: AWS S3 configuration\n';
    } else if (config.cloudProvider === CloudProvider.AZURE) {
      terraformReadmeContent += '- `resource_group.tf`: Azure Resource Group configuration\n';
      terraformReadmeContent += '- `vnet.tf`: Azure Virtual Network configuration\n';
      terraformReadmeContent += '- `vm.tf`: Azure Virtual Machine configuration\n';
      terraformReadmeContent += '- `database.tf`: Azure Database configuration\n';
      terraformReadmeContent += '- `storage.tf`: Azure Storage configuration\n';
    } else if (config.cloudProvider === CloudProvider.GCP) {
      terraformReadmeContent += '- `network.tf`: GCP Network configuration\n';
      terraformReadmeContent += '- `compute.tf`: GCP Compute Engine configuration\n';
      terraformReadmeContent += '- `database.tf`: GCP Database configuration\n';
      terraformReadmeContent += '- `storage.tf`: GCP Storage configuration\n';
    } else if (config.cloudProvider === CloudProvider.DIGITAL_OCEAN) {
      terraformReadmeContent += '- `droplet.tf`: DigitalOcean Droplet configuration\n';
      terraformReadmeContent += '- `kubernetes.tf`: DigitalOcean Kubernetes configuration\n';
      terraformReadmeContent += '- `database.tf`: DigitalOcean Database configuration\n';
      terraformReadmeContent += '- `spaces.tf`: DigitalOcean Spaces configuration\n';
    }
    
    terraformReadmeContent += '\n## Usage\n\n';
    terraformReadmeContent += '### Initializing Terraform\n\n';
    terraformReadmeContent += '```bash\n';
    terraformReadmeContent += 'terraform init\n';
    terraformReadmeContent += '```\n\n';
    
    terraformReadmeContent += '### Creating a Plan\n\n';
    terraformReadmeContent += '```bash\n';
    terraformReadmeContent += 'terraform plan -out=tfplan\n';
    terraformReadmeContent += '```\n\n';
    
    terraformReadmeContent += '### Applying the Plan\n\n';
    terraformReadmeContent += '```bash\n';
    terraformReadmeContent += 'terraform apply tfplan\n';
    terraformReadmeContent += '```\n\n';
    
    terraformReadmeContent += '### Destroying Resources\n\n';
    terraformReadmeContent += '```bash\n';
    terraformReadmeContent += 'terraform destroy\n';
    terraformReadmeContent += '```\n';

    // Write Terraform README.md
    fs.writeFileSync(path.join(terraformDir, 'README.md'), terraformReadmeContent);

    this.logger.info(`Terraform configuration created in ${terraformDir}`);
    return terraformDir;
  }

  /**
   * Creates AWS infrastructure files
   * @param terraformDir Directory to create files in
   * @param config Terraform configuration
   */
  private createAwsInfrastructure(terraformDir: string, config: TerraformConfig): void {
    // Create vpc.tf
    let vpcTfContent = 'resource "aws_vpc" "main" {\n';
    vpcTfContent += '  cidr_block           = "10.0.0.0/16"\n';
    vpcTfContent += '  enable_dns_support   = true\n';
    vpcTfContent += '  enable_dns_hostnames = true\n';
    vpcTfContent += '\n';
    vpcTfContent += '  tags = {\n';
    vpcTfContent += '    Name        = "${var.project_name}-vpc-${var.environment}"\n';
    vpcTfContent += '    Environment = var.environment\n';
    vpcTfContent += '  }\n';
    vpcTfContent += '}\n\n';
    
    vpcTfContent += 'resource "aws_subnet" "public" {\n';
    vpcTfContent += '  count                   = 2\n';
    vpcTfContent += '  vpc_id                  = aws_vpc.main.id\n';
    vpcTfContent += '  cidr_block              = "10.0.${count.index}.0/24"\n';
    vpcTfContent += '  availability_zone       = data.aws_availability_zones.available.names[count.index]\n';
    vpcTfContent += '  map_public_ip_on_launch = true\n';
    vpcTfContent += '\n';
    vpcTfContent += '  tags = {\n';
    vpcTfContent += '    Name        = "${var.project_name}-public-subnet-${count.index}-${var.environment}"\n';
    vpcTfContent += '    Environment = var.environment\n';
    vpcTfContent += '  }\n';
    vpcTfContent += '}\n\n';
    
    vpcTfContent += 'resource "aws_subnet" "private" {\n';
    vpcTfContent += '  count             = 2\n';
    vpcTfContent += '  vpc_id            = aws_vpc.main.id\n';
    vpcTfContent += '  cidr_block        = "10.0.${count.index + 2}.0/24"\n';
    vpcTfContent += '  availability_zone = data.aws_availability_zones.available.names[count.index]\n';
    vpcTfContent += '\n';
    vpcTfContent += '  tags = {\n';
    vpcTfContent += '    Name        = "${var.project_name}-private-subnet-${count.index}-${var.environment}"\n';
    vpcTfContent += '    Environment = var.environment\n';
    vpcTfContent += '  }\n';
    vpcTfContent += '}\n\n';
    
    vpcTfContent += 'resource "aws_internet_gateway" "main" {\n';
    vpcTfContent += '  vpc_id = aws_vpc.main.id\n';
    vpcTfContent += '\n';
    vpcTfContent += '  tags = {\n';
    vpcTfContent += '    Name        = "${var.project_name}-igw-${var.environment}"\n';
    vpcTfContent += '    Environment = var.environment\n';
    vpcTfContent += '  }\n';
    vpcTfContent += '}\n\n';
    
    vpcTfContent += 'resource "aws_route_table" "public" {\n';
    vpcTfContent += '  vpc_id = aws_vpc.main.id\n';
    vpcTfContent += '\n';
    vpcTfContent += '  route {\n';
    vpcTfContent += '    cidr_block = "0.0.0.0/0"\n';
    vpcTfContent += '    gateway_id = aws_internet_gateway.main.id\n';
    vpcTfContent += '  }\n';
    vpcTfContent += '\n';
    vpcTfContent += '  tags = {\n';
    vpcTfContent += '    Name        = "${var.project_name}-public-route-table-${var.environment}"\n';
    vpcTfContent += '    Environment = var.environment\n';
    vpcTfContent += '  }\n';
    vpcTfContent += '}\n\n';
    
    vpcTfContent += 'resource "aws_route_table_association" "public" {\n';
    vpcTfContent += '  count          = 2\n';
    vpcTfContent += '  subnet_id      = aws_subnet.public[count.index].id\n';
    vpcTfContent += '  route_table_id = aws_route_table.public.id\n';
    vpcTfContent += '}\n\n';
    
    vpcTfContent += 'data "aws_availability_zones" "available" {}\n';

    // Write vpc.tf
    fs.writeFileSync(path.join(terraformDir, 'vpc.tf'), vpcTfContent);

    // Create ec2.tf
    let ec2TfContent = 'resource "aws_security_group" "app" {\n';
    ec2TfContent += '  name        = "${var.project_name}-app-sg-${var.environment}"\n';
    ec2TfContent += '  description = "Security group for app servers"\n';
    ec2TfContent += '  vpc_id      = aws_vpc.main.id\n';
    ec2TfContent += '\n';
    ec2TfContent += '  ingress {\n';
    ec2TfContent += '    from_port   = 22\n';
    ec2TfContent += '    to_port     = 22\n';
    ec2TfContent += '    protocol    = "tcp"\n';
    ec2TfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '\n';
    ec2TfContent += '  ingress {\n';
    ec2TfContent += '    from_port   = 80\n';
    ec2TfContent += '    to_port     = 80\n';
    ec2TfContent += '    protocol    = "tcp"\n';
    ec2TfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '\n';
    ec2TfContent += '  ingress {\n';
    ec2TfContent += '    from_port   = 443\n';
    ec2TfContent += '    to_port     = 443\n';
    ec2TfContent += '    protocol    = "tcp"\n';
    ec2TfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '\n';
    ec2TfContent += '  egress {\n';
    ec2TfContent += '    from_port   = 0\n';
    ec2TfContent += '    to_port     = 0\n';
    ec2TfContent += '    protocol    = "-1"\n';
    ec2TfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '\n';
    ec2TfContent += '  tags = {\n';
    ec2TfContent += '    Name        = "${var.project_name}-app-sg-${var.environment}"\n';
    ec2TfContent += '    Environment = var.environment\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '}\n\n';
    
    ec2TfContent += 'resource "aws_instance" "app" {\n';
    ec2TfContent += '  count                  = 2\n';
    ec2TfContent += '  ami                    = data.aws_ami.amazon_linux.id\n';
    ec2TfContent += '  instance_type          = "t3.micro"\n';
    ec2TfContent += '  subnet_id              = aws_subnet.public[count.index % 2].id\n';
    ec2TfContent += '  vpc_security_group_ids = [aws_security_group.app.id]\n';
    ec2TfContent += '  key_name               = aws_key_pair.app.key_name\n';
    ec2TfContent += '\n';
    ec2TfContent += '  user_data = <<-EOF\n';
    ec2TfContent += '    #!/bin/bash\n';
    ec2TfContent += '    yum update -y\n';
    ec2TfContent += '    yum install -y docker\n';
    ec2TfContent += '    systemctl start docker\n';
    ec2TfContent += '    systemctl enable docker\n';
    ec2TfContent += '    usermod -a -G docker ec2-user\n';
    ec2TfContent += '    curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose\n';
    ec2TfContent += '    chmod +x /usr/local/bin/docker-compose\n';
    ec2TfContent += '  EOF\n';
    ec2TfContent += '\n';
    ec2TfContent += '  tags = {\n';
    ec2TfContent += '    Name        = "${var.project_name}-app-${count.index}-${var.environment}"\n';
    ec2TfContent += '    Environment = var.environment\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '}\n\n';
    
    ec2TfContent += 'resource "aws_key_pair" "app" {\n';
    ec2TfContent += '  key_name   = "${var.project_name}-key-${var.environment}"\n';
    ec2TfContent += '  public_key = file("${path.module}/ssh/id_rsa.pub")\n';
    ec2TfContent += '}\n\n';
    
    ec2TfContent += 'data "aws_ami" "amazon_linux" {\n';
    ec2TfContent += '  most_recent = true\n';
    ec2TfContent += '  owners      = ["amazon"]\n';
    ec2TfContent += '\n';
    ec2TfContent += '  filter {\n';
    ec2TfContent += '    name   = "name"\n';
    ec2TfContent += '    values = ["amzn2-ami-hvm-*-x86_64-gp2"]\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '\n';
    ec2TfContent += '  filter {\n';
    ec2TfContent += '    name   = "virtualization-type"\n';
    ec2TfContent += '    values = ["hvm"]\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '}\n\n';
    
    ec2TfContent += 'resource "aws_lb" "app" {\n';
    ec2TfContent += '  name               = "${var.project_name}-alb-${var.environment}"\n';
    ec2TfContent += '  internal           = false\n';
    ec2TfContent += '  load_balancer_type = "application"\n';
    ec2TfContent += '  security_groups    = [aws_security_group.app.id]\n';
    ec2TfContent += '  subnets            = aws_subnet.public[*].id\n';
    ec2TfContent += '\n';
    ec2TfContent += '  tags = {\n';
    ec2TfContent += '    Name        = "${var.project_name}-alb-${var.environment}"\n';
    ec2TfContent += '    Environment = var.environment\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '}\n\n';
    
    ec2TfContent += 'resource "aws_lb_target_group" "app" {\n';
    ec2TfContent += '  name     = "${var.project_name}-tg-${var.environment}"\n';
    ec2TfContent += '  port     = 80\n';
    ec2TfContent += '  protocol = "HTTP"\n';
    ec2TfContent += '  vpc_id   = aws_vpc.main.id\n';
    ec2TfContent += '\n';
    ec2TfContent += '  health_check {\n';
    ec2TfContent += '    path                = "/"\n';
    ec2TfContent += '    port                = "traffic-port"\n';
    ec2TfContent += '    healthy_threshold   = 3\n';
    ec2TfContent += '    unhealthy_threshold = 3\n';
    ec2TfContent += '    timeout             = 5\n';
    ec2TfContent += '    interval            = 30\n';
    ec2TfContent += '    matcher             = "200"\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '}\n\n';
    
    ec2TfContent += 'resource "aws_lb_target_group_attachment" "app" {\n';
    ec2TfContent += '  count            = 2\n';
    ec2TfContent += '  target_group_arn = aws_lb_target_group.app.arn\n';
    ec2TfContent += '  target_id        = aws_instance.app[count.index].id\n';
    ec2TfContent += '  port             = 80\n';
    ec2TfContent += '}\n\n';
    
    ec2TfContent += 'resource "aws_lb_listener" "app" {\n';
    ec2TfContent += '  load_balancer_arn = aws_lb.app.arn\n';
    ec2TfContent += '  port              = "80"\n';
    ec2TfContent += '  protocol          = "HTTP"\n';
    ec2TfContent += '\n';
    ec2TfContent += '  default_action {\n';
    ec2TfContent += '    type             = "forward"\n';
    ec2TfContent += '    target_group_arn = aws_lb_target_group.app.arn\n';
    ec2TfContent += '  }\n';
    ec2TfContent += '}\n';

        // Write ec2.tf
        fs.writeFileSync(path.join(terraformDir, 'ec2.tf'), ec2TfContent);

        // Create rds.tf
        let rdsTfContent = 'resource "aws_security_group" "db" {\n';
        rdsTfContent += '  name        = "${var.project_name}-db-sg-${var.environment}"\n';
        rdsTfContent += '  description = "Security group for database"\n';
        rdsTfContent += '  vpc_id      = aws_vpc.main.id\n';
        rdsTfContent += '\n';
        rdsTfContent += '  ingress {\n';
        rdsTfContent += '    from_port       = 3306\n';
        rdsTfContent += '    to_port         = 3306\n';
        rdsTfContent += '    protocol        = "tcp"\n';
        rdsTfContent += '    security_groups = [aws_security_group.app.id]\n';
        rdsTfContent += '  }\n';
        rdsTfContent += '\n';
        rdsTfContent += '  egress {\n';
        rdsTfContent += '    from_port   = 0\n';
        rdsTfContent += '    to_port     = 0\n';
        rdsTfContent += '    protocol    = "-1"\n';
        rdsTfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
        rdsTfContent += '  }\n';
        rdsTfContent += '\n';
        rdsTfContent += '  tags = {\n';
        rdsTfContent += '    Name        = "${var.project_name}-db-sg-${var.environment}"\n';
        rdsTfContent += '    Environment = var.environment\n';
        rdsTfContent += '  }\n';
        rdsTfContent += '}\n\n';
        
        rdsTfContent += 'resource "aws_db_subnet_group" "main" {\n';
        rdsTfContent += '  name       = "${var.project_name}-db-subnet-group-${var.environment}"\n';
        rdsTfContent += '  subnet_ids = aws_subnet.private[*].id\n';
        rdsTfContent += '\n';
        rdsTfContent += '  tags = {\n';
        rdsTfContent += '    Name        = "${var.project_name}-db-subnet-group-${var.environment}"\n';
        rdsTfContent += '    Environment = var.environment\n';
        rdsTfContent += '  }\n';
        rdsTfContent += '}\n\n';
        
        rdsTfContent += 'resource "aws_db_instance" "main" {\n';
        rdsTfContent += '  identifier             = "${var.project_name}-db-${var.environment}"\n';
        rdsTfContent += '  allocated_storage      = 20\n';
        rdsTfContent += '  storage_type           = "gp2"\n';
        rdsTfContent += '  engine                 = "mysql"\n';
        rdsTfContent += '  engine_version         = "8.0"\n';
        rdsTfContent += '  instance_class         = "db.t3.micro"\n';
        rdsTfContent += '  db_name                = "${replace(var.project_name, "-", "_")}"\n';
        rdsTfContent += '  username               = "admin"\n';
        rdsTfContent += '  password               = var.db_password\n';
        rdsTfContent += '  parameter_group_name   = "default.mysql8.0"\n';
        rdsTfContent += '  vpc_security_group_ids = [aws_security_group.db.id]\n';
        rdsTfContent += '  db_subnet_group_name   = aws_db_subnet_group.main.name\n';
        rdsTfContent += '  skip_final_snapshot    = true\n';
        rdsTfContent += '\n';
        rdsTfContent += '  tags = {\n';
        rdsTfContent += '    Name        = "${var.project_name}-db-${var.environment}"\n';
        rdsTfContent += '    Environment = var.environment\n';
        rdsTfContent += '  }\n';
        rdsTfContent += '}\n\n';
        
        rdsTfContent += 'variable "db_password" {\n';
        rdsTfContent += '  description = "Password for the database"\n';
        rdsTfContent += '  type        = string\n';
        rdsTfContent += '  sensitive   = true\n';
        rdsTfContent += '}\n';
    
        // Write rds.tf
        fs.writeFileSync(path.join(terraformDir, 'rds.tf'), rdsTfContent);
    
        // Create s3.tf
        let s3TfContent = 'resource "aws_s3_bucket" "main" {\n';
        s3TfContent += '  bucket = "${var.project_name}-${var.environment}-${random_string.suffix.result}"\n';
        s3TfContent += '\n';
        s3TfContent += '  tags = {\n';
        s3TfContent += '    Name        = "${var.project_name}-bucket-${var.environment}"\n';
        s3TfContent += '    Environment = var.environment\n';
        s3TfContent += '  }\n';
        s3TfContent += '}\n\n';
        
        s3TfContent += 'resource "aws_s3_bucket_public_access_block" "main" {\n';
        s3TfContent += '  bucket = aws_s3_bucket.main.id\n';
        s3TfContent += '\n';
        s3TfContent += '  block_public_acls       = true\n';
        s3TfContent += '  block_public_policy     = true\n';
        s3TfContent += '  ignore_public_acls      = true\n';
        s3TfContent += '  restrict_public_buckets = true\n';
        s3TfContent += '}\n\n';
        
        s3TfContent += 'resource "aws_s3_bucket_versioning" "main" {\n';
        s3TfContent += '  bucket = aws_s3_bucket.main.id\n';
        s3TfContent += '\n';
        s3TfContent += '  versioning_configuration {\n';
        s3TfContent += '    status = "Enabled"\n';
        s3TfContent += '  }\n';
        s3TfContent += '}\n\n';
        
        s3TfContent += 'resource "random_string" "suffix" {\n';
        s3TfContent += '  length  = 8\n';
        s3TfContent += '  special = false\n';
        s3TfContent += '  upper   = false\n';
        s3TfContent += '}\n';
    
        // Write s3.tf
        fs.writeFileSync(path.join(terraformDir, 's3.tf'), s3TfContent);
    
        // Create ssh directory for keys
        const sshDir = path.join(terraformDir, 'ssh');
        if (!fs.existsSync(sshDir)) {
          fs.mkdirSync(sshDir, { recursive: true });
        }
    
        // Create a README.md for the ssh directory
        const sshReadmeContent = '# SSH Keys\n\n';
        fs.writeFileSync(path.join(sshDir, 'README.md'), sshReadmeContent + 'Place your SSH public key file (id_rsa.pub) in this directory for use with EC2 instances.\n');
      }
    
      /**
       * Creates Azure infrastructure files
       * @param terraformDir Directory to create files in
       * @param config Terraform configuration
       */
      private createAzureInfrastructure(terraformDir: string, config: TerraformConfig): void {
        // Create resource_group.tf
        let resourceGroupTfContent = 'resource "azurerm_resource_group" "main" {\n';
        resourceGroupTfContent += '  name     = "${var.project_name}-rg-${var.environment}"\n';
        resourceGroupTfContent += '  location = "' + (config.region || 'East US') + '"\n';
        resourceGroupTfContent += '\n';
        resourceGroupTfContent += '  tags = {\n';
        resourceGroupTfContent += '    environment = var.environment\n';
        resourceGroupTfContent += '  }\n';
        resourceGroupTfContent += '}\n';
    
        // Write resource_group.tf
        fs.writeFileSync(path.join(terraformDir, 'resource_group.tf'), resourceGroupTfContent);
    
        // Create vnet.tf
        let vnetTfContent = 'resource "azurerm_virtual_network" "main" {\n';
        vnetTfContent += '  name                = "${var.project_name}-vnet-${var.environment}"\n';
        vnetTfContent += '  address_space       = ["10.0.0.0/16"]\n';
        vnetTfContent += '  location            = azurerm_resource_group.main.location\n';
        vnetTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        vnetTfContent += '\n';
        vnetTfContent += '  tags = {\n';
        vnetTfContent += '    environment = var.environment\n';
        vnetTfContent += '  }\n';
        vnetTfContent += '}\n\n';
        
        vnetTfContent += 'resource "azurerm_subnet" "public" {\n';
        vnetTfContent += '  name                 = "${var.project_name}-public-subnet-${var.environment}"\n';
        vnetTfContent += '  resource_group_name  = azurerm_resource_group.main.name\n';
        vnetTfContent += '  virtual_network_name = azurerm_virtual_network.main.name\n';
        vnetTfContent += '  address_prefixes     = ["10.0.1.0/24"]\n';
        vnetTfContent += '}\n\n';
        
        vnetTfContent += 'resource "azurerm_subnet" "private" {\n';
        vnetTfContent += '  name                 = "${var.project_name}-private-subnet-${var.environment}"\n';
        vnetTfContent += '  resource_group_name  = azurerm_resource_group.main.name\n';
        vnetTfContent += '  virtual_network_name = azurerm_virtual_network.main.name\n';
        vnetTfContent += '  address_prefixes     = ["10.0.2.0/24"]\n';
        vnetTfContent += '}\n\n';
        
        vnetTfContent += 'resource "azurerm_network_security_group" "main" {\n';
        vnetTfContent += '  name                = "${var.project_name}-nsg-${var.environment}"\n';
        vnetTfContent += '  location            = azurerm_resource_group.main.location\n';
        vnetTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        vnetTfContent += '\n';
        vnetTfContent += '  security_rule {\n';
        vnetTfContent += '    name                       = "SSH"\n';
        vnetTfContent += '    priority                   = 1001\n';
        vnetTfContent += '    direction                  = "Inbound"\n';
        vnetTfContent += '    access                     = "Allow"\n';
        vnetTfContent += '    protocol                   = "Tcp"\n';
        vnetTfContent += '    source_port_range          = "*"\n';
        vnetTfContent += '    destination_port_range     = "22"\n';
        vnetTfContent += '    source_address_prefix      = "*"\n';
        vnetTfContent += '    destination_address_prefix = "*"\n';
        vnetTfContent += '  }\n';
        vnetTfContent += '\n';
        vnetTfContent += '  security_rule {\n';
        vnetTfContent += '    name                       = "HTTP"\n';
        vnetTfContent += '    priority                   = 1002\n';
        vnetTfContent += '    direction                  = "Inbound"\n';
        vnetTfContent += '    access                     = "Allow"\n';
        vnetTfContent += '    protocol                   = "Tcp"\n';
        vnetTfContent += '    source_port_range          = "*"\n';
        vnetTfContent += '    destination_port_range     = "80"\n';
        vnetTfContent += '    source_address_prefix      = "*"\n';
        vnetTfContent += '    destination_address_prefix = "*"\n';
        vnetTfContent += '  }\n';
        vnetTfContent += '\n';
        vnetTfContent += '  security_rule {\n';
        vnetTfContent += '    name                       = "HTTPS"\n';
        vnetTfContent += '    priority                   = 1003\n';
        vnetTfContent += '    direction                  = "Inbound"\n';
        vnetTfContent += '    access                     = "Allow"\n';
        vnetTfContent += '    protocol                   = "Tcp"\n';
        vnetTfContent += '    source_port_range          = "*"\n';
        vnetTfContent += '    destination_port_range     = "443"\n';
        vnetTfContent += '    source_address_prefix      = "*"\n';
        vnetTfContent += '    destination_address_prefix = "*"\n';
        vnetTfContent += '  }\n';
        vnetTfContent += '\n';
        vnetTfContent += '  tags = {\n';
        vnetTfContent += '    environment = var.environment\n';
        vnetTfContent += '  }\n';
        vnetTfContent += '}\n\n';
        
        vnetTfContent += 'resource "azurerm_subnet_network_security_group_association" "public" {\n';
        vnetTfContent += '  subnet_id                 = azurerm_subnet.public.id\n';
        vnetTfContent += '  network_security_group_id = azurerm_network_security_group.main.id\n';
        vnetTfContent += '}\n';
    
        // Write vnet.tf
        fs.writeFileSync(path.join(terraformDir, 'vnet.tf'), vnetTfContent);
    
        // Create vm.tf
        let vmTfContent = 'resource "azurerm_public_ip" "main" {\n';
        vmTfContent += '  count               = 2\n';
        vmTfContent += '  name                = "${var.project_name}-pip-${count.index}-${var.environment}"\n';
        vmTfContent += '  location            = azurerm_resource_group.main.location\n';
        vmTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        vmTfContent += '  allocation_method   = "Dynamic"\n';
        vmTfContent += '\n';
        vmTfContent += '  tags = {\n';
        vmTfContent += '    environment = var.environment\n';
        vmTfContent += '  }\n';
        vmTfContent += '}\n\n';
        
        vmTfContent += 'resource "azurerm_network_interface" "main" {\n';
        vmTfContent += '  count               = 2\n';
        vmTfContent += '  name                = "${var.project_name}-nic-${count.index}-${var.environment}"\n';
        vmTfContent += '  location            = azurerm_resource_group.main.location\n';
        vmTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        vmTfContent += '\n';
        vmTfContent += '  ip_configuration {\n';
        vmTfContent += '    name                          = "internal"\n';
        vmTfContent += '    subnet_id                     = azurerm_subnet.public.id\n';
        vmTfContent += '    private_ip_address_allocation = "Dynamic"\n';
        vmTfContent += '    public_ip_address_id          = azurerm_public_ip.main[count.index].id\n';
        vmTfContent += '  }\n';
        vmTfContent += '\n';
        vmTfContent += '  tags = {\n';
        vmTfContent += '    environment = var.environment\n';
        vmTfContent += '  }\n';
        vmTfContent += '}\n\n';
        
        vmTfContent += 'resource "azurerm_linux_virtual_machine" "main" {\n';
        vmTfContent += '  count               = 2\n';
        vmTfContent += '  name                = "${var.project_name}-vm-${count.index}-${var.environment}"\n';
        vmTfContent += '  location            = azurerm_resource_group.main.location\n';
        vmTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        vmTfContent += '  size                = "Standard_B1s"\n';
        vmTfContent += '  admin_username      = "adminuser"\n';
        vmTfContent += '  network_interface_ids = [\n';
        vmTfContent += '    azurerm_network_interface.main[count.index].id,\n';
        vmTfContent += '  ]\n';
        vmTfContent += '\n';
        vmTfContent += '  admin_ssh_key {\n';
        vmTfContent += '    username   = "adminuser"\n';
        vmTfContent += '    public_key = file("${path.module}/ssh/id_rsa.pub")\n';
        vmTfContent += '  }\n';
        vmTfContent += '\n';
        vmTfContent += '  os_disk {\n';
        vmTfContent += '    caching              = "ReadWrite"\n';
        vmTfContent += '    storage_account_type = "Standard_LRS"\n';
        vmTfContent += '  }\n';
        vmTfContent += '\n';
        vmTfContent += '  source_image_reference {\n';
        vmTfContent += '    publisher = "Canonical"\n';
        vmTfContent += '    offer     = "UbuntuServer"\n';
        vmTfContent += '    sku       = "18.04-LTS"\n';
        vmTfContent += '    version   = "latest"\n';
        vmTfContent += '  }\n';
        vmTfContent += '\n';
        vmTfContent += '  custom_data = base64encode(<<-EOF\n';
        vmTfContent += '    #!/bin/bash\n';
        vmTfContent += '    apt-get update\n';
        vmTfContent += '    apt-get install -y docker.io\n';
        vmTfContent += '    systemctl start docker\n';
        vmTfContent += '    systemctl enable docker\n';
        vmTfContent += '    usermod -aG docker adminuser\n';
        vmTfContent += '    curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose\n';
        vmTfContent += '    chmod +x /usr/local/bin/docker-compose\n';
        vmTfContent += '  EOF\n';
        vmTfContent += '  )\n';
        vmTfContent += '\n';
        vmTfContent += '  tags = {\n';
        vmTfContent += '    environment = var.environment\n';
        vmTfContent += '  }\n';
        vmTfContent += '}\n\n';
        
        vmTfContent += 'resource "azurerm_lb" "main" {\n';
        vmTfContent += '  name                = "${var.project_name}-lb-${var.environment}"\n';
        vmTfContent += '  location            = azurerm_resource_group.main.location\n';
        vmTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        vmTfContent += '\n';
        vmTfContent += '  frontend_ip_configuration {\n';
        vmTfContent += '    name                 = "PublicIPAddress"\n';
        vmTfContent += '    public_ip_address_id = azurerm_public_ip.lb.id\n';
        vmTfContent += '  }\n';
        vmTfContent += '\n';
        vmTfContent += '  tags = {\n';
        vmTfContent += '    environment = var.environment\n';
        vmTfContent += '  }\n';
        vmTfContent += '}\n\n';
        
        vmTfContent += 'resource "azurerm_public_ip" "lb" {\n';
        vmTfContent += '  name                = "${var.project_name}-lb-pip-${var.environment}"\n';
        vmTfContent += '  location            = azurerm_resource_group.main.location\n';
        vmTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        vmTfContent += '  allocation_method   = "Static"\n';
        vmTfContent += '\n';
        vmTfContent += '  tags = {\n';
        vmTfContent += '    environment = var.environment\n';
        vmTfContent += '  }\n';
        vmTfContent += '}\n\n';
        
        vmTfContent += 'resource "azurerm_lb_backend_address_pool" "main" {\n';
        vmTfContent += '  loadbalancer_id = azurerm_lb.main.id\n';
        vmTfContent += '  name            = "BackEndAddressPool"\n';
        vmTfContent += '}\n\n';
        
        vmTfContent += 'resource "azurerm_network_interface_backend_address_pool_association" "main" {\n';
        vmTfContent += '  count                   = 2\n';
        vmTfContent += '  network_interface_id    = azurerm_network_interface.main[count.index].id\n';
        vmTfContent += '  ip_configuration_name   = "internal"\n';
        vmTfContent += '  backend_address_pool_id = azurerm_lb_backend_address_pool.main.id\n';
        vmTfContent += '}\n\n';
        
        vmTfContent += 'resource "azurerm_lb_rule" "main" {\n';
        vmTfContent += '  loadbalancer_id                = azurerm_lb.main.id\n';
        vmTfContent += '  name                           = "HTTP"\n';
        vmTfContent += '  protocol                       = "Tcp"\n';
        vmTfContent += '  frontend_port                  = 80\n';
        vmTfContent += '  backend_port                   = 80\n';
        vmTfContent += '  frontend_ip_configuration_name = "PublicIPAddress"\n';
        vmTfContent += '  backend_address_pool_ids       = [azurerm_lb_backend_address_pool.main.id]\n';
        vmTfContent += '}\n';
    
        // Write vm.tf
        fs.writeFileSync(path.join(terraformDir, 'vm.tf'), vmTfContent);
    
        // Create database.tf
        let databaseTfContent = 'resource "azurerm_mysql_server" "main" {\n';
        databaseTfContent += '  name                = "${var.project_name}-mysql-${var.environment}"\n';
        databaseTfContent += '  location            = azurerm_resource_group.main.location\n';
        databaseTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        databaseTfContent += '\n';
        databaseTfContent += '  administrator_login          = "mysqladmin"\n';
        databaseTfContent += '  administrator_login_password = var.db_password\n';
        databaseTfContent += '\n';
        databaseTfContent += '  sku_name   = "B_Gen5_1"\n';
        databaseTfContent += '  storage_mb = 5120\n';
        databaseTfContent += '  version    = "5.7"\n';
        databaseTfContent += '\n';
        databaseTfContent += '  auto_grow_enabled                 = true\n';
        databaseTfContent += '  backup_retention_days             = 7\n';
        databaseTfContent += '  geo_redundant_backup_enabled      = false\n';
        databaseTfContent += '  infrastructure_encryption_enabled = false\n';
        databaseTfContent += '  public_network_access_enabled     = true\n';
        databaseTfContent += '  ssl_enforcement_enabled           = true\n';
        databaseTfContent += '  ssl_minimal_tls_version_enforced  = "TLS1_2"\n';
        databaseTfContent += '\n';
        databaseTfContent += '  tags = {\n';
        databaseTfContent += '    environment = var.environment\n';
        databaseTfContent += '  }\n';
        databaseTfContent += '}\n\n';
        
        databaseTfContent += 'resource "azurerm_mysql_database" "main" {\n';
        databaseTfContent += '  name                = "${replace(var.project_name, "-", "_")}"\n';
        databaseTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        databaseTfContent += '  server_name         = azurerm_mysql_server.main.name\n';
        databaseTfContent += '  charset             = "utf8"\n';
        databaseTfContent += '  collation           = "utf8_unicode_ci"\n';
        databaseTfContent += '}\n\n';
        
        databaseTfContent += 'resource "azurerm_mysql_firewall_rule" "allow_azure_services" {\n';
        databaseTfContent += '  name                = "AllowAzureServices"\n';
        databaseTfContent += '  resource_group_name = azurerm_resource_group.main.name\n';
        databaseTfContent += '  server_name         = azurerm_mysql_server.main.name\n';
        databaseTfContent += '  start_ip_address    = "0.0.0.0"\n';
        databaseTfContent += '  end_ip_address      = "0.0.0.0"\n';
        databaseTfContent += '}\n\n';
        
        databaseTfContent += 'variable "db_password" {\n';
        databaseTfContent += '  description = "Password for the database"\n';
        databaseTfContent += '  type        = string\n';
        databaseTfContent += '  sensitive   = true\n';
        databaseTfContent += '}\n';
    
        // Write database.tf
        fs.writeFileSync(path.join(terraformDir, 'database.tf'), databaseTfContent);
    
        // Create storage.tf
        let storageTfContent = 'resource "azurerm_storage_account" "main" {\n';
        storageTfContent += '  name                     = "${replace(var.project_name, "-", "")}${var.environment}${random_string.suffix.result}"\n';
        storageTfContent += '  resource_group_name      = azurerm_resource_group.main.name\n';
        storageTfContent += '  location                 = azurerm_resource_group.main.location\n';
        storageTfContent += '  account_tier             = "Standard"\n';
        storageTfContent += '  account_replication_type = "LRS"\n';
        storageTfContent += '\n';
        storageTfContent += '  tags = {\n';
        storageTfContent += '    environment = var.environment\n';
        storageTfContent += '  }\n';
        storageTfContent += '}\n\n';
        
        storageTfContent += 'resource "azurerm_storage_container" "main" {\n';
        storageTfContent += '  name                  = "${var.project_name}-container-${var.environment}"\n';
        storageTfContent += '  storage_account_name  = azurerm_storage_account.main.name\n';
        storageTfContent += '  container_access_type = "private"\n';
        storageTfContent += '}\n\n';
        
        storageTfContent += 'resource "random_string" "suffix" {\n';
        storageTfContent += '  length  = 8\n';
        storageTfContent += '  special = false\n';
        storageTfContent += '  upper   = false\n';
        storageTfContent += '}\n';
    
        // Write storage.tf
        fs.writeFileSync(path.join(terraformDir, 'storage.tf'), storageTfContent);
    
        // Create ssh directory for keys
        const sshDir = path.join(terraformDir, 'ssh');
        if (!fs.existsSync(sshDir)) {
          fs.mkdirSync(sshDir, { recursive: true });
        }
    
        // Create a README.md for the ssh directory
        const sshReadmeContent = '# SSH Keys\n\n';
        fs.writeFileSync(path.join(sshDir, 'README.md'), sshReadmeContent + 'Place your SSH public key file (id_rsa.pub) in this directory for use with Azure VMs.\n');
      }
    
      /**
       * Creates GCP infrastructure files
       * @param terraformDir Directory to create files in
       * @param config Terraform configuration
       */
      private createGcpInfrastructure(terraformDir: string, config: TerraformConfig): void {
        // Create network.tf
        let networkTfContent = 'resource "google_compute_network" "main" {\n';
        networkTfContent += '  name                    = "${var.project_name}-vpc-${var.environment}"\n';
        networkTfContent += '  auto_create_subnetworks = false\n';
        networkTfContent += '}\n\n';
        
        networkTfContent += 'resource "google_compute_subnetwork" "public" {\n';
        networkTfContent += '  name          = "${var.project_name}-public-subnet-${var.environment}"\n';
        networkTfContent += '  ip_cidr_range = "10.0.1.0/24"\n';
        networkTfContent += '  region        = "' + (config.region || 'us-central1') + '"\n';
        networkTfContent += '  network       = google_compute_network.main.id\n';
        networkTfContent += '}\n\n';
        
        networkTfContent += 'resource "google_compute_subnetwork" "private" {\n';
        networkTfContent += '  name          = "${var.project_name}-private-subnet-${var.environment}"\n';
        networkTfContent += '  ip_cidr_range = "10.0.2.0/24"\n';
        networkTfContent += '  region        = "' + (config.region || 'us-central1') + '"\n';
        networkTfContent += '  network       = google_compute_network.main.id\n';
        networkTfContent += '}\n\n';
        
        networkTfContent += 'resource "google_compute_firewall" "allow_ssh" {\n';
        networkTfContent += '  name    = "${var.project_name}-allow-ssh-${var.environment}"\n';
        networkTfContent += '  network = google_compute_network.main.name\n';
        networkTfContent += '\n';
        networkTfContent += '  allow {\n';
        networkTfContent += '    protocol = "tcp"\n';
        networkTfContent += '    ports    = ["22"]\n';
        networkTfContent += '  }\n';
        networkTfContent += '\n';
        networkTfContent += '  source_ranges = ["0.0.0.0/0"]\n';
        networkTfContent += '}\n\n';
        
        networkTfContent += 'resource "google_compute_firewall" "allow_http" {\n';
        networkTfContent += '  name    = "${var.project_name}-allow-http-${var.environment}"\n';
        networkTfContent += '  network = google_compute_network.main.name\n';
        networkTfContent += '\n';
        networkTfContent += '  allow {\n';
        networkTfContent += '    protocol = "tcp"\n';
        networkTfContent += '    ports    = ["80"]\n';
        networkTfContent += '  }\n';
        networkTfContent += '\n';
        networkTfContent += '  source_ranges = ["0.0.0.0/0"]\n';
        networkTfContent += '}\n\n';
        
        networkTfContent += 'resource "google_compute_firewall" "allow_https" {\n';
        networkTfContent += '  name    = "${var.project_name}-allow-https-${var.environment}"\n';
        networkTfContent += '  network = google_compute_network.main.name\n';
        networkTfContent += '\n';
        networkTfContent += '  allow {\n';
        networkTfContent += '    protocol = "tcp"\n';
        networkTfContent += '    ports    = ["443"]\n';
        networkTfContent += '  }\n';
        networkTfContent += '\n';
        networkTfContent += '  source_ranges = ["0.0.0.0/0"]\n';
        networkTfContent += '}\n';

        // Write network.tf
        fs.writeFileSync(path.join(terraformDir, 'network.tf'), networkTfContent);

        // Create compute.tf
        let computeTfContent = 'resource "google_compute_instance" "main" {\n';
        computeTfContent += '  count        = 2\n';
        computeTfContent += '  name         = "${var.project_name}-vm-${count.index}-${var.environment}"\n';
        computeTfContent += '  machine_type = "e2-medium"\n';
        computeTfContent += '  zone         = "' + (config.region || 'us-central1') + '-a"\n';
        computeTfContent += '\n';
        computeTfContent += '  boot_disk {\n';
        computeTfContent += '    initialize_params {\n';
        computeTfContent += '      image = "debian-cloud/debian-11"\n';
        computeTfContent += '    }\n';
        computeTfContent += '  }\n';
        computeTfContent += '\n';
        computeTfContent += '  network_interface {\n';
        computeTfContent += '    subnetwork = google_compute_subnetwork.public.id\n';
        computeTfContent += '\n';
        computeTfContent += '    access_config {\n';
        computeTfContent += '      // Ephemeral public IP\n';
        computeTfContent += '    }\n';
        computeTfContent += '  }\n';
        computeTfContent += '\n';
        computeTfContent += '  metadata = {\n';
        computeTfContent += '    ssh-keys = "adminuser:${file(\"${path.module}/ssh/id_rsa.pub\")}"\n';
        computeTfContent += '  }\n';
        computeTfContent += '\n';
        computeTfContent += '  metadata_startup_script = <<-EOF\n';
        computeTfContent += '    #!/bin/bash\n';
        computeTfContent += '    apt-get update\n';
        computeTfContent += '    apt-get install -y docker.io\n';
        computeTfContent += '    systemctl start docker\n';
        computeTfContent += '    systemctl enable docker\n';
        computeTfContent += '    usermod -aG docker adminuser\n';
        computeTfContent += '    curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose\n';
        computeTfContent += '    chmod +x /usr/local/bin/docker-compose\n';
        computeTfContent += '  EOF\n';
        computeTfContent += '\n';
        computeTfContent += '  tags = ["http-server", "https-server", "ssh"]\n';
        computeTfContent += '}\n\n';
        
        computeTfContent += 'resource "google_compute_instance_group" "main" {\n';
        computeTfContent += '  name        = "${var.project_name}-instance-group-${var.environment}"\n';
        computeTfContent += '  description = "Instance group for ${var.project_name}"\n';
        computeTfContent += '  zone        = "' + (config.region || 'us-central1') + '-a"\n';
        computeTfContent += '\n';
        computeTfContent += '  instances = google_compute_instance.main[*].self_link\n';
        computeTfContent += '\n';
        computeTfContent += '  named_port {\n';
        computeTfContent += '    name = "http"\n';
        computeTfContent += '    port = 80\n';
        computeTfContent += '  }\n';
        computeTfContent += '}\n\n';
        
        computeTfContent += 'resource "google_compute_health_check" "http" {\n';
        computeTfContent += '  name               = "${var.project_name}-http-health-check-${var.environment}"\n';
        computeTfContent += '  check_interval_sec = 5\n';
        computeTfContent += '  timeout_sec        = 5\n';
        computeTfContent += '  http_health_check {\n';
        computeTfContent += '    port = 80\n';
        computeTfContent += '  }\n';
        computeTfContent += '}\n\n';
        
        computeTfContent += 'resource "google_compute_backend_service" "main" {\n';
        computeTfContent += '  name        = "${var.project_name}-backend-service-${var.environment}"\n';
        computeTfContent += '  port_name   = "http"\n';
        computeTfContent += '  protocol    = "HTTP"\n';
        computeTfContent += '  timeout_sec = 10\n';
        computeTfContent += '\n';
        computeTfContent += '  health_checks = [google_compute_health_check.http.id]\n';
        computeTfContent += '\n';
        computeTfContent += '  backend {\n';
        computeTfContent += '    group = google_compute_instance_group.main.id\n';
        computeTfContent += '  }\n';
        computeTfContent += '}\n\n';
        
        computeTfContent += 'resource "google_compute_url_map" "main" {\n';
        computeTfContent += '  name            = "${var.project_name}-url-map-${var.environment}"\n';
        computeTfContent += '  default_service = google_compute_backend_service.main.id\n';
        computeTfContent += '}\n\n';
        
        computeTfContent += 'resource "google_compute_target_http_proxy" "main" {\n';
        computeTfContent += '  name    = "${var.project_name}-http-proxy-${var.environment}"\n';
        computeTfContent += '  url_map = google_compute_url_map.main.id\n';
        computeTfContent += '}\n\n';
        
        computeTfContent += 'resource "google_compute_global_forwarding_rule" "http" {\n';
        computeTfContent += '  name       = "${var.project_name}-http-rule-${var.environment}"\n';
        computeTfContent += '  target     = google_compute_target_http_proxy.main.id\n';
        computeTfContent += '  port_range = "80"\n';
        computeTfContent += '}\n';

        // Write compute.tf
        fs.writeFileSync(path.join(terraformDir, 'compute.tf'), computeTfContent);

        // Create database.tf
        let databaseTfContent = 'resource "google_sql_database_instance" "main" {\n';
        databaseTfContent += '  name             = "${var.project_name}-db-${var.environment}"\n';
        databaseTfContent += '  database_version = "MYSQL_8_0"\n';
        databaseTfContent += '  region           = "' + (config.region || 'us-central1') + '"\n';
        databaseTfContent += '\n';
        databaseTfContent += '  settings {\n';
        databaseTfContent += '    tier = "db-f1-micro"\n';
        databaseTfContent += '\n';
        databaseTfContent += '    ip_configuration {\n';
        databaseTfContent += '      ipv4_enabled = true\n';
        databaseTfContent += '      authorized_networks {\n';
        databaseTfContent += '        name  = "all"\n';
        databaseTfContent += '        value = "0.0.0.0/0"\n';
        databaseTfContent += '      }\n';
        databaseTfContent += '    }\n';
        databaseTfContent += '\n';
        databaseTfContent += '    backup_configuration {\n';
        databaseTfContent += '      enabled            = true\n';
        databaseTfContent += '      binary_log_enabled = true\n';
        databaseTfContent += '    }\n';
        databaseTfContent += '  }\n';
        databaseTfContent += '\n';
        databaseTfContent += '  deletion_protection = false\n';
        databaseTfContent += '}\n\n';
        
        databaseTfContent += 'resource "google_sql_database" "main" {\n';
        databaseTfContent += '  name     = "${replace(var.project_name, "-", "_")}"\n';
        databaseTfContent += '  instance = google_sql_database_instance.main.name\n';
        databaseTfContent += '}\n\n';
        
        databaseTfContent += 'resource "google_sql_user" "main" {\n';
        databaseTfContent += '  name     = "admin"\n';
        databaseTfContent += '  instance = google_sql_database_instance.main.name\n';
        databaseTfContent += '  password = var.db_password\n';
        databaseTfContent += '}\n\n';
        
        databaseTfContent += 'variable "db_password" {\n';
        databaseTfContent += '  description = "Password for the database"\n';
        databaseTfContent += '  type        = string\n';
        databaseTfContent += '  sensitive   = true\n';
        databaseTfContent += '}\n';

        // Write database.tf
        fs.writeFileSync(path.join(terraformDir, 'database.tf'), databaseTfContent);

        // Create storage.tf
        let storageTfContent = 'resource "google_storage_bucket" "main" {\n';
        storageTfContent += '  name          = "${var.project_name}-${var.environment}-${random_string.suffix.result}"\n';
        storageTfContent += '  location      = "' + (config.region || 'US') + '"\n';
        storageTfContent += '  force_destroy = true\n';
        storageTfContent += '\n';
        storageTfContent += '  versioning {\n';
        storageTfContent += '    enabled = true\n';
        storageTfContent += '  }\n';
        storageTfContent += '}\n\n';
        
        storageTfContent += 'resource "random_string" "suffix" {\n';
        storageTfContent += '  length  = 8\n';
        storageTfContent += '  special = false\n';
        storageTfContent += '  upper   = false\n';
        storageTfContent += '}\n';

        // Write storage.tf
        fs.writeFileSync(path.join(terraformDir, 'storage.tf'), storageTfContent);

        // Create ssh directory for keys
        const sshDir = path.join(terraformDir, 'ssh');
        if (!fs.existsSync(sshDir)) {
          fs.mkdirSync(sshDir, { recursive: true });
        }

        // Create a README.md for the ssh directory
        const sshReadmeContent = '# SSH Keys\n\n';
        fs.writeFileSync(path.join(sshDir, 'README.md'), sshReadmeContent + 'Place your SSH public key file (id_rsa.pub) in this directory for use with GCP instances.\n');
      }

      /**
       * Creates Docker Compose files
       * @param projectDir Directory to create files in
       * @param config Docker Compose configuration
       */
      private createDockerComposeFiles(projectDir: string, config: DockerComposeConfig): void {
        const dockerComposeDir = path.join(projectDir, 'docker');
        if (!fs.existsSync(dockerComposeDir)) {
          fs.mkdirSync(dockerComposeDir, { recursive: true });
        }

        // Create docker-compose.yml
        let dockerComposeContent = 'version: "3.8"\n\n';
        dockerComposeContent += 'services:\n';
        
        // Add frontend service
        dockerComposeContent += '  frontend:\n';
        dockerComposeContent += '    build:\n';
        dockerComposeContent += '      context: ../frontend\n';
        dockerComposeContent += '      dockerfile: Dockerfile\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "80:80"\n';
        dockerComposeContent += '    depends_on:\n';
        dockerComposeContent += '      - backend\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - REACT_APP_API_URL=http://localhost:8080/api\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - app-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        // Add backend service
        dockerComposeContent += '  backend:\n';
        dockerComposeContent += '    build:\n';
        dockerComposeContent += '      context: ../backend\n';
        dockerComposeContent += '      dockerfile: Dockerfile\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "8080:8080"\n';
        dockerComposeContent += '    depends_on:\n';
        dockerComposeContent += '      - db\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - DB_HOST=db\n';
        dockerComposeContent += '      - DB_PORT=3306\n';
        dockerComposeContent += '      - DB_NAME=' + (config.dbName || 'app_db') + '\n';
        dockerComposeContent += '      - DB_USER=root\n';
        dockerComposeContent += '      - DB_PASSWORD=${DB_PASSWORD}\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - app-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        // Add database service
        dockerComposeContent += '  db:\n';
        dockerComposeContent += '    image: mysql:8.0\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "3306:3306"\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - MYSQL_ROOT_PASSWORD=${DB_PASSWORD}\n';
        dockerComposeContent += '      - MYSQL_DATABASE=' + (config.dbName || 'app_db') + '\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - db-data:/var/lib/mysql\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - app-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        // Add networks and volumes
        dockerComposeContent += 'networks:\n';
        dockerComposeContent += '  app-network:\n';
        dockerComposeContent += '    driver: bridge\n\n';
        
        dockerComposeContent += 'volumes:\n';
        dockerComposeContent += '  db-data:\n';
        dockerComposeContent += '    driver: local\n';

        // Write docker-compose.yml
        fs.writeFileSync(path.join(dockerComposeDir, 'docker-compose.yml'), dockerComposeContent);

        // Create .env file
        let envContent = '# Docker Compose Environment Variables\n\n';
        envContent += '# Database\n';
        envContent += 'DB_PASSWORD=your_secure_password\n';

        // Write .env file
        fs.writeFileSync(path.join(dockerComposeDir, '.env'), envContent);

        // Create .env.example file
        fs.writeFileSync(path.join(dockerComposeDir, '.env.example'), envContent);

        // Create docker-compose.prod.yml
        let dockerComposeProdContent = 'version: "3.8"\n\n';
        dockerComposeProdContent += 'services:\n';
        
        // Add frontend service for production
        dockerComposeProdContent += '  frontend:\n';
        dockerComposeProdContent += '    build:\n';
        dockerComposeProdContent += '      context: ../frontend\n';
        dockerComposeProdContent += '      dockerfile: Dockerfile.prod\n';
        dockerComposeProdContent += '    ports:\n';
        dockerComposeProdContent += '      - "80:80"\n';
        dockerComposeProdContent += '    depends_on:\n';
        dockerComposeProdContent += '      - backend\n';
        dockerComposeProdContent += '    environment:\n';
        dockerComposeProdContent += '      - REACT_APP_API_URL=https://api.example.com/api\n';
        dockerComposeProdContent += '    networks:\n';
        dockerComposeProdContent += '      - app-network\n';
        dockerComposeProdContent += '    restart: unless-stopped\n\n';
        
        // Add backend service for production
        dockerComposeProdContent += '  backend:\n';
        dockerComposeProdContent += '    build:\n';
        dockerComposeProdContent += '      context: ../backend\n';
        dockerComposeProdContent += '      dockerfile: Dockerfile.prod\n';
        dockerComposeProdContent += '    ports:\n';
        dockerComposeProdContent += '      - "8080:8080"\n';
        dockerComposeProdContent += '    depends_on:\n';
        dockerComposeProdContent += '      - db\n';
        dockerComposeProdContent += '    environment:\n';
        dockerComposeProdContent += '      - DB_HOST=db\n';
        dockerComposeProdContent += '      - DB_PORT=3306\n';
        dockerComposeProdContent += '      - DB_NAME=' + (config.dbName || 'app_db') + '\n';
        dockerComposeProdContent += '      - DB_USER=root\n';
        dockerComposeProdContent += '      - DB_PASSWORD=${DB_PASSWORD}\n';
        dockerComposeProdContent += '    networks:\n';
        dockerComposeProdContent += '      - app-network\n';
        dockerComposeProdContent += '    restart: unless-stopped\n\n';
        
        // Add database service for production
        dockerComposeProdContent += '  db:\n';
        dockerComposeProdContent += '    image: mysql:8.0\n';
        dockerComposeProdContent += '    ports:\n';
        dockerComposeProdContent += '      - "3306:3306"\n';
        dockerComposeProdContent += '    environment:\n';
        dockerComposeProdContent += '      - MYSQL_ROOT_PASSWORD=${DB_PASSWORD}\n';
        dockerComposeProdContent += '      - MYSQL_DATABASE=' + (config.dbName || 'app_db') + '\n';
        dockerComposeProdContent += '    volumes:\n';
        dockerComposeProdContent += '      - db-data:/var/lib/mysql\n';
        dockerComposeProdContent += '    networks:\n';
        dockerComposeProdContent += '      - app-network\n';
        dockerComposeProdContent += '    restart: unless-stopped\n\n';
        
        // Add networks and volumes for production
        dockerComposeProdContent += 'networks:\n';
        dockerComposeProdContent += '  app-network:\n';
        dockerComposeProdContent += '    driver: bridge\n\n';
        
        dockerComposeProdContent += 'volumes:\n';
        dockerComposeProdContent += '  db-data:\n';
        dockerComposeProdContent += '    driver: local\n';

        // Write docker-compose.prod.yml
        fs.writeFileSync(path.join(dockerComposeDir, 'docker-compose.prod.yml'), dockerComposeProdContent);

        // Create README.md
        let readmeContent = '# Docker Compose Setup\n\n';
        readmeContent += '## Development\n\n';
        readmeContent += 'To start the development environment:\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Copy the example environment file\n';
        readmeContent += 'cp .env.example .env\n\n';
        readmeContent += '# Edit the .env file with your secure password\n';
        readmeContent += '# Then start the containers\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += '## Production\n\n';
        readmeContent += 'To start the production environment:\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Copy the example environment file\n';
        readmeContent += 'cp .env.example .env\n\n';
        readmeContent += '# Edit the .env file with your secure password\n';
        readmeContent += '# Then start the containers using the production configuration\n';
        readmeContent += 'docker-compose -f docker-compose.prod.yml up -d\n';
        readmeContent += '```\n';

        // Write README.md
        fs.writeFileSync(path.join(dockerComposeDir, 'README.md'), readmeContent);

        // Create frontend Dockerfile
        const frontendDockerfileDir = path.join(projectDir, 'frontend');
        if (!fs.existsSync(frontendDockerfileDir)) {
          fs.mkdirSync(frontendDockerfileDir, { recursive: true });
        }

        let frontendDockerfileContent = '# Development Dockerfile for Frontend\n';
        frontendDockerfileContent += 'FROM node:16-alpine\n\n';
        frontendDockerfileContent += 'WORKDIR /app\n\n';
        frontendDockerfileContent += 'COPY package*.json ./\n\n';
        frontendDockerfileContent += 'RUN npm install\n\n';
        frontendDockerfileContent += 'COPY . .\n\n';
        frontendDockerfileContent += 'EXPOSE 3000\n\n';
        frontendDockerfileContent += 'CMD ["npm", "start"]\n';

        // Write frontend Dockerfile
        fs.writeFileSync(path.join(frontendDockerfileDir, 'Dockerfile'), frontendDockerfileContent);

        // Create frontend production Dockerfile
        let frontendProdDockerfileContent = '# Production Dockerfile for Frontend\n';
        frontendProdDockerfileContent += '# Build stage\n';
        frontendProdDockerfileContent += 'FROM node:16-alpine as build\n\n';
        frontendProdDockerfileContent += 'WORKDIR /app\n\n';
        frontendProdDockerfileContent += 'COPY package*.json ./\n\n';
        frontendProdDockerfileContent += 'RUN npm ci\n\n';
        frontendProdDockerfileContent += 'COPY . .\n\n';
        frontendProdDockerfileContent += 'RUN npm run build\n\n';
        frontendProdDockerfileContent += '# Production stage\n';
        frontendProdDockerfileContent += 'FROM nginx:alpine\n\n';
        frontendProdDockerfileContent += 'COPY --from=build /app/build /usr/share/nginx/html\n\n';
        frontendProdDockerfileContent += 'COPY nginx.conf /etc/nginx/conf.d/default.conf\n\n';
        frontendProdDockerfileContent += 'EXPOSE 80\n\n';
        frontendProdDockerfileContent += 'CMD ["nginx", "-g", "daemon off;"]\n';

        // Write frontend production Dockerfile
        fs.writeFileSync(path.join(frontendDockerfileDir, 'Dockerfile.prod'), frontendProdDockerfileContent);

        // Create nginx.conf
        let nginxConfContent = 'server {\n';
        nginxConfContent += '    listen 80;\n';
        nginxConfContent += '    server_name localhost;\n\n';
        nginxConfContent += '    root /usr/share/nginx/html;\n';
        nginxConfContent += '    index index.html;\n\n';
        nginxConfContent += '    location / {\n';
        nginxConfContent += '        try_files $uri $uri/ /index.html;\n';
        nginxConfContent += '    }\n\n';
        nginxConfContent += '    location /api/ {\n';
        nginxConfContent += '        proxy_pass http://backend:8080/api/;\n';
        nginxConfContent += '        proxy_set_header Host $host;\n';
        nginxConfContent += '        proxy_set_header X-Real-IP $remote_addr;\n';
        nginxConfContent += '    }\n';
        nginxConfContent += '}\n';

        // Write nginx.conf
        fs.writeFileSync(path.join(frontendDockerfileDir, 'nginx.conf'), nginxConfContent);

        // Create backend Dockerfile
        const backendDockerfileDir = path.join(projectDir, 'backend');
        if (!fs.existsSync(backendDockerfileDir)) {
          fs.mkdirSync(backendDockerfileDir, { recursive: true });
        }

        let backendDockerfileContent = '# Development Dockerfile for Backend\n';
        backendDockerfileContent += 'FROM node:16-alpine\n\n';
        backendDockerfileContent += 'WORKDIR /app\n\n';
        backendDockerfileContent += 'COPY package*.json ./\n\n';
        backendDockerfileContent += 'RUN npm install\n\n';
        backendDockerfileContent += 'COPY . .\n\n';
        backendDockerfileContent += 'EXPOSE 8080\n\n';
        backendDockerfileContent += 'CMD ["npm", "run", "dev"]\n';

        // Write backend Dockerfile
        fs.writeFileSync(path.join(backendDockerfileDir, 'Dockerfile'), backendDockerfileContent);

        // Create backend production Dockerfile
        let backendProdDockerfileContent = '# Production Dockerfile for Backend\n';
        backendProdDockerfileContent += 'FROM node:16-alpine\n\n';
        backendProdDockerfileContent += 'WORKDIR /app\n\n';
        backendProdDockerfileContent += 'COPY package*.json ./\n\n';
        backendProdDockerfileContent += 'RUN npm ci\n\n';
        backendProdDockerfileContent += 'COPY . .\n\n';
        backendProdDockerfileContent += 'RUN npm run build\n\n';
        backendProdDockerfileContent += 'EXPOSE 8080\n\n';
        backendProdDockerfileContent += 'CMD ["npm", "start"]\n';

        // Write backend production Dockerfile
        fs.writeFileSync(path.join(backendDockerfileDir, 'Dockerfile.prod'), backendProdDockerfileContent);
      }

      /**
       * Creates Kubernetes files
       * @param projectDir Directory to create files in
       * @param config Kubernetes configuration
       */
      private createKubernetesFiles(projectDir: string, config: KubernetesConfig): void {
        const kubernetesDir = path.join(projectDir, 'kubernetes');
        if (!fs.existsSync(kubernetesDir)) {
          fs.mkdirSync(kubernetesDir, { recursive: true });
        }

        // Create namespace.yaml
        let namespaceContent = 'apiVersion: v1\n';
        namespaceContent += 'kind: Namespace\n';
        namespaceContent += 'metadata:\n';
        namespaceContent += '  name: ' + (config.namespace || 'app') + '\n';

        // Write namespace.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'namespace.yaml'), namespaceContent);

        // Create frontend-deployment.yaml
        let frontendDeploymentContent = 'apiVersion: apps/v1\n';
        frontendDeploymentContent += 'kind: Deployment\n';
        frontendDeploymentContent += 'metadata:\n';
        frontendDeploymentContent += '  name: frontend\n';
        frontendDeploymentContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        frontendDeploymentContent += 'spec:\n';
        frontendDeploymentContent += '  replicas: ' + (config.frontendReplicas || 2) + '\n';
        frontendDeploymentContent += '  selector:\n';
        frontendDeploymentContent += '    matchLabels:\n';
        frontendDeploymentContent += '      app: frontend\n';
        frontendDeploymentContent += '  template:\n';
        frontendDeploymentContent += '    metadata:\n';
        frontendDeploymentContent += '      labels:\n';
        frontendDeploymentContent += '        app: frontend\n';
        frontendDeploymentContent += '    spec:\n';
        frontendDeploymentContent += '      containers:\n';
        frontendDeploymentContent += '      - name: frontend\n';
        frontendDeploymentContent += '        image: ${DOCKER_REGISTRY}/frontend:${VERSION}\n';
        frontendDeploymentContent += '        ports:\n';
        frontendDeploymentContent += '        - containerPort: 80\n';
        frontendDeploymentContent += '        resources:\n';
        frontendDeploymentContent += '          limits:\n';
        frontendDeploymentContent += '            cpu: "500m"\n';
        frontendDeploymentContent += '            memory: "512Mi"\n';
        frontendDeploymentContent += '          requests:\n';
        frontendDeploymentContent += '            cpu: "100m"\n';
        frontendDeploymentContent += '            memory: "128Mi"\n';
        frontendDeploymentContent += '        livenessProbe:\n';
        frontendDeploymentContent += '          httpGet:\n';
        frontendDeploymentContent += '            path: /\n';
        frontendDeploymentContent += '            port: 80\n';
        frontendDeploymentContent += '          initialDelaySeconds: 30\n';
        frontendDeploymentContent += '          periodSeconds: 10\n';
        frontendDeploymentContent += '        readinessProbe:\n';
        frontendDeploymentContent += '          httpGet:\n';
        frontendDeploymentContent += '            path: /\n';
        frontendDeploymentContent += '            port: 80\n';
        frontendDeploymentContent += '          initialDelaySeconds: 5\n';
        frontendDeploymentContent += '          periodSeconds: 5\n';
        frontendDeploymentContent += '        env:\n';
        frontendDeploymentContent += '        - name: REACT_APP_API_URL\n';
        frontendDeploymentContent += '          value: "http://backend-service:8080/api"\n';

        // Write frontend-deployment.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'frontend-deployment.yaml'), frontendDeploymentContent);

        // Create frontend-service.yaml
        let frontendServiceContent = 'apiVersion: v1\n';
        frontendServiceContent += 'kind: Service\n';
        frontendServiceContent += 'metadata:\n';
        frontendServiceContent += '  name: frontend-service\n';
        frontendServiceContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        frontendServiceContent += 'spec:\n';
        frontendServiceContent += '  selector:\n';
        frontendServiceContent += '    app: frontend\n';
        frontendServiceContent += '  ports:\n';
        frontendServiceContent += '  - port: 80\n';
        frontendServiceContent += '    targetPort: 80\n';
        frontendServiceContent += '  type: ClusterIP\n';

        // Write frontend-service.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'frontend-service.yaml'), frontendServiceContent);

        // Create backend-deployment.yaml
        let backendDeploymentContent = 'apiVersion: apps/v1\n';
        backendDeploymentContent += 'kind: Deployment\n';
        backendDeploymentContent += 'metadata:\n';
        backendDeploymentContent += '  name: backend\n';
        backendDeploymentContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        backendDeploymentContent += 'spec:\n';
        backendDeploymentContent += '  replicas: ' + (config.backendReplicas || 2) + '\n';
        backendDeploymentContent += '  selector:\n';
        backendDeploymentContent += '    matchLabels:\n';
        backendDeploymentContent += '      app: backend\n';
        backendDeploymentContent += '  template:\n';
        backendDeploymentContent += '    metadata:\n';
        backendDeploymentContent += '      labels:\n';
        backendDeploymentContent += '        app: backend\n';
        backendDeploymentContent += '    spec:\n';
        backendDeploymentContent += '      containers:\n';
        backendDeploymentContent += '      - name: backend\n';
        backendDeploymentContent += '        image: ${DOCKER_REGISTRY}/backend:${VERSION}\n';
        backendDeploymentContent += '        ports:\n';
        backendDeploymentContent += '        - containerPort: 8080\n';
        backendDeploymentContent += '        resources:\n';
        backendDeploymentContent += '          limits:\n';
        backendDeploymentContent += '            cpu: "500m"\n';
        backendDeploymentContent += '            memory: "512Mi"\n';
        backendDeploymentContent += '          requests:\n';
        backendDeploymentContent += '            cpu: "100m"\n';
        backendDeploymentContent += '            memory: "256Mi"\n';
        backendDeploymentContent += '        livenessProbe:\n';
        backendDeploymentContent += '          httpGet:\n';
        backendDeploymentContent += '            path: /health\n';
        backendDeploymentContent += '            port: 8080\n';
        backendDeploymentContent += '          initialDelaySeconds: 30\n';
        backendDeploymentContent += '          periodSeconds: 10\n';
        backendDeploymentContent += '        readinessProbe:\n';
        backendDeploymentContent += '          httpGet:\n';
        backendDeploymentContent += '            path: /health\n';
        backendDeploymentContent += '            port: 8080\n';
        backendDeploymentContent += '          initialDelaySeconds: 5\n';
        backendDeploymentContent += '          periodSeconds: 5\n';
        backendDeploymentContent += '        env:\n';
        backendDeploymentContent += '        - name: DB_HOST\n';
        backendDeploymentContent += '          value: "db-service"\n';
        backendDeploymentContent += '        - name: DB_PORT\n';
        backendDeploymentContent += '          value: "3306"\n';
        backendDeploymentContent += '        - name: DB_NAME\n';
        backendDeploymentContent += '          value: "' + (config.dbName || 'app_db') + '"\n';
        backendDeploymentContent += '        - name: DB_USER\n';
        backendDeploymentContent += '          valueFrom:\n';
        backendDeploymentContent += '            secretKeyRef:\n';
        backendDeploymentContent += '              name: db-credentials\n';
        backendDeploymentContent += '              key: username\n';
        backendDeploymentContent += '        - name: DB_PASSWORD\n';
        backendDeploymentContent += '          valueFrom:\n';
        backendDeploymentContent += '            secretKeyRef:\n';
        backendDeploymentContent += '              name: db-credentials\n';
        backendDeploymentContent += '              key: password\n';

        // Write backend-deployment.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'backend-deployment.yaml'), backendDeploymentContent);

        // Create backend-service.yaml
        let backendServiceContent = 'apiVersion: v1\n';
        backendServiceContent += 'kind: Service\n';
        backendServiceContent += 'metadata:\n';
        backendServiceContent += '  name: backend-service\n';
        backendServiceContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        backendServiceContent += 'spec:\n';
        backendServiceContent += '  selector:\n';
        backendServiceContent += '    app: backend\n';
        backendServiceContent += '  ports:\n';
        backendServiceContent += '  - port: 8080\n';
        backendServiceContent += '    targetPort: 8080\n';
        backendServiceContent += '  type: ClusterIP\n';

        // Write backend-service.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'backend-service.yaml'), backendServiceContent);

        // Create db-deployment.yaml
        let dbDeploymentContent = 'apiVersion: apps/v1\n';
        dbDeploymentContent += 'kind: Deployment\n';
        dbDeploymentContent += 'metadata:\n';
        dbDeploymentContent += '  name: db\n';
        dbDeploymentContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        dbDeploymentContent += 'spec:\n';
        dbDeploymentContent += '  replicas: 1\n';
        dbDeploymentContent += '  selector:\n';
        dbDeploymentContent += '    matchLabels:\n';
        dbDeploymentContent += '      app: db\n';
        dbDeploymentContent += '  template:\n';
        dbDeploymentContent += '    metadata:\n';
        dbDeploymentContent += '      labels:\n';
        dbDeploymentContent += '        app: db\n';
        dbDeploymentContent += '    spec:\n';
        dbDeploymentContent += '      containers:\n';
        dbDeploymentContent += '      - name: db\n';
        dbDeploymentContent += '        image: mysql:8.0\n';
        dbDeploymentContent += '        ports:\n';
        dbDeploymentContent += '        - containerPort: 3306\n';
        dbDeploymentContent += '        resources:\n';
        dbDeploymentContent += '          limits:\n';
        dbDeploymentContent += '            cpu: "1000m"\n';
        dbDeploymentContent += '            memory: "1Gi"\n';
        dbDeploymentContent += '          requests:\n';
        dbDeploymentContent += '            cpu: "500m"\n';
        dbDeploymentContent += '            memory: "512Mi"\n';
        dbDeploymentContent += '        env:\n';
        dbDeploymentContent += '        - name: MYSQL_ROOT_PASSWORD\n';
        dbDeploymentContent += '          valueFrom:\n';
        dbDeploymentContent += '            secretKeyRef:\n';
        dbDeploymentContent += '              name: db-credentials\n';
        dbDeploymentContent += '              key: password\n';
        dbDeploymentContent += '        - name: MYSQL_DATABASE\n';
        dbDeploymentContent += '          value: "' + (config.dbName || 'app_db') + '"\n';
        dbDeploymentContent += '        volumeMounts:\n';
        dbDeploymentContent += '        - name: db-data\n';
        dbDeploymentContent += '          mountPath: /var/lib/mysql\n';
        dbDeploymentContent += '      volumes:\n';
        dbDeploymentContent += '      - name: db-data\n';
        dbDeploymentContent += '        persistentVolumeClaim:\n';
        dbDeploymentContent += '          claimName: db-pvc\n';

        // Write db-deployment.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'db-deployment.yaml'), dbDeploymentContent);

        // Create db-service.yaml
        let dbServiceContent = 'apiVersion: v1\n';
        dbServiceContent += 'kind: Service\n';
        dbServiceContent += 'metadata:\n';
        dbServiceContent += '  name: db-service\n';
        dbServiceContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        dbServiceContent += 'spec:\n';
        dbServiceContent += '  selector:\n';
        dbServiceContent += '    app: db\n';
        dbServiceContent += '  ports:\n';
        dbServiceContent += '  - port: 3306\n';
        dbServiceContent += '    targetPort: 3306\n';
        dbServiceContent += '  type: ClusterIP\n';

        // Write db-service.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'db-service.yaml'), dbServiceContent);

        // Create db-pvc.yaml
        let dbPvcContent = 'apiVersion: v1\n';
        dbPvcContent += 'kind: PersistentVolumeClaim\n';
        dbPvcContent += 'metadata:\n';
        dbPvcContent += '  name: db-pvc\n';
        dbPvcContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        dbPvcContent += 'spec:\n';
        dbPvcContent += '  accessModes:\n';
        dbPvcContent += '    - ReadWriteOnce\n';
        dbPvcContent += '  resources:\n';
        dbPvcContent += '    requests:\n';
        dbPvcContent += '      storage: 10Gi\n';
        dbPvcContent += '  storageClassName: standard\n';

        // Write db-pvc.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'db-pvc.yaml'), dbPvcContent);

        // Create db-credentials-secret.yaml
        let dbSecretContent = 'apiVersion: v1\n';
        dbSecretContent += 'kind: Secret\n';
        dbSecretContent += 'metadata:\n';
        dbSecretContent += '  name: db-credentials\n';
        dbSecretContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        dbSecretContent += 'type: Opaque\n';
        dbSecretContent += 'data:\n';
        dbSecretContent += '  username: YWRtaW4=  # admin (base64 encoded)\n';
        dbSecretContent += '  password: Y2hhbmdlbWU=  # changeme (base64 encoded)\n';

        // Write db-credentials-secret.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'db-credentials-secret.yaml'), dbSecretContent);

        // Create ingress.yaml
        let ingressContent = 'apiVersion: networking.k8s.io/v1\n';
        ingressContent += 'kind: Ingress\n';
        ingressContent += 'metadata:\n';
        ingressContent += '  name: app-ingress\n';
        ingressContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        ingressContent += '  annotations:\n';
        ingressContent += '    kubernetes.io/ingress.class: nginx\n';
        ingressContent += '    nginx.ingress.kubernetes.io/ssl-redirect: "false"\n';
        ingressContent += 'spec:\n';
        ingressContent += '  rules:\n';
        ingressContent += '  - host: ' + (config.domain || 'app.example.com') + '\n';
        ingressContent += '    http:\n';
        ingressContent += '      paths:\n';
        ingressContent += '      - path: /\n';
        ingressContent += '        pathType: Prefix\n';
        ingressContent += '        backend:\n';
        ingressContent += '          service:\n';
        ingressContent += '            name: frontend-service\n';
        ingressContent += '            port:\n';
        ingressContent += '              number: 80\n';
        ingressContent += '      - path: /api\n';
        ingressContent += '        pathType: Prefix\n';
        ingressContent += '        backend:\n';
        ingressContent += '          service:\n';
        ingressContent += '            name: backend-service\n';
        ingressContent += '            port:\n';
        ingressContent += '              number: 8080\n';

        // Write ingress.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'ingress.yaml'), ingressContent);

        // Create hpa.yaml (Horizontal Pod Autoscaler)
        let hpaContent = 'apiVersion: autoscaling/v2\n';
        hpaContent += 'kind: HorizontalPodAutoscaler\n';
        hpaContent += 'metadata:\n';
        hpaContent += '  name: frontend-hpa\n';
        hpaContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        hpaContent += 'spec:\n';
        hpaContent += '  scaleTargetRef:\n';
        hpaContent += '    apiVersion: apps/v1\n';
        hpaContent += '    kind: Deployment\n';
        hpaContent += '    name: frontend\n';
        hpaContent += '  minReplicas: ' + (config.frontendReplicas || 2) + '\n';
        hpaContent += '  maxReplicas: ' + (config.frontendMaxReplicas || 5) + '\n';
        hpaContent += '  metrics:\n';
        hpaContent += '  - type: Resource\n';
        hpaContent += '    resource:\n';
        hpaContent += '      name: cpu\n';
        hpaContent += '      target:\n';
        hpaContent += '        type: Utilization\n';
        hpaContent += '        averageUtilization: 80\n';
        hpaContent += '---\n';
        hpaContent += 'apiVersion: autoscaling/v2\n';
        hpaContent += 'kind: HorizontalPodAutoscaler\n';
        hpaContent += 'metadata:\n';
        hpaContent += '  name: backend-hpa\n';
        hpaContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        hpaContent += 'spec:\n';
        hpaContent += '  scaleTargetRef:\n';
        hpaContent += '    apiVersion: apps/v1\n';
        hpaContent += '    kind: Deployment\n';
        hpaContent += '    name: backend\n';
        hpaContent += '  minReplicas: ' + (config.backendReplicas || 2) + '\n';
        hpaContent += '  maxReplicas: ' + (config.backendMaxReplicas || 5) + '\n';
        hpaContent += '  metrics:\n';
        hpaContent += '  - type: Resource\n';
        hpaContent += '    resource:\n';
        hpaContent += '      name: cpu\n';
        hpaContent += '      target:\n';
        hpaContent += '        type: Utilization\n';
        hpaContent += '        averageUtilization: 80\n';

        // Write hpa.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'hpa.yaml'), hpaContent);

        // Create configmap.yaml
        let configMapContent = 'apiVersion: v1\n';
        configMapContent += 'kind: ConfigMap\n';
        configMapContent += 'metadata:\n';
        configMapContent += '  name: app-config\n';
        configMapContent += '  namespace: ' + (config.namespace || 'app') + '\n';
        configMapContent += 'data:\n';
        configMapContent += '  APP_ENV: "' + (config.environment || 'production') + '"\n';
        configMapContent += '  LOG_LEVEL: "info"\n';
        configMapContent += '  ENABLE_METRICS: "true"\n';

        // Write configmap.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'configmap.yaml'), configMapContent);

        // Create README.md
        let readmeContent = '# Kubernetes Configuration\n\n';
        readmeContent += 'This directory contains Kubernetes manifests for deploying the application.\n\n';
        readmeContent += '## Components\n\n';
        readmeContent += '- **Frontend**: React application\n';
        readmeContent += '- **Backend**: Node.js API\n';
        readmeContent += '- **Database**: MySQL\n\n';
        readmeContent += '## Deployment Instructions\n\n';
        readmeContent += '1. Create the namespace:\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f namespace.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '2. Create secrets (update with secure credentials first):\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f db-credentials-secret.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '3. Create persistent volume claim for the database:\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f db-pvc.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '4. Deploy the database:\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f db-deployment.yaml\n';
        readmeContent += 'kubectl apply -f db-service.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '5. Deploy the backend:\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f backend-deployment.yaml\n';
        readmeContent += 'kubectl apply -f backend-service.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '6. Deploy the frontend:\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f frontend-deployment.yaml\n';
        readmeContent += 'kubectl apply -f frontend-service.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '7. Configure ingress:\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f ingress.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '8. Set up autoscaling:\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f hpa.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '## Accessing the Application\n\n';
        readmeContent += 'Once deployed, the application will be available at: http://' + (config.domain || 'app.example.com') + '\n\n';
        readmeContent += '## Monitoring\n\n';
        readmeContent += 'To check the status of the deployments:\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl get all -n ' + (config.namespace || 'app') + '\n';
        readmeContent += '```\n';

        // Write README.md
        fs.writeFileSync(path.join(kubernetesDir, 'README.md'), readmeContent);
      }

      /**
       * Creates CI/CD pipeline files
       * @param projectDir Directory to create files in
       * @param config CI/CD configuration
       */
      private createCiCdFiles(projectDir: string, config: any): void {
        const cicdDir = path.join(projectDir, 'cicd');
        if (!fs.existsSync(cicdDir)) {
          fs.mkdirSync(cicdDir, { recursive: true });
        }

        // Create GitHub Actions workflow
        const githubDir = path.join(cicdDir, 'github');
        if (!fs.existsSync(githubDir)) {
          fs.mkdirSync(githubDir, { recursive: true });
        }

        // Create GitHub Actions workflow file
        let githubWorkflowContent = 'name: CI/CD Pipeline\n\n';
        githubWorkflowContent += 'on:\n';
        githubWorkflowContent += '  push:\n';
        githubWorkflowContent += '    branches: [ main, develop ]\n';
        githubWorkflowContent += '  pull_request:\n';
        githubWorkflowContent += '    branches: [ main, develop ]\n\n';
        githubWorkflowContent += 'jobs:\n';
        
        // Add test job
        githubWorkflowContent += '  test:\n';
        githubWorkflowContent += '    runs-on: ubuntu-latest\n';
        githubWorkflowContent += '    steps:\n';
        githubWorkflowContent += '    - uses: actions/checkout@v3\n';
        githubWorkflowContent += '    - name: Set up Node.js\n';
        githubWorkflowContent += '      uses: actions/setup-node@v3\n';
        githubWorkflowContent += '      with:\n';
        githubWorkflowContent += '        node-version: 16\n';
        githubWorkflowContent += '        cache: "npm"\n';
        githubWorkflowContent += '    - name: Install dependencies\n';
        githubWorkflowContent += '      run: |\n';
        githubWorkflowContent += '        cd frontend\n';
        githubWorkflowContent += '        npm ci\n';
        githubWorkflowContent += '        cd ../backend\n';
        githubWorkflowContent += '        npm ci\n';
        githubWorkflowContent += '    - name: Run tests\n';
        githubWorkflowContent += '      run: |\n';
        githubWorkflowContent += '        cd frontend\n';
        githubWorkflowContent += '        npm test\n';
        githubWorkflowContent += '        cd ../backend\n';
        githubWorkflowContent += '        npm test\n\n';
        
        // Add build job
        githubWorkflowContent += '  build:\n';
        githubWorkflowContent += '    needs: test\n';
        githubWorkflowContent += '    runs-on: ubuntu-latest\n';
        githubWorkflowContent += '    if: github.event_name == \'push\'\n';
        githubWorkflowContent += '    steps:\n';
        githubWorkflowContent += '    - uses: actions/checkout@v3\n';
        githubWorkflowContent += '    - name: Set up Docker Buildx\n';
        githubWorkflowContent += '      uses: docker/setup-buildx-action@v2\n';
        githubWorkflowContent += '    - name: Login to DockerHub\n';
        githubWorkflowContent += '      uses: docker/login-action@v2\n';
        githubWorkflowContent += '      with:\n';
        githubWorkflowContent += '        username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
        githubWorkflowContent += '        password: ${{ secrets.DOCKERHUB_TOKEN }}\n';
        githubWorkflowContent += '    - name: Extract metadata\n';
        githubWorkflowContent += '      id: meta\n';
        githubWorkflowContent += '      run: |\n';
        githubWorkflowContent += '        echo "::set-output name=version::$(echo ${{ github.sha }} | cut -c1-7)"\n';
        githubWorkflowContent += '        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then\n';
        githubWorkflowContent += '          echo "::set-output name=env::production"\n';
        githubWorkflowContent += '        else\n';
        githubWorkflowContent += '          echo "::set-output name=env::staging"\n';
        githubWorkflowContent += '        fi\n';
        githubWorkflowContent += '    - name: Build and push frontend image\n';
        githubWorkflowContent += '      uses: docker/build-push-action@v3\n';
        githubWorkflowContent += '      with:\n';
        githubWorkflowContent += '        context: ./frontend\n';
        githubWorkflowContent += '        file: ./frontend/Dockerfile.prod\n';
        githubWorkflowContent += '        push: true\n';
        githubWorkflowContent += '        tags: ${{ secrets.DOCKERHUB_USERNAME }}/frontend:${{ steps.meta.outputs.version }}\n';
        githubWorkflowContent += '    - name: Build and push backend image\n';
        githubWorkflowContent += '      uses: docker/build-push-action@v3\n';
        githubWorkflowContent += '      with:\n';
        githubWorkflowContent += '        context: ./backend\n';
        githubWorkflowContent += '        file: ./backend/Dockerfile.prod\n';
        githubWorkflowContent += '        push: true\n';
        githubWorkflowContent += '        tags: ${{ secrets.DOCKERHUB_USERNAME }}/backend:${{ steps.meta.outputs.version }}\n\n';
        
        // Add deploy job
        githubWorkflowContent += '  deploy:\n';
        githubWorkflowContent += '    needs: build\n';
        githubWorkflowContent += '    runs-on: ubuntu-latest\n';
        githubWorkflowContent += '    if: github.event_name == \'push\'\n';
        githubWorkflowContent += '    steps:\n';
        githubWorkflowContent += '    - uses: actions/checkout@v3\n';
        githubWorkflowContent += '    - name: Set up kubectl\n';
        githubWorkflowContent += '      uses: azure/setup-kubectl@v3\n';
        githubWorkflowContent += '    - name: Set up kubeconfig\n';
        githubWorkflowContent += '      run: |\n';
        githubWorkflowContent += '        mkdir -p $HOME/.kube\n';
        githubWorkflowContent += '        echo "${{ secrets.KUBE_CONFIG }}" > $HOME/.kube/config\n';
        githubWorkflowContent += '        chmod 600 $HOME/.kube/config\n';
        githubWorkflowContent += '    - name: Extract metadata\n';
        githubWorkflowContent += '      id: meta\n';
        githubWorkflowContent += '      run: |\n';
        githubWorkflowContent += '        echo "::set-output name=version::$(echo ${{ github.sha }} | cut -c1-7)"\n';
        githubWorkflowContent += '        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then\n';
        githubWorkflowContent += '          echo "::set-output name=env::production"\n';
        githubWorkflowContent += '        else\n';
        githubWorkflowContent += '          echo "::set-output name=env::staging"\n';
        githubWorkflowContent += '        fi\n';
        githubWorkflowContent += '    - name: Update Kubernetes manifests\n';
        githubWorkflowContent += '      run: |\n';
        githubWorkflowContent += '        cd kubernetes\n';
        githubWorkflowContent += '        sed -i "s|image:.*|image: ${{ secrets.DOCKERHUB_USERNAME }}/frontend:${{ steps.meta.outputs.version }}|g" frontend-deployment.yaml\n';
        githubWorkflowContent += '        sed -i "s|image:.*|image: ${{ secrets.DOCKERHUB_USERNAME }}/backend:${{ steps.meta.outputs.version }}|g" backend-deployment.yaml\n';
        githubWorkflowContent += '    - name: Deploy to Kubernetes\n';
        githubWorkflowContent += '      run: |\n';
        githubWorkflowContent += '        cd kubernetes\n';
        githubWorkflowContent += '        kubectl apply -f namespace.yaml\n';
        githubWorkflowContent += '        kubectl apply -f db-credentials-secret.yaml\n';
        githubWorkflowContent += '        kubectl apply -f db-pvc.yaml\n';
        githubWorkflowContent += '        kubectl apply -f db-deployment.yaml\n';
        githubWorkflowContent += '        kubectl apply -f db-service.yaml\n';
        githubWorkflowContent += '        kubectl apply -f backend-deployment.yaml\n';
        githubWorkflowContent += '        kubectl apply -f backend-service.yaml\n';
        githubWorkflowContent += '        kubectl apply -f frontend-deployment.yaml\n';
        githubWorkflowContent += '        kubectl apply -f frontend-service.yaml\n';
        githubWorkflowContent += '        kubectl apply -f ingress.yaml\n';
        githubWorkflowContent += '        kubectl apply -f hpa.yaml\n';
        githubWorkflowContent += '        kubectl apply -f configmap.yaml\n';
        githubWorkflowContent += '    - name: Verify deployment\n';
        githubWorkflowContent += '      run: |\n';
        githubWorkflowContent += '        kubectl get pods -n app\n';
        githubWorkflowContent += '        kubectl get services -n app\n';
        githubWorkflowContent += '        kubectl get ingress -n app\n';

        // Write GitHub Actions workflow file
        fs.writeFileSync(path.join(githubDir, 'ci-cd.yml'), githubWorkflowContent);

        // Create GitLab CI/CD pipeline
        const gitlabDir = path.join(cicdDir, 'gitlab');
        if (!fs.existsSync(gitlabDir)) {
          fs.mkdirSync(gitlabDir, { recursive: true });
        }

        // Create GitLab CI/CD pipeline file
        let gitlabCiContent = 'stages:\n';
        gitlabCiContent += '  - test\n';
        gitlabCiContent += '  - build\n';
        gitlabCiContent += '  - deploy\n\n';
        
        // Add test job
        gitlabCiContent += 'test:\n';
        gitlabCiContent += '  stage: test\n';
        gitlabCiContent += '  image: node:16-alpine\n';
        gitlabCiContent += '  script:\n';
        gitlabCiContent += '    - cd frontend\n';
        gitlabCiContent += '    - npm ci\n';
        gitlabCiContent += '    - npm test\n';
        gitlabCiContent += '    - cd ../backend\n';
        gitlabCiContent += '    - npm ci\n';
        gitlabCiContent += '    - npm test\n';
        gitlabCiContent += '  only:\n';
        gitlabCiContent += '    - main\n';
        gitlabCiContent += '    - develop\n\n';
        
        // Add build job
        gitlabCiContent += 'build:\n';
        gitlabCiContent += '  stage: build\n';
        gitlabCiContent += '  image: docker:20.10.16\n';
        gitlabCiContent += '  services:\n';
        gitlabCiContent += '    - docker:20.10.16-dind\n';
        gitlabCiContent += '  variables:\n';
        gitlabCiContent += '    DOCKER_TLS_CERTDIR: "/certs"\n';
        gitlabCiContent += '  before_script:\n';
        gitlabCiContent += '    - docker login -u $DOCKERHUB_USERNAME -p $DOCKERHUB_TOKEN\n';
        gitlabCiContent += '    - export VERSION=$(echo $CI_COMMIT_SHA | cut -c1-7)\n';
        gitlabCiContent += '    - |\n';
        gitlabCiContent += '      if [[ "$CI_COMMIT_BRANCH" == "main" ]]; then\n';
        gitlabCiContent += '        export ENV="production"\n';
        gitlabCiContent += '      else\n';
        gitlabCiContent += '        export ENV="staging"\n';
        gitlabCiContent += '      fi\n';
        gitlabCiContent += '  script:\n';
        gitlabCiContent += '    - cd frontend\n';
        gitlabCiContent += '    - docker build -t $DOCKERHUB_USERNAME/frontend:$VERSION -f Dockerfile.prod .\n';
        gitlabCiContent += '    - docker push $DOCKERHUB_USERNAME/frontend:$VERSION\n';
        gitlabCiContent += '    - cd ../backend\n';
        gitlabCiContent += '    - docker build -t $DOCKERHUB_USERNAME/backend:$VERSION -f Dockerfile.prod .\n';
        gitlabCiContent += '    - docker push $DOCKERHUB_USERNAME/backend:$VERSION\n';
        gitlabCiContent += '  only:\n';
        gitlabCiContent += '    - main\n';
        gitlabCiContent += '    - develop\n\n';
        
        // Add deploy job
        gitlabCiContent += 'deploy:\n';
        gitlabCiContent += '  stage: deploy\n';
        gitlabCiContent += '  image: bitnami/kubectl:latest\n';
        gitlabCiContent += '  before_script:\n';
        gitlabCiContent += '    - export VERSION=$(echo $CI_COMMIT_SHA | cut -c1-7)\n';
        gitlabCiContent += '    - mkdir -p $HOME/.kube\n';
        gitlabCiContent += '    - echo "$KUBE_CONFIG" > $HOME/.kube/config\n';
        gitlabCiContent += '    - chmod 600 $HOME/.kube/config\n';
        gitlabCiContent += '  script:\n';
        gitlabCiContent += '    - cd kubernetes\n';
        gitlabCiContent += '    - sed -i "s|image:.*|image: $DOCKERHUB_USERNAME/frontend:$VERSION|g" frontend-deployment.yaml\n';
        gitlabCiContent += '    - sed -i "s|image:.*|image: $DOCKERHUB_USERNAME/backend:$VERSION|g" backend-deployment.yaml\n';
        gitlabCiContent += '    - kubectl apply -f namespace.yaml\n';
        gitlabCiContent += '    - kubectl apply -f db-credentials-secret.yaml\n';
        gitlabCiContent += '    - kubectl apply -f db-pvc.yaml\n';
        gitlabCiContent += '    - kubectl apply -f db-deployment.yaml\n';
        gitlabCiContent += '    - kubectl apply -f db-service.yaml\n';
        gitlabCiContent += '    - kubectl apply -f backend-deployment.yaml\n';
        gitlabCiContent += '    - kubectl apply -f backend-service.yaml\n';
        gitlabCiContent += '    - kubectl apply -f frontend-deployment.yaml\n';
        gitlabCiContent += '    - kubectl apply -f frontend-service.yaml\n';
        gitlabCiContent += '    - kubectl apply -f ingress.yaml\n';
        gitlabCiContent += '    - kubectl apply -f hpa.yaml\n';
        gitlabCiContent += '    - kubectl apply -f configmap.yaml\n';
        gitlabCiContent += '    - kubectl get pods -n app\n';
        gitlabCiContent += '    - kubectl get services -n app\n';
        gitlabCiContent += '    - kubectl get ingress -n app\n';
        gitlabCiContent += '  only:\n';
        gitlabCiContent += '    - main\n';
        gitlabCiContent += '    - develop\n';

        // Write GitLab CI/CD pipeline file
        fs.writeFileSync(path.join(gitlabDir, '.gitlab-ci.yml'), gitlabCiContent);

        // Create Jenkins pipeline
        const jenkinsDir = path.join(cicdDir, 'jenkins');
        if (!fs.existsSync(jenkinsDir)) {
          fs.mkdirSync(jenkinsDir, { recursive: true });
        }

        // Create Jenkinsfile
        let jenkinsfileContent = 'pipeline {\n';
        jenkinsfileContent += '  agent any\n\n';
        jenkinsfileContent += '  environment {\n';
        jenkinsfileContent += '    DOCKERHUB_CREDENTIALS = credentials(\'dockerhub\')\n';
        jenkinsfileContent += '    VERSION = sh(script: \'echo ${GIT_COMMIT.take(7)}\', returnStdout: true).trim()\n';
        jenkinsfileContent += '  }\n\n';
        jenkinsfileContent += '  stages {\n';
        
        // Add test stage
        jenkinsfileContent += '    stage(\'Test\') {\n';
        jenkinsfileContent += '      agent {\n';
        jenkinsfileContent += '        docker {\n';
        jenkinsfileContent += '          image \'node:16-alpine\'\n';
        jenkinsfileContent += '        }\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '      steps {\n';
        jenkinsfileContent += '        sh \'cd frontend && npm ci && npm test\'\n';
        jenkinsfileContent += '        sh \'cd backend && npm ci && npm test\'\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '    }\n\n';
        
        // Add build stage
        jenkinsfileContent += '    stage(\'Build\') {\n';
        jenkinsfileContent += '      steps {\n';
        jenkinsfileContent += '        sh \'echo $DOCKERHUB_CREDENTIALS_PSW | docker login -u $DOCKERHUB_CREDENTIALS_USR --password-stdin\'\n';
        jenkinsfileContent += '        sh \'cd frontend && docker build -t $DOCKERHUB_CREDENTIALS_USR/frontend:$VERSION -f Dockerfile.prod .\'\n';
        jenkinsfileContent += '        sh \'docker push $DOCKERHUB_CREDENTIALS_USR/frontend:$VERSION\'\n';
        jenkinsfileContent += '        sh \'cd backend && docker build -t $DOCKERHUB_CREDENTIALS_USR/backend:$VERSION -f Dockerfile.prod .\'\n';
        jenkinsfileContent += '        sh \'docker push $DOCKERHUB_CREDENTIALS_USR/backend:$VERSION\'\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '    }\n\n';
        
        // Add deploy stage
        jenkinsfileContent += '    stage(\'Deploy\') {\n';
        jenkinsfileContent += '      agent {\n';
        jenkinsfileContent += '        docker {\n';
        jenkinsfileContent += '          image \'bitnami/kubectl:latest\'\n';
        jenkinsfileContent += '        }\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '      steps {\n';
        jenkinsfileContent += '        withCredentials([file(credentialsId: \'kubeconfig\', variable: \'KUBECONFIG\')]) {\n';
        jenkinsfileContent += '          sh \'mkdir -p $HOME/.kube\'\n';
        jenkinsfileContent += '          sh \'cp $KUBECONFIG $HOME/.kube/config\'\n';
        jenkinsfileContent += '          sh \'chmod 600 $HOME/.kube/config\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && sed -i "s|image:.*|image: $DOCKERHUB_CREDENTIALS_USR/frontend:$VERSION|g" frontend-deployment.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && sed -i "s|image:.*|image: $DOCKERHUB_CREDENTIALS_USR/backend:$VERSION|g" backend-deployment.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f namespace.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f db-credentials-secret.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f db-pvc.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f db-deployment.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f db-service.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f backend-deployment.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f backend-service.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f frontend-deployment.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f frontend-service.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f ingress.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f hpa.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl apply -f configmap.yaml\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl get pods -n app\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl get services -n app\'\n';
        jenkinsfileContent += '          sh \'cd kubernetes && kubectl get ingress -n app\'\n';
        jenkinsfileContent += '        }\n';
        jenkinsfileContent += '      }\n';
        jenkinsfileContent += '    }\n';
        jenkinsfileContent += '  }\n';
        jenkinsfileContent += '}\n';

        // Write Jenkinsfile
        fs.writeFileSync(path.join(jenkinsDir, 'Jenkinsfile'), jenkinsfileContent);

        // Create Azure DevOps pipeline
        const azureDir = path.join(cicdDir, 'azure');
        if (!fs.existsSync(azureDir)) {
          fs.mkdirSync(azureDir, { recursive: true });
        }

        // Create azure-pipelines.yml
        let azurePipelinesContent = 'trigger:\n';
        azurePipelinesContent += '  branches:\n';
        azurePipelinesContent += '    include:\n';
        azurePipelinesContent += '    - main\n';
        azurePipelinesContent += '    - develop\n\n';
        azurePipelinesContent += 'pool:\n';
        azurePipelinesContent += '  vmImage: ubuntu-latest\n\n';
        azurePipelinesContent += 'variables:\n';
        azurePipelinesContent += '  version: \'$(Build.SourceVersion)\'\n';
        azurePipelinesContent += '  dockerHubUsername: \'$(DOCKERHUB_USERNAME)\'\n\n';
        azurePipelinesContent += 'stages:\n';
        
        // Add test stage
        azurePipelinesContent += '- stage: Test\n';
        azurePipelinesContent += '  jobs:\n';
        azurePipelinesContent += '  - job: TestCode\n';
        azurePipelinesContent += '    steps:\n';
        azurePipelinesContent += '    - task: NodeTool@0\n';
        azurePipelinesContent += '      inputs:\n';
        azurePipelinesContent += '        versionSpec: \'16.x\'\n';
        azurePipelinesContent += '      displayName: \'Install Node.js\'\n';
        azurePipelinesContent += '    - script: |\n';
        azurePipelinesContent += '        cd frontend\n';
        azurePipelinesContent += '        npm ci\n';
        azurePipelinesContent += '        npm test\n';
        azurePipelinesContent += '      displayName: \'Test Frontend\'\n';
        azurePipelinesContent += '    - script: |\n';
        azurePipelinesContent += '        cd backend\n';
        azurePipelinesContent += '        npm ci\n';
        azurePipelinesContent += '        npm test\n';
        azurePipelinesContent += '      displayName: \'Test Backend\'\n\n';
        
        // Add build stage
        azurePipelinesContent += '- stage: Build\n';
        azurePipelinesContent += '  dependsOn: Test\n';
        azurePipelinesContent += '  jobs:\n';
        azurePipelinesContent += '  - job: BuildImages\n';
        azurePipelinesContent += '    steps:\n';
        azurePipelinesContent += '    - task: Docker@2\n';
        azurePipelinesContent += '      inputs:\n';
        azurePipelinesContent += '        containerRegistry: \'dockerhub\'\n';
        azurePipelinesContent += '        command: \'login\'\n';
        azurePipelinesContent += '      displayName: \'Login to DockerHub\'\n';
        azurePipelinesContent += '    - script: |\n';
        azurePipelinesContent += '        VERSION=$(echo $(Build.SourceVersion) | cut -c1-7)\n';
        azurePipelinesContent += '        cd frontend\n';
        azurePipelinesContent += '        docker build -t $(dockerHubUsername)/frontend:$VERSION -f Dockerfile.prod .\n';
        azurePipelinesContent += '        docker push $(dockerHubUsername)/frontend:$VERSION\n';
        azurePipelinesContent += '      displayName: \'Build and Push Frontend Image\'\n';
        azurePipelinesContent += '    - script: |\n';
        azurePipelinesContent += '        VERSION=$(echo $(Build.SourceVersion) | cut -c1-7)\n';
        azurePipelinesContent += '        cd backend\n';
        azurePipelinesContent += '        docker build -t $(dockerHubUsername)/backend:$VERSION -f Dockerfile.prod .\n';
        azurePipelinesContent += '        docker push $(dockerHubUsername)/backend:$VERSION\n';
        azurePipelinesContent += '      displayName: \'Build and Push Backend Image\'\n\n';
        
        // Add deploy stage
        azurePipelinesContent += '- stage: Deploy\n';
        azurePipelinesContent += '  dependsOn: Build\n';
        azurePipelinesContent += '  jobs:\n';
        azurePipelinesContent += '  - job: DeployToKubernetes\n';
        azurePipelinesContent += '    steps:\n';
        azurePipelinesContent += '    - task: Kubernetes@1\n';
        azurePipelinesContent += '      inputs:\n';
        azurePipelinesContent += '        connectionType: \'kubeConfig\'\n';
        azurePipelinesContent += '        kubeConfigVariable: \'KUBE_CONFIG\'\n';
        azurePipelinesContent += '      displayName: \'Set up Kubernetes connection\'\n';
        azurePipelinesContent += '    - script: |\n';
        azurePipelinesContent += '        VERSION=$(echo $(Build.SourceVersion) | cut -c1-7)\n';
        azurePipelinesContent += '        cd kubernetes\n';
        azurePipelinesContent += '        sed -i "s|image:.*|image: $(dockerHubUsername)/frontend:$VERSION|g" frontend-deployment.yaml\n';
        azurePipelinesContent += '        sed -i "s|image:.*|image: $(dockerHubUsername)/backend:$VERSION|g" backend-deployment.yaml\n';
        azurePipelinesContent += '        kubectl apply -f namespace.yaml\n';
        azurePipelinesContent += '        kubectl apply -f db-credentials-secret.yaml\n';
        azurePipelinesContent += '        kubectl apply -f db-pvc.yaml\n';
        azurePipelinesContent += '        kubectl apply -f db-deployment.yaml\n';
        azurePipelinesContent += '        kubectl apply -f db-service.yaml\n';
        azurePipelinesContent += '        kubectl apply -f backend-deployment.yaml\n';
        azurePipelinesContent += '        kubectl apply -f backend-service.yaml\n';
        azurePipelinesContent += '        kubectl apply -f frontend-deployment.yaml\n';
        azurePipelinesContent += '        kubectl apply -f frontend-service.yaml\n';
        azurePipelinesContent += '        kubectl apply -f ingress.yaml\n';
        azurePipelinesContent += '        kubectl apply -f hpa.yaml\n';
        azurePipelinesContent += '        kubectl apply -f configmap.yaml\n';
        azurePipelinesContent += '        kubectl get pods -n app\n';
        azurePipelinesContent += '        kubectl get services -n app\n';
        azurePipelinesContent += '        kubectl get ingress -n app\n';
        azurePipelinesContent += '      displayName: \'Deploy to Kubernetes\'\n';

        // Write azure-pipelines.yml
        fs.writeFileSync(path.join(azureDir, 'azure-pipelines.yml'), azurePipelinesContent);

        // Create README.md
        let readmeContent = '# CI/CD Pipelines\n\n';
        readmeContent += 'Este directorio contiene configuraciones para diferentes plataformas de CI/CD.\n\n';
        readmeContent += '## Plataformas Soportadas\n\n';
        readmeContent += '- **GitHub Actions**: Configuración en `github/ci-cd.yml`\n';
        readmeContent += '- **GitLab CI/CD**: Configuración en `gitlab/.gitlab-ci.yml`\n';
        readmeContent += '- **Jenkins**: Configuración en `jenkins/Jenkinsfile`\n';
        readmeContent += '- **Azure DevOps**: Configuración en `azure/azure-pipelines.yml`\n\n';
        readmeContent += '## Instrucciones de Uso\n\n';
        readmeContent += '### GitHub Actions\n\n';
        readmeContent += '1. Copia el archivo `github/ci-cd.yml` a `.github/workflows/` en tu repositorio.\n';
        readmeContent += '2. Configura los siguientes secretos en tu repositorio de GitHub:\n';
        readmeContent += '   - `DOCKERHUB_USERNAME`: Tu nombre de usuario de DockerHub\n';
        readmeContent += '   - `DOCKERHUB_TOKEN`: Tu token de acceso de DockerHub\n';
        readmeContent += '   - `KUBE_CONFIG`: Tu archivo kubeconfig codificado en base64\n\n';
        readmeContent += '### GitLab CI/CD\n\n';
        readmeContent += '1. Copia el archivo `gitlab/.gitlab-ci.yml` a la raíz de tu repositorio.\n';
        readmeContent += '2. Configura las siguientes variables en la configuración CI/CD de tu proyecto GitLab:\n';
        readmeContent += '   - `DOCKERHUB_USERNAME`: Tu nombre de usuario de DockerHub\n';
        readmeContent += '   - `DOCKERHUB_TOKEN`: Tu token de acceso de DockerHub\n';
        readmeContent += '   - `KUBE_CONFIG`: Tu archivo kubeconfig\n\n';
        readmeContent += '### Jenkins\n\n';
        readmeContent += '1. Crea un nuevo pipeline en Jenkins usando el archivo `jenkins/Jenkinsfile`.\n';
        readmeContent += '2. Configura las siguientes credenciales en Jenkins:\n';
        readmeContent += '   - `dockerhub`: Credenciales de tipo Username with password para DockerHub\n';
        readmeContent += '   - `kubeconfig`: Credenciales de tipo Secret file para tu archivo kubeconfig\n\n';
        readmeContent += '### Azure DevOps\n\n';
        readmeContent += '1. Copia el archivo `azure/azure-pipelines.yml` a la raíz de tu repositorio.\n';
        readmeContent += '2. Configura las siguientes variables en tu pipeline de Azure DevOps:\n';
        readmeContent += '   - `DOCKERHUB_USERNAME`: Tu nombre de usuario de DockerHub\n';
        readmeContent += '   - `KUBE_CONFIG`: Tu archivo kubeconfig\n';
        readmeContent += '3. Configura una conexión de servicio de tipo Docker Registry para DockerHub con el nombre `dockerhub`.\n';

        // Write README.md
        fs.writeFileSync(path.join(cicdDir, 'README.md'), readmeContent);
      }

      /**
       * Creates monitoring files
       * @param projectDir Directory to create files in
       * @param config Monitoring configuration
       */
      private createMonitoringFiles(projectDir: string, config: MonitoringConfig): void {
        const monitoringDir = path.join(projectDir, 'monitoring');
        if (!fs.existsSync(monitoringDir)) {
          fs.mkdirSync(monitoringDir, { recursive: true });
        }

        // Create Prometheus configuration
        const prometheusDir = path.join(monitoringDir, 'prometheus');
        if (!fs.existsSync(prometheusDir)) {
          fs.mkdirSync(prometheusDir, { recursive: true });
        }

        // Create prometheus.yml
        let prometheusContent = 'global:\n';
        prometheusContent += '  scrape_interval: 15s\n';
        prometheusContent += '  evaluation_interval: 15s\n\n';
        prometheusContent += 'alerting:\n';
        prometheusContent += '  alertmanagers:\n';
        prometheusContent += '  - static_configs:\n';
        prometheusContent += '    - targets:\n';
        prometheusContent += '      - alertmanager:9093\n\n';
        prometheusContent += 'rule_files:\n';
        prometheusContent += '  - "alert_rules.yml"\n\n';
        prometheusContent += 'scrape_configs:\n';
        prometheusContent += '  - job_name: "prometheus"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '    - targets: ["localhost:9090"]\n\n';
        prometheusContent += '  - job_name: "node_exporter"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '    - targets: ["node-exporter:9100"]\n\n';
        prometheusContent += '  - job_name: "cadvisor"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '    - targets: ["cadvisor:8080"]\n\n';
        prometheusContent += '  - job_name: "backend"\n';
        prometheusContent += '    metrics_path: /metrics\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '    - targets: ["backend:8080"]\n';

        // Write prometheus.yml
        fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);

        // Create alert_rules.yml
        let alertRulesContent = 'groups:\n';
        alertRulesContent += '- name: example\n';
        alertRulesContent += '  rules:\n';
        alertRulesContent += '  - alert: HighCPULoad\n';
        alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: High CPU load\n';
        alertRulesContent += '      description: "CPU load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
        alertRulesContent += '  - alert: HighMemoryLoad\n';
        alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: High memory load\n';
        alertRulesContent += '      description: "Memory load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
        alertRulesContent += '  - alert: HighDiskUsage\n';
        alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 80\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: High disk usage\n';
        alertRulesContent += '      description: "Disk usage is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n';

        // Write alert_rules.yml
        fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);

        // Create Alertmanager configuration
        const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
        if (!fs.existsSync(alertmanagerDir)) {
          fs.mkdirSync(alertmanagerDir, { recursive: true });
        }

        // Create alertmanager.yml
        let alertmanagerContent = 'global:\n';
        alertmanagerContent += '  resolve_timeout: 5m\n';
        alertmanagerContent += '  smtp_smarthost: "smtp.example.com:587"\n';
        alertmanagerContent += '  smtp_from: "alertmanager@example.com"\n';
        alertmanagerContent += '  smtp_auth_username: "alertmanager"\n';
        alertmanagerContent += '  smtp_auth_password: "password"\n\n';
        alertmanagerContent += 'route:\n';
        alertmanagerContent += '  group_by: [\'alertname\', \'instance\']\n';
        alertmanagerContent += '  group_wait: 30s\n';
        alertmanagerContent += '  group_interval: 5m\n';
        alertmanagerContent += '  repeat_interval: 1h\n';
        alertmanagerContent += '  receiver: \'email\'\n\n';
        alertmanagerContent += 'receivers:\n';
        alertmanagerContent += '- name: \'email\'\n';
        alertmanagerContent += '  email_configs:\n';
        alertmanagerContent += '  - to: "alerts@example.com"\n';
        alertmanagerContent += '    send_resolved: true\n\n';
        alertmanagerContent += 'inhibit_rules:\n';
        alertmanagerContent += '  - source_match:\n';
        alertmanagerContent += '      severity: \'critical\'\n';
        alertmanagerContent += '    target_match:\n';
        alertmanagerContent += '      severity: \'warning\'\n';
        alertmanagerContent += '    equal: [\'alertname\', \'instance\']\n';

        // Write alertmanager.yml
        fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);

        // Create Grafana configuration
        const grafanaDir = path.join(monitoringDir, 'grafana');
        if (!fs.existsSync(grafanaDir)) {
          fs.mkdirSync(grafanaDir, { recursive: true });
        }

        // Create datasources.yml
        let datasourcesContent = 'apiVersion: 1\n\n';
        datasourcesContent += 'datasources:\n';
        datasourcesContent += '  - name: Prometheus\n';
        datasourcesContent += '    type: prometheus\n';
        datasourcesContent += '    access: proxy\n';
        datasourcesContent += '    url: http://prometheus:9090\n';
        datasourcesContent += '    isDefault: true\n';
        datasourcesContent += '    editable: true\n';

        // Write datasources.yml
        fs.writeFileSync(path.join(grafanaDir, 'datasources.yml'), datasourcesContent);

        // Create dashboard.json
        let dashboardContent = '{\n';
        dashboardContent += '  "annotations": {\n';
        dashboardContent += '    "list": [\n';
        dashboardContent += '      {\n';
        dashboardContent += '        "builtIn": 1,\n';
        dashboardContent += '        "datasource": "-- Grafana --",\n';
        dashboardContent += '        "enable": true,\n';
        dashboardContent += '        "hide": true,\n';
        dashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
        dashboardContent += '        "name": "Annotations & Alerts",\n';
        dashboardContent += '        "type": "dashboard"\n';
        dashboardContent += '      }\n';
        dashboardContent += '    ]\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "editable": true,\n';
        dashboardContent += '  "gnetId": null,\n';
        dashboardContent += '  "graphTooltip": 0,\n';
        dashboardContent += '  "id": 1,\n';
        dashboardContent += '  "links": [],\n';
        dashboardContent += '  "panels": [\n';
        dashboardContent += '    {\n';
        dashboardContent += '      "alert": {\n';
        dashboardContent += '        "conditions": [\n';
        dashboardContent += '          {\n';
        dashboardContent += '            "evaluator": {\n';
        dashboardContent += '              "params": [\n';
        dashboardContent += '                80\n';
        dashboardContent += '              ],\n';
        dashboardContent += '              "type": "gt"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "operator": {\n';
        dashboardContent += '              "type": "and"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "query": {\n';
        dashboardContent += '              "params": [\n';
        dashboardContent += '                "A",\n';
        dashboardContent += '                "5m",\n';
        dashboardContent += '                "now"\n';
        dashboardContent += '              ]\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "reducer": {\n';
        dashboardContent += '              "params": [],\n';
        dashboardContent += '              "type": "avg"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "type": "query"\n';
        dashboardContent += '          }\n';
        dashboardContent += '        ],\n';
        dashboardContent += '        "executionErrorState": "alerting",\n';
        dashboardContent += '        "frequency": "60s",\n';
        dashboardContent += '        "handler": 1,\n';
        dashboardContent += '        "name": "CPU Usage alert",\n';
        dashboardContent += '        "noDataState": "no_data",\n';
        dashboardContent += '        "notifications": []\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "aliasColors": {},\n';
        dashboardContent += '      "bars": false,\n';
        dashboardContent += '      "dashLength": 10,\n';
        dashboardContent += '      "dashes": false,\n';
        dashboardContent += '      "datasource": "Prometheus",\n';
        dashboardContent += '      "fieldConfig": {\n';
        dashboardContent += '        "defaults": {\n';
        dashboardContent += '          "custom": {}\n';
        dashboardContent += '        },\n';
        dashboardContent += '        "overrides": []\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "fill": 1,\n';
        dashboardContent += '      "fillGradient": 0,\n';
        dashboardContent += '      "gridPos": {\n';
        dashboardContent += '        "h": 9,\n';
        dashboardContent += '        "w": 12,\n';
        dashboardContent += '        "x": 0,\n';
        dashboardContent += '        "y": 0\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "hiddenSeries": false,\n';
        dashboardContent += '      "id": 2,\n';
        dashboardContent += '      "legend": {\n';
        dashboardContent += '        "avg": false,\n';
        dashboardContent += '        "current": false,\n';
        dashboardContent += '        "max": false,\n';
        dashboardContent += '        "min": false,\n';
        dashboardContent += '        "show": true,\n';
        dashboardContent += '        "total": false,\n';
        dashboardContent += '        "values": false\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "lines": true,\n';
        dashboardContent += '      "linewidth": 1,\n';
        dashboardContent += '      "nullPointMode": "null",\n';
        dashboardContent += '      "options": {\n';
        dashboardContent += '        "alertThreshold": true\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "percentage": false,\n';
        dashboardContent += '      "pluginVersion": "7.3.7",\n';
        dashboardContent += '      "pointradius": 2,\n';
        dashboardContent += '      "points": false,\n';
        dashboardContent += '      "renderer": "flot",\n';
        dashboardContent += '      "seriesOverrides": [],\n';
        dashboardContent += '      "spaceLength": 10,\n';
        dashboardContent += '      "stack": false,\n';
        dashboardContent += '      "steppedLine": false,\n';
        dashboardContent += '      "targets": [\n';
        dashboardContent += '        {\n';
        dashboardContent += '          "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\\"idle\\"}[5m])) * 100)",\n';
        dashboardContent += '          "interval": "",\n';
        dashboardContent += '          "legendFormat": "",\n';
        dashboardContent += '          "refId": "A"\n';
        dashboardContent += '        }\n';
        dashboardContent += '      ],\n';
        dashboardContent += '      "thresholds": [\n';
        dashboardContent += '        {\n';
        dashboardContent += '          "colorMode": "critical",\n';
        dashboardContent += '          "fill": true,\n';
        dashboardContent += '          "line": true,\n';
        dashboardContent += '          "op": "gt",\n';
        dashboardContent += '          "value": 80\n';
        dashboardContent += '        }\n';
        dashboardContent += '      ],\n';
        dashboardContent += '      "timeFrom": null,\n';
        dashboardContent += '      "timeRegions": [],\n';
        dashboardContent += '      "timeShift": null,\n';
        dashboardContent += '      "title": "CPU Usage",\n';
        dashboardContent += '      "tooltip": {\n';
        dashboardContent += '        "shared": true,\n';
        dashboardContent += '        "sort": 0,\n';
        dashboardContent += '        "value_type": "individual"\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "type": "graph",\n';
        dashboardContent += '      "xaxis": {\n';
        dashboardContent += '        "buckets": null,\n';
        dashboardContent += '        "mode": "time",\n';
        dashboardContent += '        "name": null,\n';
        dashboardContent += '        "show": true,\n';
        dashboardContent += '        "values": []\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "yaxes": [\n';
        dashboardContent += '        {\n';
        dashboardContent += '          "format": "percent",\n';
        dashboardContent += '          "label": null,\n';
        dashboardContent += '          "logBase": 1,\n';
        dashboardContent += '          "max": null,\n';
        dashboardContent += '          "min": null,\n';
        dashboardContent += '          "show": true\n';
        dashboardContent += '        },\n';
        dashboardContent += '        {\n';
        dashboardContent += '          "format": "short",\n';
        dashboardContent += '          "label": null,\n';
        dashboardContent += '          "logBase": 1,\n';
        dashboardContent += '          "max": null,\n';
        dashboardContent += '          "min": null,\n';
        dashboardContent += '          "show": true\n';
        dashboardContent += '        }\n';
        dashboardContent += '      ],\n';
        dashboardContent += '      "yaxis": {\n';
        dashboardContent += '        "align": false,\n';
        dashboardContent += '        "alignLevel": null\n';
        dashboardContent += '      }\n';
        dashboardContent += '    }\n';
        dashboardContent += '  ],\n';
        dashboardContent += '  "schemaVersion": 26,\n';
        dashboardContent += '  "style": "dark",\n';
        dashboardContent += '  "tags": [],\n';
        dashboardContent += '  "templating": {\n';
        dashboardContent += '    "list": []\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "time": {\n';
        dashboardContent += '    "from": "now-6h",\n';
        dashboardContent += '    "to": "now"\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "timepicker": {},\n';
        dashboardContent += '  "timezone": "",\n';
        dashboardContent += '  "title": "System Monitoring",\n';
        dashboardContent += '  "uid": "system-monitoring",\n';
        dashboardContent += '  "version": 1\n';
        dashboardContent += '}\n';

        // Create dashboards directory
        const dashboardsDir = path.join(grafanaDir, 'dashboards');
        if (!fs.existsSync(dashboardsDir)) {
          fs.mkdirSync(dashboardsDir, { recursive: true });
        }

        // Write dashboard.json
        fs.writeFileSync(path.join(dashboardsDir, 'dashboard.json'), dashboardContent);

        // Create dashboard.yml
        let dashboardYamlContent = 'apiVersion: 1\n\n';
        dashboardYamlContent += 'providers:\n';
        dashboardYamlContent += '  - name: \'default\'\n';
        dashboardYamlContent += '    orgId: 1\n';
        dashboardYamlContent += '    folder: \'\'\n';
        dashboardYamlContent += '    type: file\n';
        dashboardYamlContent += '    disableDeletion: false\n';
        dashboardYamlContent += '    editable: true\n';
        dashboardYamlContent += '    options:\n';
        dashboardYamlContent += '      path: /etc/grafana/dashboards\n';

        // Write dashboard.yml
        fs.writeFileSync(path.join(grafanaDir, 'dashboard.yml'), dashboardYamlContent);

        // Create docker-compose.yml for monitoring
        let dockerComposeContent = 'version: "3.8"\n\n';
        dockerComposeContent += 'services:\n';
        dockerComposeContent += '  prometheus:\n';
        dockerComposeContent += '    image: prom/prometheus:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
        dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
        dockerComposeContent += '      - prometheus_data:/prometheus\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
        dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
        dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
        dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9090:9090"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  alertmanager:\n';
        dockerComposeContent += '    image: prom/alertmanager:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
        dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
        dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9093:9093"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  grafana:\n';
        dockerComposeContent += '    image: grafana/grafana:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
        dockerComposeContent += '      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml\n';
        dockerComposeContent += '      - ./grafana/dashboards:/etc/grafana/dashboards\n';
        dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
        dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
        dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "3000:3000"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  node-exporter:\n';
        dockerComposeContent += '    image: prom/node-exporter:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - /proc:/host/proc:ro\n';
        dockerComposeContent += '      - /sys:/host/sys:ro\n';
        dockerComposeContent += '      - /:/rootfs:ro\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
        dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
        dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9100:9100"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  cadvisor:\n';
        dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - /:/rootfs:ro\n';
        dockerComposeContent += '      - /var/run:/var/run:ro\n';
        dockerComposeContent += '      - /sys:/sys:ro\n';
        dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "8080:8080"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += 'networks:\n';
        dockerComposeContent += '  monitoring-network:\n';
        dockerComposeContent += '    driver: bridge\n\n';
        
        dockerComposeContent += 'volumes:\n';
        dockerComposeContent += '  prometheus_data:\n';
        dockerComposeContent += '    driver: local\n';
        dockerComposeContent += '  alertmanager_data:\n';
        dockerComposeContent += '    driver: local\n';
        dockerComposeContent += '  grafana_data:\n';
        dockerComposeContent += '    driver: local\n';

        // Write docker-compose.yml
        fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);

        // Create README.md
        let readmeContent = '# Monitoring Stack\n\n';
        readmeContent += 'Este directorio contiene la configuración para un stack de monitoreo completo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
        readmeContent += '## Componentes\n\n';
        readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
        readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
        readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
        readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
        readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
        readmeContent += '## Inicio Rápido\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Iniciar el stack de monitoreo\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += '## Acceso\n\n';
        readmeContent += '- **Prometheus**: http://localhost:9090\n';
        readmeContent += '- **Alertmanager**: http://localhost:9093\n';
        readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
        readmeContent += '- **Node Exporter**: http://localhost:9100\n';
        readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
        readmeContent += '## Personalización\n\n';
        readmeContent += '### Prometheus\n\n';
        readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
        readmeContent += '### Alertmanager\n\n';
        readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
        readmeContent += '### Grafana\n\n';
        readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/dashboard.yml` si es necesario.\n';

        // Write README.md
        fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);

        // Create ELK stack directory
        const elkDir = path.join(monitoringDir, 'elk');
        if (!fs.existsSync(elkDir)) {
          fs.mkdirSync(elkDir, { recursive: true });
        }

        // Create docker-compose.yml for ELK stack
        let elkComposeContent = 'version: "3.8"\n\n';
        elkComposeContent += 'services:\n';
        elkComposeContent += '  elasticsearch:\n';
        elkComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - discovery.type=single-node\n';
        elkComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "9200:9200"\n';
        elkComposeContent += '      - "9300:9300"\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  logstash:\n';
        elkComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "5000:5000"\n';
        elkComposeContent += '      - "9600:9600"\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  kibana:\n';
        elkComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "5601:5601"\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  filebeat:\n';
        elkComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
        elkComposeContent += '    user: root\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
        elkComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
        elkComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '      - logstash\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += 'networks:\n';
        elkComposeContent += '  elk-network:\n';
        elkComposeContent += '    driver: bridge\n\n';
        
        elkComposeContent += 'volumes:\n';
        elkComposeContent += '  elasticsearch_data:\n';
        elkComposeContent += '    driver: local\n';

        // Write docker-compose.yml for ELK stack
        fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), elkComposeContent);

        // Create Logstash pipeline directory
        const logstashDir = path.join(elkDir, 'logstash');
        if (!fs.existsSync(logstashDir)) {
          fs.mkdirSync(logstashDir, { recursive: true });
        }

        const pipelineDir = path.join(logstashDir, 'pipeline');
        if (!fs.existsSync(pipelineDir)) {
          fs.mkdirSync(pipelineDir, { recursive: true });
        }

        // Create logstash.conf
        let logstashConfContent = 'input {\n';
        logstashConfContent += '  beats {\n';
        logstashConfContent += '    port => 5000\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n\n';
        logstashConfContent += 'filter {\n';
        logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  } else {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n\n';
        logstashConfContent += 'output {\n';
        logstashConfContent += '  elasticsearch {\n';
        logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
        logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n';

        // Write logstash.conf
        fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);

        // Create Filebeat directory
        const filebeatDir = path.join(elkDir, 'filebeat');
        if (!fs.existsSync(filebeatDir)) {
          fs.mkdirSync(filebeatDir, { recursive: true });
        }

        // Create filebeat.yml
        let filebeatContent = 'filebeat.inputs:\n';
        filebeatContent += '- type: container\n';
        filebeatContent += '  paths:\n';
        filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
        filebeatContent += '  processors:\n';
        filebeatContent += '    - add_docker_metadata:\n';
        filebeatContent += '        host: "unix:///var/run/docker.sock"\n\n';
        filebeatContent += 'processors:\n';
        filebeatContent += '  - add_host_metadata:\n';
        filebeatContent += '      when.not.contains.tags: forwarded\n';
        filebeatContent += '  - add_cloud_metadata: ~\n';
        filebeatContent += '  - add_docker_metadata: ~\n';
        filebeatContent += '  - add_kubernetes_metadata: ~\n\n';
        filebeatContent += 'output.logstash:\n';
        filebeatContent += '  hosts: ["logstash:5000"]\n';
        filebeatContent += '  ssl.enabled: false\n';

        // Write filebeat.yml
        fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);

        // Create README.md for ELK stack
        let elkReadmeContent = '# ELK Stack para Monitoreo de Logs\n\n';
        elkReadmeContent += 'Este directorio contiene la configuración para un stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat para la recolección de logs.\n\n';
        elkReadmeContent += '## Componentes\n\n';
        elkReadmeContent += '- **Elasticsearch**: Motor de búsqueda y análisis\n';
        elkReadmeContent += '- **Logstash**: Procesamiento de logs\n';
        elkReadmeContent += '- **Kibana**: Visualización de datos\n';
        elkReadmeContent += '- **Filebeat**: Recolector de logs\n\n';
        elkReadmeContent += '## Inicio Rápido\n\n';
        elkReadmeContent += '```bash\n';
        elkReadmeContent += '# Iniciar el stack ELK\n';
        elkReadmeContent += 'docker-compose up -d\n';
        elkReadmeContent += '```\n\n';
        elkReadmeContent += '## Acceso\n\n';
        elkReadmeContent += '- **Elasticsearch**: http://localhost:9200\n';
        elkReadmeContent += '- **Kibana**: http://localhost:5601\n\n';
        elkReadmeContent += '## Personalización\n\n';
        elkReadmeContent += '### Logstash\n\n';
        elkReadmeContent += 'Edita `logstash/pipeline/logstash.conf` para modificar el procesamiento de logs.\n\n';
        elkReadmeContent += '### Filebeat\n\n';
        elkReadmeContent += 'Edita `filebeat/filebeat.yml` para configurar la recolección de logs.\n';

        // Write README.md for ELK stack
        fs.writeFileSync(path.join(elkDir, 'README.md'), elkReadmeContent);

        // Create Loki stack directory
        const lokiDir = path.join(monitoringDir, 'loki');
        if (!fs.existsSync(lokiDir)) {
          fs.mkdirSync(lokiDir, { recursive: true });
        }

        // Create docker-compose.yml for Loki stack
        let lokiComposeContent = 'version: "3.8"\n\n';
        lokiComposeContent += 'services:\n';
        lokiComposeContent += '  loki:\n';
        lokiComposeContent += '    image: grafana/loki:latest\n';
        lokiComposeContent += '    ports:\n';
        lokiComposeContent += '      - "3100:3100"\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./loki-config.yml:/etc/loki/local-config.yaml\n';
        lokiComposeContent += '      - loki_data:/loki\n';
        lokiComposeContent += '    command: -config.file=/etc/loki/local-config.yaml\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += '  promtail:\n';
        lokiComposeContent += '    image: grafana/promtail:latest\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./promtail-config.yml:/etc/promtail/config.yml\n';
        lokiComposeContent += '      - /var/log:/var/log\n';
        lokiComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
        lokiComposeContent += '    command: -config.file=/etc/promtail/config.yml\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    depends_on:\n';
        lokiComposeContent += '      - loki\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += '  grafana:\n';
        lokiComposeContent += '    image: grafana/grafana:latest\n';
        lokiComposeContent += '    ports:\n';
        lokiComposeContent += '      - "3200:3000"\n';
        lokiComposeContent += '    environment:\n';
        lokiComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
        lokiComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
        lokiComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
        lokiComposeContent += '      - grafana_loki_data:/var/lib/grafana\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    depends_on:\n';
        lokiComposeContent += '      - loki\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += 'networks:\n';
        lokiComposeContent += '  loki-network:\n';
        lokiComposeContent += '    driver: bridge\n\n';
        
        lokiComposeContent += 'volumes:\n';
        lokiComposeContent += '  loki_data:\n';
        lokiComposeContent += '    driver: local\n';
        lokiComposeContent += '  grafana_loki_data:\n';
        lokiComposeContent += '    driver: local\n';

        // Write docker-compose.yml for Loki stack
        fs.writeFileSync(path.join(lokiDir, 'docker-compose.yml'), lokiComposeContent);

        // Create loki-config.yml
        let lokiConfigContent = 'auth_enabled: false\n\n';
        lokiConfigContent += 'server:\n';
        lokiConfigContent += '  http_listen_port: 3100\n\n';
        lokiConfigContent += 'ingester:\n';
        lokiConfigContent += '  lifecycler:\n';
        lokiConfigContent += '    address: 127.0.0.1\n';
        lokiConfigContent += '    ring:\n';
        lokiConfigContent += '      kvstore:\n';
        lokiConfigContent += '        store: inmemory\n';
        lokiConfigContent += '      replication_factor: 1\n';
        lokiConfigContent += '    final_sleep: 0s\n';
        lokiConfigContent += '  chunk_idle_period: 5m\n';
        lokiConfigContent += '  chunk_retain_period: 30s\n\n';
        lokiConfigContent += 'schema_config:\n';
        lokiConfigContent += '  configs:\n';
        lokiConfigContent += '    - from: 2020-05-15\n';
        lokiConfigContent += '      store: boltdb\n';
        lokiConfigContent += '      object_store: filesystem\n';
        lokiConfigContent += '      schema: v11\n';
        lokiConfigContent += '      index:\n';
        lokiConfigContent += '        prefix: index_\n';
        lokiConfigContent += '        period: 168h\n\n';
        lokiConfigContent += 'storage_config:\n';
        lokiConfigContent += '  boltdb:\n';
        lokiConfigContent += '    directory: /loki/index\n\n';
        lokiConfigContent += '  filesystem:\n';
        lokiConfigContent += '    directory: /loki/chunks\n\n';
        lokiConfigContent += 'limits_config:\n';
        lokiConfigContent += '  enforce_metric_name: false\n';
        lokiConfigContent += '  reject_old_samples: true\n';
        lokiConfigContent += '  reject_old_samples_max_age: 168h\n\n';
        lokiConfigContent += 'chunk_store_config:\n';
        lokiConfigContent += '  max_look_back_period: 0s\n\n';
        lokiConfigContent += 'table_manager:\n';
        lokiConfigContent += '  retention_deletes_enabled: false\n';
        lokiConfigContent += '  retention_period: 0s\n';

        // Write loki-config.yml
        fs.writeFileSync(path.join(lokiDir, 'loki-config.yml'), lokiConfigContent);

        // Create promtail-config.yml
        let promtailConfigContent = 'server:\n';
        promtailConfigContent += '  http_listen_port: 9080\n';
        promtailConfigContent += '  grpc_listen_port: 0\n\n';
        promtailConfigContent += 'positions:\n';
        promtailConfigContent += '  filename: /tmp/positions.yaml\n\n';
        promtailConfigContent += 'clients:\n';
        promtailConfigContent += '  - url: http://loki:3100/loki/api/v1/push\n\n';
        promtailConfigContent += 'scrape_configs:\n';
        promtailConfigContent += '  - job_name: system\n';
        promtailConfigContent += '    static_configs:\n';
        promtailConfigContent += '      - targets:\n';
        promtailConfigContent += '          - localhost\n';
        promtailConfigContent += '        labels:\n';
        promtailConfigContent += '          job: varlogs\n';
        promtailConfigContent += '          __path__: /var/log/*log\n\n';
        promtailConfigContent += '  - job_name: containers\n';
        promtailConfigContent += '    static_configs:\n';
        promtailConfigContent += '      - targets:\n';
        promtailConfigContent += '          - localhost\n';
        promtailConfigContent += '        labels:\n';
        promtailConfigContent += '          job: containerlogs\n';
        promtailConfigContent += '          __path__: /var/lib/docker/containers/*/*log\n\n';
        promtailConfigContent += '    pipeline_stages:\n';
        promtailConfigContent += '      - json:\n';
        promtailConfigContent += '          expressions:\n';
        promtailConfigContent += '            stream: stream\n';
        promtailConfigContent += '            attrs: attrs\n';
        promtailConfigContent += '            tag: attrs.tag\n\n';
        promtailConfigContent += '      - labels:\n';
        promtailConfigContent += '          stream:\n';
        promtailConfigContent += '          tag:\n';

        // Write promtail-config.yml
        fs.writeFileSync(path.join(lokiDir, 'promtail-config.yml'), promtailConfigContent);

        // Create grafana-datasources.yml
        let grafanaDatasourcesContent = 'apiVersion: 1\n\n';
        grafanaDatasourcesContent += 'datasources:\n';
        grafanaDatasourcesContent += '  - name: Loki\n';
        grafanaDatasourcesContent += '    type: loki\n';
        grafanaDatasourcesContent += '    access: proxy\n';
        grafanaDatasourcesContent += '    url: http://loki:3100\n';
        grafanaDatasourcesContent += '    isDefault: true\n';
        grafanaDatasourcesContent += '    editable: true\n';

        // Write grafana-datasources.yml
        fs.writeFileSync(path.join(lokiDir, 'grafana-datasources.yml'), grafanaDatasourcesContent);

        // Create README.md for Loki stack
        let lokiReadmeContent = '# Loki Stack para Monitoreo de Logs\n\n';
        lokiReadmeContent += 'Este directorio contiene la configuración para un stack Loki (Loki, Promtail, Grafana) para la recolección y visualización de logs.\n\n';
        lokiReadmeContent += '## Componentes\n\n';
        lokiReadmeContent += '- **Loki**: Sistema de agregación de logs\n';
        lokiReadmeContent += '- **Promtail**: Agente para enviar logs a Loki\n';
        lokiReadmeContent += '- **Grafana**: Visualización de datos\n\n';
        lokiReadmeContent += '## Inicio Rápido\n\n';
        lokiReadmeContent += '```bash\n';
        lokiReadmeContent += '# Iniciar el stack Loki\n';
        lokiReadmeContent += 'docker-compose up -d\n';
        lokiReadmeContent += '```\n\n';
        lokiReadmeContent += '## Acceso\n\n';
        lokiReadmeContent += '- **Loki**: http://localhost:3100\n';
        lokiReadmeContent += '- **Grafana**: http://localhost:3200 (usuario: admin, contraseña: admin)\n\n';
        lokiReadmeContent += '## Personalización\n\n';
        lokiReadmeContent += '### Loki\n\n';
        lokiReadmeContent += 'Edita `loki-config.yml` para modificar la configuración de Loki.\n\n';
        lokiReadmeContent += '### Promtail\n\n';
        lokiReadmeContent += 'Edita `promtail-config.yml` para configurar la recolección de logs.\n';

        // Write README.md for Loki stack
        fs.writeFileSync(path.join(lokiDir, 'README.md'), lokiReadmeContent);

        // Create main README.md for monitoring directory
        let mainReadmeContent = '# Monitoreo y Observabilidad\n\n';
        mainReadmeContent += 'Este directorio contiene diferentes stacks de monitoreo y observabilidad para tu aplicación.\n\n';
        mainReadmeContent += '## Stacks Disponibles\n\n';
        mainReadmeContent += '### 1. Prometheus Stack\n\n';
        mainReadmeContent += 'Stack completo de monitoreo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
        mainReadmeContent += '```bash\n';
        mainReadmeContent += '# Iniciar el stack de Prometheus\n';
        mainReadmeContent += 'cd prometheus-stack\n';
        mainReadmeContent += 'docker-compose up -d\n';
        mainReadmeContent += '```\n\n';
        mainReadmeContent += '### 2. ELK Stack\n\n';
        mainReadmeContent += 'Stack para recolección y análisis de logs basado en Elasticsearch, Logstash, Kibana y Filebeat.\n\n';
        mainReadmeContent += '```bash\n';
        mainReadmeContent += '# Iniciar el stack ELK\n';
        mainReadmeContent += 'cd elk\n';
        mainReadmeContent += 'docker-compose up -d\n';
        mainReadmeContent += '```\n\n';
        mainReadmeContent += '### 3. Loki Stack\n\n';
        mainReadmeContent += 'Stack ligero para recolección y análisis de logs basado en Loki, Promtail y Grafana.\n\n';
        mainReadmeContent += '```bash\n';
        mainReadmeContent += '# Iniciar el stack Loki\n';
        mainReadmeContent += 'cd loki\n';
        mainReadmeContent += 'docker-compose up -d\n';
        mainReadmeContent += '```\n\n';
        mainReadmeContent += '## Recomendaciones\n\n';
        mainReadmeContent += '- Para entornos de producción, se recomienda utilizar el stack de Prometheus para métricas y el stack ELK o Loki para logs.\n';
        mainReadmeContent += '- Para entornos de desarrollo o pruebas, el stack de Loki es más ligero y consume menos recursos.\n';
        mainReadmeContent += '- Asegúrate de ajustar las configuraciones según tus necesidades específicas antes de desplegar en producción.\n';

        // Write main README.md
        fs.writeFileSync(path.join(monitoringDir, 'README.md'), mainReadmeContent);

        return monitoringDir;
      } catch (error) {
        this.logger.error(`Error creating monitoring files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates CI/CD pipeline files for the project
     * @param projectDir - The project directory
     * @param config - The CI/CD configuration
     * @returns The path to the CI/CD directory
     */
    private async createCICDFiles(projectDir: string, config: any): Promise<string> {
      try {
        const cicdDir = path.join(projectDir, '.github', 'workflows');
        if (!fs.existsSync(cicdDir)) {
          fs.mkdirSync(cicdDir, { recursive: true });
        }

        // Create GitHub Actions workflow for CI
        let ciWorkflowContent = 'name: CI\n\n';
        ciWorkflowContent += 'on:\n';
        ciWorkflowContent += '  push:\n';
        ciWorkflowContent += '    branches: [ main, develop ]\n';
        ciWorkflowContent += '  pull_request:\n';
        ciWorkflowContent += '    branches: [ main, develop ]\n\n';
        ciWorkflowContent += 'jobs:\n';
        ciWorkflowContent += '  build-and-test:\n';
        ciWorkflowContent += '    runs-on: ubuntu-latest\n\n';
        ciWorkflowContent += '    steps:\n';
        ciWorkflowContent += '    - uses: actions/checkout@v3\n\n';
        
        // Add Node.js setup if needed
        if (config.language === 'javascript' || config.language === 'typescript') {
          ciWorkflowContent += '    - name: Set up Node.js\n';
          ciWorkflowContent += '      uses: actions/setup-node@v3\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        node-version: 16\n';
          ciWorkflowContent += '        cache: \'npm\'\n\n';
          ciWorkflowContent += '    - name: Install dependencies\n';
          ciWorkflowContent += '      run: npm ci\n\n';
          ciWorkflowContent += '    - name: Lint\n';
          ciWorkflowContent += '      run: npm run lint\n\n';
          ciWorkflowContent += '    - name: Build\n';
          ciWorkflowContent += '      run: npm run build\n\n';
          ciWorkflowContent += '    - name: Test\n';
          ciWorkflowContent += '      run: npm test\n\n';
        }
        
        // Add Python setup if needed
        else if (config.language === 'python') {
          ciWorkflowContent += '    - name: Set up Python\n';
          ciWorkflowContent += '      uses: actions/setup-python@v4\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        python-version: \'3.10\'\n';
          ciWorkflowContent += '        cache: \'pip\'\n\n';
          ciWorkflowContent += '    - name: Install dependencies\n';
          ciWorkflowContent += '      run: |\n';
          ciWorkflowContent += '        python -m pip install --upgrade pip\n';
          ciWorkflowContent += '        pip install flake8 pytest\n';
          ciWorkflowContent += '        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n';
          ciWorkflowContent += '    - name: Lint with flake8\n';
          ciWorkflowContent += '      run: |\n';
          ciWorkflowContent += '        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n';
          ciWorkflowContent += '        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics\n\n';
          ciWorkflowContent += '    - name: Test with pytest\n';
          ciWorkflowContent += '      run: |\n';
          ciWorkflowContent += '        pytest\n\n';
        }
        
        // Add Java setup if needed
        else if (config.language === 'java') {
          ciWorkflowContent += '    - name: Set up JDK\n';
          ciWorkflowContent += '      uses: actions/setup-java@v3\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        java-version: \'11\'\n';
          ciWorkflowContent += '        distribution: \'temurin\'\n';
          ciWorkflowContent += '        cache: maven\n\n';
          ciWorkflowContent += '    - name: Build with Maven\n';
          ciWorkflowContent += '      run: mvn -B package --file pom.xml\n\n';
          ciWorkflowContent += '    - name: Test\n';
          ciWorkflowContent += '      run: mvn test\n\n';
        }
        
        // Add Docker build step if needed
        if (config.containerization === 'docker') {
          ciWorkflowContent += '    - name: Build Docker image\n';
          ciWorkflowContent += '      run: docker build -t ${{ github.repository }}:${{ github.sha }} .\n\n';
        }

        // Write CI workflow file
        fs.writeFileSync(path.join(cicdDir, 'ci.yml'), ciWorkflowContent);

        // Create GitHub Actions workflow for CD
        let cdWorkflowContent = 'name: CD\n\n';
        cdWorkflowContent += 'on:\n';
        cdWorkflowContent += '  push:\n';
        cdWorkflowContent += '    branches: [ main ]\n';
        cdWorkflowContent += '    tags: [ \'v*\' ]\n\n';
        cdWorkflowContent += 'jobs:\n';
        cdWorkflowContent += '  deploy:\n';
        cdWorkflowContent += '    runs-on: ubuntu-latest\n';
        cdWorkflowContent += '    needs: build-and-test\n\n';
        cdWorkflowContent += '    steps:\n';
        cdWorkflowContent += '    - uses: actions/checkout@v3\n\n';
        
        // Add Docker build and push steps if needed
        if (config.containerization === 'docker') {
          cdWorkflowContent += '    - name: Login to DockerHub\n';
          cdWorkflowContent += '      uses: docker/login-action@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
          cdWorkflowContent += '        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n';
          cdWorkflowContent += '    - name: Build and push Docker image\n';
          cdWorkflowContent += '      uses: docker/build-push-action@v4\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        push: true\n';
          cdWorkflowContent += '        tags: ${{ secrets.DOCKERHUB_USERNAME }}/${{ github.repository }}:${{ github.sha }}\n\n';
        }
        
        // Add deployment steps based on infrastructure type
        if (config.infrastructureType === InfrastructureType.KUBERNETES) {
          cdWorkflowContent += '    - name: Set up kubectl\n';
          cdWorkflowContent += '      uses: azure/setup-kubectl@v3\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        version: \'latest\'\n\n';
          cdWorkflowContent += '    - name: Set up kubeconfig\n';
          cdWorkflowContent += '      uses: azure/k8s-set-context@v3\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        kubeconfig: ${{ secrets.KUBECONFIG }}\n\n';
          cdWorkflowContent += '    - name: Deploy to Kubernetes\n';
          cdWorkflowContent += '      run: |\n';
          cdWorkflowContent += '        kubectl apply -f k8s/\n';
          cdWorkflowContent += '        kubectl set image deployment/${{ github.repository }} ${{ github.repository }}=${{ secrets.DOCKERHUB_USERNAME }}/${{ github.repository }}:${{ github.sha }}\n\n';
        } else if (config.infrastructureType === InfrastructureType.AWS) {
          cdWorkflowContent += '    - name: Configure AWS credentials\n';
          cdWorkflowContent += '      uses: aws-actions/configure-aws-credentials@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
          cdWorkflowContent += '        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
          cdWorkflowContent += '        aws-region: ${{ secrets.AWS_REGION }}\n\n';
          cdWorkflowContent += '    - name: Deploy to AWS\n';
          cdWorkflowContent += '      run: |\n';
          cdWorkflowContent += '        aws s3 sync ./build s3://${{ secrets.AWS_S3_BUCKET }}/\n\n';
        } else if (config.infrastructureType === InfrastructureType.AZURE) {
          cdWorkflowContent += '    - name: Azure Login\n';
          cdWorkflowContent += '      uses: azure/login@v1\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n';
          cdWorkflowContent += '    - name: Deploy to Azure Web App\n';
          cdWorkflowContent += '      uses: azure/webapps-deploy@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        app-name: ${{ secrets.AZURE_WEBAPP_NAME }}\n';
          cdWorkflowContent += '        package: ./build\n\n';
        }

        // Write CD workflow file
        fs.writeFileSync(path.join(cicdDir, 'cd.yml'), cdWorkflowContent);

        // Create README.md for CI/CD
        let readmeContent = '# CI/CD Pipelines\n\n';
        readmeContent += 'Este directorio contiene los flujos de trabajo de CI/CD para el proyecto.\n\n';
        readmeContent += '## Flujos de Trabajo\n\n';
        readmeContent += '### CI (Integración Continua)\n\n';
        readmeContent += 'El flujo de trabajo de CI se ejecuta en cada push a las ramas `main` y `develop`, así como en cada pull request a estas ramas.\n\n';
        readmeContent += 'Pasos:\n';
        readmeContent += '1. Checkout del código\n';
        
        if (config.language === 'javascript' || config.language === 'typescript') {
          readmeContent += '2. Configuración de Node.js\n';
          readmeContent += '3. Instalación de dependencias\n';
          readmeContent += '4. Linting\n';
          readmeContent += '5. Build\n';
          readmeContent += '6. Tests\n';
        } else if (config.language === 'python') {
          readmeContent += '2. Configuración de Python\n';
          readmeContent += '3. Instalación de dependencias\n';
          readmeContent += '4. Linting con flake8\n';
          readmeContent += '5. Tests con pytest\n';
        } else if (config.language === 'java') {
          readmeContent += '2. Configuración de JDK\n';
          readmeContent += '3. Build con Maven\n';
          readmeContent += '4. Tests\n';
        }
        
        if (config.containerization === 'docker') {
          readmeContent += '7. Build de imagen Docker\n';
        }
        
        readmeContent += '\n### CD (Despliegue Continuo)\n\n';
        readmeContent += 'El flujo de trabajo de CD se ejecuta en cada push a la rama `main` y en cada tag que comience con `v`.\n\n';
        readmeContent += 'Pasos:\n';
        readmeContent += '1. Checkout del código\n';
        
        if (config.containerization === 'docker') {
          readmeContent += '2. Login a DockerHub\n';
          readmeContent += '3. Build y push de imagen Docker\n';
        }
        
        if (config.infrastructureType === InfrastructureType.KUBERNETES) {
          readmeContent += '4. Configuración de kubectl\n';
          readmeContent += '5. Configuración de kubeconfig\n';
          readmeContent += '6. Despliegue a Kubernetes\n';
        } else if (config.infrastructureType === InfrastructureType.AWS) {
          readmeContent += '4. Configuración de credenciales AWS\n';
          readmeContent += '5. Despliegue a AWS\n';
        } else if (config.infrastructureType === InfrastructureType.AZURE) {
          readmeContent += '4. Login a Azure\n';
          readmeContent += '5. Despliegue a Azure Web App\n';
        }
        
        readmeContent += '\n## Secretos Requeridos\n\n';
        readmeContent += 'Para que estos flujos de trabajo funcionen correctamente, necesitas configurar los siguientes secretos en tu repositorio de GitHub:\n\n';
        
        if (config.containerization === 'docker') {
          readmeContent += '- `DOCKERHUB_USERNAME`: Tu nombre de usuario de DockerHub\n';
          readmeContent += '- `DOCKERHUB_TOKEN`: Tu token de acceso a DockerHub\n';
        }
        
        if (config.infrastructureType === InfrastructureType.KUBERNETES) {
          readmeContent += '- `KUBECONFIG`: Tu archivo kubeconfig codificado en base64\n';
        } else if (config.infrastructureType === InfrastructureType.AWS) {
          readmeContent += '- `AWS_ACCESS_KEY_ID`: Tu ID de clave de acceso de AWS\n';
          readmeContent += '- `AWS_SECRET_ACCESS_KEY`: Tu clave de acceso secreta de AWS\n';
          readmeContent += '- `AWS_REGION`: La región de AWS donde desplegar\n';
          readmeContent += '- `AWS_S3_BUCKET`: El nombre del bucket S3 para desplegar\n';
        } else if (config.infrastructureType === InfrastructureType.AZURE) {
          readmeContent += '- `AZURE_CREDENTIALS`: Tus credenciales de Azure en formato JSON\n';
          readmeContent += '- `AZURE_WEBAPP_NAME`: El nombre de tu Azure Web App\n';
        }
        
        // Write README.md for CI/CD
        fs.writeFileSync(path.join(projectDir, '.github', 'README.md'), readmeContent);

        return cicdDir;
      } catch (error) {
        this.logger.error(`Error creating CI/CD files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates infrastructure as code files for the project
     * @param projectDir - The project directory
     * @param config - The infrastructure configuration
     * @returns The path to the infrastructure directory
     */
    private async createInfrastructureFiles(projectDir: string, config: any): Promise<string> {
      try {
        const infraDir = path.join(projectDir, 'infrastructure');
        if (!fs.existsSync(infraDir)) {
          fs.mkdirSync(infraDir, { recursive: true });
        }

        // Create infrastructure files based on the infrastructure type
        if (config.infrastructureType === InfrastructureType.KUBERNETES) {
          return this.createKubernetesFiles(infraDir, config);
        } else if (config.infrastructureType === InfrastructureType.AWS) {
          return this.createTerraformAWSFiles(infraDir, config);
        } else if (config.infrastructureType === InfrastructureType.AZURE) {
          return this.createTerraformAzureFiles(infraDir, config);
        } else if (config.infrastructureType === InfrastructureType.GCP) {
          return this.createTerraformGCPFiles(infraDir, config);
        } else {
          return this.createDockerComposeFiles(infraDir, config);
        }
      } catch (error) {
        this.logger.error(`Error creating infrastructure files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates Kubernetes manifest files
     * @param infraDir - The infrastructure directory
     * @param config - The infrastructure configuration
     * @returns The path to the Kubernetes directory
     */
    private async createKubernetesFiles(infraDir: string, config: any): Promise<string> {
      try {
        const k8sDir = path.join(infraDir, 'kubernetes');
        if (!fs.existsSync(k8sDir)) {
          fs.mkdirSync(k8sDir, { recursive: true });
        }

        // Create namespace.yaml
        let namespaceContent = 'apiVersion: v1\n';
        namespaceContent += 'kind: Namespace\n';
        namespaceContent += 'metadata:\n';
        namespaceContent += `  name: ${config.projectName.toLowerCase()}\n`;
        namespaceContent += '  labels:\n';
        namespaceContent += `    name: ${config.projectName.toLowerCase()}\n`;

        // Write namespace.yaml
        fs.writeFileSync(path.join(k8sDir, 'namespace.yaml'), namespaceContent);

        // Create deployment.yaml
        let deploymentContent = 'apiVersion: apps/v1\n';
        deploymentContent += 'kind: Deployment\n';
        deploymentContent += 'metadata:\n';
        deploymentContent += `  name: ${config.projectName.toLowerCase()}\n`;
        deploymentContent += `  namespace: ${config.projectName.toLowerCase()}\n`;
        deploymentContent += 'spec:\n';
        deploymentContent += '  replicas: 3\n';
        deploymentContent += '  selector:\n';
        deploymentContent += '    matchLabels:\n';
        deploymentContent += `      app: ${config.projectName.toLowerCase()}\n`;
        deploymentContent += '  template:\n';
        deploymentContent += '    metadata:\n';
        deploymentContent += '      labels:\n';
        deploymentContent += `        app: ${config.projectName.toLowerCase()}\n`;
        deploymentContent += '    spec:\n';
        deploymentContent += '      containers:\n';
        deploymentContent += `      - name: ${config.projectName.toLowerCase()}\n`;
        deploymentContent += `        image: ${config.dockerRegistry || 'docker.io'}/${config.dockerUsername || 'username'}/${config.projectName.toLowerCase()}:latest\n`;
        deploymentContent += '        ports:\n';
        deploymentContent += '        - containerPort: 80\n';
        deploymentContent += '        resources:\n';
        deploymentContent += '          limits:\n';
        deploymentContent += '            cpu: "500m"\n';
        deploymentContent += '            memory: "512Mi"\n';
        deploymentContent += '          requests:\n';
        deploymentContent += '            cpu: "100m"\n';
        deploymentContent += '            memory: "128Mi"\n';
        deploymentContent += '        env:\n';
        deploymentContent += '        - name: NODE_ENV\n';
        deploymentContent += '          value: "production"\n';
        deploymentContent += '        livenessProbe:\n';
        deploymentContent += '          httpGet:\n';
        deploymentContent += '            path: /health\n';
        deploymentContent += '            port: 80\n';
        deploymentContent += '          initialDelaySeconds: 30\n';
        deploymentContent += '          periodSeconds: 10\n';
        deploymentContent += '        readinessProbe:\n';
        deploymentContent += '          httpGet:\n';
        deploymentContent += '            path: /health\n';
        deploymentContent += '            port: 80\n';
        deploymentContent += '          initialDelaySeconds: 5\n';
        deploymentContent += '          periodSeconds: 5\n';

        // Write deployment.yaml
        fs.writeFileSync(path.join(k8sDir, 'deployment.yaml'), deploymentContent);

        // Create service.yaml
        let serviceContent = 'apiVersion: v1\n';
        serviceContent += 'kind: Service\n';
        serviceContent += 'metadata:\n';
        serviceContent += `  name: ${config.projectName.toLowerCase()}\n`;
        serviceContent += `  namespace: ${config.projectName.toLowerCase()}\n`;
        serviceContent += 'spec:\n';
        serviceContent += '  selector:\n';
        serviceContent += `    app: ${config.projectName.toLowerCase()}\n`;
        serviceContent += '  ports:\n';
        serviceContent += '  - port: 80\n';
        serviceContent += '    targetPort: 80\n';
        serviceContent += '  type: ClusterIP\n';

        // Write service.yaml
        fs.writeFileSync(path.join(k8sDir, 'service.yaml'), serviceContent);

        // Create ingress.yaml
        let ingressContent = 'apiVersion: networking.k8s.io/v1\n';
        ingressContent += 'kind: Ingress\n';
        ingressContent += 'metadata:\n';
        ingressContent += `  name: ${config.projectName.toLowerCase()}\n`;
        ingressContent += `  namespace: ${config.projectName.toLowerCase()}\n`;
        ingressContent += '  annotations:\n';
        ingressContent += '    kubernetes.io/ingress.class: "nginx"\n';
        ingressContent += '    cert-manager.io/cluster-issuer: "letsencrypt-prod"\n';
        ingressContent += 'spec:\n';
        ingressContent += '  tls:\n';
        ingressContent += '  - hosts:\n';
        ingressContent += `    - ${config.projectName.toLowerCase()}.example.com\n`;
        ingressContent += `    secretName: ${config.projectName.toLowerCase()}-tls\n`;
        ingressContent += '  rules:\n';
        ingressContent += `  - host: ${config.projectName.toLowerCase()}.example.com\n`;
        ingressContent += '    http:\n';
        ingressContent += '      paths:\n';
        ingressContent += '      - path: /\n';
        ingressContent += '        pathType: Prefix\n';
        ingressContent += '        backend:\n';
        ingressContent += '          service:\n';
        ingressContent += `            name: ${config.projectName.toLowerCase()}\n`;
        ingressContent += '            port:\n';
        ingressContent += '              number: 80\n';

        // Write ingress.yaml
        fs.writeFileSync(path.join(k8sDir, 'ingress.yaml'), ingressContent);

        // Create configmap.yaml
        let configMapContent = 'apiVersion: v1\n';
        configMapContent += 'kind: ConfigMap\n';
        configMapContent += 'metadata:\n';
        configMapContent += `  name: ${config.projectName.toLowerCase()}-config\n`;
        configMapContent += `  namespace: ${config.projectName.toLowerCase()}\n`;
        configMapContent += 'data:\n';
        configMapContent += '  config.json: |\n';
        configMapContent += '    {\n';
        configMapContent += '      "environment": "production",\n';
        configMapContent += '      "logLevel": "info",\n';
        configMapContent += '      "apiUrl": "https://api.example.com"\n';
        configMapContent += '    }\n';

        // Write configmap.yaml
        fs.writeFileSync(path.join(k8sDir, 'configmap.yaml'), configMapContent);

        // Create secret.yaml
        let secretContent = 'apiVersion: v1\n';
        secretContent += 'kind: Secret\n';
        secretContent += 'metadata:\n';
        secretContent += `  name: ${config.projectName.toLowerCase()}-secret\n`;
        secretContent += `  namespace: ${config.projectName.toLowerCase()}\n`;
        secretContent += 'type: Opaque\n';
        secretContent += 'data:\n';
        secretContent += '  # Base64 encoded secrets\n';
        secretContent += '  # Example: echo -n "password" | base64\n';
        secretContent += '  DB_PASSWORD: cGFzc3dvcmQ=\n';
        secretContent += '  API_KEY: c2VjcmV0LWFwaS1rZXk=\n';

        // Write secret.yaml
        fs.writeFileSync(path.join(k8sDir, 'secret.yaml'), secretContent);

        // Create hpa.yaml (Horizontal Pod Autoscaler)
        let hpaContent = 'apiVersion: autoscaling/v2\n';
        hpaContent += 'kind: HorizontalPodAutoscaler\n';
        hpaContent += 'metadata:\n';
        hpaContent += `  name: ${config.projectName.toLowerCase()}\n`;
        hpaContent += `  namespace: ${config.projectName.toLowerCase()}\n`;
        hpaContent += 'spec:\n';
        hpaContent += `  scaleTargetRef:\n`;
        hpaContent += '    apiVersion: apps/v1\n';
        hpaContent += '    kind: Deployment\n';
        hpaContent += `    name: ${config.projectName.toLowerCase()}\n`;
        hpaContent += '  minReplicas: 3\n';
        hpaContent += '  maxReplicas: 10\n';
        hpaContent += '  metrics:\n';
        hpaContent += '  - type: Resource\n';
        hpaContent += '    resource:\n';
        hpaContent += '      name: cpu\n';
        hpaContent += '      target:\n';
        hpaContent += '        type: Utilization\n';
        hpaContent += '        averageUtilization: 70\n';
        hpaContent += '  - type: Resource\n';
        hpaContent += '    resource:\n';
        hpaContent += '      name: memory\n';
        hpaContent += '      target:\n';
        hpaContent += '        type: Utilization\n';
        hpaContent += '        averageUtilization: 80\n';

        // Write hpa.yaml
        fs.writeFileSync(path.join(k8sDir, 'hpa.yaml'), hpaContent);

        // Create README.md for Kubernetes
        let readmeContent = '# Kubernetes Manifests\n\n';
        readmeContent += `Este directorio contiene los manifiestos de Kubernetes para desplegar ${config.projectName} en un clúster de Kubernetes.\n\n`;
        readmeContent += '## Archivos\n\n';
        readmeContent += '- `namespace.yaml`: Define el namespace para el proyecto\n';
        readmeContent += '- `deployment.yaml`: Define el deployment para la aplicación\n';
        readmeContent += '- `service.yaml`: Define el servicio para exponer la aplicación\n';
        readmeContent += '- `ingress.yaml`: Define el ingress para acceder a la aplicación desde el exterior\n';
        readmeContent += '- `configmap.yaml`: Define las configuraciones para la aplicación\n';
        readmeContent += '- `secret.yaml`: Define los secretos para la aplicación\n';
        readmeContent += '- `hpa.yaml`: Define el Horizontal Pod Autoscaler para escalar automáticamente la aplicación\n\n';
        readmeContent += '## Despliegue\n\n';
        readmeContent += 'Para desplegar la aplicación en Kubernetes, ejecuta:\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Crear el namespace\n';
        readmeContent += 'kubectl apply -f namespace.yaml\n\n';
        readmeContent += '# Crear los recursos\n';
        readmeContent += 'kubectl apply -f .\n';
        readmeContent += '```\n\n';
        readmeContent += '## Verificación\n\n';
        readmeContent += 'Para verificar el estado del despliegue, ejecuta:\n\n';
        readmeContent += '```bash\n';
        readmeContent += `kubectl get all -n ${config.projectName.toLowerCase()}\n`;
        readmeContent += '```\n\n';
        readmeContent += '## Acceso\n\n';
        readmeContent += `Una vez desplegado, puedes acceder a la aplicación a través de ${config.projectName.toLowerCase()}.example.com (asegúrate de configurar el DNS adecuadamente).\n`;

        // Write README.md for Kubernetes
        fs.writeFileSync(path.join(k8sDir, 'README.md'), readmeContent);

        return k8sDir;
      } catch (error) {
        this.logger.error(`Error creating Kubernetes files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates Terraform files for AWS
     * @param infraDir - The infrastructure directory
     * @param config - The infrastructure configuration
     * @returns The path to the Terraform directory
     */
    private async createTerraformAWSFiles(infraDir: string, config: any): Promise<string> {
      try {
        const terraformDir = path.join(infraDir, 'terraform-aws');
        if (!fs.existsSync(terraformDir)) {
          fs.mkdirSync(terraformDir, { recursive: true });
        }

        // Create main.tf
        let mainContent = 'provider "aws" {\n';
        mainContent += '  region = var.aws_region\n';
        mainContent += '}\n\n';
        mainContent += 'terraform {\n';
        mainContent += '  required_version = ">= 1.0.0"\n';
        mainContent += '  required_providers {\n';
        mainContent += '    aws = {\n';
        mainContent += '      source  = "hashicorp/aws"\n';
        mainContent += '      version = "~> 4.0"\n';
        mainContent += '    }\n';
        mainContent += '  }\n';
        mainContent += '  backend "s3" {\n';
        mainContent += '    bucket = "terraform-state-${var.project_name}"\n';
        mainContent += '    key    = "terraform.tfstate"\n';
        mainContent += '    region = var.aws_region\n';
        mainContent += '  }\n';
        mainContent += '}\n\n';
        mainContent += '# VPC\n';
        mainContent += 'module "vpc" {\n';
        mainContent += '  source = "terraform-aws-modules/vpc/aws"\n';
        mainContent += '  version = "3.14.0"\n\n';
        mainContent += '  name = "${var.project_name}-vpc"\n';
        mainContent += '  cidr = "10.0.0.0/16"\n\n';
        mainContent += '  azs             = ["${var.aws_region}a", "${var.aws_region}b", "${var.aws_region}c"]\n';
        mainContent += '  private_subnets = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]\n';
        mainContent += '  public_subnets  = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]\n\n';
        mainContent += '  enable_nat_gateway = true\n';
        mainContent += '  single_nat_gateway = true\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# Security Group\n';
        mainContent += 'resource "aws_security_group" "app_sg" {\n';
        mainContent += '  name        = "${var.project_name}-sg"\n';
        mainContent += '  description = "Security group for ${var.project_name}"\n';
        mainContent += '  vpc_id      = module.vpc.vpc_id\n\n';
        mainContent += '  ingress {\n';
        mainContent += '    from_port   = 80\n';
        mainContent += '    to_port     = 80\n';
        mainContent += '    protocol    = "tcp"\n';
        mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
        mainContent += '  }\n\n';
        mainContent += '  ingress {\n';
        mainContent += '    from_port   = 443\n';
        mainContent += '    to_port     = 443\n';
        mainContent += '    protocol    = "tcp"\n';
        mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
        mainContent += '  }\n\n';
        mainContent += '  egress {\n';
        mainContent += '    from_port   = 0\n';
        mainContent += '    to_port     = 0\n';
        mainContent += '    protocol    = "-1"\n';
        mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
        mainContent += '  }\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# ECR Repository\n';
        mainContent += 'resource "aws_ecr_repository" "app_repo" {\n';
        mainContent += '  name                 = var.project_name\n';
        mainContent += '  image_tag_mutability = "MUTABLE"\n\n';
        mainContent += '  image_scanning_configuration {\n';
        mainContent += '    scan_on_push = true\n';
        mainContent += '  }\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# ECS Cluster\n';
        mainContent += 'resource "aws_ecs_cluster" "app_cluster" {\n';
        mainContent += '  name = "${var.project_name}-cluster"\n\n';
        mainContent += '  setting {\n';
        mainContent += '    name  = "containerInsights"\n';
        mainContent += '    value = "enabled"\n';
        mainContent += '  }\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# ECS Task Definition\n';
        mainContent += 'resource "aws_ecs_task_definition" "app_task" {\n';
        mainContent += '  family                   = var.project_name\n';
        mainContent += '  network_mode             = "awsvpc"\n';
        mainContent += '  requires_compatibilities = ["FARGATE"]\n';
        mainContent += '  cpu                      = var.task_cpu\n';
        mainContent += '  memory                   = var.task_memory\n';
        mainContent += '  execution_role_arn       = aws_iam_role.ecs_execution_role.arn\n';
        mainContent += '  task_role_arn            = aws_iam_role.ecs_task_role.arn\n\n';
        mainContent += '  container_definitions = jsonencode([\n';
        mainContent += '    {\n';
        mainContent += '      name      = var.project_name\n';
        mainContent += '      image     = "${aws_ecr_repository.app_repo.repository_url}:latest"\n';
        mainContent += '      essential = true\n';
        mainContent += '      portMappings = [\n';
        mainContent += '        {\n';
        mainContent += '          containerPort = 80\n';
        mainContent += '          hostPort      = 80\n';
        mainContent += '          protocol      = "tcp"\n';
        mainContent += '        }\n';
        mainContent += '      ]\n';
        mainContent += '      environment = [\n';
        mainContent += '        {\n';
        mainContent += '          name  = "NODE_ENV"\n';
        mainContent += '          value = "production"\n';
        mainContent += '        }\n';
        mainContent += '      ]\n';
        mainContent += '      logConfiguration = {\n';
        mainContent += '        logDriver = "awslogs"\n';
        mainContent += '        options = {\n';
        mainContent += '          "awslogs-group"         = "/ecs/${var.project_name}"\n';
        mainContent += '          "awslogs-region"        = var.aws_region\n';
        mainContent += '          "awslogs-stream-prefix" = "ecs"\n';
        mainContent += '        }\n';
        mainContent += '      }\n';
        mainContent += '    }\n';
        mainContent += '  ])\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# ECS Service\n';
        mainContent += 'resource "aws_ecs_service" "app_service" {\n';
        mainContent += '  name            = "${var.project_name}-service"\n';
        mainContent += '  cluster         = aws_ecs_cluster.app_cluster.id\n';
        mainContent += '  task_definition = aws_ecs_task_definition.app_task.arn\n';
        mainContent += '  desired_count   = var.service_desired_count\n';
        mainContent += '  launch_type     = "FARGATE"\n\n';
        mainContent += '  network_configuration {\n';
        mainContent += '    security_groups  = [aws_security_group.app_sg.id]\n';
        mainContent += '    subnets          = module.vpc.private_subnets\n';
        mainContent += '    assign_public_ip = false\n';
        mainContent += '  }\n\n';
        mainContent += '  load_balancer {\n';
        mainContent += '    target_group_arn = aws_lb_target_group.app_tg.arn\n';
        mainContent += '    container_name   = var.project_name\n';
        mainContent += '    container_port   = 80\n';
        mainContent += '  }\n\n';
        mainContent += '  depends_on = [\n';
        mainContent += '    aws_lb_listener.app_listener,\n';
        mainContent += '  ]\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# Application Load Balancer\n';
        mainContent += 'resource "aws_lb" "app_lb" {\n';
        mainContent += '  name               = "${var.project_name}-alb"\n';
        mainContent += '  internal           = false\n';
        mainContent += '  load_balancer_type = "application"\n';
        mainContent += '  security_groups    = [aws_security_group.app_sg.id]\n';
        mainContent += '  subnets            = module.vpc.public_subnets\n\n';
        mainContent += '  enable_deletion_protection = false\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# Target Group\n';
        mainContent += 'resource "aws_lb_target_group" "app_tg" {\n';
        mainContent += '  name        = "${var.project_name}-tg"\n';
        mainContent += '  port        = 80\n';
        mainContent += '  protocol    = "HTTP"\n';
        mainContent += '  vpc_id      = module.vpc.vpc_id\n';
        mainContent += '  target_type = "ip"\n\n';
        mainContent += '  health_check {\n';
        mainContent += '    healthy_threshold   = 3\n';
        mainContent += '    unhealthy_threshold = 3\n';
        mainContent += '    timeout             = 5\n';
        mainContent += '    interval            = 30\n';
        mainContent += '    path                = "/health"\n';
        mainContent += '    port                = "traffic-port"\n';
        mainContent += '    matcher             = "200"\n';
        mainContent += '  }\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# Listener\n';
        mainContent += 'resource "aws_lb_listener" "app_listener" {\n';
        mainContent += '  load_balancer_arn = aws_lb.app_lb.arn\n';
        mainContent += '  port              = 80\n';
        mainContent += '  protocol          = "HTTP"\n\n';
        mainContent += '  default_action {\n';
        mainContent += '    type             = "forward"\n';
        mainContent += '    target_group_arn = aws_lb_target_group.app_tg.arn\n';
        mainContent += '  }\n';
        mainContent += '}\n\n';
        mainContent += '# CloudWatch Log Group\n';
        mainContent += 'resource "aws_cloudwatch_log_group" "app_logs" {\n';
        mainContent += '  name              = "/ecs/${var.project_name}"\n';
        mainContent += '  retention_in_days = 30\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# IAM Roles\n';
        mainContent += 'resource "aws_iam_role" "ecs_execution_role" {\n';
        mainContent += '  name = "${var.project_name}-ecs-execution-role"\n\n';
        mainContent += '  assume_role_policy = jsonencode({\n';
        mainContent += '    Version = "2012-10-17"\n';
        mainContent += '    Statement = [\n';
        mainContent += '      {\n';
        mainContent += '        Action = "sts:AssumeRole"\n';
        mainContent += '        Effect = "Allow"\n';
        mainContent += '        Principal = {\n';
        mainContent += '          Service = "ecs-tasks.amazonaws.com"\n';
        mainContent += '        }\n';
        mainContent += '      }\n';
        mainContent += '    ]\n';
        mainContent += '  })\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_iam_role_policy_attachment" "ecs_execution_role_policy" {\n';
        mainContent += '  role       = aws_iam_role.ecs_execution_role.name\n';
        mainContent += '  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_iam_role" "ecs_task_role" {\n';
        mainContent += '  name = "${var.project_name}-ecs-task-role"\n\n';
        mainContent += '  assume_role_policy = jsonencode({\n';
        mainContent += '    Version = "2012-10-17"\n';
        mainContent += '    Statement = [\n';
        mainContent += '      {\n';
        mainContent += '        Action = "sts:AssumeRole"\n';
        mainContent += '        Effect = "Allow"\n';
        mainContent += '        Principal = {\n';
        mainContent += '          Service = "ecs-tasks.amazonaws.com"\n';
        mainContent += '        }\n';
        mainContent += '      }\n';
        mainContent += '    ]\n';
        mainContent += '  })\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# Auto Scaling\n';
        mainContent += 'resource "aws_appautoscaling_target" "ecs_target" {\n';
        mainContent += '  max_capacity       = var.max_capacity\n';
        mainContent += '  min_capacity       = var.min_capacity\n';
        mainContent += '  resource_id        = "service/${aws_ecs_cluster.app_cluster.name}/${aws_ecs_service.app_service.name}"\n';
        mainContent += '  scalable_dimension = "ecs:service:DesiredCount"\n';
        mainContent += '  service_namespace  = "ecs"\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_appautoscaling_policy" "ecs_policy_cpu" {\n';
        mainContent += '  name               = "${var.project_name}-cpu-autoscaling"\n';
        mainContent += '  policy_type        = "TargetTrackingScaling"\n';
        mainContent += '  resource_id        = aws_appautoscaling_target.ecs_target.resource_id\n';
        mainContent += '  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension\n';
        mainContent += '  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace\n\n';
        mainContent += '  target_tracking_scaling_policy_configuration {\n';
        mainContent += '    predefined_metric_specification {\n';
        mainContent += '      predefined_metric_type = "ECSServiceAverageCPUUtilization"\n';
        mainContent += '    }\n';
        mainContent += '    target_value = 70\n';
        mainContent += '    scale_in_cooldown  = 300\n';
        mainContent += '    scale_out_cooldown = 300\n';
        mainContent += '  }\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_appautoscaling_policy" "ecs_policy_memory" {\n';
        mainContent += '  name               = "${var.project_name}-memory-autoscaling"\n';
        mainContent += '  policy_type        = "TargetTrackingScaling"\n';
        mainContent += '  resource_id        = aws_appautoscaling_target.ecs_target.resource_id\n';
        mainContent += '  scalable_dimension = aws_appautoscaling_target.ecs_target.scalable_dimension\n';
        mainContent += '  service_namespace  = aws_appautoscaling_target.ecs_target.service_namespace\n\n';
        mainContent += '  target_tracking_scaling_policy_configuration {\n';
        mainContent += '    predefined_metric_specification {\n';
        mainContent += '      predefined_metric_type = "ECSServiceAverageMemoryUtilization"\n';
        mainContent += '    }\n';
        mainContent += '    target_value = 80\n';
        mainContent += '    scale_in_cooldown  = 300\n';
        mainContent += '    scale_out_cooldown = 300\n';
        mainContent += '  }\n';
        mainContent += '}\n\n';
        mainContent += '# S3 Bucket for Static Assets\n';
        mainContent += 'resource "aws_s3_bucket" "static_assets" {\n';
        mainContent += '  bucket = "${var.project_name}-static-assets"\n';
        mainContent += '  tags   = var.tags\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_s3_bucket_ownership_controls" "static_assets" {\n';
        mainContent += '  bucket = aws_s3_bucket.static_assets.id\n';
        mainContent += '  rule {\n';
        mainContent += '    object_ownership = "BucketOwnerPreferred"\n';
        mainContent += '  }\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_s3_bucket_public_access_block" "static_assets" {\n';
        mainContent += '  bucket = aws_s3_bucket.static_assets.id\n';
        mainContent += '  block_public_acls       = false\n';
        mainContent += '  block_public_policy     = false\n';
        mainContent += '  ignore_public_acls      = false\n';
        mainContent += '  restrict_public_buckets = false\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_s3_bucket_acl" "static_assets" {\n';
        mainContent += '  depends_on = [\n';
        mainContent += '    aws_s3_bucket_ownership_controls.static_assets,\n';
        mainContent += '    aws_s3_bucket_public_access_block.static_assets,\n';
        mainContent += '  ]\n';
        mainContent += '  bucket = aws_s3_bucket.static_assets.id\n';
        mainContent += '  acl    = "public-read"\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_s3_bucket_website_configuration" "static_assets" {\n';
        mainContent += '  bucket = aws_s3_bucket.static_assets.id\n';
        mainContent += '  index_document {\n';
        mainContent += '    suffix = "index.html"\n';
        mainContent += '  }\n';
        mainContent += '  error_document {\n';
        mainContent += '    key = "error.html"\n';
        mainContent += '  }\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_s3_bucket_policy" "static_assets" {\n';
        mainContent += '  bucket = aws_s3_bucket.static_assets.id\n';
        mainContent += '  policy = jsonencode({\n';
        mainContent += '    Version = "2012-10-17"\n';
        mainContent += '    Statement = [\n';
        mainContent += '      {\n';
        mainContent += '        Sid       = "PublicReadGetObject"\n';
        mainContent += '        Effect    = "Allow"\n';
        mainContent += '        Principal = "*"\n';
        mainContent += '        Action    = "s3:GetObject"\n';
        mainContent += '        Resource  = "${aws_s3_bucket.static_assets.arn}/*"\n';
        mainContent += '      }\n';
        mainContent += '    ]\n';
        mainContent += '  })\n';
        mainContent += '}\n\n';
        mainContent += '# CloudFront Distribution\n';
        mainContent += 'resource "aws_cloudfront_distribution" "s3_distribution" {\n';
        mainContent += '  origin {\n';
        mainContent += '    domain_name = aws_s3_bucket.static_assets.bucket_regional_domain_name\n';
        mainContent += '    origin_id   = "S3-${aws_s3_bucket.static_assets.id}"\n';
        mainContent += '  }\n\n';
        mainContent += '  enabled             = true\n';
        mainContent += '  is_ipv6_enabled     = true\n';
        mainContent += '  comment             = "CloudFront distribution for ${var.project_name} static assets"\n';
        mainContent += '  default_root_object = "index.html"\n\n';
        mainContent += '  default_cache_behavior {\n';
        mainContent += '    allowed_methods  = ["GET", "HEAD", "OPTIONS"]\n';
        mainContent += '    cached_methods   = ["GET", "HEAD"]\n';
        mainContent += '    target_origin_id = "S3-${aws_s3_bucket.static_assets.id}"\n\n';
        mainContent += '    forwarded_values {\n';
        mainContent += '      query_string = false\n';
        mainContent += '      cookies {\n';
        mainContent += '        forward = "none"\n';
        mainContent += '      }\n';
        mainContent += '    }\n\n';
        mainContent += '    viewer_protocol_policy = "redirect-to-https"\n';
        mainContent += '    min_ttl                = 0\n';
        mainContent += '    default_ttl            = 3600\n';
        mainContent += '    max_ttl                = 86400\n';
        mainContent += '  }\n\n';
        mainContent += '  price_class = "PriceClass_100"\n\n';
        mainContent += '  restrictions {\n';
        mainContent += '    geo_restriction {\n';
        mainContent += '      restriction_type = "none"\n';
        mainContent += '    }\n';
        mainContent += '  }\n\n';
        mainContent += '  viewer_certificate {\n';
        mainContent += '    cloudfront_default_certificate = true\n';
        mainContent += '  }\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# RDS Database\n';
        mainContent += 'resource "aws_db_subnet_group" "db_subnet_group" {\n';
        mainContent += '  name       = "${var.project_name}-db-subnet-group"\n';
        mainContent += '  subnet_ids = module.vpc.private_subnets\n';
        mainContent += '  tags       = var.tags\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_security_group" "db_sg" {\n';
        mainContent += '  name        = "${var.project_name}-db-sg"\n';
        mainContent += '  description = "Security group for ${var.project_name} database"\n';
        mainContent += '  vpc_id      = module.vpc.vpc_id\n\n';
        mainContent += '  ingress {\n';
        mainContent += '    from_port       = 3306\n';
        mainContent += '    to_port         = 3306\n';
        mainContent += '    protocol        = "tcp"\n';
        mainContent += '    security_groups = [aws_security_group.app_sg.id]\n';
        mainContent += '  }\n\n';
        mainContent += '  egress {\n';
        mainContent += '    from_port   = 0\n';
        mainContent += '    to_port     = 0\n';
        mainContent += '    protocol    = "-1"\n';
        mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
        mainContent += '  }\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_db_instance" "db" {\n';
        mainContent += '  identifier             = "${var.project_name}-db"\n';
        mainContent += '  allocated_storage      = 20\n';
        mainContent += '  storage_type           = "gp2"\n';
        mainContent += '  engine                 = "mysql"\n';
        mainContent += '  engine_version         = "8.0"\n';
        mainContent += '  instance_class         = "db.t3.micro"\n';
        mainContent += '  db_name                = var.db_name\n';
        mainContent += '  username               = var.db_username\n';
        mainContent += '  password               = var.db_password\n';
        mainContent += '  parameter_group_name   = "default.mysql8.0"\n';
        mainContent += '  db_subnet_group_name   = aws_db_subnet_group.db_subnet_group.name\n';
        mainContent += '  vpc_security_group_ids = [aws_security_group.db_sg.id]\n';
        mainContent += '  skip_final_snapshot    = true\n';
        mainContent += '  tags                   = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# ElastiCache Redis\n';
        mainContent += 'resource "aws_elasticache_subnet_group" "redis_subnet_group" {\n';
        mainContent += '  name       = "${var.project_name}-redis-subnet-group"\n';
        mainContent += '  subnet_ids = module.vpc.private_subnets\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_security_group" "redis_sg" {\n';
        mainContent += '  name        = "${var.project_name}-redis-sg"\n';
        mainContent += '  description = "Security group for ${var.project_name} Redis"\n';
        mainContent += '  vpc_id      = module.vpc.vpc_id\n\n';
        mainContent += '  ingress {\n';
        mainContent += '    from_port       = 6379\n';
        mainContent += '    to_port         = 6379\n';
        mainContent += '    protocol        = "tcp"\n';
        mainContent += '    security_groups = [aws_security_group.app_sg.id]\n';
        mainContent += '  }\n\n';
        mainContent += '  egress {\n';
        mainContent += '    from_port   = 0\n';
        mainContent += '    to_port     = 0\n';
        mainContent += '    protocol    = "-1"\n';
        mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
        mainContent += '  }\n\n';
        mainContent += '  tags = var.tags\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_elasticache_cluster" "redis" {\n';
        mainContent += '  cluster_id           = "${var.project_name}-redis"\n';
        mainContent += '  engine               = "redis"\n';
        mainContent += '  node_type            = "cache.t3.micro"\n';
        mainContent += '  num_cache_nodes      = 1\n';
        mainContent += '  parameter_group_name = "default.redis6.x"\n';
        mainContent += '  engine_version       = "6.x"\n';
        mainContent += '  port                 = 6379\n';
        mainContent += '  subnet_group_name    = aws_elasticache_subnet_group.redis_subnet_group.name\n';
        mainContent += '  security_group_ids   = [aws_security_group.redis_sg.id]\n';
        mainContent += '  tags                 = var.tags\n';
        mainContent += '}\n\n';
        mainContent += '# Route53 DNS\n';
        mainContent += 'resource "aws_route53_zone" "main" {\n';
        mainContent += '  count = var.create_route53_zone ? 1 : 0\n';
        mainContent += '  name  = var.domain_name\n';
        mainContent += '  tags  = var.tags\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_route53_record" "api" {\n';
        mainContent += '  count   = var.create_route53_zone ? 1 : 0\n';
        mainContent += '  zone_id = aws_route53_zone.main[0].zone_id\n';
        mainContent += '  name    = "api.${var.domain_name}"\n';
        mainContent += '  type    = "A"\n\n';
        mainContent += '  alias {\n';
        mainContent += '    name                   = aws_lb.app_lb.dns_name\n';
        mainContent += '    zone_id                = aws_lb.app_lb.zone_id\n';
        mainContent += '    evaluate_target_health = true\n';
        mainContent += '  }\n';
        mainContent += '}\n\n';
        mainContent += 'resource "aws_route53_record" "www" {\n';
        mainContent += '  count   = var.create_route53_zone ? 1 : 0\n';
        mainContent += '  zone_id = aws_route53_zone.main[0].zone_id\n';
        mainContent += '  name    = "www.${var.domain_name}"\n';
        mainContent += '  type    = "A"\n\n';
        mainContent += '  alias {\n';
        mainContent += '    name                   = aws_cloudfront_distribution.s3_distribution.domain_name\n';
        mainContent += '    zone_id                = aws_cloudfront_distribution.s3_distribution.hosted_zone_id\n';
        mainContent += '    evaluate_target_health = false\n';
        mainContent += '  }\n';
        mainContent += '}\n\n';
        mainContent += '# Outputs\n';
        mainContent += 'output "alb_dns_name" {\n';
        mainContent += '  description = "The DNS name of the load balancer"\n';
        mainContent += '  value       = aws_lb.app_lb.dns_name\n';
        mainContent += '}\n\n';
        mainContent += 'output "ecr_repository_url" {\n';
        mainContent += '  description = "The URL of the ECR repository"\n';
        mainContent += '  value       = aws_ecr_repository.app_repo.repository_url\n';
        mainContent += '}\n\n';
        mainContent += 'output "cloudfront_domain_name" {\n';
        mainContent += '  description = "The domain name of the CloudFront distribution"\n';
        mainContent += '  value       = aws_cloudfront_distribution.s3_distribution.domain_name\n';
        mainContent += '}\n\n';
        mainContent += 'output "db_endpoint" {\n';
        mainContent += '  description = "The endpoint of the database"\n';
        mainContent += '  value       = aws_db_instance.db.endpoint\n';
        mainContent += '  sensitive   = true\n';
        mainContent += '}\n\n';
        mainContent += 'output "redis_endpoint" {\n';
        mainContent += '  description = "The endpoint of the Redis cluster"\n';
        mainContent += '  value       = aws_elasticache_cluster.redis.cache_nodes.0.address\n';
        mainContent += '  sensitive   = true\n';
        mainContent += '}\n';

        // Write main.tf
        fs.writeFileSync(path.join(terraformDir, 'main.tf'), mainContent);

        // Create variables.tf
        let variablesContent = 'variable "aws_region" {\n';
        variablesContent += '  description = "The AWS region to deploy to"\n';
        variablesContent += '  type        = string\n';
        variablesContent += '  default     = "us-east-1"\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "project_name" {\n';
        variablesContent += '  description = "The name of the project"\n';
        variablesContent += '  type        = string\n';
        variablesContent += `  default     = "${config.projectName.toLowerCase()}"\n`;
        variablesContent += '}\n\n';
        variablesContent += 'variable "task_cpu" {\n';
        variablesContent += '  description = "The CPU units for the task"\n';
        variablesContent += '  type        = number\n';
        variablesContent += '  default     = 256\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "task_memory" {\n';
        variablesContent += '  description = "The memory for the task in MiB"\n';
        variablesContent += '  type        = number\n';
        variablesContent += '  default     = 512\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "service_desired_count" {\n';
        variablesContent += '  description = "The desired number of tasks for the service"\n';
        variablesContent += '  type        = number\n';
        variablesContent += '  default     = 3\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "min_capacity" {\n';
        variablesContent += '  description = "The minimum capacity for auto scaling"\n';
        variablesContent += '  type        = number\n';
        variablesContent += '  default     = 3\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "max_capacity" {\n';
        variablesContent += '  description = "The maximum capacity for auto scaling"\n';
        variablesContent += '  type        = number\n';
        variablesContent += '  default     = 10\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "db_name" {\n';
        variablesContent += '  description = "The name of the database"\n';
        variablesContent += '  type        = string\n';
        variablesContent += `  default     = "${config.projectName.toLowerCase().replace(/-/g, '_')}"\n`;
        variablesContent += '}\n\n';
        variablesContent += 'variable "db_username" {\n';
        variablesContent += '  description = "The username for the database"\n';
        variablesContent += '  type        = string\n';
        variablesContent += '  default     = "admin"\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "db_password" {\n';
        variablesContent += '  description = "The password for the database"\n';
        variablesContent += '  type        = string\n';
        variablesContent += '  sensitive   = true\n';
        variablesContent += '  default     = "changeme"\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "domain_name" {\n';
        variablesContent += '  description = "The domain name for the application"\n';
        variablesContent += '  type        = string\n';
        variablesContent += `  default     = "${config.projectName.toLowerCase()}.com"\n`;
        variablesContent += '}\n\n';
        variablesContent += 'variable "create_route53_zone" {\n';
        variablesContent += '  description = "Whether to create a Route53 zone"\n';
        variablesContent += '  type        = bool\n';
        variablesContent += '  default     = false\n';
        variablesContent += '}\n\n';
        variablesContent += 'variable "tags" {\n';
        variablesContent += '  description = "Tags to apply to resources"\n';
        variablesContent += '  type        = map(string)\n';
        variablesContent += '  default     = {\n';
        variablesContent += `    Project     = "${config.projectName}"\n`;
        variablesContent += '    Environment = "production"\n';
        variablesContent += '    Terraform   = "true"\n';
        variablesContent += '  }\n';
        variablesContent += '}\n';

        // Write variables.tf
        fs.writeFileSync(path.join(terraformDir, 'variables.tf'), variablesContent);

        // Create terraform.tfvars
        let tfvarsContent = 'aws_region = "us-east-1"\n';
        tfvarsContent += `project_name = "${config.projectName.toLowerCase()}"\n`;
        tfvarsContent += 'task_cpu = 256\n';
        tfvarsContent += 'task_memory = 512\n';
        tfvarsContent += 'service_desired_count = 3\n';
        tfvarsContent += 'min_capacity = 3\n';
        tfvarsContent += 'max_capacity = 10\n';
        tfvarsContent += `db_name = "${config.projectName.toLowerCase().replace(/-/g, '_')}"\n`;
        tfvarsContent += 'db_username = "admin"\n';
        tfvarsContent += '# db_password = "changeme" # Set this in a secure way, not in version control\n';
        tfvarsContent += `domain_name = "${config.projectName.toLowerCase()}.com"\n`;
        tfvarsContent += 'create_route53_zone = false\n';
        tfvarsContent += 'tags = {\n';
        tfvarsContent += `  Project     = "${config.projectName}"\n`;
        tfvarsContent += '  Environment = "production"\n';
        tfvarsContent += '  Terraform   = "true"\n';
        tfvarsContent += '}\n';

        // Write terraform.tfvars
        fs.writeFileSync(path.join(terraformDir, 'terraform.tfvars'), tfvarsContent);

        // Create outputs.tf
        let outputsContent = 'output "vpc_id" {\n';
        outputsContent += '  description = "The ID of the VPC"\n';
        outputsContent += '  value       = module.vpc.vpc_id\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "private_subnets" {\n';
        outputsContent += '  description = "List of IDs of private subnets"\n';
        outputsContent += '  value       = module.vpc.private_subnets\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "public_subnets" {\n';
        outputsContent += '  description = "List of IDs of public subnets"\n';
        outputsContent += '  value       = module.vpc.public_subnets\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "alb_dns_name" {\n';
        outputsContent += '  description = "The DNS name of the load balancer"\n';
        outputsContent += '  value       = aws_lb.app_lb.dns_name\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "ecr_repository_url" {\n';
        outputsContent += '  description = "The URL of the ECR repository"\n';
        outputsContent += '  value       = aws_ecr_repository.app_repo.repository_url\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "cloudfront_domain_name" {\n';
        outputsContent += '  description = "The domain name of the CloudFront distribution"\n';
        outputsContent += '  value       = aws_cloudfront_distribution.s3_distribution.domain_name\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "s3_bucket_name" {\n';
        outputsContent += '  description = "The name of the S3 bucket for static assets"\n';
        outputsContent += '  value       = aws_s3_bucket.static_assets.id\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "s3_website_endpoint" {\n';
        outputsContent += '  description = "The website endpoint of the S3 bucket"\n';
        outputsContent += '  value       = aws_s3_bucket_website_configuration.static_assets.website_endpoint\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "db_endpoint" {\n';
        outputsContent += '  description = "The endpoint of the database"\n';
        outputsContent += '  value       = aws_db_instance.db.endpoint\n';
        outputsContent += '  sensitive   = true\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "redis_endpoint" {\n';
        outputsContent += '  description = "The endpoint of the Redis cluster"\n';
        outputsContent += '  value       = aws_elasticache_cluster.redis.cache_nodes.0.address\n';
        outputsContent += '  sensitive   = true\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "ecs_cluster_name" {\n';
        outputsContent += '  description = "The name of the ECS cluster"\n';
        outputsContent += '  value       = aws_ecs_cluster.app_cluster.name\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "ecs_service_name" {\n';
        outputsContent += '  description = "The name of the ECS service"\n';
        outputsContent += '  value       = aws_ecs_service.app_service.name\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "route53_zone_id" {\n';
        outputsContent += '  description = "The ID of the Route53 zone"\n';
        outputsContent += '  value       = var.create_route53_zone ? aws_route53_zone.main[0].zone_id : "Route53 zone not created"\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "api_url" {\n';
        outputsContent += '  description = "The URL for the API"\n';
        outputsContent += '  value       = var.create_route53_zone ? "https://api.${var.domain_name}" : aws_lb.app_lb.dns_name\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "website_url" {\n';
        outputsContent += '  description = "The URL for the website"\n';
        outputsContent += '  value       = var.create_route53_zone ? "https://www.${var.domain_name}" : aws_cloudfront_distribution.s3_distribution.domain_name\n';
        outputsContent += '  description = "The endpoint of the Redis cluster"\n';
        outputsContent += '  value       = aws_elasticache_cluster.redis.cache_nodes.0.address\n';
        outputsContent += '  sensitive   = true\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "ecs_cluster_name" {\n';
        outputsContent += '  description = "The name of the ECS cluster"\n';
        outputsContent += '  value       = aws_ecs_cluster.app_cluster.name\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "ecs_service_name" {\n';
        outputsContent += '  description = "The name of the ECS service"\n';
        outputsContent += '  value       = aws_ecs_service.app_service.name\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "route53_zone_id" {\n';
        outputsContent += '  description = "The ID of the Route53 zone"\n';
        outputsContent += '  value       = var.create_route53_zone ? aws_route53_zone.main[0].zone_id : "Route53 zone not created"\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "api_url" {\n';
        outputsContent += '  description = "The URL for the API"\n';
        outputsContent += '  value       = var.create_route53_zone ? "https://api.${var.domain_name}" : aws_lb.app_lb.dns_name\n';
        outputsContent += '}\n\n';
        outputsContent += 'output "website_url" {\n';
        outputsContent += '  description = "The URL for the website"\n';
        outputsContent += '  value       = var.create_route53_zone ? "https://www.${var.domain_name}" : aws_cloudfront_distribution.s3_distribution.domain_name\n';
        outputsContent += '}\n';

        // Write outputs.tf
        fs.writeFileSync(path.join(terraformDir, 'outputs.tf'), outputsContent);

        // Create README.md
        let readmeContent = `# ${config.projectName} Infrastructure\n\n`;
        readmeContent += 'Este directorio contiene la configuración de Terraform para desplegar la infraestructura del proyecto en AWS.\n\n';
        readmeContent += '## Componentes\n\n';
        readmeContent += '- **VPC**: Red virtual con subredes públicas y privadas\n';
        readmeContent += '- **ECS**: Clúster y servicio para ejecutar la aplicación en contenedores\n';
        readmeContent += '- **ECR**: Repositorio para almacenar imágenes de Docker\n';
        readmeContent += '- **ALB**: Balanceador de carga para distribuir el tráfico\n';
        readmeContent += '- **S3**: Bucket para almacenar activos estáticos\n';
        readmeContent += '- **CloudFront**: CDN para distribuir activos estáticos\n';
        readmeContent += '- **RDS**: Base de datos MySQL\n';
        readmeContent += '- **ElastiCache**: Clúster Redis para caché\n';
        readmeContent += '- **Route53**: Configuración DNS (opcional)\n\n';
        readmeContent += '## Requisitos\n\n';
        readmeContent += '- Terraform v1.0.0 o superior\n';
        readmeContent += '- AWS CLI configurado con credenciales\n\n';
        readmeContent += '## Uso\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Inicializar Terraform\n';
        readmeContent += 'terraform init\n\n';
        readmeContent += '# Ver los cambios que se aplicarán\n';
        readmeContent += 'terraform plan\n\n';
        readmeContent += '# Aplicar los cambios\n';
        readmeContent += 'terraform apply\n\n';
        readmeContent += '# Destruir la infraestructura\n';
        readmeContent += 'terraform destroy\n';
        readmeContent += '```\n\n';
        readmeContent += '## Variables\n\n';
        readmeContent += 'Las variables se definen en `variables.tf` y se pueden configurar en `terraform.tfvars`.\n\n';
        readmeContent += '### Variables importantes\n\n';
        readmeContent += '- `aws_region`: Región de AWS (default: "us-east-1")\n';
        readmeContent += `- \`project_name\`: Nombre del proyecto (default: "${config.projectName.toLowerCase()}")\n`;
        readmeContent += '- `db_username`: Usuario de la base de datos (default: "admin")\n';
        readmeContent += '- `db_password`: Contraseña de la base de datos (sensible, no incluir en control de versiones)\n';
        readmeContent += `- \`domain_name\`: Nombre de dominio (default: "${config.projectName.toLowerCase()}.com")\n`;
        readmeContent += '- `create_route53_zone`: Si se debe crear una zona en Route53 (default: false)\n\n';
        readmeContent += '## Outputs\n\n';
        readmeContent += 'Después de aplicar la configuración, Terraform mostrará varios outputs:\n\n';
        readmeContent += '- `alb_dns_name`: Nombre DNS del balanceador de carga\n';
        readmeContent += '- `ecr_repository_url`: URL del repositorio ECR\n';
        readmeContent += '- `cloudfront_domain_name`: Nombre de dominio de la distribución CloudFront\n';
        readmeContent += '- `s3_bucket_name`: Nombre del bucket S3\n';
        readmeContent += '- `db_endpoint`: Endpoint de la base de datos (sensible)\n';
        readmeContent += '- `redis_endpoint`: Endpoint del clúster Redis (sensible)\n';
        readmeContent += '- `api_url`: URL para la API\n';
        readmeContent += '- `website_url`: URL para el sitio web\n\n';
        readmeContent += '## Notas\n\n';
        readmeContent += '- La contraseña de la base de datos debe configurarse de forma segura, preferiblemente usando variables de entorno o AWS Secrets Manager.\n';
        readmeContent += '- Si `create_route53_zone` es `true`, se creará una zona en Route53 para el dominio especificado. Asegúrate de actualizar los servidores de nombres en tu registrador de dominios.\n';
        readmeContent += '- Para un entorno de producción, considera habilitar el cifrado en reposo para S3, RDS y ElastiCache.\n';

        // Write README.md
        fs.writeFileSync(path.join(terraformDir, 'README.md'), readmeContent);

        // Create .gitignore
        let gitignoreContent = '# Local .terraform directories\n';
        gitignoreContent += '**/.terraform/*\n\n';
        gitignoreContent += '# .tfstate files\n';
        gitignoreContent += '*.tfstate\n';
        gitignoreContent += '*.tfstate.*\n\n';
        gitignoreContent += '# Crash log files\n';
        gitignoreContent += 'crash.log\n\n';
        gitignoreContent += '# Exclude all .tfvars files, which are likely to contain sensitive data\n';
        gitignoreContent += '*.tfvars\n';
        gitignoreContent += '*.tfvars.json\n\n';
        gitignoreContent += '# Ignore override files as they are usually used for local dev\n';
        gitignoreContent += 'override.tf\n';
        gitignoreContent += 'override.tf.json\n';
        gitignoreContent += '*_override.tf\n';
        gitignoreContent += '*_override.tf.json\n\n';
        gitignoreContent += '# Ignore CLI configuration files\n';
        gitignoreContent += '.terraformrc\n';
        gitignoreContent += 'terraform.rc\n';
        gitignoreContent += '.terraform.lock.hcl\n';

        // Write .gitignore
        fs.writeFileSync(path.join(terraformDir, '.gitignore'), gitignoreContent);

        return terraformDir;
      } catch (error) {
        this.logger.error(`Error creating Terraform files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Crea archivos de configuración para monitoreo
     * @param config Configuración de monitoreo
     * @param projectDir Directorio del proyecto
     * @returns Directorio de monitoreo
     */
    private async createMonitoringFiles(config: MonitoringConfig, projectDir: string): Promise<string> {
      try {
        const monitoringDir = path.join(projectDir, 'monitoring');
        if (!fs.existsSync(monitoringDir)) {
          fs.mkdirSync(monitoringDir, { recursive: true });
        }

        // Create Prometheus configuration
        const prometheusDir = path.join(monitoringDir, 'prometheus');
        if (!fs.existsSync(prometheusDir)) {
          fs.mkdirSync(prometheusDir, { recursive: true });
        }

        // Create prometheus.yml
        let prometheusContent = 'global:\n';
        prometheusContent += '  scrape_interval: 15s\n';
        prometheusContent += '  evaluation_interval: 15s\n\n';
        prometheusContent += 'alerting:\n';
        prometheusContent += '  alertmanagers:\n';
        prometheusContent += '  - static_configs:\n';
        prometheusContent += '    - targets:\n';
        prometheusContent += '      - alertmanager:9093\n\n';
        prometheusContent += 'rule_files:\n';
        prometheusContent += '  - "alert_rules.yml"\n\n';
        prometheusContent += 'scrape_configs:\n';
        prometheusContent += '  - job_name: "prometheus"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '    - targets: ["localhost:9090"]\n\n';
        prometheusContent += '  - job_name: "node"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '    - targets: ["node-exporter:9100"]\n\n';
        prometheusContent += '  - job_name: "cadvisor"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '    - targets: ["cadvisor:8080"]\n\n';

        // Add application-specific targets
        if (config.targets && config.targets.length > 0) {
          config.targets.forEach(target => {
            prometheusContent += `  - job_name: "${target.name}"\n`;
            prometheusContent += '    static_configs:\n';
            prometheusContent += '    - targets: [';
            target.endpoints.forEach((endpoint, index) => {
              prometheusContent += `"${endpoint}"${index < target.endpoints.length - 1 ? ', ' : ''}`;
            });
            prometheusContent += ']\n\n';
          });
        }

        // Write prometheus.yml
        fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);

        // Create alert_rules.yml
        let alertRulesContent = 'groups:\n';
        alertRulesContent += '- name: example\n';
        alertRulesContent += '  rules:\n';
        alertRulesContent += '  - alert: HighCPULoad\n';
        alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High CPU load (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "CPU load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
        alertRulesContent += '  - alert: HighMemoryLoad\n';
        alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 > 80\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High memory load (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "Memory load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
        alertRulesContent += '  - alert: HighDiskUsage\n';
        alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High disk usage (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "Disk usage is > 85%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n';

        // Write alert_rules.yml
        fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);

        // Create Alertmanager configuration
        const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
        if (!fs.existsSync(alertmanagerDir)) {
          fs.mkdirSync(alertmanagerDir, { recursive: true });
        }

        // Create alertmanager.yml
        let alertmanagerContent = 'global:\n';
        alertmanagerContent += '  resolve_timeout: 5m\n';
        alertmanagerContent += '  smtp_smarthost: "smtp.example.com:587"\n';
        alertmanagerContent += '  smtp_from: "alertmanager@example.com"\n';
        alertmanagerContent += '  smtp_auth_username: "alertmanager"\n';
        alertmanagerContent += '  smtp_auth_password: "password"\n\n';
        alertmanagerContent += 'route:\n';
        alertmanagerContent += '  group_by: [\'alertname\', \'instance\']\n';
        alertmanagerContent += '  group_wait: 30s\n';
        alertmanagerContent += '  group_interval: 5m\n';
        alertmanagerContent += '  repeat_interval: 1h\n';
        alertmanagerContent += '  receiver: \'email\'\n\n';
        alertmanagerContent += 'receivers:\n';
        alertmanagerContent += '- name: \'email\'\n';
        alertmanagerContent += '  email_configs:\n';
        alertmanagerContent += '  - to: "alerts@example.com"\n';
        alertmanagerContent += '    send_resolved: true\n\n';
        alertmanagerContent += 'inhibit_rules:\n';
        alertmanagerContent += '  - source_match:\n';
        alertmanagerContent += '      severity: \'critical\'\n';
        alertmanagerContent += '    target_match:\n';
        alertmanagerContent += '      severity: \'warning\'\n';
        alertmanagerContent += '    equal: [\'alertname\', \'instance\']\n';

        // Write alertmanager.yml
        fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);

        // Create Grafana configuration
        const grafanaDir = path.join(monitoringDir, 'grafana');
        if (!fs.existsSync(grafanaDir)) {
          fs.mkdirSync(grafanaDir, { recursive: true });
        }

        // Create datasources.yml
        let datasourcesContent = 'apiVersion: 1\n\n';
        datasourcesContent += 'datasources:\n';
        datasourcesContent += '  - name: Prometheus\n';
        datasourcesContent += '    type: prometheus\n';
        datasourcesContent += '    access: proxy\n';
        datasourcesContent += '    url: http://prometheus:9090\n';
        datasourcesContent += '    isDefault: true\n';
        datasourcesContent += '    editable: true\n';

        // Write datasources.yml
        fs.writeFileSync(path.join(grafanaDir, 'datasources.yml'), datasourcesContent);

        // Create dashboards directory
        const dashboardsDir = path.join(grafanaDir, 'dashboards');
        if (!fs.existsSync(dashboardsDir)) {
          fs.mkdirSync(dashboardsDir, { recursive: true });
        }

        // Create dashboard.json (simplified version)
        let dashboardContent = '{\n';
        dashboardContent += '  "annotations": {\n';
        dashboardContent += '    "list": [\n';
        dashboardContent += '      {\n';
        dashboardContent += '        "builtIn": 1,\n';
        dashboardContent += '        "datasource": "-- Grafana --",\n';
        dashboardContent += '        "enable": true,\n';
        dashboardContent += '        "hide": true,\n';
        dashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
        dashboardContent += '        "name": "Annotations & Alerts",\n';
        dashboardContent += '        "type": "dashboard"\n';
        dashboardContent += '      }\n';
        dashboardContent += '    ]\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "editable": true,\n';
        dashboardContent += '  "gnetId": null,\n';
        dashboardContent += '  "graphTooltip": 0,\n';
        dashboardContent += '  "id": 1,\n';
        dashboardContent += '  "links": [],\n';
        dashboardContent += '  "panels": [\n';
        dashboardContent += '    {\n';
        dashboardContent += '      "alert": {\n';
        dashboardContent += '        "conditions": [\n';
        dashboardContent += '          {\n';
        dashboardContent += '            "evaluator": {\n';
        dashboardContent += '              "params": [\n';
        dashboardContent += '                80\n';
        dashboardContent += '              ],\n';
        dashboardContent += '              "type": "gt"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "operator": {\n';
        dashboardContent += '              "type": "and"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "query": {\n';
        dashboardContent += '              "params": [\n';
        dashboardContent += '                "A",\n';
        dashboardContent += '                "5m",\n';
        dashboardContent += '                "now"\n';
        dashboardContent += '              ]\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "reducer": {\n';
        dashboardContent += '              "params": [],\n';
        dashboardContent += '              "type": "avg"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "type": "query"\n';
        dashboardContent += '          }\n';
        dashboardContent += '        ],\n';
        dashboardContent += '        "executionErrorState": "alerting",\n';
        dashboardContent += '        "frequency": "60s",\n';
        dashboardContent += '        "handler": 1,\n';
        dashboardContent += '        "name": "CPU Usage alert",\n';
        dashboardContent += '        "noDataState": "no_data",\n';
        dashboardContent += '        "notifications": []\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "aliasColors": {},\n';
        dashboardContent += '      "bars": false,\n';
        dashboardContent += '      "dashLength": 10,\n';
        dashboardContent += '      "dashes": false,\n';
        dashboardContent += '      "datasource": "Prometheus",\n';
        dashboardContent += '      "fieldConfig": {\n';
        dashboardContent += '        "defaults": {\n';
        dashboardContent += '          "custom": {}\n';
        dashboardContent += '        },\n';
        dashboardContent += '        "overrides": []\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "fill": 1,\n';
        dashboardContent += '      "fillGradient": 0,\n';
        dashboardContent += '      "gridPos": {\n';
        dashboardContent += '        "h": 9,\n';
        dashboardContent += '        "w": 12,\n';
        dashboardContent += '        "x": 0,\n';
        dashboardContent += '        "y": 0\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "hiddenSeries": false,\n';
        dashboardContent += '      "id": 2,\n';
        dashboardContent += '      "legend": {\n';
        dashboardContent += '        "avg": false,\n';
        dashboardContent += '        "current": false,\n';
        dashboardContent += '        "max": false,\n';
        dashboardContent += '        "min": false,\n';
        dashboardContent += '        "show": true,\n';
        dashboardContent += '        "total": false,\n';
        dashboardContent += '        "values": false\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "lines": true,\n';
        dashboardContent += '      "linewidth": 1,\n';
        dashboardContent += '      "nullPointMode": "null",\n';
        dashboardContent += '      "options": {\n';
        dashboardContent += '        "alertThreshold": true\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "percentage": false,\n';
        dashboardContent += '      "pluginVersion": "7.3.7",\n';
        dashboardContent += '      "pointradius": 2,\n';
        dashboardContent += '      "points": false,\n';
        dashboardContent += '      "renderer": "flot",\n';
        dashboardContent += '      "seriesOverrides": [],\n';
        dashboardContent += '      "spaceLength": 10,\n';
        dashboardContent += '      "stack": false,\n';
        dashboardContent += '      "steppedLine": false,\n';
        dashboardContent += '      "targets": [\n';
        dashboardContent += '        {\n';
        dashboardContent += '          "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\\"idle\\"}[5m])) * 100)",\n';
        dashboardContent += '          "interval": "",\n';
        dashboardContent += '          "legendFormat": "",\n';
        dashboardContent += '          "refId": "A"\n';
        dashboardContent += '        }\n';
        dashboardContent += '      ],\n';
        dashboardContent += '      "thresholds": [\n';
        dashboardContent += '        {\n';
        dashboardContent += '          "colorMode": "critical",\n';
        dashboardContent += '          "fill": true,\n';
        dashboardContent += '          "line": true,\n';
        dashboardContent += '          "op": "gt",\n';
        dashboardContent += '          "value": 80\n';
        dashboardContent += '        }\n';
        dashboardContent += '      ],\n';
        dashboardContent += '      "timeFrom": null,\n';
        dashboardContent += '      "timeRegions": [],\n';
        dashboardContent += '      "timeShift": null,\n';
        dashboardContent += '      "title": "CPU Usage",\n';
        dashboardContent += '      "tooltip": {\n';
        dashboardContent += '        "shared": true,\n';
        dashboardContent += '        "sort": 0,\n';
        dashboardContent += '        "value_type": "individual"\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "type": "graph",\n';
        dashboardContent += '      "xaxis": {\n';
        dashboardContent += '        "buckets": null,\n';
        dashboardContent += '        "mode": "time",\n';
        dashboardContent += '        "name": null,\n';
        dashboardContent += '        "show": true,\n';
        dashboardContent += '        "values": []\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "yaxes": [\n';
        dashboardContent += '        {\n';
        dashboardContent += '          "format": "percent",\n';
        dashboardContent += '          "label": null,\n';
        dashboardContent += '          "logBase": 1,\n';
        dashboardContent += '          "max": null,\n';
        dashboardContent += '          "min": null,\n';
        dashboardContent += '          "show": true\n';
        dashboardContent += '        },\n';
        dashboardContent += '        {\n';
        dashboardContent += '          "format": "short",\n';
        dashboardContent += '          "label": null,\n';
        dashboardContent += '          "logBase": 1,\n';
        dashboardContent += '          "max": null,\n';
        dashboardContent += '          "min": null,\n';
        dashboardContent += '          "show": true\n';
        dashboardContent += '        }\n';
        dashboardContent += '      ],\n';
        dashboardContent += '      "yaxis": {\n';
        dashboardContent += '        "align": false,\n';
        dashboardContent += '        "alignLevel": null\n';
        dashboardContent += '      }\n';
        dashboardContent += '    }\n';
        dashboardContent += '  ],\n';
        dashboardContent += '  "schemaVersion": 26,\n';
        dashboardContent += '  "style": "dark",\n';
        dashboardContent += '  "tags": [],\n';
        dashboardContent += '  "templating": {\n';
        dashboardContent += '    "list": []\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "time": {\n';
        dashboardContent += '    "from": "now-6h",\n';
        dashboardContent += '    "to": "now"\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "timepicker": {},\n';
        dashboardContent += '  "timezone": "",\n';
        dashboardContent += '  "title": "System Monitoring",\n';
        dashboardContent += '  "uid": "system-monitoring",\n';
        dashboardContent += '  "version": 1\n';
        dashboardContent += '}\n';

        // Write dashboard.json
        fs.writeFileSync(path.join(dashboardsDir, 'dashboard.json'), dashboardContent);

        // Create dashboard.yml
        let dashboardYamlContent = 'apiVersion: 1\n\n';
        dashboardYamlContent += 'providers:\n';
        dashboardYamlContent += '  - name: \'default\'\n';
        dashboardYamlContent += '    orgId: 1\n';
        dashboardYamlContent += '    folder: \'\'\n';
        dashboardYamlContent += '    type: file\n';
        dashboardYamlContent += '    disableDeletion: false\n';
        dashboardYamlContent += '    editable: true\n';
        dashboardYamlContent += '    options:\n';
        dashboardYamlContent += '      path: /etc/grafana/dashboards\n';

        // Write dashboard.yml
        fs.writeFileSync(path.join(grafanaDir, 'dashboard.yml'), dashboardYamlContent);

        // Create docker-compose.yml for monitoring
        let dockerComposeContent = 'version: "3.8"\n\n';
        dockerComposeContent += 'services:\n';
        dockerComposeContent += '  prometheus:\n';
        dockerComposeContent += '    image: prom/prometheus:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
        dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
        dockerComposeContent += '      - prometheus_data:/prometheus\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
        dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
        dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
        dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9090:9090"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  alertmanager:\n';
        dockerComposeContent += '    image: prom/alertmanager:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
        dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
        dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9093:9093"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  grafana:\n';
        dockerComposeContent += '    image: grafana/grafana:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
        dockerComposeContent += '      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml\n';
        dockerComposeContent += '      - ./grafana/dashboards:/etc/grafana/dashboards\n';
        dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
        dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
        dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "3000:3000"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  node-exporter:\n';
        dockerComposeContent += '    image: prom/node-exporter:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - /proc:/host/proc:ro\n';
        dockerComposeContent += '      - /sys:/host/sys:ro\n';
        dockerComposeContent += '      - /:/rootfs:ro\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
        dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
        dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9100:9100"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  cadvisor:\n';
        dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - /:/rootfs:ro\n';
        dockerComposeContent += '      - /var/run:/var/run:ro\n';
        dockerComposeContent += '      - /sys:/sys:ro\n';
        dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "8080:8080"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += 'networks:\n';
        dockerComposeContent += '  monitoring-network:\n';
        dockerComposeContent += '    driver: bridge\n\n';
        
        dockerComposeContent += 'volumes:\n';
        dockerComposeContent += '  prometheus_data:\n';
        dockerComposeContent += '    driver: local\n';
        dockerComposeContent += '  alertmanager_data:\n';
        dockerComposeContent += '    driver: local\n';
        dockerComposeContent += '  grafana_data:\n';
        dockerComposeContent += '    driver: local\n';

        // Write docker-compose.yml
        fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);

        // Create README.md
        let readmeContent = '# Monitoring Stack\n\n';
        readmeContent += 'Este directorio contiene la configuración para un stack de monitoreo completo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
        readmeContent += '## Componentes\n\n';
        readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
        readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
        readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
        readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
        readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
        readmeContent += '## Inicio Rápido\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Iniciar el stack de monitoreo\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += '## Acceso\n\n';
        readmeContent += '- **Prometheus**: http://localhost:9090\n';
        readmeContent += '- **Alertmanager**: http://localhost:9093\n';
        readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
        readmeContent += '- **Node Exporter**: http://localhost:9100\n';
        readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
        readmeContent += '## Personalización\n\n';
        readmeContent += '### Prometheus\n\n';
        readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
        readmeContent += '### Alertmanager\n\n';
        readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
        readmeContent += '### Grafana\n\n';
        readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/dashboard.yml` si es necesario.\n';

        // Write README.md
        fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);

        // Create ELK stack directory
        const elkDir = path.join(monitoringDir, 'elk');
        if (!fs.existsSync(elkDir)) {
          fs.mkdirSync(elkDir, { recursive: true });
        }

        // Create docker-compose.yml for ELK stack
        let elkComposeContent = 'version: "3.8"\n\n';
        elkComposeContent += 'services:\n';
        elkComposeContent += '  elasticsearch:\n';
        elkComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - discovery.type=single-node\n';
        elkComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "9200:9200"\n';
        elkComposeContent += '      - "9300:9300"\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  logstash:\n';
        elkComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "5000:5000"\n';
        elkComposeContent += '      - "9600:9600"\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  kibana:\n';
        elkComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "5601:5601"\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  filebeat:\n';
        elkComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
        elkComposeContent += '    user: root\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
        elkComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
        elkComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '      - logstash\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += 'networks:\n';
        elkComposeContent += '  elk-network:\n';
        elkComposeContent += '    driver: bridge\n\n';
        
        elkComposeContent += 'volumes:\n';
        elkComposeContent += '  elasticsearch_data:\n';
        elkComposeContent += '    driver: local\n';

        // Write docker-compose.yml for ELK stack
        fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), elkComposeContent);

        // Create Logstash pipeline directory
        const logstashDir = path.join(elkDir, 'logstash');
        if (!fs.existsSync(logstashDir)) {
          fs.mkdirSync(logstashDir, { recursive: true });
        }

        const pipelineDir = path.join(logstashDir, 'pipeline');
        if (!fs.existsSync(pipelineDir)) {
          fs.mkdirSync(pipelineDir, { recursive: true });
        }

        // Create logstash.conf
        let logstashConfContent = 'input {\n';
        logstashConfContent += '  beats {\n';
        logstashConfContent += '    port => 5000\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n\n';
        logstashConfContent += 'filter {\n';
        logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  } else {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n\n';
        logstashConfContent += 'output {\n';
        logstashConfContent += '  elasticsearch {\n';
        logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
        logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n';

        // Write logstash.conf
        fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);

        // Create Filebeat directory
        const filebeatDir = path.join(elkDir, 'filebeat');
        if (!fs.existsSync(filebeatDir)) {
          fs.mkdirSync(filebeatDir, { recursive: true });
        }

        // Create filebeat.yml
        let filebeatContent = 'filebeat.inputs:\n';
        filebeatContent += '- type: container\n';
        filebeatContent += '  paths:\n';
        filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
        filebeatContent += '  processors:\n';
        filebeatContent += '    - add_docker_metadata:\n';
        filebeatContent += '        host: "unix:///var/run/docker.sock"\n\n';
        filebeatContent += 'processors:\n';
        filebeatContent += '  - add_host_metadata:\n';
        filebeatContent += '      when.not.contains.tags: forwarded\n';
        filebeatContent += '  - add_cloud_metadata: ~\n';
        filebeatContent += '  - add_docker_metadata: ~\n';
        filebeatContent += '  - add_kubernetes_metadata: ~\n\n';
        filebeatContent += 'output.logstash:\n';
        filebeatContent += '  hosts: ["logstash:5000"]\n';

        // Write filebeat.yml
        fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);

        // Create README.md for ELK stack
        let elkReadmeContent = '# ELK Stack\n\n';
        elkReadmeContent += 'Este directorio contiene la configuración para un stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat para la recolección de logs.\n\n';
        elkReadmeContent += '## Componentes\n\n';
        elkReadmeContent += '- **Elasticsearch**: Motor de búsqueda y análisis\n';
        elkReadmeContent += '- **Logstash**: Procesamiento de datos y logs\n';
        elkReadmeContent += '- **Kibana**: Visualización de datos\n';
        elkReadmeContent += '- **Filebeat**: Recolector de logs\n\n';
        elkReadmeContent += '## Inicio Rápido\n\n';
        elkReadmeContent += '```bash\n';
        elkReadmeContent += '# Iniciar el stack ELK\n';
        elkReadmeContent += 'docker-compose up -d\n';
        elkReadmeContent += '```\n\n';
        elkReadmeContent += '## Acceso\n\n';
        elkReadmeContent += '- **Elasticsearch**: http://localhost:9200\n';
        elkReadmeContent += '- **Kibana**: http://localhost:5601\n';
        elkReadmeContent += '- **Logstash**: http://localhost:9600\n\n';
        elkReadmeContent += '## Personalización\n\n';
        elkReadmeContent += '### Logstash\n\n';
        elkReadmeContent += 'Edita `logstash/pipeline/logstash.conf` para configurar el procesamiento de logs.\n\n';
        elkReadmeContent += '### Filebeat\n\n';
        elkReadmeContent += 'Edita `filebeat/filebeat.yml` para configurar la recolección de logs.\n\n';
        elkReadmeContent += '### Kibana\n\n';
        elkReadmeContent += 'Accede a Kibana para crear visualizaciones y dashboards.\n';

        // Write README.md for ELK stack
        fs.writeFileSync(path.join(elkDir, 'README.md'), elkReadmeContent);

        // Create Loki stack directory
        const lokiDir = path.join(monitoringDir, 'loki');
        if (!fs.existsSync(lokiDir)) {
          fs.mkdirSync(lokiDir, { recursive: true });
        }

        // Create docker-compose.yml for Loki stack
        let lokiComposeContent = 'version: "3.8"\n\n';
        lokiComposeContent += 'services:\n';
        lokiComposeContent += '  loki:\n';
        lokiComposeContent += '    image: grafana/loki:latest\n';
        lokiComposeContent += '    ports:\n';
        lokiComposeContent += '      - "3100:3100"\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./loki-config.yaml:/etc/loki/local-config.yaml\n';
        lokiComposeContent += '      - loki_data:/loki\n';
        lokiComposeContent += '    command: -config.file=/etc/loki/local-config.yaml\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += '  promtail:\n';
        lokiComposeContent += '    image: grafana/promtail:latest\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./promtail-config.yaml:/etc/promtail/config.yaml\n';
        lokiComposeContent += '      - /var/log:/var/log\n';
        lokiComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers\n';
        lokiComposeContent += '    command: -config.file=/etc/promtail/config.yaml\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    depends_on:\n';
        lokiComposeContent += '      - loki\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += '  grafana:\n';
        lokiComposeContent += '    image: grafana/grafana:latest\n';
        lokiComposeContent += '    ports:\n';
        lokiComposeContent += '      - "3200:3000"\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./grafana/datasources:/etc/grafana/provisioning/datasources\n';
        lokiComposeContent += '      - grafana_loki_data:/var/lib/grafana\n';
        lokiComposeContent += '    environment:\n';
        lokiComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
        lokiComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
        lokiComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    depends_on:\n';
        lokiComposeContent += '      - loki\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += 'networks:\n';
        lokiComposeContent += '  loki-network:\n';
        lokiComposeContent += '    driver: bridge\n\n';
        
        lokiComposeContent += 'volumes:\n';
        lokiComposeContent += '  loki_data:\n';
        lokiComposeContent += '    driver: local\n';
        lokiComposeContent += '  grafana_loki_data:\n';
        lokiComposeContent += '    driver: local\n';

        // Write docker-compose.yml for Loki stack
        fs.writeFileSync(path.join(lokiDir, 'docker-compose.yml'), lokiComposeContent);

        // Create loki-config.yaml
        let lokiConfigContent = 'auth_enabled: false\n\n';
        lokiConfigContent += 'server:\n';
        lokiConfigContent += '  http_listen_port: 3100\n\n';
        lokiConfigContent += 'ingester:\n';
        lokiConfigContent += '  lifecycler:\n';
        lokiConfigContent += '    address: 127.0.0.1\n';
        lokiConfigContent += '    ring:\n';
        lokiConfigContent += '      kvstore:\n';
        lokiConfigContent += '        store: inmemory\n';
        lokiConfigContent += '      replication_factor: 1\n';
        lokiConfigContent += '    final_sleep: 0s\n';
        lokiConfigContent += '  chunk_idle_period: 5m\n';
        lokiConfigContent += '  chunk_retain_period: 30s\n\n';
        lokiConfigContent += 'schema_config:\n';
        lokiConfigContent += '  configs:\n';
        lokiConfigContent += '  - from: 2020-10-24\n';
        lokiConfigContent += '    store: boltdb-shipper\n';
        lokiConfigContent += '    object_store: filesystem\n';
        lokiConfigContent += '    schema: v11\n';
        lokiConfigContent += '    index:\n';
        lokiConfigContent += '      prefix: index_\n';
        lokiConfigContent += '      period: 24h\n\n';
        lokiConfigContent += 'storage_config:\n';
        lokiConfigContent += '  boltdb_shipper:\n';
        lokiConfigContent += '    active_index_directory: /loki/boltdb-shipper-active\n';
        lokiConfigContent += '    cache_location: /loki/boltdb-shipper-cache\n';
        lokiConfigContent += '    cache_ttl: 24h\n';
        lokiConfigContent += '    shared_store: filesystem\n';
        lokiConfigContent += '  filesystem:\n';
        lokiConfigContent += '    directory: /loki/chunks\n\n';
        lokiConfigContent += 'limits_config:\n';
        lokiConfigContent += '  enforce_metric_name: false\n';
        lokiConfigContent += '  reject_old_samples: true\n';
        lokiConfigContent += '  reject_old_samples_max_age: 168h\n\n';
        lokiConfigContent += 'chunk_store_config:\n';
        lokiConfigContent += '  max_look_back_period: 0s\n\n';
        lokiConfigContent += 'table_manager:\n';
        lokiConfigContent += '  retention_deletes_enabled: false\n';
        lokiConfigContent += '  retention_period: 0s\n\n';
        lokiConfigContent += 'compactor:\n';
        lokiConfigContent += '  working_directory: /loki/boltdb-shipper-compactor\n';
        lokiConfigContent += '  shared_store: filesystem\n';

        // Write loki-config.yaml
        fs.writeFileSync(path.join(lokiDir, 'loki-config.yaml'), lokiConfigContent);

        // Create promtail-config.yaml
        let promtailConfigContent = 'server:\n';
        promtailConfigContent += '  http_listen_port: 9080\n';
        promtailConfigContent += '  grpc_listen_port: 0\n\n';
        promtailConfigContent += 'positions:\n';
        promtailConfigContent += '  filename: /tmp/positions.yaml\n\n';
        promtailConfigContent += 'clients:\n';
        promtailConfigContent += '  - url: http://loki:3100/loki/api/v1/push\n\n';
        promtailConfigContent += 'scrape_configs:\n';
        promtailConfigContent += '  - job_name: system\n';
        promtailConfigContent += '    static_configs:\n';
        promtailConfigContent += '    - targets:\n';
        promtailConfigContent += '        - localhost\n';
        promtailConfigContent += '      labels:\n';
        promtailConfigContent += '        job: varlogs\n';
        promtailConfigContent += '        __path__: /var/log/*log\n\n';
        promtailConfigContent += '  - job_name: containers\n';
        promtailConfigContent += '    static_configs:\n';
        promtailConfigContent += '    - targets:\n';
        promtailConfigContent += '        - localhost\n';
        promtailConfigContent += '      labels:\n';
        promtailConfigContent += '        job: containerlogs\n';
        promtailConfigContent += '        __path__: /var/lib/docker/containers/*/*log\n';
        promtailConfigContent += '    pipeline_stages:\n';
        promtailConfigContent += '    - json:\n';
        promtailConfigContent += '        expressions:\n';
        promtailConfigContent += '          stream: stream\n';
        promtailConfigContent += '          attrs: attrs\n';
        promtailConfigContent += '          tag: attrs.tag\n';
        promtailConfigContent += '    - labels:\n';
        promtailConfigContent += '        stream:\n';
        promtailConfigContent += '        tag:\n';

        // Write promtail-config.yaml
        fs.writeFileSync(path.join(lokiDir, 'promtail-config.yaml'), promtailConfigContent);

        // Create Grafana datasources directory
        const grafanaLokiDir = path.join(lokiDir, 'grafana');
        if (!fs.existsSync(grafanaLokiDir)) {
          fs.mkdirSync(grafanaLokiDir, { recursive: true });
        }

        const datasourcesLokiDir = path.join(grafanaLokiDir, 'datasources');
        if (!fs.existsSync(datasourcesLokiDir)) {
          fs.mkdirSync(datasourcesLokiDir, { recursive: true });
        }

        // Create datasource.yml
        let datasourceLokiContent = 'apiVersion: 1\n\n';
        datasourceLokiContent += 'datasources:\n';
        datasourceLokiContent += '  - name: Loki\n';
        datasourceLokiContent += '    type: loki\n';
        datasourceLokiContent += '    access: proxy\n';
        datasourceLokiContent += '    url: http://loki:3100\n';
        datasourceLokiContent += '    isDefault: true\n';
        datasourceLokiContent += '    editable: true\n';

        // Write datasource.yml
        fs.writeFileSync(path.join(datasourcesLokiDir, 'datasource.yml'), datasourceLokiContent);

        // Create README.md for Loki stack
        let lokiReadmeContent = '# Loki Stack\n\n';
        lokiReadmeContent += 'Este directorio contiene la configuración para un stack Loki (Loki, Promtail, Grafana) para la recolección y visualización de logs.\n\n';
        lokiReadmeContent += '## Componentes\n\n';
        lokiReadmeContent += '- **Loki**: Sistema de agregación de logs\n';
        lokiReadmeContent += '- **Promtail**: Agente para enviar logs a Loki\n';
        lokiReadmeContent += '- **Grafana**: Visualización de logs\n\n';
        lokiReadmeContent += '## Inicio Rápido\n\n';
        lokiReadmeContent += '```bash\n';
        lokiReadmeContent += '# Iniciar el stack Loki\n';
        lokiReadmeContent += 'docker-compose up -d\n';
        lokiReadmeContent += '```\n\n';
        lokiReadmeContent += '## Acceso\n\n';
        lokiReadmeContent += '- **Loki**: http://localhost:3100\n';
        lokiReadmeContent += '- **Grafana**: http://localhost:3200 (usuario: admin, contraseña: admin)\n\n';
        lokiReadmeContent += '## Personalización\n\n';
        lokiReadmeContent += '### Loki\n\n';
        lokiReadmeContent += 'Edita `loki-config.yaml` para configurar Loki.\n\n';
        lokiReadmeContent += '### Promtail\n\n';
        lokiReadmeContent += 'Edita `promtail-config.yaml` para configurar la recolección de logs.\n\n';
        lokiReadmeContent += '### Grafana\n\n';
        lokiReadmeContent += 'Accede a Grafana para crear visualizaciones y dashboards para los logs.\n';

        // Write README.md for Loki stack
        fs.writeFileSync(path.join(lokiDir, 'README.md'), lokiReadmeContent);

        // Create a main README.md for the monitoring directory
        let mainReadmeContent = '# Monitoreo y Observabilidad\n\n';
        mainReadmeContent += 'Este directorio contiene diferentes stacks de monitoreo y observabilidad para tu proyecto.\n\n';
        mainReadmeContent += '## Stacks Disponibles\n\n';
        mainReadmeContent += '### 1. Prometheus Stack\n\n';
        mainReadmeContent += 'Un stack completo de monitoreo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
        mainReadmeContent += '```bash\n';
        mainReadmeContent += 'cd prometheus-stack\n';
        mainReadmeContent += 'docker-compose up -d\n';
        mainReadmeContent += '```\n\n';
        mainReadmeContent += '### 2. ELK Stack\n\n';
        mainReadmeContent += 'Un stack de logs basado en Elasticsearch, Logstash, Kibana y Filebeat.\n\n';
        mainReadmeContent += '```bash\n';
        mainReadmeContent += 'cd elk\n';
        mainReadmeContent += 'docker-compose up -d\n';
        mainReadmeContent += '```\n\n';
        mainReadmeContent += '### 3. Loki Stack\n\n';
        mainReadmeContent += 'Un stack de logs ligero basado en Loki, Promtail y Grafana.\n\n';
        mainReadmeContent += '```bash\n';
        mainReadmeContent += 'cd loki\n';
        mainReadmeContent += 'docker-compose up -d\n';
        mainReadmeContent += '```\n\n';
        mainReadmeContent += '## Comparación\n\n';
        mainReadmeContent += '| Stack | Pros | Contras |\n';
        mainReadmeContent += '|-------|------|--------|\n';
        mainReadmeContent += '| Prometheus | Excelente para métricas, alertas configurables, visualización potente | Limitado para logs |\n';
        mainReadmeContent += '| ELK | Potente para logs, búsqueda avanzada, análisis profundo | Consumo alto de recursos |\n';
        mainReadmeContent += '| Loki | Ligero, integración con Grafana, eficiente | Menos potente que ELK para búsquedas complejas |\n\n';
        mainReadmeContent += '## Recomendaciones\n\n';
        mainReadmeContent += '- **Entornos pequeños**: Loki Stack\n';
        mainReadmeContent += '- **Entornos medianos**: Prometheus Stack + Loki Stack\n';
        mainReadmeContent += '- **Entornos grandes**: Prometheus Stack + ELK Stack\n';

        // Write main README.md
        fs.writeFileSync(path.join(monitoringDir, 'README.md'), mainReadmeContent);

        return monitoringDir;
      } catch (error) {
        Logger.error(`Error creating monitoring files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates CI/CD pipeline files for the project
     * @param projectDir - The project directory
     * @param config - The CI/CD configuration
     * @returns The path to the CI/CD directory
     */
    async createCICDFiles(projectDir: string, config: any): Promise<string> {
      try {
        Logger.info('Creating CI/CD pipeline files...');
        
        const cicdDir = path.join(projectDir, '.github', 'workflows');
        if (!fs.existsSync(cicdDir)) {
          fs.mkdirSync(cicdDir, { recursive: true });
        }

        // Create GitHub Actions workflow for CI
        let ciWorkflowContent = 'name: CI\n\n';
        ciWorkflowContent += 'on:\n';
        ciWorkflowContent += '  push:\n';
        ciWorkflowContent += '    branches: [ main, develop ]\n';
        ciWorkflowContent += '  pull_request:\n';
        ciWorkflowContent += '    branches: [ main, develop ]\n\n';
        ciWorkflowContent += 'jobs:\n';
        ciWorkflowContent += '  build-and-test:\n';
        ciWorkflowContent += '    runs-on: ubuntu-latest\n\n';
        ciWorkflowContent += '    steps:\n';
        ciWorkflowContent += '    - uses: actions/checkout@v3\n\n';
        
        // Add Node.js setup if it's a Node.js project
        if (config.language === 'javascript' || config.language === 'typescript') {
          ciWorkflowContent += '    - name: Set up Node.js\n';
          ciWorkflowContent += '      uses: actions/setup-node@v3\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        node-version: 18\n';
          ciWorkflowContent += '        cache: \'npm\'\n\n';
          ciWorkflowContent += '    - name: Install dependencies\n';
          ciWorkflowContent += '      run: npm ci\n\n';
          ciWorkflowContent += '    - name: Lint\n';
          ciWorkflowContent += '      run: npm run lint\n\n';
          ciWorkflowContent += '    - name: Build\n';
          ciWorkflowContent += '      run: npm run build\n\n';
          ciWorkflowContent += '    - name: Test\n';
          ciWorkflowContent += '      run: npm test\n';
        }
        
        // Add Python setup if it's a Python project
        else if (config.language === 'python') {
          ciWorkflowContent += '    - name: Set up Python\n';
          ciWorkflowContent += '      uses: actions/setup-python@v4\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        python-version: 3.10\n';
          ciWorkflowContent += '        cache: \'pip\'\n\n';
          ciWorkflowContent += '    - name: Install dependencies\n';
          ciWorkflowContent += '      run: |\n';
          ciWorkflowContent += '        python -m pip install --upgrade pip\n';
          ciWorkflowContent += '        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n';
          ciWorkflowContent += '        pip install pytest flake8\n\n';
          ciWorkflowContent += '    - name: Lint with flake8\n';
          ciWorkflowContent += '      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n\n';
          ciWorkflowContent += '    - name: Test with pytest\n';
          ciWorkflowContent += '      run: pytest\n';
        }
        
        // Add Java setup if it's a Java project
        else if (config.language === 'java') {
          ciWorkflowContent += '    - name: Set up JDK\n';
          ciWorkflowContent += '      uses: actions/setup-java@v3\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        java-version: 17\n';
          ciWorkflowContent += '        distribution: \'temurin\'\n';
          ciWorkflowContent += '        cache: maven\n\n';
          ciWorkflowContent += '    - name: Build with Maven\n';
          ciWorkflowContent += '      run: mvn -B package --file pom.xml\n\n';
          ciWorkflowContent += '    - name: Test\n';
          ciWorkflowContent += '      run: mvn test\n';
        }
        
        // Add Go setup if it's a Go project
        else if (config.language === 'go') {
          ciWorkflowContent += '    - name: Set up Go\n';
          ciWorkflowContent += '      uses: actions/setup-go@v4\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        go-version: 1.19\n\n';
          ciWorkflowContent += '    - name: Build\n';
          ciWorkflowContent += '      run: go build -v ./...\n\n';
          ciWorkflowContent += '    - name: Test\n';
          ciWorkflowContent += '      run: go test -v ./...\n';
        }
        
        // Add Docker build step if Docker is used
        if (config.docker) {
          ciWorkflowContent += '\n    - name: Set up Docker Buildx\n';
          ciWorkflowContent += '      uses: docker/setup-buildx-action@v2\n\n';
          ciWorkflowContent += '    - name: Build Docker image\n';
          ciWorkflowContent += '      uses: docker/build-push-action@v4\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        context: .\n';
          ciWorkflowContent += '        push: false\n';
          ciWorkflowContent += '        tags: ${{ github.repository }}:${{ github.sha }}\n';
          ciWorkflowContent += '        cache-from: type=gha\n';
          ciWorkflowContent += '        cache-to: type=gha,mode=max\n';
        }

        // Write CI workflow file
        fs.writeFileSync(path.join(cicdDir, 'ci.yml'), ciWorkflowContent);

        // Create GitHub Actions workflow for CD
        let cdWorkflowContent = 'name: CD\n\n';
        cdWorkflowContent += 'on:\n';
        cdWorkflowContent += '  push:\n';
        cdWorkflowContent += '    branches: [ main ]\n';
        cdWorkflowContent += '    tags: [ \'v*\' ]\n\n';
        cdWorkflowContent += 'jobs:\n';
        cdWorkflowContent += '  deploy:\n';
        cdWorkflowContent += '    runs-on: ubuntu-latest\n';
        cdWorkflowContent += '    needs: build-and-test\n\n';
        cdWorkflowContent += '    steps:\n';
        cdWorkflowContent += '    - uses: actions/checkout@v3\n\n';
        
        // Add Docker build and push steps if Docker is used
        if (config.docker) {
          cdWorkflowContent += '    - name: Set up Docker Buildx\n';
          cdWorkflowContent += '      uses: docker/setup-buildx-action@v2\n\n';
          cdWorkflowContent += '    - name: Login to DockerHub\n';
          cdWorkflowContent += '      uses: docker/login-action@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
          cdWorkflowContent += '        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n';
          cdWorkflowContent += '    - name: Build and push Docker image\n';
          cdWorkflowContent += '      uses: docker/build-push-action@v4\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        context: .\n';
          cdWorkflowContent += '        push: true\n';
          cdWorkflowContent += '        tags: ${{ secrets.DOCKERHUB_USERNAME }}/${{ github.repository }}:latest,${{ secrets.DOCKERHUB_USERNAME }}/${{ github.repository }}:${{ github.sha }}\n';
          cdWorkflowContent += '        cache-from: type=gha\n';
          cdWorkflowContent += '        cache-to: type=gha,mode=max\n\n';
        }
        
        // Add deployment steps based on the deployment environment
        if (config.deploymentEnvironment === 'kubernetes') {
          cdWorkflowContent += '    - name: Set up kubectl\n';
          cdWorkflowContent += '      uses: azure/setup-kubectl@v3\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        version: \'latest\'\n\n';
          cdWorkflowContent += '    - name: Set Kubernetes context\n';
          cdWorkflowContent += '      uses: azure/k8s-set-context@v3\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        kubeconfig: ${{ secrets.KUBE_CONFIG }}\n\n';
          cdWorkflowContent += '    - name: Deploy to Kubernetes\n';
          cdWorkflowContent += '      run: |\n';
          cdWorkflowContent += '        kubectl apply -f kubernetes/\n';
          cdWorkflowContent += '        kubectl set image deployment/${{ github.event.repository.name }} ${{ github.event.repository.name }}=${{ secrets.DOCKERHUB_USERNAME }}/${{ github.repository }}:${{ github.sha }}\n';
        } else if (config.deploymentEnvironment === 'aws') {
          cdWorkflowContent += '    - name: Configure AWS credentials\n';
          cdWorkflowContent += '      uses: aws-actions/configure-aws-credentials@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
          cdWorkflowContent += '        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
          cdWorkflowContent += '        aws-region: ${{ secrets.AWS_REGION }}\n\n';
          cdWorkflowContent += '    - name: Deploy to AWS\n';
          cdWorkflowContent += '      run: |\n';
          cdWorkflowContent += '        aws s3 sync ./build s3://${{ secrets.AWS_S3_BUCKET }}/\n';
          cdWorkflowContent += '        aws cloudfront create-invalidation --distribution-id ${{ secrets.AWS_CLOUDFRONT_DISTRIBUTION_ID }} --paths "/*"\n';
        } else if (config.deploymentEnvironment === 'azure') {
          cdWorkflowContent += '    - name: Azure Login\n';
          cdWorkflowContent += '      uses: azure/login@v1\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n';
          cdWorkflowContent += '    - name: Deploy to Azure Web App\n';
          cdWorkflowContent += '      uses: azure/webapps-deploy@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        app-name: ${{ secrets.AZURE_WEBAPP_NAME }}\n';
          cdWorkflowContent += '        package: ./build\n';
        } else if (config.deploymentEnvironment === 'gcp') {
          cdWorkflowContent += '    - name: Set up Cloud SDK\n';
          cdWorkflowContent += '      uses: google-github-actions/setup-gcloud@v1\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        project_id: ${{ secrets.GCP_PROJECT_ID }}\n';
          cdWorkflowContent += '        service_account_key: ${{ secrets.GCP_SA_KEY }}\n';
          cdWorkflowContent += '        export_default_credentials: true\n\n';
          cdWorkflowContent += '    - name: Deploy to GCP\n';
          cdWorkflowContent += '      run: |\n';
          cdWorkflowContent += '        gcloud app deploy app.yaml --quiet\n';
        } else if (config.deploymentEnvironment === 'heroku') {
          cdWorkflowContent += '    - name: Deploy to Heroku\n';
          cdWorkflowContent += '      uses: akhileshns/heroku-deploy@v3.12.14\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n';
          cdWorkflowContent += '        heroku_app_name: ${{ secrets.HEROKU_APP_NAME }}\n';
          cdWorkflowContent += '        heroku_email: ${{ secrets.HEROKU_EMAIL }}\n';
        }

        // Write CD workflow file
        fs.writeFileSync(path.join(cicdDir, 'cd.yml'), cdWorkflowContent);

        // Create a README.md file for CI/CD
        let readmeContent = '# CI/CD Pipelines\n\n';
        readmeContent += 'Este directorio contiene los flujos de trabajo de GitHub Actions para CI/CD.\n\n';
        readmeContent += '## Flujos de Trabajo\n\n';
        readmeContent += '### CI (Integración Continua)\n\n';
        readmeContent += 'El flujo de trabajo de CI se ejecuta en cada push a las ramas `main` y `develop`, así como en las pull requests a estas ramas.\n\n';
        readmeContent += 'Pasos:\n';
        readmeContent += '1. Checkout del código\n';
        
        if (config.language === 'javascript' || config.language === 'typescript') {
          readmeContent += '2. Configuración de Node.js\n';
          readmeContent += '3. Instalación de dependencias\n';
          readmeContent += '4. Linting\n';
          readmeContent += '5. Build\n';
          readmeContent += '6. Pruebas\n';
        } else if (config.language === 'python') {
          readmeContent += '2. Configuración de Python\n';
          readmeContent += '3. Instalación de dependencias\n';
          readmeContent += '4. Linting con flake8\n';
          readmeContent += '5. Pruebas con pytest\n';
        } else if (config.language === 'java') {
          readmeContent += '2. Configuración de JDK\n';
          readmeContent += '3. Build con Maven\n';
          readmeContent += '4. Pruebas\n';
        } else if (config.language === 'go') {
          readmeContent += '2. Configuración de Go\n';
          readmeContent += '3. Build\n';
          readmeContent += '4. Pruebas\n';
        }
        
        if (config.docker) {
          readmeContent += '7. Build de imagen Docker\n';
        }
        
        readmeContent += '\n### CD (Despliegue Continuo)\n\n';
        readmeContent += 'El flujo de trabajo de CD se ejecuta en cada push a la rama `main` y en los tags que comienzan con `v`.\n\n';
        readmeContent += 'Pasos:\n';
        readmeContent += '1. Checkout del código\n';
        
        if (config.docker) {
          readmeContent += '2. Configuración de Docker Buildx\n';
          readmeContent += '3. Login a DockerHub\n';
          readmeContent += '4. Build y push de imagen Docker\n';
        }
        
        if (config.deploymentEnvironment === 'kubernetes') {
          readmeContent += '5. Configuración de kubectl\n';
          readmeContent += '6. Configuración del contexto de Kubernetes\n';
          readmeContent += '7. Despliegue a Kubernetes\n';
        } else if (config.deploymentEnvironment === 'aws') {
          readmeContent += '5. Configuración de credenciales AWS\n';
          readmeContent += '6. Despliegue a AWS (S3 + CloudFront)\n';
        } else if (config.deploymentEnvironment === 'azure') {
          readmeContent += '5. Login a Azure\n';
          readmeContent += '6. Despliegue a Azure Web App\n';
        } else if (config.deploymentEnvironment === 'gcp') {
          readmeContent += '5. Configuración de Cloud SDK\n';
          readmeContent += '6. Despliegue a GCP App Engine\n';
        } else if (config.deploymentEnvironment === 'heroku') {
          readmeContent += '5. Despliegue a Heroku\n';
        }
        
        readmeContent += '\n## Secretos Requeridos\n\n';
        
        if (config.docker) {
          readmeContent += '- `DOCKERHUB_USERNAME`: Nombre de usuario de DockerHub\n';
          readmeContent += '- `DOCKERHUB_TOKEN`: Token de acceso de DockerHub\n';
        }
        
        if (config.deploymentEnvironment === 'kubernetes') {
          readmeContent += '- `KUBE_CONFIG`: Archivo kubeconfig codificado en base64\n';
        } else if (config.deploymentEnvironment === 'aws') {
          readmeContent += '- `AWS_ACCESS_KEY_ID`: ID de clave de acceso de AWS\n';
          readmeContent += '- `AWS_SECRET_ACCESS_KEY`: Clave de acceso secreta de AWS\n';
          readmeContent += '- `AWS_REGION`: Región de AWS\n';
          readmeContent += '- `AWS_S3_BUCKET`: Nombre del bucket de S3\n';
          readmeContent += '- `AWS_CLOUDFRONT_DISTRIBUTION_ID`: ID de distribución de CloudFront\n';
        } else if (config.deploymentEnvironment === 'azure') {
          readmeContent += '- `AZURE_CREDENTIALS`: Credenciales de Azure\n';
          readmeContent += '- `AZURE_WEBAPP_NAME`: Nombre de la aplicación web de Azure\n';
        } else if (config.deploymentEnvironment === 'gcp') {
          readmeContent += '- `GCP_PROJECT_ID`: ID del proyecto de GCP\n';
          readmeContent += '- `GCP_SA_KEY`: Clave de cuenta de servicio de GCP\n';
        } else if (config.deploymentEnvironment === 'heroku') {
          readmeContent += '- `HEROKU_API_KEY`: Clave API de Heroku\n';
          readmeContent += '- `HEROKU_APP_NAME`: Nombre de la aplicación de Heroku\n';
          readmeContent += '- `HEROKU_EMAIL`: Email de la cuenta de Heroku\n';
        }
        
        readmeContent += '\n## Configuración\n\n';
        readmeContent += 'Para configurar los secretos en GitHub, ve a Settings > Secrets > Actions > New repository secret.\n';

        // Write README.md
        fs.writeFileSync(path.join(path.dirname(cicdDir), 'README.md'), readmeContent);

        return cicdDir;
      } catch (error) {
        Logger.error(`Error creating CI/CD files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates security configuration files for the project
     * @param projectDir - The project directory
     * @returns The path to the security directory
     */
    async createSecurityFiles(projectDir: string): Promise<string> {
      try {
        Logger.info('Creating security configuration files...');
        
        const securityDir = path.join(projectDir, 'security');
        if (!fs.existsSync(securityDir)) {
          fs.mkdirSync(securityDir, { recursive: true });
        }

        // Create security policy file
        let securityPolicyContent = '# Security Policy\n\n';
        securityPolicyContent += '## Supported Versions\n\n';
        securityPolicyContent += 'We release patches for security vulnerabilities. Currently supported versions are:\n\n';
        securityPolicyContent += '| Version | Supported          |\n';
        securityPolicyContent += '| ------- | ------------------ |\n';
        securityPolicyContent += '| 1.0.x   | :white_check_mark: |\n';
        securityPolicyContent += '| < 1.0   | :x:                |\n\n';
        securityPolicyContent += '## Reporting a Vulnerability\n\n';
        securityPolicyContent += 'Please report security vulnerabilities to security@example.com.\n\n';
        securityPolicyContent += 'We will acknowledge receipt of your vulnerability report and send you regular updates about our progress. If you\'re curious about the status of your disclosure please feel free to email us again.\n\n';
        securityPolicyContent += 'If the vulnerability is confirmed, we will release a patch as soon as possible depending on complexity.\n';

        // Write security policy file
        fs.writeFileSync(path.join(projectDir, 'SECURITY.md'), securityPolicyContent);

        // Create .gitignore for security directory
        let gitignoreContent = '# Ignore all files in this directory\n';
        gitignoreContent += '*\n';
        gitignoreContent += '# Except this file\n';
        gitignoreContent += '!.gitignore\n';
        gitignoreContent += '# And README\n';
        gitignoreContent += '!README.md\n';
        gitignoreContent += '# And example files\n';
        gitignoreContent += '!*.example\n';

        // Write .gitignore
        fs.writeFileSync(path.join(securityDir, '.gitignore'), gitignoreContent);

        // Create README.md for security directory
        let readmeContent = '# Security Configuration\n\n';
        readmeContent += 'Este directorio contiene archivos de configuración relacionados con la seguridad.\n\n';
        readmeContent += '## Archivos\n\n';
        readmeContent += '- `.env.example`: Ejemplo de archivo de variables de entorno\n';
        readmeContent += '- `secrets.yaml.example`: Ejemplo de archivo de secretos para Kubernetes\n';
        readmeContent += '- `vault-policy.hcl.example`: Ejemplo de política de Vault\n\n';
        readmeContent += '## Uso\n\n';
        readmeContent += '1. Copia los archivos de ejemplo y elimina la extensión `.example`\n';
        readmeContent += '2. Rellena los valores reales en los archivos copiados\n';
        readmeContent += '3. **NUNCA** comitees los archivos con valores reales al repositorio\n\n';
        readmeContent += '## Mejores Prácticas\n\n';
        readmeContent += '- Usa variables de entorno para configuración sensible\n';
        readmeContent += '- Utiliza un gestor de secretos como HashiCorp Vault o AWS Secrets Manager\n';
        readmeContent += '- Rota las credenciales regularmente\n';
        readmeContent += '- Usa el principio de privilegio mínimo\n';
        readmeContent += '- Implementa autenticación multifactor (MFA)\n';
        readmeContent += '- Audita y registra el acceso a secretos\n';

        // Write README.md
        fs.writeFileSync(path.join(securityDir, 'README.md'), readmeContent);

        // Create .env.example file
        let envExampleContent = '# Ejemplo de archivo .env\n\n';
        envExampleContent += '# Configuración de la aplicación\n';
        envExampleContent += 'APP_ENV=development\n';
        envExampleContent += 'APP_DEBUG=true\n';
        envExampleContent += 'APP_SECRET=your_secret_key_here\n\n';
        envExampleContent += '# Configuración de la base de datos\n';
        envExampleContent += 'DB_HOST=localhost\n';
        envExampleContent += 'DB_PORT=5432\n';
        envExampleContent += 'DB_NAME=myapp\n';
        envExampleContent += 'DB_USER=dbuser\n';
        envExampleContent += 'DB_PASSWORD=dbpassword\n\n';
        envExampleContent += '# Configuración de API\n';
        envExampleContent += 'API_KEY=your_api_key_here\n';
        envExampleContent += 'API_URL=https://api.example.com\n\n';
        envExampleContent += '# Configuración de JWT\n';
        envExampleContent += 'JWT_SECRET=your_jwt_secret_here\n';
        envExampleContent += 'JWT_EXPIRATION=3600\n\n';
        envExampleContent += '# Configuración de correo electrónico\n';
        envExampleContent += 'MAIL_HOST=smtp.example.com\n';
        envExampleContent += 'MAIL_PORT=587\n';
        envExampleContent += 'MAIL_USERNAME=user@example.com\n';
        envExampleContent += 'MAIL_PASSWORD=mailpassword\n';
        envExampleContent += 'MAIL_ENCRYPTION=tls\n';
        envExampleContent += 'MAIL_FROM_ADDRESS=noreply@example.com\n';
        envExampleContent += 'MAIL_FROM_NAME="My App"\n';

        // Write .env.example
        fs.writeFileSync(path.join(securityDir, '.env.example'), envExampleContent);

        // Create secrets.yaml.example file for Kubernetes
        let secretsYamlContent = 'apiVersion: v1\n';
        secretsYamlContent += 'kind: Secret\n';
        secretsYamlContent += 'metadata:\n';
        secretsYamlContent += '  name: app-secrets\n';
        secretsYamlContent += 'type: Opaque\n';
        secretsYamlContent += 'data:\n';
        secretsYamlContent += '  # Nota: Los valores deben estar codificados en base64\n';
        secretsYamlContent += '  # Ejemplo: echo -n "valor" | base64\n';
        secretsYamlContent += '  APP_SECRET: eW91cl9zZWNyZXRfa2V5X2hlcmU=\n';
        secretsYamlContent += '  DB_PASSWORD: ZGJwYXNzd29yZA==\n';
        secretsYamlContent += '  API_KEY: eW91cl9hcGlfa2V5X2hlcmU=\n';
        secretsYamlContent += '  JWT_SECRET: eW91cl9qd3Rfc2VjcmV0X2hlcmU=\n';
        secretsYamlContent += '  MAIL_PASSWORD: bWFpbHBhc3N3b3Jk\n';

        // Write secrets.yaml.example
        fs.writeFileSync(path.join(securityDir, 'secrets.yaml.example'), secretsYamlContent);

        // Create vault-policy.hcl.example file for HashiCorp Vault
        let vaultPolicyContent = '# Ejemplo de política de HashiCorp Vault\n\n';
        vaultPolicyContent += '# Política para acceso a secretos de la aplicación\n';
        vaultPolicyContent += 'path "secret/data/app/*" {\n';
        vaultPolicyContent += '  capabilities = ["read"]\n';
        vaultPolicyContent += '}\n\n';
        vaultPolicyContent += '# Política para acceso a secretos de base de datos\n';
        vaultPolicyContent += 'path "secret/data/db/*" {\n';
        vaultPolicyContent += '  capabilities = ["read"]\n';
        vaultPolicyContent += '}\n\n';
        vaultPolicyContent += '# Política para acceso a secretos de API\n';
        vaultPolicyContent += 'path "secret/data/api/*" {\n';
        vaultPolicyContent += '  capabilities = ["read"]\n';
        vaultPolicyContent += '}\n\n';
        vaultPolicyContent += '# Política para acceso a secretos de JWT\n';
        vaultPolicyContent += 'path "secret/data/jwt/*" {\n';
        vaultPolicyContent += '  capabilities = ["read"]\n';
        vaultPolicyContent += '}\n\n';
        vaultPolicyContent += '# Política para acceso a secretos de correo electrónico\n';
        vaultPolicyContent += 'path "secret/data/mail/*" {\n';
        vaultPolicyContent += '  capabilities = ["read"]\n';
        vaultPolicyContent += '}\n';

        // Write vault-policy.hcl.example
        fs.writeFileSync(path.join(securityDir, 'vault-policy.hcl.example'), vaultPolicyContent);

        // Create security checklist
        let checklistContent = '# Lista de Verificación de Seguridad\n\n';
        checklistContent += '## Configuración General\n\n';
        checklistContent += '- [ ] Variables de entorno configuradas correctamente\n';
        checklistContent += '- [ ] Secretos almacenados de forma segura (no en el código)\n';
        checklistContent += '- [ ] Archivos de configuración sensibles excluidos de Git\n';
        checklistContent += '- [ ] Política de seguridad (SECURITY.md) actualizada\n\n';
        checklistContent += '## Autenticación y Autorización\n\n';
        checklistContent += '- [ ] Implementación de autenticación segura\n';
        checklistContent += '- [ ] Uso de HTTPS/TLS\n';
        checklistContent += '- [ ] Implementación de JWT con secretos seguros\n';
        checklistContent += '- [ ] Control de acceso basado en roles (RBAC)\n';
        checklistContent += '- [ ] Autenticación multifactor (MFA) habilitada\n\n';
        checklistContent += '## Base de Datos\n\n';
        checklistContent += '- [ ] Credenciales de base de datos seguras\n';
        checklistContent += '- [ ] Conexiones de base de datos cifradas\n';
        checklistContent += '- [ ] Consultas parametrizadas (prevención de inyección SQL)\n';
        checklistContent += '- [ ] Backups regulares configurados\n\n';
        checklistContent += '## API y Comunicación\n\n';
        checklistContent += '- [ ] Validación de entrada en todas las API\n';
        checklistContent += '- [ ] Limitación de tasa (rate limiting) configurada\n';
        checklistContent += '- [ ] Cabeceras de seguridad HTTP configuradas\n';
        checklistContent += '- [ ] CORS configurado correctamente\n\n';
        checklistContent += '## Infraestructura\n\n';
        checklistContent += '- [ ] Firewalls configurados\n';
        checklistContent += '- [ ] Actualizaciones de seguridad automatizadas\n';
        checklistContent += '- [ ] Monitoreo de seguridad implementado\n';
        checklistContent += '- [ ] Escaneo de vulnerabilidades configurado\n\n';
        checklistContent += '## Código\n\n';
        checklistContent += '- [ ] Dependencias actualizadas y sin vulnerabilidades conocidas\n';
        checklistContent += '- [ ] Análisis estático de código configurado\n';
        checklistContent += '- [ ] Revisiones de seguridad en el proceso de CI/CD\n';
        checklistContent += '- [ ] Pruebas de seguridad automatizadas\n';

        // Write security checklist
        fs.writeFileSync(path.join(securityDir, 'CHECKLIST.md'), checklistContent);

        return securityDir;
      } catch (error) {
        Logger.error(`Error creating security files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates backup and recovery configuration files
     * @param projectDir - The project directory
     * @returns The path to the backup directory
     */
    async createBackupFiles(projectDir: string): Promise<string> {
      try {
        Logger.info('Creating backup and recovery configuration files...');
        
        const backupDir = path.join(projectDir, 'ops', 'backup');
        if (!fs.existsSync(backupDir)) {
          fs.mkdirSync(backupDir, { recursive: true });
        }

        // Create backup script for database
        let dbBackupScript = '#!/bin/bash\n\n';
        dbBackupScript += '# Database backup script\n\n';
        dbBackupScript += '# Configuration\n';
        dbBackupScript += 'DB_USER=${DB_USER:-"dbuser"}\n';
        dbBackupScript += 'DB_PASSWORD=${DB_PASSWORD:-"dbpassword"}\n';
        dbBackupScript += 'DB_NAME=${DB_NAME:-"myapp"}\n';
        dbBackupScript += 'DB_HOST=${DB_HOST:-"localhost"}\n';
        dbBackupScript += 'BACKUP_DIR=${BACKUP_DIR:-"/backups"}\n';
        dbBackupScript += 'TIMESTAMP=$(date +"%Y%m%d_%H%M%S")\n';
        dbBackupScript += 'BACKUP_FILE="$BACKUP_DIR/${DB_NAME}_${TIMESTAMP}.sql.gz"\n\n';
        dbBackupScript += '# Create backup directory if it doesn\'t exist\n';
        dbBackupScript += 'mkdir -p $BACKUP_DIR\n\n';
        dbBackupScript += '# Perform backup\n';
        dbBackupScript += 'echo "Starting database backup..."\n';
        dbBackupScript += 'PGPASSWORD=$DB_PASSWORD pg_dump -h $DB_HOST -U $DB_USER $DB_NAME | gzip > $BACKUP_FILE\n\n';
        dbBackupScript += '# Check if backup was successful\n';
        dbBackupScript += 'if [ $? -eq 0 ]; then\n';
        dbBackupScript += '  echo "Backup completed successfully: $BACKUP_FILE"\n';
        dbBackupScript += 'else\n';
        dbBackupScript += '  echo "Backup failed!"\n';
        dbBackupScript += '  exit 1\n';
        dbBackupScript += 'fi\n\n';
        dbBackupScript += '# Cleanup old backups (keep last 7 days)\n';
        dbBackupScript += 'find $BACKUP_DIR -name "${DB_NAME}_*.sql.gz" -type f -mtime +7 -delete\n';
        dbBackupScript += 'echo "Old backups cleaned up."\n';

        // Write database backup script
        fs.writeFileSync(path.join(backupDir, 'db-backup.sh'), dbBackupScript, { mode: 0o755 });

        // Create backup script for files
        let fileBackupScript = '#!/bin/bash\n\n';
        fileBackupScript += '# File backup script\n\n';
        fileBackupScript += '# Configuration\n';
        fileBackupScript += 'SOURCE_DIR=${SOURCE_DIR:-"/app/data"}\n';
        fileBackupScript += 'BACKUP_DIR=${BACKUP_DIR:-"/backups"}\n';
        fileBackupScript += 'TIMESTAMP=$(date +"%Y%m%d_%H%M%S")\n';
        fileBackupScript += 'BACKUP_FILE="$BACKUP_DIR/files_${TIMESTAMP}.tar.gz"\n\n';
        fileBackupScript += '# Create backup directory if it doesn\'t exist\n';
        fileBackupScript += 'mkdir -p $BACKUP_DIR\n\n';
        fileBackupScript += '# Perform backup\n';
        fileBackupScript += 'echo "Starting file backup..."\n';
        fileBackupScript += 'tar -czf $BACKUP_FILE -C $(dirname $SOURCE_DIR) $(basename $SOURCE_DIR)\n\n';
        fileBackupScript += '# Check if backup was successful\n';
        fileBackupScript += 'if [ $? -eq 0 ]; then\n';
        fileBackupScript += '  echo "Backup completed successfully: $BACKUP_FILE"\n';
        fileBackupScript += 'else\n';
        fileBackupScript += '  echo "Backup failed!"\n';
        fileBackupScript += '  exit 1\n';
        fileBackupScript += 'fi\n\n';
        fileBackupScript += '# Cleanup old backups (keep last 7 days)\n';
        fileBackupScript += 'find $BACKUP_DIR -name "files_*.tar.gz" -type f -mtime +7 -delete\n';
        fileBackupScript += 'echo "Old backups cleaned up."\n';

        // Write file backup script
        fs.writeFileSync(path.join(backupDir, 'file-backup.sh'), fileBackupScript, { mode: 0o755 });

        // Create restore script for database
        let dbRestoreScript = '#!/bin/bash\n\n';
        dbRestoreScript += '# Database restore script\n\n';
        dbRestoreScript += '# Configuration\n';
        dbRestoreScript += 'DB_USER=${DB_USER:-"dbuser"}\n';
        dbRestoreScript += 'DB_PASSWORD=${DB_PASSWORD:-"dbpassword"}\n';
        dbRestoreScript += 'DB_NAME=${DB_NAME:-"myapp"}\n';
        dbRestoreScript += 'DB_HOST=${DB_HOST:-"localhost"}\n';
        dbRestoreScript += 'BACKUP_DIR=${BACKUP_DIR:-"/backups"}\n\n';
        dbRestoreScript += '# Check if backup file is provided\n';
        dbRestoreScript += 'if [ -z "$1" ]; then\n';
        dbRestoreScript += '  echo "Usage: $0 <backup_file>"\n';
        dbRestoreScript += '  echo "Available backups:"\n';
        dbRestoreScript += '  ls -la $BACKUP_DIR/${DB_NAME}_*.sql.gz\n';
        dbRestoreScript += '  exit 1\n';
        dbRestoreScript += 'fi\n\n';
        dbRestoreScript += 'BACKUP_FILE=$1\n\n';
        dbRestoreScript += '# Check if backup file exists\n';
        dbRestoreScript += 'if [ ! -f "$BACKUP_FILE" ]; then\n';
        dbRestoreScript += '  echo "Backup file not found: $BACKUP_FILE"\n';
        dbRestoreScript += '  exit 1\n';
        dbRestoreScript += 'fi\n\n';
        dbRestoreScript += '# Confirm restore\n';
        dbRestoreScript += 'echo "WARNING: This will overwrite the current database ($DB_NAME)."\n';
        dbRestoreScript += 'read -p "Are you sure you want to proceed? (y/n): " -n 1 -r\n';
        dbRestoreScript += 'echo\n';
        dbRestoreScript += 'if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n';
        dbRestoreScript += '  echo "Restore cancelled."\n';
        dbRestoreScript += '  exit 1\n';
        dbRestoreScript += 'fi\n\n';
        dbRestoreScript += '# Perform restore\n';
        dbRestoreScript += 'echo "Starting database restore..."\n';
        dbRestoreScript += 'gunzip -c $BACKUP_FILE | PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -U $DB_USER $DB_NAME\n\n';
        dbRestoreScript += '# Check if restore was successful\n';
        dbRestoreScript += 'if [ $? -eq 0 ]; then\n';
        dbRestoreScript += '  echo "Restore completed successfully."\n';
        dbRestoreScript += 'else\n';
        dbRestoreScript += '  echo "Restore failed!"\n';
        dbRestoreScript += '  exit 1\n';
        dbRestoreScript += 'fi\n';

        // Write database restore script
        fs.writeFileSync(path.join(backupDir, 'db-restore.sh'), dbRestoreScript, { mode: 0o755 });

        // Create restore script for files
        let fileRestoreScript = '#!/bin/bash\n\n';
        fileRestoreScript += '# File restore script\n\n';
        fileRestoreScript += '# Configuration\n';
        fileRestoreScript += 'TARGET_DIR=${TARGET_DIR:-"/app/data"}\n';
        fileRestoreScript += 'BACKUP_DIR=${BACKUP_DIR:-"/backups"}\n\n';
        fileRestoreScript += '# Check if backup file is provided\n';
        fileRestoreScript += 'if [ -z "$1" ]; then\n';
        fileRestoreScript += '  echo "Usage: $0 <backup_file>"\n';
        fileRestoreScript += '  echo "Available backups:"\n';
        fileRestoreScript += '  ls -la $BACKUP_DIR/files_*.tar.gz\n';
        fileRestoreScript += '  exit 1\n';
        fileRestoreScript += 'fi\n\n';
        fileRestoreScript += 'BACKUP_FILE=$1\n\n';
        fileRestoreScript += '# Check if backup file exists\n';
        fileRestoreScript += 'if [ ! -f "$BACKUP_FILE" ]; then\n';
        fileRestoreScript += '  echo "Backup file not found: $BACKUP_FILE"\n';
        fileRestoreScript += '  exit 1\n';
        fileRestoreScript += 'fi\n\n';
        fileRestoreScript += '# Confirm restore\n';
        fileRestoreScript += 'echo "WARNING: This will overwrite files in $TARGET_DIR."\n';
        fileRestoreScript += 'read -p "Are you sure you want to proceed? (y/n): " -n 1 -r\n';
        fileRestoreScript += 'echo\n';
        fileRestoreScript += 'if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n';
        fileRestoreScript += '  echo "Restore cancelled."\n';
        fileRestoreScript += '  exit 1\n';
        fileRestoreScript += 'fi\n\n';
        fileRestoreScript += '# Perform restore\n';
        fileRestoreScript += 'echo "Starting file restore..."\n';
        fileRestoreScript += 'mkdir -p $TARGET_DIR\n';
        fileRestoreScript += 'tar -xzf $BACKUP_FILE -C $(dirname $TARGET_DIR)\n\n';
        fileRestoreScript += '# Check if restore was successful\n';
        fileRestoreScript += 'if [ $? -eq 0 ]; then\n';
        fileRestoreScript += '  echo "Restore completed successfully."\n';
        fileRestoreScript += 'else\n';
        fileRestoreScript += '  echo "Restore failed!"\n';
        fileRestoreScript += '  exit 1\n';
        fileRestoreScript += 'fi\n';

        // Write file restore script
        fs.writeFileSync(path.join(backupDir, 'file-restore.sh'), fileRestoreScript, { mode: 0o755 });

        // Create cron job configuration
        let cronConfig = '# Cron jobs for backup\n\n';
        cronConfig += '# Database backup - daily at 1:00 AM\n';
        cronConfig += '0 1 * * * /app/ops/backup/db-backup.sh > /var/log/db-backup.log 2>&1\n\n';
        cronConfig += '# File backup - daily at 2:00 AM\n';
        cronConfig += '0 2 * * * /app/ops/backup/file-backup.sh > /var/log/file-backup.log 2>&1\n';

        // Write cron configuration
        fs.writeFileSync(path.join(backupDir, 'crontab.example'), cronConfig);

        // Create README.md for backup directory
        let readmeContent = '# Backup y Recuperación\n\n';
        readmeContent += 'Este directorio contiene scripts para realizar backups y recuperación de datos.\n\n';
        readmeContent += '## Scripts\n\n';
        readmeContent += '### Backup\n\n';
        readmeContent += '- `db-backup.sh`: Script para realizar backup de la base de datos\n';
        readmeContent += '- `file-backup.sh`: Script para realizar backup de archivos\n\n';
        readmeContent += '### Recuperación\n\n';
        readmeContent += '- `db-restore.sh`: Script para restaurar la base de datos desde un backup\n';
        readmeContent += '- `file-restore.sh`: Script para restaurar archivos desde un backup\n\n';
        readmeContent += '## Uso\n\n';
        readmeContent += '### Backup de Base de Datos\n\n';
        readmeContent += '```bash\n';
        readmeContent += './db-backup.sh\n';
        readmeContent += '```\n\n';
        readmeContent += 'Variables de entorno:\n';
        readmeContent += '- `DB_USER`: Usuario de la base de datos (default: "dbuser")\n';
        readmeContent += '- `DB_PASSWORD`: Contraseña de la base de datos (default: "dbpassword")\n';
        readmeContent += '- `DB_NAME`: Nombre de la base de datos (default: "myapp")\n';
        readmeContent += '- `DB_HOST`: Host de la base de datos (default: "localhost")\n';
        readmeContent += '- `BACKUP_DIR`: Directorio de backups (default: "/backups")\n\n';
        readmeContent += '### Backup de Archivos\n\n';
        readmeContent += '```bash\n';
        readmeContent += './file-backup.sh\n';
        readmeContent += '```\n\n';
        readmeContent += 'Variables de entorno:\n';
        readmeContent += '- `SOURCE_DIR`: Directorio a respaldar (default: "/app/data")\n';
        readmeContent += '- `BACKUP_DIR`: Directorio de backups (default: "/backups")\n\n';
        readmeContent += '### Restauración de Base de Datos\n\n';
        readmeContent += '```bash\n';
        readmeContent += './db-restore.sh /backups/myapp_20230101_120000.sql.gz\n';
        readmeContent += '```\n\n';
        readmeContent += '### Restauración de Archivos\n\n';
        readmeContent += '```bash\n';
        readmeContent += './file-restore.sh /backups/files_20230101_120000.tar.gz\n';
        readmeContent += '```\n\n';
        readmeContent += '## Automatización\n\n';
        readmeContent += 'Para automatizar los backups, configura los trabajos cron usando el archivo `crontab.example`:\n\n';
        readmeContent += '```bash\n';
        readmeContent += 'crontab crontab.example\n';
        readmeContent += '```\n';

        // Write README.md
        fs.writeFileSync(path.join(backupDir, 'README.md'), readmeContent);

        return backupDir;
      } catch (error) {
        Logger.error(`Error creating backup files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates scaling configuration files for the project
     * @param projectDir - The project directory
     * @param config - The scaling configuration
     * @returns The path to the scaling directory
     */
    async createScalingFiles(projectDir: string, config: ScalingConfig): Promise<string> {
      try {
        Logger.info('Creating scaling configuration files...');
        
        const scalingDir = path.join(projectDir, 'ops', 'scaling');
        if (!fs.existsSync(scalingDir)) {
          fs.mkdirSync(scalingDir, { recursive: true });
        }

        // Create horizontal pod autoscaler for Kubernetes
        let hpaYaml = 'apiVersion: autoscaling/v2\n';
        hpaYaml += 'kind: HorizontalPodAutoscaler\n';
        hpaYaml += 'metadata:\n';
        hpaYaml += '  name: app-hpa\n';
        hpaYaml += 'spec:\n';
        hpaYaml += '  scaleTargetRef:\n';
        hpaYaml += '    apiVersion: apps/v1\n';
        hpaYaml += '    kind: Deployment\n';
        hpaYaml += '    name: app-deployment\n';
        hpaYaml += `  minReplicas: ${config.minReplicas || 2}\n`;
        hpaYaml += `  maxReplicas: ${config.maxReplicas || 10}\n`;
        hpaYaml += '  metrics:\n';
        hpaYaml += '  - type: Resource\n';
        hpaYaml += '    resource:\n';
        hpaYaml += '      name: cpu\n';
        hpaYaml += '      target:\n';
        hpaYaml += '        type: Utilization\n';
        hpaYaml += `        averageUtilization: ${config.cpuThreshold || 70}\n`;
        hpaYaml += '  - type: Resource\n';
        hpaYaml += '    resource:\n';
        hpaYaml += '      name: memory\n';
        hpaYaml += '      target:\n';
        hpaYaml += '        type: Utilization\n';
        hpaYaml += `        averageUtilization: ${config.memoryThreshold || 80}\n`;

        // Write horizontal pod autoscaler file
        fs.writeFileSync(path.join(scalingDir, 'kubernetes-hpa.yaml'), hpaYaml);

        // Create vertical pod autoscaler for Kubernetes
        let vpaYaml = 'apiVersion: autoscaling.k8s.io/v1\n';
        vpaYaml += 'kind: VerticalPodAutoscaler\n';
        vpaYaml += 'metadata:\n';
        vpaYaml += '  name: app-vpa\n';
        vpaYaml += 'spec:\n';
        vpaYaml += '  targetRef:\n';
        vpaYaml += '    apiVersion: apps/v1\n';
        vpaYaml += '    kind: Deployment\n';
        vpaYaml += '    name: app-deployment\n';
        vpaYaml += '  updatePolicy:\n';
        vpaYaml += '    updateMode: "Auto"\n';
        vpaYaml += '  resourcePolicy:\n';
        vpaYaml += '    containerPolicies:\n';
        vpaYaml += '    - containerName: "*"\n';
        vpaYaml += '      minAllowed:\n';
        vpaYaml += '        cpu: 100m\n';
        vpaYaml += '        memory: 128Mi\n';
        vpaYaml += '      maxAllowed:\n';
        vpaYaml += '        cpu: 4\n';
        vpaYaml += '        memory: 8Gi\n';
        vpaYaml += '      controlledResources: ["cpu", "memory"]\n';

        // Write vertical pod autoscaler file
        fs.writeFileSync(path.join(scalingDir, 'kubernetes-vpa.yaml'), vpaYaml);

        // Create AWS Auto Scaling configuration
        let awsAutoScalingJson = '{\n';
        awsAutoScalingJson += '  "AWSTemplateFormatVersion": "2010-09-09",\n';
        awsAutoScalingJson += '  "Resources": {\n';
        awsAutoScalingJson += '    "AppAutoScalingGroup": {\n';
        awsAutoScalingJson += '      "Type": "AWS::AutoScaling::AutoScalingGroup",\n';
        awsAutoScalingJson += '      "Properties": {\n';
        awsAutoScalingJson += '        "LaunchConfigurationName": { "Ref": "AppLaunchConfig" },\n';
        awsAutoScalingJson += '        "MinSize": ' + (config.minReplicas || 2) + ',\n';
        awsAutoScalingJson += '        "MaxSize": ' + (config.maxReplicas || 10) + ',\n';
        awsAutoScalingJson += '        "DesiredCapacity": ' + (config.minReplicas || 2) + ',\n';
        awsAutoScalingJson += '        "VPCZoneIdentifier": { "Ref": "Subnets" },\n';
        awsAutoScalingJson += '        "TargetGroupARNs": [{ "Ref": "AppTargetGroup" }],\n';
        awsAutoScalingJson += '        "Tags": [\n';
        awsAutoScalingJson += '          {\n';
        awsAutoScalingJson += '            "Key": "Name",\n';
        awsAutoScalingJson += '            "Value": "app-instance",\n';
        awsAutoScalingJson += '            "PropagateAtLaunch": true\n';
        awsAutoScalingJson += '          }\n';
        awsAutoScalingJson += '        ]\n';
        awsAutoScalingJson += '      }\n';
        awsAutoScalingJson += '    },\n';
        awsAutoScalingJson += '    "AppScaleUpPolicy": {\n';
        awsAutoScalingJson += '      "Type": "AWS::AutoScaling::ScalingPolicy",\n';
        awsAutoScalingJson += '      "Properties": {\n';
        awsAutoScalingJson += '        "AutoScalingGroupName": { "Ref": "AppAutoScalingGroup" },\n';
        awsAutoScalingJson += '        "PolicyType": "TargetTrackingScaling",\n';
        awsAutoScalingJson += '        "TargetTrackingConfiguration": {\n';
        awsAutoScalingJson += '          "PredefinedMetricSpecification": {\n';
        awsAutoScalingJson += '            "PredefinedMetricType": "ASGAverageCPUUtilization"\n';
        awsAutoScalingJson += '          },\n';
        awsAutoScalingJson += '          "TargetValue": ' + (config.cpuThreshold || 70) + '\n';
        awsAutoScalingJson += '        }\n';
        awsAutoScalingJson += '      }\n';
        awsAutoScalingJson += '    }\n';
        awsAutoScalingJson += '  }\n';
        awsAutoScalingJson += '}\n';

        // Write AWS Auto Scaling configuration
        fs.writeFileSync(path.join(scalingDir, 'aws-autoscaling.json'), awsAutoScalingJson);

        // Create Docker Swarm scaling script
        let swarmScalingScript = '#!/bin/bash\n\n';
        swarmScalingScript += '# Docker Swarm service scaling script\n\n';
        swarmScalingScript += '# Configuration\n';
        swarmScalingScript += 'SERVICE_NAME=${SERVICE_NAME:-"app_service"}\n';
        swarmScalingScript += 'MIN_REPLICAS=${MIN_REPLICAS:-' + (config.minReplicas || 2) + '}\n';
        swarmScalingScript += 'MAX_REPLICAS=${MAX_REPLICAS:-' + (config.maxReplicas || 10) + '}\n';
        swarmScalingScript += 'CPU_THRESHOLD=${CPU_THRESHOLD:-' + (config.cpuThreshold || 70) + '}\n';
        swarmScalingScript += 'CHECK_INTERVAL=${CHECK_INTERVAL:-60}\n\n';
        swarmScalingScript += '# Function to get current CPU usage\n';
        swarmScalingScript += 'get_cpu_usage() {\n';
        swarmScalingScript += '  local service_name=$1\n';
        swarmScalingScript += '  local containers=$(docker ps --filter "name=$service_name" --format "{{.ID}}")\n';
        swarmScalingScript += '  local total_cpu=0\n';
        swarmScalingScript += '  local count=0\n\n';
        swarmScalingScript += '  for container in $containers; do\n';
        swarmScalingScript += '    local cpu=$(docker stats --no-stream $container --format "{{.CPUPerc}}" | sed \'s/%//\')\n';
        swarmScalingScript += '    total_cpu=$(echo "$total_cpu + $cpu" | bc)\n';
        swarmScalingScript += '    count=$((count + 1))\n';
        swarmScalingScript += '  done\n\n';
        swarmScalingScript += '  if [ $count -eq 0 ]; then\n';
        swarmScalingScript += '    echo 0\n';
        swarmScalingScript += '    return\n';
        swarmScalingScript += '  fi\n\n';
        swarmScalingScript += '  local avg_cpu=$(echo "scale=2; $total_cpu / $count" | bc)\n';
        swarmScalingScript += '  echo $avg_cpu\n';
        swarmScalingScript += '}\n';
        swarmScalingScript += '  echo $avg_cpu\n';
        swarmScalingScript += '}\n\n';
        swarmScalingScript += '# Function to get current number of replicas\n';
        swarmScalingScript += 'get_current_replicas() {\n';
        swarmScalingScript += '  local service_name=$1\n';
        swarmScalingScript += '  docker service inspect $service_name --format "{{.Spec.Mode.Replicated.Replicas}}"\n';
        swarmScalingScript += '}\n\n';
        swarmScalingScript += '# Function to scale service\n';
        swarmScalingScript += 'scale_service() {\n';
        swarmScalingScript += '  local service_name=$1\n';
        swarmScalingScript += '  local replicas=$2\n';
        swarmScalingScript += '  echo "Scaling service $service_name to $replicas replicas..."\n';
        swarmScalingScript += '  docker service scale $service_name=$replicas\n';
        swarmScalingScript += '}\n\n';
        swarmScalingScript += '# Main loop\n';
        swarmScalingScript += 'echo "Starting auto-scaling for service $SERVICE_NAME..."\n';
        swarmScalingScript += 'echo "CPU threshold: $CPU_THRESHOLD%"\n';
        swarmScalingScript += 'echo "Min replicas: $MIN_REPLICAS, Max replicas: $MAX_REPLICAS"\n';
        swarmScalingScript += 'echo "Check interval: $CHECK_INTERVAL seconds"\n\n';
        swarmScalingScript += 'while true; do\n';
        swarmScalingScript += '  # Get current CPU usage\n';
        swarmScalingScript += '  CPU_USAGE=$(get_cpu_usage $SERVICE_NAME)\n';
        swarmScalingScript += '  # Get current number of replicas\n';
        swarmScalingScript += '  CURRENT_REPLICAS=$(get_current_replicas $SERVICE_NAME)\n\n';
        swarmScalingScript += '  echo "$(date) - Current CPU usage: $CPU_USAGE%, Replicas: $CURRENT_REPLICAS"\n\n';
        swarmScalingScript += '  # Scale up if CPU usage is above threshold\n';
        swarmScalingScript += '  if (( $(echo "$CPU_USAGE > $CPU_THRESHOLD" | bc -l) )); then\n';
        swarmScalingScript += '    if [ $CURRENT_REPLICAS -lt $MAX_REPLICAS ]; then\n';
        swarmScalingScript += '      NEW_REPLICAS=$((CURRENT_REPLICAS + 1))\n';
        swarmScalingScript += '      echo "CPU usage above threshold. Scaling up to $NEW_REPLICAS replicas."\n';
        swarmScalingScript += '      scale_service $SERVICE_NAME $NEW_REPLICAS\n';
        swarmScalingScript += '    else\n';
        swarmScalingScript += '      echo "Already at maximum replicas ($MAX_REPLICAS)."\n';
        swarmScalingScript += '    fi\n';
        swarmScalingScript += '  # Scale down if CPU usage is below threshold - 20%\n';
        swarmScalingScript += '  elif (( $(echo "$CPU_USAGE < ($CPU_THRESHOLD - 20)" | bc -l) )); then\n';
        swarmScalingScript += '    if [ $CURRENT_REPLICAS -gt $MIN_REPLICAS ]; then\n';
        swarmScalingScript += '      NEW_REPLICAS=$((CURRENT_REPLICAS - 1))\n';
        swarmScalingScript += '      echo "CPU usage below threshold - 20%. Scaling down to $NEW_REPLICAS replicas."\n';
        swarmScalingScript += '      scale_service $SERVICE_NAME $NEW_REPLICAS\n';
        swarmScalingScript += '    else\n';
        swarmScalingScript += '      echo "Already at minimum replicas ($MIN_REPLICAS)."\n';
        swarmScalingScript += '    fi\n';
        swarmScalingScript += '  else\n';
        swarmScalingScript += '    echo "CPU usage within acceptable range. No scaling needed."\n';
        swarmScalingScript += '  fi\n\n';
        swarmScalingScript += '  # Wait for next check\n';
        swarmScalingScript += '  sleep $CHECK_INTERVAL\n';
        swarmScalingScript += 'done\n';

        // Write Docker Swarm scaling script
        fs.writeFileSync(path.join(scalingDir, 'swarm-autoscale.sh'), swarmScalingScript, { mode: 0o755 });

        // Create README.md for scaling directory
        let readmeContent = '# Configuración de Escalado Automático\n\n';
        readmeContent += 'Este directorio contiene configuraciones y scripts para el escalado automático de la aplicación en diferentes plataformas.\n\n';
        readmeContent += '## Kubernetes\n\n';
        readmeContent += '### Escalado Horizontal (HPA)\n\n';
        readmeContent += 'El archivo `kubernetes-hpa.yaml` define un Horizontal Pod Autoscaler para Kubernetes que escala automáticamente los pods basándose en el uso de CPU y memoria.\n\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f kubernetes-hpa.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '### Escalado Vertical (VPA)\n\n';
        readmeContent += 'El archivo `kubernetes-vpa.yaml` define un Vertical Pod Autoscaler para Kubernetes que ajusta automáticamente los recursos (CPU y memoria) asignados a los pods.\n\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -f kubernetes-vpa.yaml\n';
        readmeContent += '```\n\n';
        readmeContent += '## AWS Auto Scaling\n\n';
        readmeContent += 'El archivo `aws-autoscaling.json` define una plantilla de CloudFormation para configurar un grupo de Auto Scaling en AWS.\n\n';
        readmeContent += '```bash\n';
        readmeContent += 'aws cloudformation create-stack --stack-name app-autoscaling --template-body file://aws-autoscaling.json --parameters ParameterKey=Subnets,ParameterValue=subnet-1,subnet-2\n';
        readmeContent += '```\n\n';
        readmeContent += '## Docker Swarm\n\n';
        readmeContent += 'El script `swarm-autoscale.sh` implementa un escalador automático para servicios de Docker Swarm basado en el uso de CPU.\n\n';
        readmeContent += '```bash\n';
        readmeContent += './swarm-autoscale.sh\n';
        readmeContent += '```\n\n';
        readmeContent += 'Variables de entorno:\n';
        readmeContent += '- `SERVICE_NAME`: Nombre del servicio a escalar (default: "app_service")\n';
        readmeContent += '- `MIN_REPLICAS`: Número mínimo de réplicas (default: ' + (config.minReplicas || 2) + ')\n';
        readmeContent += '- `MAX_REPLICAS`: Número máximo de réplicas (default: ' + (config.maxReplicas || 10) + ')\n';
        readmeContent += '- `CPU_THRESHOLD`: Umbral de uso de CPU para escalar (default: ' + (config.cpuThreshold || 70) + ')\n';
        readmeContent += '- `CHECK_INTERVAL`: Intervalo de verificación en segundos (default: 60)\n\n';
        readmeContent += '## Configuración\n\n';
        readmeContent += 'La configuración actual está establecida con los siguientes parámetros:\n\n';
        readmeContent += '- Réplicas mínimas: ' + (config.minReplicas || 2) + '\n';
        readmeContent += '- Réplicas máximas: ' + (config.maxReplicas || 10) + '\n';
        readmeContent += '- Umbral de CPU: ' + (config.cpuThreshold || 70) + '%\n';
        readmeContent += '- Umbral de memoria: ' + (config.memoryThreshold || 80) + '%\n';

        // Write README.md
        fs.writeFileSync(path.join(scalingDir, 'README.md'), readmeContent);

        return scalingDir;
      } catch (error) {
        Logger.error(`Error creating scaling files: ${error.message}`);
        throw error;
      }
    }

    /**
     * Creates monitoring configuration files for the project
     * @param projectDir - The project directory
     * @param config - The monitoring configuration
     * @returns The path to the monitoring directory
     */
    async createMonitoringFiles(projectDir: string, config: MonitoringConfig): Promise<string> {
      try {
        Logger.info('Creating monitoring configuration files...');
        
        const monitoringDir = path.join(projectDir, 'ops', 'monitoring');
        if (!fs.existsSync(monitoringDir)) {
          fs.mkdirSync(monitoringDir, { recursive: true });
        }

        // Create Prometheus directory
        const prometheusDir = path.join(monitoringDir, 'prometheus');
        if (!fs.existsSync(prometheusDir)) {
          fs.mkdirSync(prometheusDir, { recursive: true });
        }

        // Create prometheus.yml
        let prometheusContent = 'global:\n';
        prometheusContent += '  scrape_interval: 15s\n';
        prometheusContent += '  evaluation_interval: 15s\n\n';
        prometheusContent += 'alerting:\n';
        prometheusContent += '  alertmanagers:\n';
        prometheusContent += '  - static_configs:\n';
        prometheusContent += '    - targets:\n';
        prometheusContent += '      - alertmanager:9093\n\n';
        prometheusContent += 'rule_files:\n';
        prometheusContent += '  - "alert_rules.yml"\n\n';
        prometheusContent += 'scrape_configs:\n';
        prometheusContent += '  - job_name: "prometheus"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '      - targets: ["localhost:9090"]\n\n';
        prometheusContent += '  - job_name: "node"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '      - targets: ["node-exporter:9100"]\n\n';
        prometheusContent += '  - job_name: "cadvisor"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '      - targets: ["cadvisor:8080"]\n\n';

        // Add application-specific targets
        if (config.targets && config.targets.length > 0) {
          config.targets.forEach((target, index) => {
            prometheusContent += `  - job_name: "${target.name || 'app-' + (index + 1)}"\n`;
            prometheusContent += '    static_configs:\n';
            prometheusContent += `      - targets: ["${target.endpoint}"]\n\n`;
          });
        } else {
          // Add default application target
          prometheusContent += '  - job_name: "application"\n';
          prometheusContent += '    static_configs:\n';
          prometheusContent += '      - targets: ["app:8080"]\n\n';
        }

        // Write prometheus.yml
        fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);

        // Create alert_rules.yml
        let alertRulesContent = 'groups:\n';
        alertRulesContent += '- name: alert_rules\n';
        alertRulesContent += '  rules:\n';
        alertRulesContent += '  - alert: HighCPULoad\n';
        alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > ' + (config.cpuThreshold || 80) + '\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High CPU load (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "CPU load is > ' + (config.cpuThreshold || 80) + '%\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}"\n\n';
        
        alertRulesContent += '  - alert: HighMemoryLoad\n';
        alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > ' + (config.memoryThreshold || 80) + '\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High memory load (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "Memory load is > ' + (config.memoryThreshold || 80) + '%\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}"\n\n';
        
        alertRulesContent += '  - alert: HighDiskUsage\n';
        alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High disk usage (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "Disk usage is > 85%\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}"\n\n';
        
        alertRulesContent += '  - alert: InstanceDown\n';
        alertRulesContent += '    expr: up == 0\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: critical\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "Instance down (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "Instance has been down for more than 5 minutes\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}"\n';

        // Write alert_rules.yml
        fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);

        // Create Alertmanager configuration
        const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
        if (!fs.existsSync(alertmanagerDir)) {
          fs.mkdirSync(alertmanagerDir, { recursive: true });
        }

        // Create alertmanager.yml
        let alertmanagerContent = 'global:\n';
        alertmanagerContent += '  resolve_timeout: 5m\n';
        alertmanagerContent += '  smtp_smarthost: "smtp.example.com:587"\n';
        alertmanagerContent += '  smtp_from: "alertmanager@example.com"\n';
        alertmanagerContent += '  smtp_auth_username: "alertmanager"\n';
        alertmanagerContent += '  smtp_auth_password: "password"\n\n';
        alertmanagerContent += 'route:\n';
        alertmanagerContent += '  group_by: [\'alertname\', \'instance\']\n';
        alertmanagerContent += '  group_wait: 30s\n';
        alertmanagerContent += '  group_interval: 5m\n';
        alertmanagerContent += '  repeat_interval: 1h\n';
        alertmanagerContent += '  receiver: \'email\'\n\n';
        alertmanagerContent += 'receivers:\n';
        alertmanagerContent += '- name: \'email\'\n';
        alertmanagerContent += '  email_configs:\n';
        alertmanagerContent += '  - to: "alerts@example.com"\n';
        alertmanagerContent += '    send_resolved: true\n\n';
        alertmanagerContent += 'inhibit_rules:\n';
        alertmanagerContent += '  - source_match:\n';
        alertmanagerContent += '      severity: \'critical\'\n';
        alertmanagerContent += '    target_match:\n';
        alertmanagerContent += '      severity: \'warning\'\n';
        alertmanagerContent += '    equal: [\'alertname\', \'instance\']\n';

        // Write alertmanager.yml
        fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);

        // Create Grafana configuration
        const grafanaDir = path.join(monitoringDir, 'grafana');
        if (!fs.existsSync(grafanaDir)) {
          fs.mkdirSync(grafanaDir, { recursive: true });
        }

        // Create datasources.yml
        let datasourcesContent = 'apiVersion: 1\n\n';
        datasourcesContent += 'datasources:\n';
        datasourcesContent += '  - name: Prometheus\n';
        datasourcesContent += '    type: prometheus\n';
        datasourcesContent += '    access: proxy\n';
        datasourcesContent += '    url: http://prometheus:9090\n';
        datasourcesContent += '    isDefault: true\n';
        datasourcesContent += '    editable: true\n';

        // Write datasources.yml
        fs.writeFileSync(path.join(grafanaDir, 'datasources.yml'), datasourcesContent);

        // Create dashboards directory
        const dashboardsDir = path.join(grafanaDir, 'dashboards');
        if (!fs.existsSync(dashboardsDir)) {
          fs.mkdirSync(dashboardsDir, { recursive: true });
        }

        // Create dashboard.json (simplified version)
        let dashboardContent = '{\n';
        dashboardContent += '  "annotations": {\n';
        dashboardContent += '    "list": [\n';
        dashboardContent += '      {\n';
        dashboardContent += '        "builtIn": 1,\n';
        dashboardContent += '        "datasource": "-- Grafana --",\n';
        dashboardContent += '        "enable": true,\n';
        dashboardContent += '        "hide": true,\n';
        dashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
        dashboardContent += '        "name": "Annotations & Alerts",\n';
        dashboardContent += '        "type": "dashboard"\n';
        dashboardContent += '      }\n';
        dashboardContent += '    ]\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "editable": true,\n';
        dashboardContent += '  "gnetId": null,\n';
        dashboardContent += '  "graphTooltip": 0,\n';
        dashboardContent += '  "id": 1,\n';
        dashboardContent += '  "links": [],\n';
        dashboardContent += '  "panels": [\n';
        dashboardContent += '    {\n';
        dashboardContent += '      "alert": {\n';
        dashboardContent += '        "conditions": [\n';
        dashboardContent += '          {\n';
        dashboardContent += '            "evaluator": {\n';
        dashboardContent += '              "params": [\n';
        dashboardContent += '                ' + (config.cpuThreshold || 80) + '\n';
        dashboardContent += '              ],\n';
        dashboardContent += '              "type": "gt"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "operator": {\n';
        dashboardContent += '              "type": "and"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "query": {\n';
        dashboardContent += '              "params": [\n';
        dashboardContent += '                "A",\n';
        dashboardContent += '                "5m",\n';
        dashboardContent += '                "now"\n';
        dashboardContent += '              ]\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "reducer": {\n';
        dashboardContent += '              "params": [],\n';
        dashboardContent += '              "type": "avg"\n';
        dashboardContent += '            },\n';
        dashboardContent += '            "type": "query"\n';
        dashboardContent += '          }\n';
        dashboardContent += '        ],\n';
        dashboardContent += '        "executionErrorState": "alerting",\n';
        dashboardContent += '        "frequency": "60s",\n';
        dashboardContent += '        "handler": 1,\n';
        dashboardContent += '        "name": "CPU Usage alert",\n';
        dashboardContent += '        "noDataState": "no_data",\n';
        dashboardContent += '        "notifications": []\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "aliasColors": {},\n';
        dashboardContent += '      "bars": false,\n';
        dashboardContent += '      "dashLength": 10,\n';
        dashboardContent += '      "dashes": false,\n';
        dashboardContent += '      "datasource": "Prometheus",\n';
        dashboardContent += '      "fieldConfig": {\n';
        dashboardContent += '        "defaults": {\n';
        dashboardContent += '          "custom": {}\n';
        dashboardContent += '        },\n';
        dashboardContent += '        "overrides": []\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "fill": 1,\n';
        dashboardContent += '      "fillGradient": 0,\n';
        dashboardContent += '      "gridPos": {\n';
        dashboardContent += '        "h": 9,\n';
        dashboardContent += '        "w": 12,\n';
        dashboardContent += '        "x": 0,\n';
        dashboardContent += '        "y": 0\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "hiddenSeries": false,\n';
        dashboardContent += '      "id": 2,\n';
        dashboardContent += '      "legend": {\n';
        dashboardContent += '        "avg": false,\n';
        dashboardContent += '        "current": false,\n';
        dashboardContent += '        "max": false,\n';
        dashboardContent += '        "min": false,\n';
        dashboardContent += '        "show": true,\n';
        dashboardContent += '        "total": false,\n';
        dashboardContent += '        "values": false\n';
        dashboardContent += '      },\n';
        dashboardContent += '      "lines": true,\n';
        dashboardContent += '      "linewidth": 1,\n';
        dashboardContent += '      "title": "CPU Usage",\n';
        dashboardContent += '      "type": "graph"\n';
        dashboardContent += '    }\n';
        dashboardContent += '  ],\n';
        dashboardContent += '  "schemaVersion": 26,\n';
        dashboardContent += '  "style": "dark",\n';
        dashboardContent += '  "tags": [],\n';
        dashboardContent += '  "templating": {\n';
        dashboardContent += '    "list": []\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "time": {\n';
        dashboardContent += '    "from": "now-6h",\n';
        dashboardContent += '    "to": "now"\n';
        dashboardContent += '  },\n';
        dashboardContent += '  "timepicker": {},\n';
        dashboardContent += '  "timezone": "",\n';
        dashboardContent += '  "title": "System Monitoring",\n';
        dashboardContent += '  "uid": "system-monitoring",\n';
        dashboardContent += '  "version": 1\n';
        dashboardContent += '}\n';

        // Write dashboard.json
        fs.writeFileSync(path.join(dashboardsDir, 'dashboard.json'), dashboardContent);

        // Create dashboard.yml
        let dashboardYamlContent = 'apiVersion: 1\n\n';
        dashboardYamlContent += 'providers:\n';
        dashboardYamlContent += '  - name: \'default\'\n';
        dashboardYamlContent += '    orgId: 1\n';
        dashboardYamlContent += '    folder: \'\'\n';
        dashboardYamlContent += '    type: file\n';
        dashboardYamlContent += '    disableDeletion: false\n';
        dashboardYamlContent += '    editable: true\n';
        dashboardYamlContent += '    options:\n';
        dashboardYamlContent += '      path: /etc/grafana/dashboards\n';

        // Write dashboard.yml
        fs.writeFileSync(path.join(grafanaDir, 'dashboard.yml'), dashboardYamlContent);

        // Create docker-compose.yml for monitoring
        let dockerComposeContent = 'version: "3.8"\n\n';
        dockerComposeContent += 'services:\n';
        dockerComposeContent += '  prometheus:\n';
        dockerComposeContent += '    image: prom/prometheus:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
        dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
        dockerComposeContent += '      - prometheus_data:/prometheus\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
        dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
        dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
        dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9090:9090"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  alertmanager:\n';
        dockerComposeContent += '    image: prom/alertmanager:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
        dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
        dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9093:9093"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  grafana:\n';
        dockerComposeContent += '    image: grafana/grafana:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
        dockerComposeContent += '      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml\n';
        dockerComposeContent += '      - ./grafana/dashboards:/etc/grafana/dashboards\n';
        dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
        dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
        dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "3000:3000"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  node-exporter:\n';
        dockerComposeContent += '    image: prom/node-exporter:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - /proc:/host/proc:ro\n';
        dockerComposeContent += '      - /sys:/host/sys:ro\n';
        dockerComposeContent += '      - /:/rootfs:ro\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
        dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
        dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9100:9100"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  cadvisor:\n';
        dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - /:/rootfs:ro\n';
        dockerComposeContent += '      - /var/run:/var/run:ro\n';
        dockerComposeContent += '      - /sys:/sys:ro\n';
        dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "8080:8080"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += 'networks:\n';
        dockerComposeContent += '  monitoring-network:\n';
        dockerComposeContent += '    driver: bridge\n\n';
        
        dockerComposeContent += 'volumes:\n';
        dockerComposeContent += '  prometheus_data:\n';
        dockerComposeContent += '    driver: local\n';
        dockerComposeContent += '  alertmanager_data:\n';
        dockerComposeContent += '    driver: local\n';
        dockerComposeContent += '  grafana_data:\n';
        dockerComposeContent += '    driver: local\n';

        // Write docker-compose.yml
        fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);

        // Create README.md
        let readmeContent = '# Monitoring Stack\n\n';
        readmeContent += 'Este directorio contiene la configuración para un stack de monitoreo completo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
        readmeContent += '## Componentes\n\n';
        readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
        readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
        readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
        readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
        readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
        readmeContent += '## Inicio Rápido\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Iniciar el stack de monitoreo\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += '## Acceso\n\n';
        readmeContent += '- **Prometheus**: http://localhost:9090\n';
        readmeContent += '- **Alertmanager**: http://localhost:9093\n';
        readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
        readmeContent += '- **Node Exporter**: http://localhost:9100\n';
        readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
        readmeContent += '## Personalización\n\n';
        readmeContent += '### Prometheus\n\n';
        readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
        readmeContent += '### Alertmanager\n\n';
        readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
        readmeContent += '### Grafana\n\n';
        readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/dashboard.yml` si es necesario.\n';

        // Write README.md
        fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);

        // Create ELK stack directory
        const elkDir = path.join(monitoringDir, 'elk');
        if (!fs.existsSync(elkDir)) {
          fs.mkdirSync(elkDir, { recursive: true });
        }

        // Create docker-compose.yml for ELK stack
        let elkComposeContent = 'version: "3.8"\n\n';
        elkComposeContent += 'services:\n';
        elkComposeContent += '  elasticsearch:\n';
        elkComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - discovery.type=single-node\n';
        elkComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "9200:9200"\n';
        elkComposeContent += '      - "9300:9300"\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  logstash:\n';
        elkComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "5000:5000"\n';
        elkComposeContent += '      - "9600:9600"\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  kibana:\n';
        elkComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
        elkComposeContent += '    ports:\n';
        elkComposeContent += '      - "5601:5601"\n';
        elkComposeContent += '    environment:\n';
        elkComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += '  filebeat:\n';
        elkComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
        elkComposeContent += '    user: root\n';
        elkComposeContent += '    volumes:\n';
        elkComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
        elkComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
        elkComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
        elkComposeContent += '    networks:\n';
        elkComposeContent += '      - elk-network\n';
        elkComposeContent += '    depends_on:\n';
        elkComposeContent += '      - elasticsearch\n';
        elkComposeContent += '      - logstash\n';
        elkComposeContent += '    restart: unless-stopped\n\n';
        
        elkComposeContent += 'networks:\n';
        elkComposeContent += '  elk-network:\n';
        elkComposeContent += '    driver: bridge\n\n';
        
        elkComposeContent += 'volumes:\n';
        elkComposeContent += '  elasticsearch_data:\n';
        elkComposeContent += '    driver: local\n';

        // Write docker-compose.yml for ELK stack
        fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), elkComposeContent);

        // Create Logstash pipeline directory
        const logstashDir = path.join(elkDir, 'logstash');
        if (!fs.existsSync(logstashDir)) {
          fs.mkdirSync(logstashDir, { recursive: true });
        }

        const pipelineDir = path.join(logstashDir, 'pipeline');
        if (!fs.existsSync(pipelineDir)) {
          fs.mkdirSync(pipelineDir, { recursive: true });
        }

        // Create logstash.conf
        let logstashConfContent = 'input {\n';
        logstashConfContent += '  beats {\n';
        logstashConfContent += '    port => 5000\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n\n';
        logstashConfContent += 'filter {\n';
        logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  } else {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n\n';
        logstashConfContent += 'output {\n';
        logstashConfContent += '  elasticsearch {\n';
        logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
        logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n';

        // Write logstash.conf
        fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);

        // Create Filebeat directory
        const filebeatDir = path.join(elkDir, 'filebeat');
        if (!fs.existsSync(filebeatDir)) {
          fs.mkdirSync(filebeatDir, { recursive: true });
        }

        // Create filebeat.yml
        let filebeatContent = 'filebeat.inputs:\n';
        filebeatContent += '- type: container\n';
        filebeatContent += '  paths:\n';
        filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
        filebeatContent += '  processors:\n';
        filebeatContent += '    - add_docker_metadata:\n';
        filebeatContent += '        host: "unix:///var/run/docker.sock"\n\n';
        filebeatContent += 'processors:\n';
        filebeatContent += '  - add_host_metadata: ~\n';
        filebeatContent += '  - add_cloud_metadata: ~\n\n';
        filebeatContent += 'output.logstash:\n';
        filebeatContent += '  hosts: ["logstash:5000"]\n';

        // Write filebeat.yml
        fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);

        // Create README.md for ELK stack
        let elkReadmeContent = '# ELK Stack para Logging\n\n';
        elkReadmeContent += 'Este directorio contiene la configuración para un stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat para la recolección y análisis de logs.\n\n';
        elkReadmeContent += '## Componentes\n\n';
        elkReadmeContent += '- **Elasticsearch**: Motor de búsqueda y análisis\n';
        elkReadmeContent += '- **Logstash**: Procesamiento de datos y logs\n';
        elkReadmeContent += '- **Kibana**: Visualización y exploración de datos\n';
        elkReadmeContent += '- **Filebeat**: Recolector de logs\n\n';
        elkReadmeContent += '## Inicio Rápido\n\n';
        elkReadmeContent += '```bash\n';
        elkReadmeContent += '# Iniciar el stack ELK\n';
        elkReadmeContent += 'docker-compose up -d\n';
        elkReadmeContent += '```\n\n';
        elkReadmeContent += '## Acceso\n\n';
        elkReadmeContent += '- **Elasticsearch**: http://localhost:9200\n';
        elkReadmeContent += '- **Kibana**: http://localhost:5601\n\n';
        elkReadmeContent += '## Personalización\n\n';
        elkReadmeContent += '### Logstash\n\n';
        elkReadmeContent += 'Edita `logstash/pipeline/logstash.conf` para modificar el procesamiento de logs.\n\n';
        elkReadmeContent += '### Filebeat\n\n';
        elkReadmeContent += 'Edita `filebeat/filebeat.yml` para configurar la recolección de logs.\n';

        // Write README.md for ELK stack
        fs.writeFileSync(path.join(elkDir, 'README.md'), elkReadmeContent);

        // Return success message
        return {
          success: true,
          message: 'Archivos de monitoreo creados exitosamente',
          files: [
            path.join(monitoringDir, 'docker-compose.yml'),
            path.join(prometheusDir, 'prometheus.yml'),
            path.join(prometheusDir, 'alert_rules.yml'),
            path.join(alertmanagerDir, 'alertmanager.yml'),
            path.join(grafanaDir, 'datasources.yml'),
            path.join(grafanaDir, 'dashboard.yml'),
            path.join(dashboardsDir, 'dashboard.json'),
            path.join(elkDir, 'docker-compose.yml'),
            path.join(pipelineDir, 'logstash.conf'),
            path.join(filebeatDir, 'filebeat.yml')
          ]
        };
      } catch (error) {
        this.logger.error(`Error al crear archivos de monitoreo: ${error.message}`);
        return {
          success: false,
          message: `Error al crear archivos de monitoreo: ${error.message}`,
          error
        };
      }
    }

    /**
     * Crea archivos de configuración para CI/CD
     * @param projectPath Ruta del proyecto
     * @param config Configuración de CI/CD
     * @returns Resultado de la operación
     */
    async createCICDFiles(projectPath: string, config: any = {}): Promise<any> {
      try {
        this.logger.info(`Creando archivos de CI/CD en ${projectPath}`);
        
        // Create .github directory if it doesn't exist
        const githubDir = path.join(projectPath, '.github');
        if (!fs.existsSync(githubDir)) {
          fs.mkdirSync(githubDir, { recursive: true });
        }
        
        // Create workflows directory if it doesn't exist
        const workflowsDir = path.join(githubDir, 'workflows');
        if (!fs.existsSync(workflowsDir)) {
          fs.mkdirSync(workflowsDir, { recursive: true });
        }
        
        // Determine project type
        const isNodeProject = fs.existsSync(path.join(projectPath, 'package.json'));
        const isDotNetProject = fs.existsSync(path.join(projectPath, '*.csproj')) || 
                               fs.existsSync(path.join(projectPath, '*.sln'));
        const isPythonProject = fs.existsSync(path.join(projectPath, 'requirements.txt')) || 
                               fs.existsSync(path.join(projectPath, 'setup.py'));
        const isJavaProject = fs.existsSync(path.join(projectPath, 'pom.xml')) || 
                             fs.existsSync(path.join(projectPath, 'build.gradle'));
        
        // Create CI workflow
        let ciWorkflowContent = 'name: CI\n\n';
        ciWorkflowContent += 'on:\n';
        ciWorkflowContent += '  push:\n';
        ciWorkflowContent += '    branches: [ main, master, develop ]\n';
        ciWorkflowContent += '  pull_request:\n';
        ciWorkflowContent += '    branches: [ main, master, develop ]\n\n';
        ciWorkflowContent += 'jobs:\n';
        ciWorkflowContent += '  build:\n';
        ciWorkflowContent += '    runs-on: ubuntu-latest\n\n';
        ciWorkflowContent += '    steps:\n';
        ciWorkflowContent += '    - uses: actions/checkout@v3\n';
        
        // Add language-specific steps
        if (isNodeProject) {
          ciWorkflowContent += '    - name: Setup Node.js\n';
          ciWorkflowContent += '      uses: actions/setup-node@v3\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        node-version: 16\n';
          ciWorkflowContent += '        cache: \'npm\'\n';
          ciWorkflowContent += '    - name: Install dependencies\n';
          ciWorkflowContent += '      run: npm ci\n';
          ciWorkflowContent += '    - name: Run linter\n';
          ciWorkflowContent += '      run: npm run lint --if-present\n';
          ciWorkflowContent += '    - name: Run tests\n';
          ciWorkflowContent += '      run: npm test --if-present\n';
          ciWorkflowContent += '    - name: Build\n';
          ciWorkflowContent += '      run: npm run build --if-present\n';
        } else if (isDotNetProject) {
          ciWorkflowContent += '    - name: Setup .NET\n';
          ciWorkflowContent += '      uses: actions/setup-dotnet@v3\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        dotnet-version: 6.0.x\n';
          ciWorkflowContent += '    - name: Restore dependencies\n';
          ciWorkflowContent += '      run: dotnet restore\n';
          ciWorkflowContent += '    - name: Build\n';
          ciWorkflowContent += '      run: dotnet build --no-restore\n';
          ciWorkflowContent += '    - name: Test\n';
          ciWorkflowContent += '      run: dotnet test --no-build --verbosity normal\n';
        } else if (isPythonProject) {
          ciWorkflowContent += '    - name: Setup Python\n';
          ciWorkflowContent += '      uses: actions/setup-python@v4\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        python-version: 3.9\n';
          ciWorkflowContent += '    - name: Install dependencies\n';
          ciWorkflowContent += '      run: |\n';
          ciWorkflowContent += '        python -m pip install --upgrade pip\n';
          ciWorkflowContent += '        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n';
          ciWorkflowContent += '        pip install pytest pytest-cov flake8\n';
          ciWorkflowContent += '    - name: Lint with flake8\n';
          ciWorkflowContent += '      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n';
          ciWorkflowContent += '    - name: Test with pytest\n';
          ciWorkflowContent += '      run: pytest --cov=./ --cov-report=xml\n';
        } else if (isJavaProject) {
          ciWorkflowContent += '    - name: Set up JDK 11\n';
          ciWorkflowContent += '      uses: actions/setup-java@v3\n';
          ciWorkflowContent += '      with:\n';
          ciWorkflowContent += '        java-version: \'11\'\n';
          ciWorkflowContent += '        distribution: \'temurin\'\n';
          ciWorkflowContent += '        cache: maven\n';
          ciWorkflowContent += '    - name: Build with Maven\n';
          ciWorkflowContent += '      run: mvn -B package --file pom.xml\n';
          ciWorkflowContent += '    - name: Test with Maven\n';
          ciWorkflowContent += '      run: mvn test\n';
        } else {
          // Generic steps for unknown project types
          ciWorkflowContent += '    - name: List directory\n';
          ciWorkflowContent += '      run: ls -la\n';
          ciWorkflowContent += '    - name: Check for Makefile\n';
          ciWorkflowContent += '      run: if [ -f Makefile ]; then make; fi\n';
        }
        
        // Add code coverage
        ciWorkflowContent += '    - name: Upload coverage to Codecov\n';
        ciWorkflowContent += '      uses: codecov/codecov-action@v3\n';
        ciWorkflowContent += '      with:\n';
        ciWorkflowContent += '        token: ${{ secrets.CODECOV_TOKEN }}\n';
        ciWorkflowContent += '        fail_ci_if_error: false\n';
        
        // Write CI workflow file
        fs.writeFileSync(path.join(workflowsDir, 'ci.yml'), ciWorkflowContent);
        
        // Create CD workflow
        let cdWorkflowContent = 'name: CD\n\n';
        cdWorkflowContent += 'on:\n';
        cdWorkflowContent += '  push:\n';
        cdWorkflowContent += '    branches: [ main, master ]\n';
        cdWorkflowContent += '    tags:\n';
        cdWorkflowContent += '      - \'v*\'\n\n';
        cdWorkflowContent += 'jobs:\n';
        cdWorkflowContent += '  deploy:\n';
        cdWorkflowContent += '    runs-on: ubuntu-latest\n';
        cdWorkflowContent += '    needs: build\n\n';
        cdWorkflowContent += '    steps:\n';
        cdWorkflowContent += '    - uses: actions/checkout@v3\n';
        
        // Add deployment steps based on configuration
        if (config.deploymentType === 'docker') {
          cdWorkflowContent += '    - name: Set up Docker Buildx\n';
          cdWorkflowContent += '      uses: docker/setup-buildx-action@v2\n';
          cdWorkflowContent += '    - name: Login to DockerHub\n';
          cdWorkflowContent += '      uses: docker/login-action@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
          cdWorkflowContent += '        password: ${{ secrets.DOCKERHUB_TOKEN }}\n';
          cdWorkflowContent += '    - name: Build and push\n';
          cdWorkflowContent += '      uses: docker/build-push-action@v4\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        push: true\n';
          cdWorkflowContent += '        tags: ${{ secrets.DOCKERHUB_USERNAME }}/' + (config.imageName || 'app') + ':latest\n';
        } else if (config.deploymentType === 'kubernetes') {
          cdWorkflowContent += '    - name: Set up Kustomize\n';
          cdWorkflowContent += '      uses: imranismail/setup-kustomize@v1\n';
          cdWorkflowContent += '    - name: Update Kubernetes resources\n';
          cdWorkflowContent += '      run: |\n';
          cdWorkflowContent += '        cd k8s/overlays/production\n';
          cdWorkflowContent += '        kustomize edit set image app=${{ secrets.DOCKERHUB_USERNAME }}/' + (config.imageName || 'app') + ':${{ github.sha }}\n';
          cdWorkflowContent += '    - name: Commit and push changes\n';
          cdWorkflowContent += '      run: |\n';
          cdWorkflowContent += '        git config --global user.name \'GitHub Actions\'\n';
          cdWorkflowContent += '        git config --global user.email \'actions@github.com\'\n';
          cdWorkflowContent += '        git add k8s/overlays/production\n';
          cdWorkflowContent += '        git commit -m "Update image tag to ${{ github.sha }}"\n';
          cdWorkflowContent += '        git push\n';
        } else if (config.deploymentType === 'aws') {
          cdWorkflowContent += '    - name: Configure AWS credentials\n';
          cdWorkflowContent += '      uses: aws-actions/configure-aws-credentials@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
          cdWorkflowContent += '        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
          cdWorkflowContent += '        aws-region: ' + (config.awsRegion || 'us-east-1') + '\n';
          cdWorkflowContent += '    - name: Deploy to AWS\n';
          cdWorkflowContent += '      run: |\n';
          cdWorkflowContent += '        aws s3 sync ./build s3://' + (config.s3Bucket || 'my-app-bucket') + ' --delete\n';
          if (config.cloudFrontId) {
            cdWorkflowContent += '        aws cloudfront create-invalidation --distribution-id ' + config.cloudFrontId + ' --paths "/*"\n';
          }
        } else if (config.deploymentType === 'azure') {
          cdWorkflowContent += '    - name: Azure Login\n';
          cdWorkflowContent += '      uses: azure/login@v1\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        creds: ${{ secrets.AZURE_CREDENTIALS }}\n';
          cdWorkflowContent += '    - name: Deploy to Azure Web App\n';
          cdWorkflowContent += '      uses: azure/webapps-deploy@v2\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        app-name: ' + (config.appName || 'my-app') + '\n';
          cdWorkflowContent += '        package: ./build\n';
        } else if (config.deploymentType === 'heroku') {
          cdWorkflowContent += '    - name: Deploy to Heroku\n';
          cdWorkflowContent += '      uses: akhileshns/heroku-deploy@v3.12.14\n';
          cdWorkflowContent += '      with:\n';
          cdWorkflowContent += '        heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n';
          cdWorkflowContent += '        heroku_app_name: ' + (config.appName || 'my-app') + '\n';
          cdWorkflowContent += '        heroku_email: ${{ secrets.HEROKU_EMAIL }}\n';
        } else {
          // Generic deployment steps
          cdWorkflowContent += '    - name: Deploy\n';
          cdWorkflowContent += '      run: echo "Add your deployment commands here"\n';
        }
        
        // Add build job
        cdWorkflowContent = cdWorkflowContent.replace('  deploy:\n', '  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    # Add build steps here\n    - name: Build\n      run: echo "Building..."\n\n  deploy:\n');
        
        // Write CD workflow file
        fs.writeFileSync(path.join(workflowsDir, 'cd.yml'), cdWorkflowContent);
        
        // Create dependabot.yml
        let dependabotContent = 'version: 2\n';
        dependabotContent += 'updates:\n';
        
        // Add package ecosystem based on project type
        if (isNodeProject) {
          dependabotContent += '  - package-ecosystem: "npm"\n';
          dependabotContent += '    directory: "/"\n';
          dependabotContent += '    schedule:\n';
          dependabotContent += '      interval: "weekly"\n';
          dependabotContent += '    open-pull-requests-limit: 10\n';
        } else if (isDotNetProject) {
          dependabotContent += '  - package-ecosystem: "nuget"\n';
          dependabotContent += '    directory: "/"\n';
          dependabotContent += '    schedule:\n';
          dependabotContent += '      interval: "weekly"\n';
          dependabotContent += '    open-pull-requests-limit: 10\n';
        } else if (isPythonProject) {
          dependabotContent += '  - package-ecosystem: "pip"\n';
          dependabotContent += '    open-pull-requests-limit: 10\n';
        } else if (isPythonProject) {
          dependabotContent += '  - package-ecosystem: "pip"\n';
          dependabotContent += '    directory: "/"\n';
          dependabotContent += '    schedule:\n';
          dependabotContent += '      interval: "weekly"\n';
          dependabotContent += '    open-pull-requests-limit: 10\n';
        } else if (isJavaProject) {
          dependabotContent += '  - package-ecosystem: "maven"\n';
          dependabotContent += '    directory: "/"\n';
          dependabotContent += '    schedule:\n';
          dependabotContent += '      interval: "weekly"\n';
          dependabotContent += '    open-pull-requests-limit: 10\n';
        }
        
        // Add GitHub Actions ecosystem
        dependabotContent += '  - package-ecosystem: "github-actions"\n';
        dependabotContent += '    directory: "/"\n';
        dependabotContent += '    schedule:\n';
        dependabotContent += '      interval: "weekly"\n';
        dependabotContent += '    open-pull-requests-limit: 10\n';
        
        // Add Docker ecosystem if Dockerfile exists
        if (fs.existsSync(path.join(projectPath, 'Dockerfile'))) {
          dependabotContent += '  - package-ecosystem: "docker"\n';
          dependabotContent += '    directory: "/"\n';
          dependabotContent += '    schedule:\n';
          dependabotContent += '      interval: "weekly"\n';
          dependabotContent += '    open-pull-requests-limit: 10\n';
        }
        
        // Write dependabot.yml
        fs.writeFileSync(path.join(githubDir, 'dependabot.yml'), dependabotContent);
        
        // Create CODEOWNERS file
        let codeownersContent = '# This file defines the code owners for this repository\n';
        codeownersContent += '# Each line is a file pattern followed by one or more owners\n\n';
        codeownersContent += '# These owners will be the default owners for everything in the repo\n';
        codeownersContent += '* @default-owner\n\n';
        
        // Add language-specific code owners
        if (isNodeProject) {
          codeownersContent += '# JavaScript/TypeScript files\n';
          codeownersContent += '*.js @js-owner\n';
          codeownersContent += '*.ts @js-owner\n';
          codeownersContent += '*.jsx @js-owner\n';
          codeownersContent += '*.tsx @js-owner\n';
        } else if (isDotNetProject) {
          codeownersContent += '# .NET files\n';
          codeownersContent += '*.cs @dotnet-owner\n';
          codeownersContent += '*.csproj @dotnet-owner\n';
          codeownersContent += '*.sln @dotnet-owner\n';
        } else if (isPythonProject) {
          codeownersContent += '# Python files\n';
          codeownersContent += '*.py @python-owner\n';
        } else if (isJavaProject) {
          codeownersContent += '# Java files\n';
          codeownersContent += '*.java @java-owner\n';
          codeownersContent += '*.xml @java-owner\n';
          codeownersContent += '*.gradle @java-owner\n';
        }
        
        // Add infrastructure code owners
        codeownersContent += '\n# Infrastructure files\n';
        codeownersContent += 'Dockerfile @devops-owner\n';
        codeownersContent += 'docker-compose.yml @devops-owner\n';
        codeownersContent += '.github/workflows/ @devops-owner\n';
        codeownersContent += 'k8s/ @devops-owner\n';
        codeownersContent += 'terraform/ @devops-owner\n';
        codeownersContent += 'helm/ @devops-owner\n';
        
        // Write CODEOWNERS file
        fs.writeFileSync(path.join(githubDir, 'CODEOWNERS'), codeownersContent);
        
        // Create pull request template
        const prTemplateDir = path.join(githubDir, 'PULL_REQUEST_TEMPLATE');
        if (!fs.existsSync(prTemplateDir)) {
          fs.mkdirSync(prTemplateDir, { recursive: true });
        }
        
        let prTemplateContent = '## Descripción\n\n';
        prTemplateContent += 'Por favor, incluye un resumen del cambio y qué problema soluciona.\n\n';
        prTemplateContent += '## Tipo de cambio\n\n';
        prTemplateContent += 'Por favor, elimina las opciones que no sean relevantes.\n\n';
        prTemplateContent += '- [ ] Corrección de error (cambio no disruptivo que soluciona un problema)\n';
        prTemplateContent += '- [ ] Nueva característica (cambio no disruptivo que añade funcionalidad)\n';
        prTemplateContent += '- [ ] Cambio disruptivo (cambio que no sería compatible con versiones anteriores y/o cambia la funcionalidad actual)\n\n';
        prTemplateContent += '## Lista de verificación:\n\n';
        prTemplateContent += '- [ ] Mi código sigue las directrices de estilo de este proyecto\n';
        prTemplateContent += '- [ ] He realizado una auto-revisión de mi propio código\n';
        prTemplateContent += '- [ ] He comentado mi código, especialmente en áreas difíciles de entender\n';
        prTemplateContent += '- [ ] He realizado los cambios correspondientes a la documentación\n';
        prTemplateContent += '- [ ] Mis cambios no generan nuevas advertencias\n';
        prTemplateContent += '- [ ] He añadido pruebas que demuestran que mi corrección es efectiva o que mi característica funciona\n';
        prTemplateContent += '- [ ] Las pruebas unitarias nuevas y existentes pasan localmente con mis cambios\n';
        prTemplateContent += '- [ ] Cualquier cambio dependiente ha sido fusionado y publicado en módulos posteriores\n';
        
        // Write pull request template
        fs.writeFileSync(path.join(prTemplateDir, 'pull_request_template.md'), prTemplateContent);
        
        // Create issue templates
        const issueTemplateDir = path.join(githubDir, 'ISSUE_TEMPLATE');
        if (!fs.existsSync(issueTemplateDir)) {
          fs.mkdirSync(issueTemplateDir, { recursive: true });
        }
        
        // Bug report template
        let bugReportContent = '---\n';
        bugReportContent += 'name: Reporte de error\n';
        bugReportContent += 'about: Crea un reporte para ayudarnos a mejorar\n';
        bugReportContent += 'title: "[BUG] "\n';
        bugReportContent += 'labels: bug\n';
        bugReportContent += 'assignees: \'\'\n';
        bugReportContent += '---\n\n';
        bugReportContent += '**Describe el error**\n';
        bugReportContent += 'Una descripción clara y concisa de cuál es el error.\n\n';
        bugReportContent += '**Reproducir**\n';
        bugReportContent += 'Pasos para reproducir el comportamiento:\n';
        bugReportContent += '1. Ir a \'...\'\n';
        bugReportContent += '2. Hacer clic en \'....\'\n';
        bugReportContent += '3. Desplazarse hacia abajo hasta \'....\'\n';
        bugReportContent += '4. Ver error\n\n';
        bugReportContent += '**Comportamiento esperado**\n';
        bugReportContent += 'Una descripción clara y concisa de lo que esperabas que sucediera.\n\n';
        bugReportContent += '**Capturas de pantalla**\n';
        bugReportContent += 'Si corresponde, agrega capturas de pantalla para ayudar a explicar tu problema.\n\n';
        bugReportContent += '**Entorno:**\n';
        bugReportContent += ' - Sistema operativo: [por ejemplo, iOS]\n';
        bugReportContent += ' - Navegador [por ejemplo, chrome, safari]\n';
        bugReportContent += ' - Versión [por ejemplo, 22]\n\n';
        bugReportContent += '**Contexto adicional**\n';
        bugReportContent += 'Agrega cualquier otro contexto sobre el problema aquí.\n';
        
        // Write bug report template
        fs.writeFileSync(path.join(issueTemplateDir, 'bug_report.md'), bugReportContent);
        
        // Feature request template
        let featureRequestContent = '---\n';
        featureRequestContent += 'name: Solicitud de característica\n';
        featureRequestContent += 'about: Sugiere una idea para este proyecto\n';
        featureRequestContent += 'title: "[FEATURE] "\n';
        featureRequestContent += 'labels: enhancement\n';
        featureRequestContent += 'assignees: \'\'\n';
        featureRequestContent += '---\n\n';
        featureRequestContent += '**¿Tu solicitud de característica está relacionada con un problema? Por favor, descríbelo.**\n';
        featureRequestContent += 'Una descripción clara y concisa de cuál es el problema. Ej. Siempre me siento frustrado cuando [...]\n\n';
        featureRequestContent += '**Describe la solución que te gustaría**\n';
        featureRequestContent += 'Una descripción clara y concisa de lo que quieres que suceda.\n\n';
        featureRequestContent += '**Describe alternativas que hayas considerado**\n';
        featureRequestContent += 'Una descripción clara y concisa de cualquier solución o característica alternativa que hayas considerado.\n\n';
        featureRequestContent += '**Contexto adicional**\n';
        featureRequestContent += 'Agrega cualquier otro contexto o capturas de pantalla sobre la solicitud de característica aquí.\n';
        
        // Write feature request template
        fs.writeFileSync(path.join(issueTemplateDir, 'feature_request.md'), featureRequestContent);
        
        // Create config.yml for issue templates
        let configContent = 'blank_issues_enabled: false\n';
        configContent += 'contact_links:\n';
        configContent += '  - name: Preguntas y Soporte\n';
        configContent += '    url: https://github.com/username/repo/discussions\n';
        configContent += '    about: Por favor, haz tus preguntas y busca soporte en nuestra sección de Discusiones.\n';
        
        // Write config.yml
        fs.writeFileSync(path.join(issueTemplateDir, 'config.yml'), configContent);
        
        // Create security policy
        let securityPolicyContent = '# Política de Seguridad\n\n';
        securityPolicyContent += '## Versiones Soportadas\n\n';
        securityPolicyContent += 'Actualmente estamos proporcionando actualizaciones de seguridad para las siguientes versiones:\n\n';
        securityPolicyContent += '| Versión | Soportada          |\n';
        securityPolicyContent += '| ------- | ------------------ |\n';
        securityPolicyContent += '| 1.0.x   | :white_check_mark: |\n';
        securityPolicyContent += '| < 1.0   | :x:                |\n\n';
        securityPolicyContent += '## Reportar una Vulnerabilidad\n\n';
        securityPolicyContent += 'Para reportar una vulnerabilidad, por favor envía un correo electrónico a security@example.com con los detalles.\n\n';
        securityPolicyContent += 'Por favor incluye la siguiente información:\n\n';
        securityPolicyContent += '- Tipo de problema (por ejemplo, desbordamiento de búfer, inyección SQL, secuencia de comandos entre sitios, etc.)\n';
        securityPolicyContent += '- Rutas completas de los archivos fuente relacionados con la manifestación del problema\n';
        securityPolicyContent += '- La ubicación del código fuente afectado (etiqueta/rama/commit o URL directa)\n';
        securityPolicyContent += '- Cualquier configuración especial requerida para reproducir el problema\n';
        securityPolicyContent += '- Instrucciones paso a paso para reproducir el problema\n';
        securityPolicyContent += '- Prueba de concepto o código de explotación (si es posible)\n';
        securityPolicyContent += '- Impacto del problema, incluida la forma en que un atacante podría explotar el problema\n\n';
        securityPolicyContent += 'Este proyecto sigue una política de divulgación de 90 días. Después de la corrección inicial, se divulgará el problema, dando crédito a los descubridores.\n';
        
        // Write security policy
        fs.writeFileSync(path.join(projectPath, 'SECURITY.md'), securityPolicyContent);
        
        // Create contributing guidelines
        let contributingContent = '# Guía de Contribución\n\n';
        contributingContent += '¡Gracias por tu interés en contribuir a nuestro proyecto! Aquí hay algunas pautas para ayudarte a comenzar.\n\n';
        contributingContent += '## Proceso de Contribución\n\n';
        contributingContent += '1. Haz un fork del repositorio\n';
        contributingContent += '2. Crea una nueva rama (`git checkout -b feature/amazing-feature`)\n';
        contributingContent += '3. Haz commit de tus cambios (`git commit -m \'Add some amazing feature\'`)\n';
        contributingContent += '4. Haz push a la rama (`git push origin feature/amazing-feature`)\n';
        contributingContent += '5. Abre un Pull Request\n\n';
        contributingContent += '## Estándares de Código\n\n';
        
        // Add language-specific coding standards
        if (isNodeProject) {
          contributingContent += '- Sigue las reglas de ESLint configuradas en el proyecto\n';
          contributingContent += '- Escribe pruebas para tu código cuando sea posible\n';
          contributingContent += '- Documenta las nuevas funciones con JSDoc\n';
        } else if (isDotNetProject) {
          contributingContent += '- Sigue las convenciones de nomenclatura de C#\n';
          contributingContent += '- Escribe pruebas unitarias para tu código\n';
          contributingContent += '- Documenta las clases y métodos públicos\n';
        } else if (isPythonProject) {
          contributingContent += '- Sigue PEP 8 para el estilo de código\n';
          contributingContent += '- Escribe docstrings para funciones y clases\n';
          contributingContent += '- Incluye pruebas unitarias cuando sea posible\n';
        } else if (isJavaProject) {
          contributingContent += '- Sigue las convenciones de código de Java\n';
          contributingContent += '- Escribe pruebas JUnit para tu código\n';
          contributingContent += '- Documenta las clases y métodos públicos con Javadoc\n';
        } else {
          contributingContent += '- Mantén un estilo de código consistente\n';
          contributingContent += '- Escribe pruebas para tu código cuando sea posible\n';
          contributingContent += '- Documenta las nuevas funcionalidades\n';
        }
        
        contributingContent += '\n## Informes de Errores\n\n';
        contributingContent += 'Los informes de errores son bienvenidos. Por favor, usa la plantilla de informe de errores y proporciona tanta información como sea posible.\n\n';
        contributingContent += '## Solicitudes de Características\n\n';
        contributingContent += 'Las solicitudes de características son bienvenidas. Por favor, usa la plantilla de solicitud de características y proporciona un caso de uso claro.\n\n';
        contributingContent += '## Preguntas\n\n';
        contributingContent += 'Si tienes alguna pregunta, por favor usa la sección de Discusiones de GitHub en lugar de abrir un problema.\n\n';
        contributingContent += '## Licencia\n\n';
        contributingContent += 'Al contribuir a este proyecto, aceptas que tus contribuciones estarán bajo la misma licencia que el proyecto.\n';
        
        // Write contributing guidelines
        fs.writeFileSync(path.join(projectPath, 'CONTRIBUTING.md'), contributingContent);
        
        // Create code of conduct
        let codeOfConductContent = '# Código de Conducta\n\n';
        codeOfConductContent += '## Nuestro Compromiso\n\n';
        codeOfConductContent += 'En el interés de fomentar un ambiente abierto y acogedor, nosotros como contribuyentes y mantenedores nos comprometemos a hacer de la participación en nuestro proyecto y nuestra comunidad una experiencia libre de acoso para todos, independientemente de la edad, tamaño corporal, discapacidad, etnia, identidad y expresión de género, nivel de experiencia, nacionalidad, apariencia personal, raza, religión, o identidad y orientación sexual.\n\n';
        codeOfConductContent += '## Nuestros Estándares\n\n';
        codeOfConductContent += 'Ejemplos de comportamiento que contribuye a crear un ambiente positivo incluyen:\n\n';
        codeOfConductContent += '* Usar un lenguaje acogedor e inclusivo\n';
        codeOfConductContent += '* Ser respetuoso con diferentes puntos de vista y experiencias\n';
        codeOfConductContent += '* Aceptar con gracia la crítica constructiva\n';
        codeOfConductContent += '* Enfocarse en lo que es mejor para la comunidad\n';
        codeOfConductContent += '* Mostrar empatía hacia otros miembros de la comunidad\n\n';
        codeOfConductContent += 'Ejemplos de comportamiento inaceptable incluyen:\n\n';
        codeOfConductContent += '* El uso de lenguaje o imágenes sexualizadas y atención o avances sexuales no deseados\n';
        codeOfConductContent += '* Trolling, comentarios insultantes/despectivos, y ataques personales o políticos\n';
        codeOfConductContent += '* Acoso público o privado\n';
        codeOfConductContent += '* Publicar información privada de otros, como una dirección física o electrónica, sin permiso explícito\n';
        codeOfConductContent += '* Otra conducta que razonablemente podría considerarse inapropiada en un entorno profesional\n\n';
        codeOfConductContent += '## Nuestras Responsabilidades\n\n';
        codeOfConductContent += 'Los mantenedores del proyecto son responsables de aclarar los estándares de comportamiento aceptable y se espera que tomen medidas correctivas apropiadas y justas en respuesta a cualquier instancia de comportamiento inaceptable.\n\n';
        codeOfConductContent += 'Los mantenedores del proyecto tienen el derecho y la responsabilidad de eliminar, editar o rechazar comentarios, commits, código, ediciones de wiki, issues y otras contribuciones que no estén alineadas con este Código de Conducta, o de prohibir temporal o permanentemente a cualquier contribuyente por otros comportamientos que consideren inapropiados, amenazantes, ofensivos o dañinos.\n\n';
        codeOfConductContent += '## Alcance\n\n';
        codeOfConductContent += 'Este Código de Conducta aplica tanto dentro de los espacios del proyecto como en espacios públicos cuando un individuo está representando al proyecto o su comunidad. Ejemplos de representación de un proyecto o comunidad incluyen el uso de una dirección de correo electrónico oficial del proyecto, publicación a través de una cuenta oficial de redes sociales, o actuar como un representante designado en un evento en línea o fuera de línea. La representación de un proyecto puede ser definida y aclarada por los mantenedores del proyecto.\n\n';
        codeOfConductContent += '## Aplicación\n\n';
        codeOfConductContent += 'Los casos de comportamiento abusivo, acosador o de otro modo inaceptable pueden ser reportados contactando al equipo del proyecto en [INSERTAR CORREO ELECTRÓNICO]. Todas las quejas serán revisadas e investigadas y resultarán en una respuesta que se considere necesaria y apropiada a las circunstancias. El equipo del proyecto está obligado a mantener la confidencialidad con respecto al reportero de un incidente. Más detalles de políticas específicas de aplicación pueden ser publicados por separado.\n\n';
        codeOfConductContent += 'Los mantenedores del proyecto que no sigan o hagan cumplir el Código de Conducta de buena fe pueden enfrentar repercusiones temporales o permanentes según lo determinen otros miembros del liderazgo del proyecto.\n\n';
        codeOfConductContent += '## Atribución\n\n';
        codeOfConductContent += 'Este Código de Conducta es adaptado del [Contributor Covenant][homepage], versión 1.4, disponible en https://www.contributor-covenant.org/es/version/1/4/code-of-conduct.html\n\n';
        codeOfConductContent += '[homepage]: https://www.contributor-covenant.org\n';
        
        // Write code of conduct
        fs.writeFileSync(path.join(projectPath, 'CODE_OF_CONDUCT.md'), codeOfConductContent);
        
        // Return success message
        return {
          success: true,
          message: 'Archivos de CI/CD creados exitosamente',
          files: [
            path.join(workflowsDir, 'ci.yml'),
            path.join(workflowsDir, 'cd.yml'),
            path.join(githubDir, 'dependabot.yml'),
            path.join(githubDir, 'CODEOWNERS'),
            path.join(prTemplateDir, 'pull_request_template.md'),
            path.join(issueTemplateDir, 'bug_report.md'),
            path.join(issueTemplateDir, 'feature_request.md'),
            path.join(issueTemplateDir, 'config.yml'),
            path.join(projectPath, 'SECURITY.md'),
            path.join(projectPath, 'CONTRIBUTING.md'),
            path.join(projectPath, 'CODE_OF_CONDUCT.md')
          ]
        };
      } catch (error) {
        this.logger.error(`Error al crear archivos de CI/CD: ${error.message}`);
        return {
          success: false,
          message: `Error al crear archivos de CI/CD: ${error.message}`,
          error
        };
      }
    }

    /**
     * Crea archivos de configuración para Terraform
     * @param projectPath Ruta del proyecto
     * @param config Configuración de Terraform
     * @returns Resultado de la operación
     */
    async createTerraformFiles(projectPath: string, config: TerraformConfig): Promise<any> {
      try {
        this.logger.info(`Creando archivos de Terraform en ${projectPath}`);
        
        // Create terraform directory if it doesn't exist
        const terraformDir = path.join(projectPath, 'terraform');
        if (!fs.existsSync(terraformDir)) {
          fs.mkdirSync(terraformDir, { recursive: true });
        }
        
        // Create environments directories
        const environments = ['dev', 'staging', 'prod'];
        for (const env of environments) {
          const envDir = path.join(terraformDir, env);
          if (!fs.existsSync(envDir)) {
            fs.mkdirSync(envDir, { recursive: true });
          }
        }
        
        // Create modules directory
        const modulesDir = path.join(terraformDir, 'modules');
        if (!fs.existsSync(modulesDir)) {
          fs.mkdirSync(modulesDir, { recursive: true });
        }
        
        // Create common modules based on configuration
        const commonModules = ['networking', 'compute', 'database', 'storage'];
        for (const module of commonModules) {
          const moduleDir = path.join(modulesDir, module);
          if (!fs.existsSync(moduleDir)) {
            fs.mkdirSync(moduleDir, { recursive: true });
          }
          
          // Create basic module files
          fs.writeFileSync(path.join(moduleDir, 'main.tf'), '# Main Terraform configuration for ' + module + ' module\n');
          fs.writeFileSync(path.join(moduleDir, 'variables.tf'), '# Variables for ' + module + ' module\n');
          fs.writeFileSync(path.join(moduleDir, 'outputs.tf'), '# Outputs for ' + module + ' module\n');
          fs.writeFileSync(path.join(moduleDir, 'README.md'), '# ' + module + ' Module\n\nThis module manages ' + module + ' resources.\n');
        }
        
        // Create provider-specific modules based on configuration
        if (config.cloudProvider === CloudProvider.AWS) {
          // Create AWS modules
          const awsModules = ['ec2', 'rds', 's3', 'vpc', 'iam', 'lambda', 'cloudfront'];
          for (const module of awsModules) {
            const moduleDir = path.join(modulesDir, module);
            if (!fs.existsSync(moduleDir)) {
              fs.mkdirSync(moduleDir, { recursive: true });
            }
            
            // Create basic module files
            fs.writeFileSync(path.join(moduleDir, 'main.tf'), '# Main Terraform configuration for AWS ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'variables.tf'), '# Variables for AWS ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'outputs.tf'), '# Outputs for AWS ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'README.md'), '# AWS ' + module + ' Module\n\nThis module manages AWS ' + module + ' resources.\n');
          }
          
          // Create AWS provider configuration for each environment
          for (const env of environments) {
            const envDir = path.join(terraformDir, env);
            
            // Create provider.tf
            let providerContent = 'provider "aws" {\n';
            providerContent += '  region = var.aws_region\n';
            providerContent += '  profile = var.aws_profile\n';
            providerContent += '  default_tags {\n';
            providerContent += '    tags = {\n';
            providerContent += '      Environment = "' + env + '"\n';
            providerContent += '      ManagedBy = "terraform"\n';
            providerContent += '      Project = "' + (config.projectName || 'my-project') + '"\n';
            providerContent += '    }\n';
            providerContent += '  }\n';
            providerContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'provider.tf'), providerContent);
            
            // Create main.tf
            let mainContent = '# Terraform configuration for ' + env + ' environment\n\n';
            mainContent += 'module "vpc" {\n';
            mainContent += '  source = "../modules/vpc"\n\n';
            mainContent += '  vpc_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  vpc_cidr = var.vpc_cidr\n';
            mainContent += '  azs = var.availability_zones\n';
            mainContent += '  private_subnets = var.private_subnets\n';
            mainContent += '  public_subnets = var.public_subnets\n';
            mainContent += '  enable_nat_gateway = true\n';
            mainContent += '  single_nat_gateway = var.environment != "prod"\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "ec2" {\n';
            mainContent += '  source = "../modules/ec2"\n\n';
            mainContent += '  instance_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  instance_type = var.instance_type\n';
            mainContent += '  vpc_id = module.vpc.vpc_id\n';
            mainContent += '  subnet_ids = module.vpc.private_subnets\n';
            mainContent += '  key_name = var.key_name\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "rds" {\n';
            mainContent += '  source = "../modules/rds"\n\n';
            mainContent += '  db_name = "${var.project_name}${var.environment}"\n';
            mainContent += '  db_instance_class = var.db_instance_class\n';
            mainContent += '  vpc_id = module.vpc.vpc_id\n';
            mainContent += '  subnet_ids = module.vpc.private_subnets\n';
            mainContent += '  engine = var.db_engine\n';
            mainContent += '  engine_version = var.db_engine_version\n';
            mainContent += '  allocated_storage = var.db_allocated_storage\n';
            mainContent += '  storage_type = var.db_storage_type\n';
            mainContent += '  multi_az = var.environment == "prod"\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "s3" {\n';
            mainContent += '  source = "../modules/s3"\n\n';
            mainContent += '  bucket_name = "${var.project_name}-${var.environment}-assets"\n';
            mainContent += '  versioning_enabled = true\n';
            mainContent += '  lifecycle_rules = var.s3_lifecycle_rules\n';
            mainContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'main.tf'), mainContent);
            
            // Create variables.tf
            let variablesContent = '# Variables for ' + env + ' environment\n\n';
            variablesContent += 'variable "aws_region" {\n';
            variablesContent += '  description = "AWS region"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "us-west-2"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "aws_profile" {\n';
            variablesContent += '  description = "AWS profile"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "default"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "project_name" {\n';
            variablesContent += '  description = "Project name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (config.projectName || 'my-project') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "environment" {\n';
            variablesContent += '  description = "Environment name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + env + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "vpc_cidr" {\n';
            variablesContent += '  description = "VPC CIDR block"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "10.0.0.0/16"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "availability_zones" {\n';
            variablesContent += '  description = "List of availability zones"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["us-west-2a", "us-west-2b", "us-west-2c"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "private_subnets" {\n';
            variablesContent += '  description = "List of private subnet CIDR blocks"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "public_subnets" {\n';
            variablesContent += '  description = "List of public subnet CIDR blocks"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "instance_type" {\n';
            variablesContent += '  description = "EC2 instance type"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (env === 'prod' ? 't3.medium' : 't3.small') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "key_name" {\n';
            variablesContent += '  description = "EC2 key pair name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (config.projectName || 'my-project') + '-' + env + '-key"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "db_instance_class" {\n';
            variablesContent += '  description = "RDS instance class"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (env === 'prod' ? 'db.t3.medium' : 'db.t3.small') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "db_engine" {\n';
            variablesContent += '  description = "RDS engine type"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "mysql"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "db_engine_version" {\n';
            variablesContent += '  description = "RDS engine version"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "8.0"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "db_allocated_storage" {\n';
            variablesContent += '  description = "RDS allocated storage in GB"\n';
            variablesContent += '  type        = number\n';
            variablesContent += '  default     = ' + (env === 'prod' ? '50' : '20') + '\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "db_storage_type" {\n';
            variablesContent += '  description = "RDS storage type"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "gp2"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "s3_lifecycle_rules" {\n';
            variablesContent += '  description = "S3 lifecycle rules"\n';
            variablesContent += '  type        = any\n';
            variablesContent += '  default     = []\n';
            variablesContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'variables.tf'), variablesContent);
            
            // Create outputs.tf
            let outputsContent = '# Outputs for ' + env + ' environment\n\n';
            outputsContent += 'output "vpc_id" {\n';
            outputsContent += '  description = "VPC ID"\n';
            outputsContent += '  value       = module.vpc.vpc_id\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "private_subnets" {\n';
            outputsContent += '  description = "List of private subnet IDs"\n';
            outputsContent += '  value       = module.vpc.private_subnets\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "public_subnets" {\n';
            outputsContent += '  description = "List of public subnet IDs"\n';
            outputsContent += '  value       = module.vpc.public_subnets\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "ec2_instance_ids" {\n';
            outputsContent += '  description = "List of EC2 instance IDs"\n';
            outputsContent += '  value       = module.ec2.instance_ids\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "rds_endpoint" {\n';
            outputsContent += '  description = "RDS endpoint"\n';
            outputsContent += '  value       = module.rds.endpoint\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "s3_bucket_name" {\n';
            outputsContent += '  description = "S3 bucket name"\n';
            outputsContent += '  value       = module.s3.bucket_name\n';
            outputsContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'outputs.tf'), outputsContent);
            
            // Create backend.tf
            let backendContent = 'terraform {\n';
            backendContent += '  backend "s3" {\n';
            backendContent += '    bucket         = "' + (config.projectName || 'my-project') + '-terraform-state"\n';
            backendContent += '    key            = "' + env + '/terraform.tfstate"\n';
            backendContent += '    region         = "us-west-2"\n';
            backendContent += '    encrypt        = true\n';
            backendContent += '    dynamodb_table = "' + (config.projectName || 'my-project') + '-terraform-locks"\n';
            backendContent += '  }\n';
            backendContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'backend.tf'), backendContent);
            
            // Create versions.tf
            let versionsContent = 'terraform {\n';
            versionsContent += '  required_version = ">= 1.0.0"\n\n';
            versionsContent += '  required_providers {\n';
            versionsContent += '    aws = {\n';
            versionsContent += '      source  = "hashicorp/aws"\n';
            versionsContent += '      version = "~> 4.0"\n';
            versionsContent += '    }\n';
            versionsContent += '  }\n';
            versionsContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'versions.tf'), versionsContent);
          }
        } else if (config.cloudProvider === CloudProvider.Azure) {
          // Create Azure modules
          const azureModules = ['vm', 'sql', 'storage', 'vnet', 'aks', 'appservice'];
          for (const module of azureModules) {
            const moduleDir = path.join(modulesDir, module);
            if (!fs.existsSync(moduleDir)) {
              fs.mkdirSync(moduleDir, { recursive: true });
            }
            
            // Create basic module files
            fs.writeFileSync(path.join(moduleDir, 'main.tf'), '# Main Terraform configuration for Azure ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'variables.tf'), '# Variables for Azure ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'outputs.tf'), '# Outputs for Azure ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'README.md'), '# Azure ' + module + ' Module\n\nThis module manages Azure ' + module + ' resources.\n');
          }
          
          // Create Azure provider configuration for each environment
          for (const env of environments) {
            const envDir = path.join(terraformDir, env);
            
            // Create provider.tf
            let providerContent = 'provider "azurerm" {\n';
            providerContent += '  features {}\n';
            providerContent += '  subscription_id = var.subscription_id\n';
            providerContent += '  tenant_id       = var.tenant_id\n';
            providerContent += '  client_id       = var.client_id\n';
            providerContent += '  client_secret   = var.client_secret\n';
            providerContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'provider.tf'), providerContent);
            
            // Create main.tf
            let mainContent = '# Terraform configuration for ' + env + ' environment\n\n';
            mainContent += 'module "vnet" {\n';
            mainContent += '  source = "../modules/vnet"\n\n';
            mainContent += '  vnet_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  resource_group_name = azurerm_resource_group.main.name\n';
            mainContent += '  address_space = var.address_space\n';
            mainContent += '  subnet_prefixes = var.subnet_prefixes\n';
            mainContent += '  subnet_names = var.subnet_names\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "vm" {\n';
            mainContent += '  source = "../modules/vm"\n\n';
            mainContent += '  vm_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  resource_group_name = azurerm_resource_group.main.name\n';
            mainContent += '  vm_size = var.vm_size\n';
            mainContent += '  subnet_id = module.vnet.subnet_ids[0]\n';
            mainContent += '  admin_username = var.admin_username\n';
            mainContent += '  admin_password = var.admin_password\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "sql" {\n';
            mainContent += '  source = "../modules/sql"\n\n';
            mainContent += '  sql_server_name = "${var.project_name}${var.environment}"\n';
            mainContent += '  resource_group_name = azurerm_resource_group.main.name\n';
            mainContent += '  sql_admin_username = var.sql_admin_username\n';
            mainContent += '  sql_admin_password = var.sql_admin_password\n';
            mainContent += '  sql_database_name = "${var.project_name}${var.environment}db"\n';
            mainContent += '  sql_sku_name = var.sql_sku_name\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "storage" {\n';
            mainContent += '  source = "../modules/storage"\n\n';
            mainContent += '  storage_account_name = "${var.project_name}${var.environment}sa"\n';
            mainContent += '  resource_group_name = azurerm_resource_group.main.name\n';
            mainContent += '  account_tier = "Standard"\n';
            mainContent += '  account_replication_type = var.environment == "prod" ? "GRS" : "LRS"\n';
            mainContent += '}\n\n';
            
            mainContent += 'resource "azurerm_resource_group" "main" {\n';
            mainContent += '  name     = "${var.project_name}-${var.environment}-rg"\n';
            mainContent += '  location = var.location\n';
            mainContent += '  tags = {\n';
            mainContent += '    Environment = var.environment\n';
            mainContent += '    ManagedBy = "terraform"\n';
            mainContent += '    Project = var.project_name\n';
            mainContent += '  }\n';
            mainContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'main.tf'), mainContent);
            
            // Create variables.tf
            let variablesContent = '# Variables for ' + env + ' environment\n\n';
            variablesContent += 'variable "subscription_id" {\n';
            variablesContent += '  description = "Azure subscription ID"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "tenant_id" {\n';
            variablesContent += '  description = "Azure tenant ID"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "client_id" {\n';
            variablesContent += '  description = "Azure client ID"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "client_secret" {\n';
            variablesContent += '  description = "Azure client secret"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  sensitive   = true\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "location" {\n';
            variablesContent += '  description = "Azure region"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "West US 2"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "project_name" {\n';
            variablesContent += '  description = "Project name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (config.projectName || 'my-project') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "environment" {\n';
            variablesContent += '  description = "Environment name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + env + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "address_space" {\n';
            variablesContent += '  description = "VNet address space"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["10.0.0.0/16"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "subnet_prefixes" {\n';
            variablesContent += '  description = "Subnet prefixes"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "subnet_names" {\n';
            variablesContent += '  description = "Subnet names"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["web", "app", "db"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "vm_size" {\n';
            variablesContent += '  description = "VM size"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (env === 'prod' ? 'Standard_D2s_v3' : 'Standard_B2s') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "admin_username" {\n';
            variablesContent += '  description = "VM admin username"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "adminuser"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "admin_password" {\n';
            variablesContent += '  description = "VM admin password"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  sensitive   = true\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "sql_admin_username" {\n';
            variablesContent += '  description = "SQL admin username"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "sqladmin"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "sql_admin_password" {\n';
            variablesContent += '  description = "SQL admin password"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  sensitive   = true\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "sql_sku_name" {\n';
            variablesContent += '  description = "SQL SKU name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (env === 'prod' ? 'S1' : 'B') + '"\n';
            variablesContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'variables.tf'), variablesContent);
            
            // Create outputs.tf
            let outputsContent = '# Outputs for ' + env + ' environment\n\n';
            outputsContent += 'output "resource_group_name" {\n';
            outputsContent += '  description = "Resource group name"\n';
            outputsContent += '  value       = azurerm_resource_group.main.name\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "vnet_id" {\n';
            outputsContent += '  description = "VNet ID"\n';
            outputsContent += '  value       = module.vnet.vnet_id\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "subnet_ids" {\n';
            outputsContent += '  description = "Subnet IDs"\n';
            outputsContent += '  value       = module.vnet.subnet_ids\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "vm_id" {\n';
            outputsContent += '  description = "VM ID"\n';
            outputsContent += '  value       = module.vm.vm_id\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "sql_server_fqdn" {\n';
            outputsContent += '  description = "SQL Server FQDN"\n';
            outputsContent += '  value       = module.sql.sql_server_fqdn\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "storage_account_name" {\n';
            outputsContent += '  description = "Storage account name"\n';
            outputsContent += '  value       = module.storage.storage_account_name\n';
            outputsContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'outputs.tf'), outputsContent);
            
            // Create backend.tf
            let backendContent = 'terraform {\n';
            backendContent += '  backend "azurerm" {\n';
            backendContent += '    resource_group_name  = "' + (config.projectName || 'my-project') + '-terraform-state-rg"\n';
            backendContent += '    storage_account_name = "' + (config.projectName || 'my-project') + 'tfstate"\n';
            backendContent += '    container_name       = "tfstate"\n';
            backendContent += '    key                  = "' + env + '.terraform.tfstate"\n';
            backendContent += '  }\n';
            backendContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'backend.tf'), backendContent);
            
            // Create versions.tf
            let versionsContent = 'terraform {\n';
            versionsContent += '  required_version = ">= 1.0.0"\n\n';
            versionsContent += '  required_providers {\n';
            versionsContent += '    azurerm = {\n';
            versionsContent += '      source  = "hashicorp/azurerm"\n';
            versionsContent += '      version = "~> 3.0"\n';
            versionsContent += '    }\n';
            versionsContent += '  }\n';
            versionsContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'versions.tf'), versionsContent);
          }
        } else if (config.cloudProvider === CloudProvider.GCP) {
          // Create GCP modules
          const gcpModules = ['compute', 'sql', 'storage', 'vpc', 'gke', 'cloud_run'];
          for (const module of gcpModules) {
            const moduleDir = path.join(modulesDir, module);
            if (!fs.existsSync(moduleDir)) {
              fs.mkdirSync(moduleDir, { recursive: true });
            }
            
            // Create basic module files
            fs.writeFileSync(path.join(moduleDir, 'main.tf'), '# Main Terraform configuration for GCP ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'variables.tf'), '# Variables for GCP ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'outputs.tf'), '# Outputs for GCP ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'README.md'), '# GCP ' + module + ' Module\n\nThis module manages GCP ' + module + ' resources.\n');
          }
          
          // Create GCP provider configuration for each environment
          for (const env of environments) {
            const envDir = path.join(terraformDir, env);
            
            // Create provider.tf
            let providerContent = 'provider "google" {\n';
            providerContent += '  project = var.project_id\n';
            providerContent += '  region  = var.region\n';
            providerContent += '  zone    = var.zone\n';
            providerContent += '}\n\n';
            
            providerContent += 'provider "google-beta" {\n';
            providerContent += '  project = var.project_id\n';
            providerContent += '  region  = var.region\n';
            providerContent += '  zone    = var.zone\n';
            providerContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'provider.tf'), providerContent);
            
            // Create main.tf
            let mainContent = '# Terraform configuration for ' + env + ' environment\n\n';
            mainContent += 'module "vpc" {\n';
            mainContent += '  source = "../modules/vpc"\n\n';
            mainContent += '  network_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  project_id = var.project_id\n';
            mainContent += '  subnets = var.subnets\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "compute" {\n';
            mainContent += '  source = "../modules/compute"\n\n';
            mainContent += '  instance_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  project_id = var.project_id\n';
            mainContent += '  machine_type = var.machine_type\n';
            mainContent += '  network = module.vpc.network_name\n';
            mainContent += '  subnetwork = module.vpc.subnet_names[0]\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "sql" {\n';
            mainContent += '  source = "../modules/sql"\n\n';
            mainContent += '  instance_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  project_id = var.project_id\n';
            mainContent += '  database_version = var.database_version\n';
            mainContent += '  tier = var.sql_tier\n';
            mainContent += '  db_name = "${var.project_name}${var.environment}db"\n';
            mainContent += '  user_name = var.sql_user_name\n';
            mainContent += '  user_password = var.sql_user_password\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "storage" {\n';
            mainContent += '  source = "../modules/storage"\n\n';
            mainContent += '  bucket_name = "${var.project_name}-${var.environment}-assets"\n';
            mainContent += '  project_id = var.project_id\n';
            mainContent += '  location = var.storage_location\n';
            mainContent += '  versioning = true\n';
            mainContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'main.tf'), mainContent);
            
            // Create variables.tf
            let variablesContent = '# Variables for ' + env + ' environment\n\n';
            variablesContent += 'variable "project_id" {\n';
            variablesContent += '  description = "GCP project ID"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "region" {\n';
            variablesContent += '  description = "GCP region"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "us-west1"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "zone" {\n';
            variablesContent += '  description = "GCP zone"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "us-west1-a"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "project_name" {\n';
            variablesContent += '  description = "Project name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (config.projectName || 'my-project') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "environment" {\n';
            variablesContent += '  description = "Environment name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + env + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "subnets" {\n';
            variablesContent += '  description = "Subnet configuration"\n';
            variablesContent += '  type        = list(map(string))\n';
            variablesContent += '  default     = [\n';
            variablesContent += '    {\n';
            variablesContent += '      subnet_name   = "subnet-01"\n';
            variablesContent += '      subnet_ip     = "10.10.10.0/24"\n';
            variablesContent += '      subnet_region = "us-west1"\n';
            variablesContent += '    },\n';
            variablesContent += '    {\n';
            variablesContent += '      subnet_name   = "subnet-02"\n';
            variablesContent += '      subnet_ip     = "10.10.20.0/24"\n';
            variablesContent += '      subnet_region = "us-west1"\n';
            variablesContent += '    }\n';
            variablesContent += '  ]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "machine_type" {\n';
            variablesContent += '  description = "GCP machine type"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (env === 'prod' ? 'n1-standard-2' : 'n1-standard-1') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "database_version" {\n';
            variablesContent += '  description = "Database version"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "MYSQL_5_7"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "sql_tier" {\n';
            variablesContent += '  description = "SQL tier"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (env === 'prod' ? 'db-n1-standard-2' : 'db-f1-micro') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "sql_user_name" {\n';
            variablesContent += '  description = "SQL user name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "dbadmin"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "sql_user_password" {\n';
            variablesContent += '  description = "SQL user password"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  sensitive   = true\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "storage_location" {\n';
            variablesContent += '  description = "Storage location"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "US"\n';
            variablesContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'variables.tf'), variablesContent);
            
            // Create outputs.tf
            let outputsContent = '# Outputs for ' + env + ' environment\n\n';
            outputsContent += 'output "network_name" {\n';
            outputsContent += '  description = "VPC network name"\n';
            outputsContent += '  value       = module.vpc.network_name\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "subnet_names" {\n';
            outputsContent += '  description = "Subnet names"\n';
            outputsContent += '  value       = module.vpc.subnet_names\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "instance_name" {\n';
            outputsContent += '  description = "Compute instance name"\n';
            outputsContent += '  value       = module.compute.instance_name\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "instance_ip" {\n';
            outputsContent += '  description = "Compute instance IP"\n';
            outputsContent += '  value       = module.compute.instance_ip\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "sql_connection_name" {\n';
            outputsContent += '  description = "SQL connection name"\n';
            outputsContent += '  value       = module.sql.connection_name\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "bucket_url" {\n';
            outputsContent += '  description = "Storage bucket URL"\n';
            outputsContent += '  value       = module.storage.bucket_url\n';
            outputsContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'outputs.tf'), outputsContent);
            
            // Create backend.tf
            let backendContent = 'terraform {\n';
            backendContent += '  backend "gcs" {\n';
            backendContent += '    bucket = "' + (config.projectName || 'my-project') + '-terraform-state"\n';
            backendContent += '    prefix = "terraform/state/' + env + '"\n';
            backendContent += '  }\n';
            backendContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'backend.tf'), backendContent);
            
            // Create versions.tf
            let versionsContent = 'terraform {\n';
            versionsContent += '  required_version = ">= 1.0.0"\n\n';
            versionsContent += '  required_providers {\n';
            versionsContent += '    google = {\n';
            versionsContent += '      source  = "hashicorp/google"\n';
            versionsContent += '      version = "~> 4.0"\n';
            versionsContent += '    }\n';
            versionsContent += '    google-beta = {\n';
            versionsContent += '      source  = "hashicorp/google-beta"\n';
            versionsContent += '      version = "~> 4.0"\n';
            versionsContent += '    }\n';
            versionsContent += '  }\n';
            versionsContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'versions.tf'), versionsContent);
          }
        } else if (config.cloudProvider === CloudProvider.AWS) {
          // Create AWS modules
          const awsModules = ['ec2', 'rds', 's3', 'vpc', 'eks', 'lambda'];
          for (const module of awsModules) {
            const moduleDir = path.join(modulesDir, module);
            if (!fs.existsSync(moduleDir)) {
              fs.mkdirSync(moduleDir, { recursive: true });
            }
            
            // Create basic module files
            fs.writeFileSync(path.join(moduleDir, 'main.tf'), '# Main Terraform configuration for AWS ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'variables.tf'), '# Variables for AWS ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'outputs.tf'), '# Outputs for AWS ' + module + ' module\n');
            fs.writeFileSync(path.join(moduleDir, 'README.md'), '# AWS ' + module + ' Module\n\nThis module manages AWS ' + module + ' resources.\n');
          }
          
          // Create AWS provider configuration for each environment
          for (const env of environments) {
            const envDir = path.join(terraformDir, env);
            
            // Create provider.tf
            let providerContent = 'provider "aws" {\n';
            providerContent += '  region     = var.region\n';
            providerContent += '  access_key = var.aws_access_key\n';
            providerContent += '  secret_key = var.aws_secret_key\n';
            providerContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'provider.tf'), providerContent);
            
            // Create main.tf
            let mainContent = '# Terraform configuration for ' + env + ' environment\n\n';
            mainContent += 'module "vpc" {\n';
            mainContent += '  source = "../modules/vpc"\n\n';
            mainContent += '  vpc_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  cidr_block = var.vpc_cidr\n';
            mainContent += '  public_subnet_cidrs = var.public_subnet_cidrs\n';
            mainContent += '  private_subnet_cidrs = var.private_subnet_cidrs\n';
            mainContent += '  availability_zones = var.availability_zones\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "ec2" {\n';
            mainContent += '  source = "../modules/ec2"\n\n';
            mainContent += '  instance_name = "${var.project_name}-${var.environment}"\n';
            mainContent += '  instance_type = var.instance_type\n';
            mainContent += '  subnet_id = module.vpc.public_subnet_ids[0]\n';
            mainContent += '  vpc_security_group_ids = [aws_security_group.app.id]\n';
            mainContent += '  key_name = var.key_name\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "rds" {\n';
            mainContent += '  source = "../modules/rds"\n\n';
            mainContent += '  db_name = "${var.project_name}${var.environment}"\n';
            mainContent += '  db_instance_class = var.db_instance_class\n';
            mainContent += '  db_username = var.db_username\n';
            mainContent += '  db_password = var.db_password\n';
            mainContent += '  subnet_ids = module.vpc.private_subnet_ids\n';
            mainContent += '  vpc_security_group_ids = [aws_security_group.db.id]\n';
            mainContent += '}\n\n';
            
            mainContent += 'module "s3" {\n';
            mainContent += '  source = "../modules/s3"\n\n';
            mainContent += '  bucket_name = "${var.project_name}-${var.environment}-assets"\n';
            mainContent += '  versioning_enabled = true\n';
            mainContent += '}\n\n';
            
            mainContent += 'resource "aws_security_group" "app" {\n';
            mainContent += '  name        = "${var.project_name}-${var.environment}-app-sg"\n';
            mainContent += '  description = "Security group for application servers"\n';
            mainContent += '  vpc_id      = module.vpc.vpc_id\n\n';
            
            mainContent += '  ingress {\n';
            mainContent += '    from_port   = 80\n';
            mainContent += '    to_port     = 80\n';
            mainContent += '    protocol    = "tcp"\n';
            mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
            mainContent += '  }\n\n';
            
            mainContent += '  ingress {\n';
            mainContent += '    from_port   = 443\n';
            mainContent += '    to_port     = 443\n';
            mainContent += '    protocol    = "tcp"\n';
            mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
            mainContent += '  }\n\n';
            
            mainContent += '  ingress {\n';
            mainContent += '    from_port   = 22\n';
            mainContent += '    to_port     = 22\n';
            mainContent += '    protocol    = "tcp"\n';
            mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
            mainContent += '  }\n\n';
            
            mainContent += '  egress {\n';
            mainContent += '    from_port   = 0\n';
            mainContent += '    to_port     = 0\n';
            mainContent += '    protocol    = "-1"\n';
            mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
            mainContent += '  }\n\n';
            
            mainContent += '  tags = {\n';
            mainContent += '    Name = "${var.project_name}-${var.environment}-app-sg"\n';
            mainContent += '    Environment = var.environment\n';
            mainContent += '    ManagedBy = "terraform"\n';
            mainContent += '  }\n';
            mainContent += '}\n\n';
            
            mainContent += 'resource "aws_security_group" "db" {\n';
            mainContent += '  name        = "${var.project_name}-${var.environment}-db-sg"\n';
            mainContent += '  description = "Security group for database servers"\n';
            mainContent += '  vpc_id      = module.vpc.vpc_id\n\n';
            
            mainContent += '  ingress {\n';
            mainContent += '    from_port       = 3306\n';
            mainContent += '    to_port         = 3306\n';
            mainContent += '    protocol        = "tcp"\n';
            mainContent += '    security_groups = [aws_security_group.app.id]\n';
            mainContent += '  }\n\n';
            
            mainContent += '  egress {\n';
            mainContent += '    from_port   = 0\n';
            mainContent += '    to_port     = 0\n';
            mainContent += '    protocol    = "-1"\n';
            mainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
            mainContent += '  }\n\n';
            
            mainContent += '  tags = {\n';
            mainContent += '    Name = "${var.project_name}-${var.environment}-db-sg"\n';
            mainContent += '    Environment = var.environment\n';
            mainContent += '    ManagedBy = "terraform"\n';
            mainContent += '  }\n';
            mainContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'main.tf'), mainContent);
            
            // Create variables.tf
            let variablesContent = '# Variables for ' + env + ' environment\n\n';
            variablesContent += 'variable "aws_access_key" {\n';
            variablesContent += '  description = "AWS access key"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "aws_secret_key" {\n';
            variablesContent += '  description = "AWS secret key"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  sensitive   = true\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "region" {\n';
            variablesContent += '  description = "AWS region"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "us-west-2"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "project_name" {\n';
            variablesContent += '  description = "Project name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (config.projectName || 'my-project') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "environment" {\n';
            variablesContent += '  description = "Environment name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + env + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "vpc_cidr" {\n';
            variablesContent += '  description = "VPC CIDR block"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "10.0.0.0/16"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "public_subnet_cidrs" {\n';
            variablesContent += '  description = "Public subnet CIDR blocks"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["10.0.1.0/24", "10.0.2.0/24"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "private_subnet_cidrs" {\n';
            variablesContent += '  description = "Private subnet CIDR blocks"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["10.0.3.0/24", "10.0.4.0/24"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "availability_zones" {\n';
            variablesContent += '  description = "Availability zones"\n';
            variablesContent += '  type        = list(string)\n';
            variablesContent += '  default     = ["us-west-2a", "us-west-2b"]\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "instance_type" {\n';
            variablesContent += '  description = "EC2 instance type"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (env === 'prod' ? 't3.medium' : 't3.micro') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "key_name" {\n';
            variablesContent += '  description = "EC2 key pair name"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (config.projectName || 'my-project') + '-key"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "db_instance_class" {\n';
            variablesContent += '  description = "RDS instance class"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "' + (env === 'prod' ? 'db.t3.medium' : 'db.t3.micro') + '"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "db_username" {\n';
            variablesContent += '  description = "Database username"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  default     = "dbadmin"\n';
            variablesContent += '}\n\n';
            
            variablesContent += 'variable "db_password" {\n';
            variablesContent += '  description = "Database password"\n';
            variablesContent += '  type        = string\n';
            variablesContent += '  sensitive   = true\n';
            variablesContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'variables.tf'), variablesContent);
            
            // Create outputs.tf
            let outputsContent = '# Outputs for ' + env + ' environment\n\n';
            outputsContent += 'output "vpc_id" {\n';
            outputsContent += '  description = "VPC ID"\n';
            outputsContent += '  value       = module.vpc.vpc_id\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "public_subnet_ids" {\n';
            outputsContent += '  description = "Public subnet IDs"\n';
            outputsContent += '  value       = module.vpc.public_subnet_ids\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "private_subnet_ids" {\n';
            outputsContent += '  description = "Private subnet IDs"\n';
            outputsContent += '  value       = module.vpc.private_subnet_ids\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "instance_id" {\n';
            outputsContent += '  description = "EC2 instance ID"\n';
            outputsContent += '  value       = module.ec2.instance_id\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "instance_public_ip" {\n';
            outputsContent += '  description = "EC2 instance public IP"\n';
            outputsContent += '  value       = module.ec2.instance_public_ip\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "db_endpoint" {\n';
            outputsContent += '  description = "RDS endpoint"\n';
            outputsContent += '  value       = module.rds.db_endpoint\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "bucket_name" {\n';
            outputsContent += '  description = "S3 bucket name"\n';
            outputsContent += '  value       = module.s3.bucket_name\n';
            outputsContent += '}\n\n';
            
            outputsContent += 'output "bucket_arn" {\n';
            outputsContent += '  description = "S3 bucket ARN"\n';
            outputsContent += '  value       = module.s3.bucket_arn\n';
            outputsContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'outputs.tf'), outputsContent);
            
            // Create backend.tf
            let backendContent = 'terraform {\n';
            backendContent += '  backend "s3" {\n';
            backendContent += '    bucket = "' + (config.projectName || 'my-project') + '-terraform-state"\n';
            backendContent += '    key    = "' + env + '/terraform.tfstate"\n';
            backendContent += '    region = "us-west-2"\n';
            backendContent += '  }\n';
            backendContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'backend.tf'), backendContent);
            
            // Create versions.tf
            let versionsContent = 'terraform {\n';
            versionsContent += '  required_version = ">= 1.0.0"\n\n';
            versionsContent += '  required_providers {\n';
            versionsContent += '    aws = {\n';
            versionsContent += '      source  = "hashicorp/aws"\n';
            versionsContent += '      version = "~> 4.0"\n';
            versionsContent += '    }\n';
            versionsContent += '  }\n';
            versionsContent += '}\n';
            
            fs.writeFileSync(path.join(envDir, 'versions.tf'), versionsContent);
          }
        }
        
        // Create README.md
        let readmeContent = '# Terraform Infrastructure\n\n';
        readmeContent += 'This directory contains Terraform configurations for managing infrastructure on ' + config.cloudProvider + '.\n\n';
        readmeContent += '## Structure\n\n';
        readmeContent += '- `modules/`: Reusable Terraform modules\n';
        
        for (const env of environments) {
          readmeContent += '- `' + env + '/`: Terraform configuration for ' + env + ' environment\n';
        }
        
        readmeContent += '\n## Usage\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Initialize Terraform\n';
        readmeContent += 'cd dev\n';
        readmeContent += 'terraform init\n\n';
        readmeContent += '# Plan changes\n';
        readmeContent += 'terraform plan -var-file=dev.tfvars\n\n';
        readmeContent += '# Apply changes\n';
        readmeContent += 'terraform apply -var-file=dev.tfvars\n';
        readmeContent += '```\n\n';
        readmeContent += '## Variables\n\n';
        readmeContent += 'Create a `dev.tfvars` file with the following variables:\n\n';
        
        if (config.cloudProvider === CloudProvider.Azure) {
          readmeContent += '```hcl\n';
          readmeContent += 'subscription_id = "your-subscription-id"\n';
          readmeContent += 'tenant_id       = "your-tenant-id"\n';
          readmeContent += 'client_id       = "your-client-id"\n';
          readmeContent += 'client_secret   = "your-client-secret"\n';
          readmeContent += 'admin_password  = "your-vm-admin-password"\n';
          readmeContent += 'sql_admin_password = "your-sql-admin-password"\n';
          readmeContent += '```\n';
        } else if (config.cloudProvider === CloudProvider.GCP) {
          readmeContent += '```hcl\n';
          readmeContent += 'project_id        = "your-gcp-project-id"\n';
          readmeContent += 'sql_user_password = "your-sql-user-password"\n';
          readmeContent += '```\n';
        } else if (config.cloudProvider === CloudProvider.AWS) {
          readmeContent += '```hcl\n';
          readmeContent += 'aws_access_key = "your-aws-access-key"\n';
          readmeContent += 'aws_secret_key = "your-aws-secret-key"\n';
          readmeContent += 'db_password    = "your-db-password"\n';
          readmeContent += '```\n';
        }
        
        fs.writeFileSync(path.join(terraformDir, 'README.md'), readmeContent);
        
        return terraformDir;
      } catch (error) {
        Logger.error('Error creating Terraform files:', error);
        throw error;
      }
    }
    
    /**
     * Creates Docker Compose configuration files
     * @param config Docker Compose configuration
     * @returns Path to the created Docker Compose files
     */
    private createDockerComposeFiles(config: DockerComposeConfig): string {
      try {
        const projectDir = process.cwd();
        const dockerDir = path.join(projectDir, 'docker');
        
        if (!fs.existsSync(dockerDir)) {
          fs.mkdirSync(dockerDir, { recursive: true });
        }
        
        // Create docker-compose.yml
        let composeContent = 'version: "3.8"\n\n';
        composeContent += 'services:\n';
        
        // Add frontend service
        if (config.services.includes('frontend')) {
          composeContent += '  frontend:\n';
          composeContent += '    build:\n';
          composeContent += '      context: ../frontend\n';
          composeContent += '      dockerfile: Dockerfile\n';
          composeContent += '    ports:\n';
          composeContent += '      - "3000:3000"\n';
          composeContent += '    volumes:\n';
          composeContent += '      - ../frontend:/app\n';
          composeContent += '      - /app/node_modules\n';
          composeContent += '    environment:\n';
          composeContent += '      - NODE_ENV=development\n';
          composeContent += '      - REACT_APP_API_URL=http://localhost:4000\n';
          composeContent += '    depends_on:\n';
          composeContent += '      - backend\n';
          composeContent += '    networks:\n';
          composeContent += '      - app-network\n';
          composeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add backend service
        if (config.services.includes('backend')) {
          composeContent += '  backend:\n';
          composeContent += '    build:\n';
          composeContent += '      context: ../backend\n';
          composeContent += '      dockerfile: Dockerfile\n';
          composeContent += '    ports:\n';
          composeContent += '      - "4000:4000"\n';
          composeContent += '    volumes:\n';
          composeContent += '      - ../backend:/app\n';
          composeContent += '      - /app/node_modules\n';
          composeContent += '    environment:\n';
          composeContent += '      - NODE_ENV=development\n';
          composeContent += '      - PORT=4000\n';
          composeContent += '      - DATABASE_URL=postgres://postgres:postgres@db:5432/app\n';
          composeContent += '      - REDIS_URL=redis://redis:6379\n';
          composeContent += '    depends_on:\n';
          composeContent += '      - db\n';
          if (config.services.includes('redis')) {
            composeContent += '      - redis\n';
          }
          composeContent += '    networks:\n';
          composeContent += '      - app-network\n';
          composeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add database service
        if (config.services.includes('database')) {
          composeContent += '  db:\n';
          composeContent += '    image: postgres:13\n';
          composeContent += '    ports:\n';
          composeContent += '      - "5432:5432"\n';
          composeContent += '    volumes:\n';
          composeContent += '      - postgres_data:/var/lib/postgresql/data\n';
          composeContent += '    environment:\n';
          composeContent += '      - POSTGRES_USER=postgres\n';
          composeContent += '      - POSTGRES_PASSWORD=postgres\n';
          composeContent += '      - POSTGRES_DB=app\n';
          composeContent += '    networks:\n';
          composeContent += '      - app-network\n';
          composeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add Redis service
        if (config.services.includes('redis')) {
          composeContent += '  redis:\n';
          composeContent += '    image: redis:6\n';
          composeContent += '    ports:\n';
          composeContent += '      - "6379:6379"\n';
          composeContent += '    volumes:\n';
          composeContent += '      - redis_data:/data\n';
          composeContent += '  networks:\n';
          composeContent += '    - app-network\n';
          composeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add Nginx service if needed
        if (config.services.includes('nginx')) {
          composeContent += '  nginx:\n';
          composeContent += '    image: nginx:latest\n';
          composeContent += '    ports:\n';
          composeContent += '      - "80:80"\n';
          composeContent += '      - "443:443"\n';
          composeContent += '    volumes:\n';
          composeContent += '      - ./nginx/conf:/etc/nginx/conf.d\n';
          composeContent += '      - ./nginx/certs:/etc/nginx/certs\n';
          composeContent += '      - ./nginx/html:/usr/share/nginx/html\n';
          composeContent += '    depends_on:\n';
          if (config.services.includes('frontend')) {
            composeContent += '      - frontend\n';
          }
          if (config.services.includes('backend')) {
            composeContent += '      - backend\n';
          }
          composeContent += '    networks:\n';
          composeContent += '      - app-network\n';
          composeContent += '    restart: unless-stopped\n\n';
          
          // Create nginx directory and config
          const nginxDir = path.join(dockerDir, 'nginx');
          if (!fs.existsSync(nginxDir)) {
            fs.mkdirSync(nginxDir, { recursive: true });
          }
          
          const nginxConfDir = path.join(nginxDir, 'conf');
          if (!fs.existsSync(nginxConfDir)) {
            fs.mkdirSync(nginxConfDir, { recursive: true });
          }
          
          const nginxCertsDir = path.join(nginxDir, 'certs');
          if (!fs.existsSync(nginxCertsDir)) {
            fs.mkdirSync(nginxCertsDir, { recursive: true });
          }
          
          const nginxHtmlDir = path.join(nginxDir, 'html');
          if (!fs.existsSync(nginxHtmlDir)) {
            fs.mkdirSync(nginxHtmlDir, { recursive: true });
          }
          
          // Create default.conf
          let nginxConfContent = 'server {\n';
          nginxConfContent += '    listen 80;\n';
          nginxConfContent += '    server_name localhost;\n\n';
          
          if (config.services.includes('frontend')) {
            nginxConfContent += '    location / {\n';
            nginxConfContent += '        proxy_pass http://frontend:3000;\n';
            nginxConfContent += '        proxy_set_header Host $host;\n';
            nginxConfContent += '        proxy_set_header X-Real-IP $remote_addr;\n';
            nginxConfContent += '        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n';
            nginxConfContent += '        proxy_set_header X-Forwarded-Proto $scheme;\n';
            nginxConfContent += '    }\n\n';
          }
          
          if (config.services.includes('backend')) {
            nginxConfContent += '    location /api {\n';
            nginxConfContent += '        proxy_pass http://backend:4000;\n';
            nginxConfContent += '        proxy_set_header Host $host;\n';
            nginxConfContent += '        proxy_set_header X-Real-IP $remote_addr;\n';
            nginxConfContent += '        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n';
            nginxConfContent += '        proxy_set_header X-Forwarded-Proto $scheme;\n';
            nginxConfContent += '    }\n\n';
          }
          
          nginxConfContent += '    # Additional configuration can be added here\n';
          nginxConfContent += '}\n';
          
          fs.writeFileSync(path.join(nginxConfDir, 'default.conf'), nginxConfContent);
          
          // Create index.html
          let indexHtmlContent = '<!DOCTYPE html>\n';
          indexHtmlContent += '<html>\n';
          indexHtmlContent += '<head>\n';
          indexHtmlContent += '    <title>Welcome to ' + (config.projectName || 'My Project') + '</title>\n';
          indexHtmlContent += '    <style>\n';
          indexHtmlContent += '        body {\n';
          indexHtmlContent += '            font-family: Arial, sans-serif;\n';
          indexHtmlContent += '            margin: 0;\n';
          indexHtmlContent += '            padding: 50px;\n';
          indexHtmlContent += '            text-align: center;\n';
          indexHtmlContent += '        }\n';
          indexHtmlContent += '        h1 {\n';
          indexHtmlContent += '            color: #333;\n';
          indexHtmlContent += '        }\n';
          indexHtmlContent += '    </style>\n';
          indexHtmlContent += '</head>\n';
          indexHtmlContent += '<body>\n';
          indexHtmlContent += '    <h1>Welcome to ' + (config.projectName || 'My Project') + '</h1>\n';
          indexHtmlContent += '    <p>If you see this page, the nginx web server is successfully installed and working.</p>\n';
          indexHtmlContent += '</body>\n';
          indexHtmlContent += '</html>\n';
          
          fs.writeFileSync(path.join(nginxHtmlDir, 'index.html'), indexHtmlContent);
        }
        
        // Add networks
        composeContent += 'networks:\n';
        composeContent += '  app-network:\n';
        composeContent += '    driver: bridge\n\n';
        
        // Add volumes
        composeContent += 'volumes:\n';
        if (config.services.includes('database')) {
          composeContent += '  postgres_data:\n';
          composeContent += '    driver: local\n';
        }
        if (config.services.includes('redis')) {
          composeContent += '  redis_data:\n';
          composeContent += '    driver: local\n';
        }
        
        // Write docker-compose.yml
        fs.writeFileSync(path.join(dockerDir, 'docker-compose.yml'), composeContent);
        
        // Create docker-compose.prod.yml
        let prodComposeContent = 'version: "3.8"\n\n';
        prodComposeContent += 'services:\n';
        
        // Add frontend service for production
        if (config.services.includes('frontend')) {
          prodComposeContent += '  frontend:\n';
          prodComposeContent += '    build:\n';
          prodComposeContent += '      context: ../frontend\n';
          prodComposeContent += '      dockerfile: Dockerfile.prod\n';
          prodComposeContent += '    ports:\n';
          prodComposeContent += '      - "3000:3000"\n';
          prodComposeContent += '    environment:\n';
          prodComposeContent += '      - NODE_ENV=production\n';
          prodComposeContent += '      - REACT_APP_API_URL=https://api.example.com\n';
          prodComposeContent += '    depends_on:\n';
          prodComposeContent += '      - backend\n';
          prodComposeContent += '    networks:\n';
          prodComposeContent += '      - app-network\n';
          prodComposeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add backend service for production
        if (config.services.includes('backend')) {
          prodComposeContent += '  backend:\n';
          prodComposeContent += '    build:\n';
          prodComposeContent += '      context: ../backend\n';
          prodComposeContent += '      dockerfile: Dockerfile.prod\n';
          prodComposeContent += '    ports:\n';
          prodComposeContent += '      - "4000:4000"\n';
          prodComposeContent += '    environment:\n';
          prodComposeContent += '      - NODE_ENV=production\n';
          prodComposeContent += '      - PORT=4000\n';
          prodComposeContent += '      - DATABASE_URL=postgres://postgres:postgres@db:5432/app\n';
          if (config.services.includes('redis')) {
            prodComposeContent += '      - REDIS_URL=redis://redis:6379\n';
          }
          prodComposeContent += '    depends_on:\n';
          prodComposeContent += '      - db\n';
          if (config.services.includes('redis')) {
            prodComposeContent += '      - redis\n';
          }
          prodComposeContent += '    networks:\n';
          prodComposeContent += '      - app-network\n';
          prodComposeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add database service for production
        if (config.services.includes('database')) {
          prodComposeContent += '  db:\n';
          prodComposeContent += '    image: postgres:13\n';
          prodComposeContent += '    volumes:\n';
          prodComposeContent += '      - postgres_data:/var/lib/postgresql/data\n';
          prodComposeContent += '    environment:\n';
          prodComposeContent += '      - POSTGRES_USER=postgres\n';
          prodComposeContent += '      - POSTGRES_PASSWORD=${DB_PASSWORD}\n';
          prodComposeContent += '      - POSTGRES_DB=app\n';
          prodComposeContent += '    networks:\n';
          prodComposeContent += '      - app-network\n';
          prodComposeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add Redis service for production
        if (config.services.includes('redis')) {
          prodComposeContent += '  redis:\n';
          prodComposeContent += '    image: redis:6\n';
          prodComposeContent += '    volumes:\n';
          prodComposeContent += '      - redis_data:/data\n';
          prodComposeContent += '    command: redis-server --appendonly yes\n';
          prodComposeContent += '    networks:\n';
          prodComposeContent += '      - app-network\n';
          prodComposeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add Nginx service for production
        if (config.services.includes('nginx')) {
          prodComposeContent += '  nginx:\n';
          prodComposeContent += '    image: nginx:latest\n';
          prodComposeContent += '    ports:\n';
          prodComposeContent += '      - "80:80"\n';
          prodComposeContent += '      - "443:443"\n';
          prodComposeContent += '    volumes:\n';
          prodComposeContent += '      - ./nginx/conf:/etc/nginx/conf.d\n';
          prodComposeContent += '      - ./nginx/certs:/etc/nginx/certs\n';
          prodComposeContent += '      - ./nginx/html:/usr/share/nginx/html\n';
          prodComposeContent += '      - /etc/letsencrypt:/etc/letsencrypt\n';
          prodComposeContent += '    depends_on:\n';
          if (config.services.includes('frontend')) {
            prodComposeContent += '      - frontend\n';
          }
          if (config.services.includes('backend')) {
            prodComposeContent += '      - backend\n';
          }
          prodComposeContent += '    networks:\n';
          prodComposeContent += '      - app-network\n';
          prodComposeContent += '    restart: unless-stopped\n\n';
        }
        
        // Add networks for production
        prodComposeContent += 'networks:\n';
        prodComposeContent += '  app-network:\n';
        prodComposeContent += '    driver: bridge\n\n';
        
        // Add volumes for production
        prodComposeContent += 'volumes:\n';
        if (config.services.includes('database')) {
          prodComposeContent += '  postgres_data:\n';
          prodComposeContent += '    driver: local\n';
        }
        if (config.services.includes('redis')) {
          prodComposeContent += '  redis_data:\n';
          prodComposeContent += '    driver: local\n';
        }
        
        // Write docker-compose.prod.yml
        fs.writeFileSync(path.join(dockerDir, 'docker-compose.prod.yml'), prodComposeContent);
        
        // Create .env.example
        let envExampleContent = '# Environment Variables\n\n';
        envExampleContent += '# Database\n';
        envExampleContent += 'DB_PASSWORD=your_secure_password\n\n';
        envExampleContent += '# API Keys\n';
        envExampleContent += 'API_KEY=your_api_key\n\n';
        envExampleContent += '# JWT Secret\n';
        envExampleContent += 'JWT_SECRET=your_jwt_secret\n\n';
        
        fs.writeFileSync(path.join(dockerDir, '.env.example'), envExampleContent);
        
        // Create README.md
        let readmeContent = '# Docker Configuration\n\n';
        readmeContent += 'This directory contains Docker Compose configurations for development and production environments.\n\n';
        readmeContent += '## Development\n\n';
        readmeContent += 'To start the development environment:\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Create .env file\n';
        readmeContent += 'cp .env.example .env\n\n';
        readmeContent += '# Start services\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += '## Production\n\n';
        readmeContent += 'To start the production environment:\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Create .env file\n';
        readmeContent += 'cp .env.example .env\n\n';
        readmeContent += '# Start services\n';
        readmeContent += 'docker-compose -f docker-compose.prod.yml up -d\n';
        readmeContent += '```\n\n';
        readmeContent += '## Services\n\n';
        
        if (config.services.includes('frontend')) {
          readmeContent += '- **Frontend**: React application running on port 3000\n';
        }
        if (config.services.includes('backend')) {
          readmeContent += '- **Backend**: Node.js API running on port 4000\n';
        }
        if (config.services.includes('database')) {
          readmeContent += '- **Database**: PostgreSQL database running on port 5432\n';
        }
        if (config.services.includes('redis')) {
          readmeContent += '- **Redis**: Redis cache running on port 6379\n';
        }
        if (config.services.includes('nginx')) {
          readmeContent += '- **Nginx**: Web server running on ports 80 and 443\n';
        }
        
        fs.writeFileSync(path.join(dockerDir, 'README.md'), readmeContent);
        
        // Create Dockerfiles for frontend and backend if they don't exist
        if (config.services.includes('frontend')) {
          const frontendDir = path.join(projectDir, 'frontend');
          if (!fs.existsSync(frontendDir)) {
            fs.mkdirSync(frontendDir, { recursive: true });
          }
          
          // Create Dockerfile for frontend
          let frontendDockerfile = 'FROM node:16-alpine\n\n';
          frontendDockerfile += 'WORKDIR /app\n\n';
          frontendDockerfile += 'COPY package*.json ./\n\n';
          frontendDockerfile += 'RUN npm install\n\n';
          frontendDockerfile += 'COPY . .\n\n';
          frontendDockerfile += 'EXPOSE 3000\n\n';
          frontendDockerfile += 'CMD ["npm", "start"]\n';
          
          fs.writeFileSync(path.join(frontendDir, 'Dockerfile'), frontendDockerfile);
          
          // Create Dockerfile.prod for frontend
          let frontendProdDockerfile = 'FROM node:16-alpine as build\n\n';
          frontendProdDockerfile += 'WORKDIR /app\n\n';
          frontendProdDockerfile += 'COPY package*.json ./\n\n';
          frontendProdDockerfile += 'RUN npm ci\n\n';
          frontendProdDockerfile += 'COPY . .\n\n';
          frontendProdDockerfile += 'RUN npm run build\n\n';
          frontendProdDockerfile += 'FROM nginx:alpine\n\n';
          frontendProdDockerfile += 'COPY --from=build /app/build /usr/share/nginx/html\n\n';
          frontendProdDockerfile += 'COPY nginx/nginx.conf /etc/nginx/conf.d/default.conf\n\n';
          frontendProdDockerfile += 'EXPOSE 80\n\n';
          frontendProdDockerfile += 'CMD ["nginx", "-g", "daemon off;"]\n';
          
          fs.writeFileSync(path.join(frontendDir, 'Dockerfile.prod'), frontendProdDockerfile);
          
          // Create nginx.conf for frontend
          const frontendNginxDir = path.join(frontendDir, 'nginx');
          if (!fs.existsSync(frontendNginxDir)) {
            fs.mkdirSync(frontendNginxDir, { recursive: true });
          }
          
          let nginxConf = 'server {\n';
          nginxConf += '    listen 80;\n';
          nginxConf += '    server_name localhost;\n\n';
          nginxConf += '    location / {\n';
          nginxConf += '        root /usr/share/nginx/html;\n';
          nginxConf += '        index index.html index.htm;\n';
          nginxConf += '        try_files $uri $uri/ /index.html;\n';
          nginxConf += '    }\n\n';
          nginxConf += '    error_page 500 502 503 504 /50x.html;\n';
          nginxConf += '    location = /50x.html {\n';
          nginxConf += '        root /usr/share/nginx/html;\n';
          nginxConf += '    }\n';
          nginxConf += '}\n';
          
          fs.writeFileSync(path.join(frontendNginxDir, 'nginx.conf'), nginxConf);
        }
        
        if (config.services.includes('backend')) {
          const backendDir = path.join(projectDir, 'backend');
          if (!fs.existsSync(backendDir)) {
            fs.mkdirSync(backendDir, { recursive: true });
          }
          
          // Create Dockerfile for backend
          let backendDockerfile = 'FROM node:16-alpine\n\n';
          backendDockerfile += 'WORKDIR /app\n\n';
          backendDockerfile += 'COPY package*.json ./\n\n';
          backendDockerfile += 'RUN npm install\n\n';
          backendDockerfile += 'COPY . .\n\n';
          backendDockerfile += 'EXPOSE 4000\n\n';
          backendDockerfile += 'CMD ["npm", "run", "dev"]\n';
          
          fs.writeFileSync(path.join(backendDir, 'Dockerfile'), backendDockerfile);
          
          // Create Dockerfile.prod for backend
          let backendProdDockerfile = 'FROM node:16-alpine\n\n';
          backendProdDockerfile += 'WORKDIR /app\n\n';
          backendProdDockerfile += 'COPY package*.json ./\n\n';
          backendProdDockerfile += 'RUN npm ci --only=production\n\n';
          backendProdDockerfile += 'COPY . .\n\n';
          backendProdDockerfile += 'EXPOSE 4000\n\n';
          backendProdDockerfile += 'CMD ["npm", "start"]\n';
          
          fs.writeFileSync(path.join(backendDir, 'Dockerfile.prod'), backendProdDockerfile);
        }
        
        return dockerDir;
      } catch (error) {
        Logger.error('Error creating Docker Compose files:', error);
        throw error;
      }
    }
    
    /**
     * Creates Kubernetes configuration files
     * @param config Kubernetes configuration
     * @returns Path to the created Kubernetes files
     */
    private createKubernetesFiles(config: KubernetesConfig): string {
      try {
        const projectDir = process.cwd();
        const k8sDir = path.join(projectDir, 'kubernetes');
        
        if (!fs.existsSync(k8sDir)) {
          fs.mkdirSync(k8sDir, { recursive: true });
        }
        
        // Create directories for different components
        const baseDir = path.join(k8sDir, 'base');
        if (!fs.existsSync(baseDir)) {
          fs.mkdirSync(baseDir, { recursive: true });
        }
        
        const overlaysDir = path.join(k8sDir, 'overlays');
        if (!fs.existsSync(overlaysDir)) {
          fs.mkdirSync(overlaysDir, { recursive: true });
        }
        
        // Create environment directories
        const environments = ['dev', 'staging', 'prod'];
        for (const env of environments) {
          const envDir = path.join(overlaysDir, env);
          if (!fs.existsSync(envDir)) {
            fs.mkdirSync(envDir, { recursive: true });
          }
        }
        
        // Create base kustomization.yaml
        let baseKustomizationContent = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
        baseKustomizationContent += 'kind: Kustomization\n\n';
        baseKustomizationContent += 'resources:\n';
        
        // Create namespace.yaml
        let namespaceContent = 'apiVersion: v1\n';
        namespaceContent += 'kind: Namespace\n';
        namespaceContent += 'metadata:\n';
        namespaceContent += '  name: ${NAMESPACE}\n';
        
        fs.writeFileSync(path.join(baseDir, 'namespace.yaml'), namespaceContent);
        baseKustomizationContent += '- namespace.yaml\n';
        
        // Create frontend deployment and service if needed
        if (config.services.includes('frontend')) {
          // Create frontend directory
          const frontendDir = path.join(baseDir, 'frontend');
          if (!fs.existsSync(frontendDir)) {
            fs.mkdirSync(frontendDir, { recursive: true });
          }
          
          // Create frontend deployment
          let frontendDeploymentContent = 'apiVersion: apps/v1\n';
          frontendDeploymentContent += 'kind: Deployment\n';
          frontendDeploymentContent += 'metadata:\n';
          frontendDeploymentContent += '  name: frontend\n';
          frontendDeploymentContent += '  namespace: ${NAMESPACE}\n';
          frontendDeploymentContent += 'spec:\n';
          frontendDeploymentContent += '  replicas: 1\n';
          frontendDeploymentContent += '  selector:\n';
          frontendDeploymentContent += '    matchLabels:\n';
          frontendDeploymentContent += '      app: frontend\n';
          frontendDeploymentContent += '  template:\n';
          frontendDeploymentContent += '    metadata:\n';
          frontendDeploymentContent += '      labels:\n';
          frontendDeploymentContent += '        app: frontend\n';
          frontendDeploymentContent += '    spec:\n';
          frontendDeploymentContent += '      containers:\n';
          frontendDeploymentContent += '      - name: frontend\n';
          frontendDeploymentContent += '        image: ${FRONTEND_IMAGE}\n';
          frontendDeploymentContent += '        ports:\n';
          frontendDeploymentContent += '        - containerPort: 80\n';
          frontendDeploymentContent += '        resources:\n';
          frontendDeploymentContent += '          limits:\n';
          frontendDeploymentContent += '            cpu: 500m\n';
          frontendDeploymentContent += '            memory: 512Mi\n';
          frontendDeploymentContent += '          requests:\n';
          frontendDeploymentContent += '            cpu: 100m\n';
          frontendDeploymentContent += '            memory: 128Mi\n';
          frontendDeploymentContent += '        env:\n';
          frontendDeploymentContent += '        - name: REACT_APP_API_URL\n';
          frontendDeploymentContent += '          value: ${API_URL}\n';
          frontendDeploymentContent += '        livenessProbe:\n';
          frontendDeploymentContent += '          httpGet:\n';
          frontendDeploymentContent += '            path: /\n';
          frontendDeploymentContent += '            port: 80\n';
          frontendDeploymentContent += '          initialDelaySeconds: 30\n';
          frontendDeploymentContent += '          periodSeconds: 10\n';
          frontendDeploymentContent += '        readinessProbe:\n';
          frontendDeploymentContent += '          httpGet:\n';
          frontendDeploymentContent += '            path: /\n';
          frontendDeploymentContent += '            port: 80\n';
          frontendDeploymentContent += '          initialDelaySeconds: 5\n';
          frontendDeploymentContent += '          periodSeconds: 5\n';
          
          fs.writeFileSync(path.join(frontendDir, 'deployment.yaml'), frontendDeploymentContent);
          
          // Create frontend service
          let frontendServiceContent = 'apiVersion: v1\n';
          frontendServiceContent += 'kind: Service\n';
          frontendServiceContent += 'metadata:\n';
          frontendServiceContent += '  name: frontend\n';
          frontendServiceContent += '  namespace: ${NAMESPACE}\n';
          frontendServiceContent += 'spec:\n';
          frontendServiceContent += '  selector:\n';
          frontendServiceContent += '    app: frontend\n';
          frontendServiceContent += '  ports:\n';
          frontendServiceContent += '  - port: 80\n';
          frontendServiceContent += '    targetPort: 80\n';
          frontendServiceContent += '  type: ClusterIP\n';
          
          fs.writeFileSync(path.join(frontendDir, 'service.yaml'), frontendServiceContent);
          
          // Create frontend kustomization
          let frontendKustomizationContent = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
          frontendKustomizationContent += 'kind: Kustomization\n\n';
          frontendKustomizationContent += 'resources:\n';
          frontendKustomizationContent += '- deployment.yaml\n';
          frontendKustomizationContent += '- service.yaml\n';
          
          fs.writeFileSync(path.join(frontendDir, 'kustomization.yaml'), frontendKustomizationContent);
          
          baseKustomizationContent += '- frontend/\n';
        }
        
        // Create backend deployment and service if needed
        if (config.services.includes('backend')) {
          // Create backend directory
          const backendDir = path.join(baseDir, 'backend');
          if (!fs.existsSync(backendDir)) {
            fs.mkdirSync(backendDir, { recursive: true });
          }
          
          // Create backend deployment
          let backendDeploymentContent = 'apiVersion: apps/v1\n';
          backendDeploymentContent += 'kind: Deployment\n';
          backendDeploymentContent += 'metadata:\n';
          backendDeploymentContent += '  name: backend\n';
          backendDeploymentContent += '  namespace: ${NAMESPACE}\n';
          backendDeploymentContent += 'spec:\n';
          backendDeploymentContent += '  replicas: 1\n';
          backendDeploymentContent += '  selector:\n';
          backendDeploymentContent += '    matchLabels:\n';
          backendDeploymentContent += '      app: backend\n';
          backendDeploymentContent += '  template:\n';
          backendDeploymentContent += '    metadata:\n';
          backendDeploymentContent += '      labels:\n';
          backendDeploymentContent += '        app: backend\n';
          backendDeploymentContent += '    spec:\n';
          backendDeploymentContent += '      containers:\n';
          backendDeploymentContent += '      - name: backend\n';
          backendDeploymentContent += '        image: ${BACKEND_IMAGE}\n';
          backendDeploymentContent += '        ports:\n';
          backendDeploymentContent += '        - containerPort: 4000\n';
          backendDeploymentContent += '        resources:\n';
          backendDeploymentContent += '          limits:\n';
          backendDeploymentContent += '            cpu: 500m\n';
          backendDeploymentContent += '            memory: 512Mi\n';
          backendDeploymentContent += '          requests:\n';
          backendDeploymentContent += '            cpu: 100m\n';
          backendDeploymentContent += '            memory: 128Mi\n';
          backendDeploymentContent += '        env:\n';
          backendDeploymentContent += '        - name: NODE_ENV\n';
          backendDeploymentContent += '          value: production\n';
          backendDeploymentContent += '        - name: PORT\n';
          backendDeploymentContent += '          value: "4000"\n';
          backendDeploymentContent += '        - name: DATABASE_URL\n';
          backendDeploymentContent += '          valueFrom:\n';
          backendDeploymentContent += '            secretKeyRef:\n';
          backendDeploymentContent += '              name: backend-secrets\n';
          backendDeploymentContent += '              key: database-url\n';
          if (config.services.includes('redis')) {
            backendDeploymentContent += '        - name: REDIS_URL\n';
            backendDeploymentContent += '          value: redis://redis:6379\n';
          }
          backendDeploymentContent += '        livenessProbe:\n';
          backendDeploymentContent += '          httpGet:\n';
          backendDeploymentContent += '            path: /health\n';
          backendDeploymentContent += '            port: 4000\n';
          backendDeploymentContent += '          initialDelaySeconds: 30\n';
          backendDeploymentContent += '          periodSeconds: 10\n';
          backendDeploymentContent += '        readinessProbe:\n';
          backendDeploymentContent += '          httpGet:\n';
          backendDeploymentContent += '            path: /health\n';
          backendDeploymentContent += '            port: 4000\n';
          backendDeploymentContent += '          initialDelaySeconds: 5\n';
          backendDeploymentContent += '          periodSeconds: 5\n';
          
          fs.writeFileSync(path.join(backendDir, 'deployment.yaml'), backendDeploymentContent);
          
          // Crear servicio de backend
          let backendServiceContent = 'apiVersion: v1\n';
          backendServiceContent += 'kind: Service\n';
          backendServiceContent += 'metadata:\n';
          backendServiceContent += '  name: backend\n';
          backendServiceContent += '  namespace: ${NAMESPACE}\n';
          backendServiceContent += 'spec:\n';
          backendServiceContent += '  selector:\n';
          backendServiceContent += '    app: backend\n';
          backendServiceContent += '  ports:\n';
          backendServiceContent += '  - port: 80\n';
          backendServiceContent += '    targetPort: 4000\n';
          backendServiceContent += '  type: ClusterIP\n';
          
          fs.writeFileSync(path.join(backendDir, 'service.yaml'), backendServiceContent);
          
          // Crear secretos para el backend
          let backendSecretsContent = 'apiVersion: v1\n';
          backendSecretsContent += 'kind: Secret\n';
          backendSecretsContent += 'metadata:\n';
          backendSecretsContent += '  name: backend-secrets\n';
          backendSecretsContent += '  namespace: ${NAMESPACE}\n';
          backendSecretsContent += 'type: Opaque\n';
          backendSecretsContent += 'data:\n';
          backendSecretsContent += '  database-url: ${DATABASE_URL_B64}\n';
          backendSecretsContent += '  jwt-secret: ${JWT_SECRET_B64}\n';
          
          fs.writeFileSync(path.join(backendDir, 'secrets.yaml'), backendSecretsContent);
          
          // Crear kustomization para backend
          let backendKustomizationContent = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
          backendKustomizationContent += 'kind: Kustomization\n\n';
          backendKustomizationContent += 'resources:\n';
          backendKustomizationContent += '- deployment.yaml\n';
          backendKustomizationContent += '- service.yaml\n';
          backendKustomizationContent += '- secrets.yaml\n';
          
          fs.writeFileSync(path.join(backendDir, 'kustomization.yaml'), backendKustomizationContent);
          
          baseKustomizationContent += '- backend/\n';
        }
        
        // Crear configuración de base de datos si es necesario
        if (config.services.includes('database')) {
          // Crear directorio de base de datos
          const dbDir = path.join(baseDir, 'database');
          if (!fs.existsSync(dbDir)) {
            fs.mkdirSync(dbDir, { recursive: true });
          }
          
          // Crear StatefulSet para la base de datos
          let dbStatefulSetContent = 'apiVersion: apps/v1\n';
          dbStatefulSetContent += 'kind: StatefulSet\n';
          dbStatefulSetContent += 'metadata:\n';
          dbStatefulSetContent += '  name: postgres\n';
          dbStatefulSetContent += '  namespace: ${NAMESPACE}\n';
          dbStatefulSetContent += 'spec:\n';
          dbStatefulSetContent += '  serviceName: postgres\n';
          dbStatefulSetContent += '  replicas: 1\n';
          dbStatefulSetContent += '  selector:\n';
          dbStatefulSetContent += '    matchLabels:\n';
          dbStatefulSetContent += '      app: postgres\n';
          dbStatefulSetContent += '  template:\n';
          dbStatefulSetContent += '    metadata:\n';
          dbStatefulSetContent += '      labels:\n';
          dbStatefulSetContent += '        app: postgres\n';
          dbStatefulSetContent += '    spec:\n';
          dbStatefulSetContent += '      containers:\n';
          dbStatefulSetContent += '      - name: postgres\n';
          dbStatefulSetContent += '        image: postgres:13\n';
          dbStatefulSetContent += '        ports:\n';
          dbStatefulSetContent += '        - containerPort: 5432\n';
          dbStatefulSetContent += '        env:\n';
          dbStatefulSetContent += '        - name: POSTGRES_USER\n';
          dbStatefulSetContent += '          value: postgres\n';
          dbStatefulSetContent += '        - name: POSTGRES_PASSWORD\n';
          dbStatefulSetContent += '          valueFrom:\n';
          dbStatefulSetContent += '            secretKeyRef:\n';
          dbStatefulSetContent += '              name: db-secrets\n';
          dbStatefulSetContent += '              key: postgres-password\n';
          dbStatefulSetContent += '        - name: POSTGRES_DB\n';
          dbStatefulSetContent += '          value: app\n';
          dbStatefulSetContent += '        - name: PGDATA\n';
          dbStatefulSetContent += '          value: /var/lib/postgresql/data/pgdata\n';
          dbStatefulSetContent += '        volumeMounts:\n';
          dbStatefulSetContent += '        - name: postgres-data\n';
          dbStatefulSetContent += '          mountPath: /var/lib/postgresql/data\n';
          dbStatefulSetContent += '        resources:\n';
          dbStatefulSetContent += '          limits:\n';
          dbStatefulSetContent += '            cpu: 1000m\n';
          dbStatefulSetContent += '            memory: 1Gi\n';
          dbStatefulSetContent += '          requests:\n';
          dbStatefulSetContent += '            cpu: 500m\n';
          dbStatefulSetContent += '            memory: 512Mi\n';
          dbStatefulSetContent += '  volumeClaimTemplates:\n';
          dbStatefulSetContent += '  - metadata:\n';
          dbStatefulSetContent += '      name: postgres-data\n';
          dbStatefulSetContent += '    spec:\n';
          dbStatefulSetContent += '      accessModes: ["ReadWriteOnce"]\n';
          dbStatefulSetContent += '      resources:\n';
          dbStatefulSetContent += '        requests:\n';
          dbStatefulSetContent += '          storage: 10Gi\n';
          
          fs.writeFileSync(path.join(dbDir, 'statefulset.yaml'), dbStatefulSetContent);
          
          // Crear servicio para la base de datos
          let dbServiceContent = 'apiVersion: v1\n';
          dbServiceContent += 'kind: Service\n';
          dbServiceContent += 'metadata:\n';
          dbServiceContent += '  name: postgres\n';
          dbServiceContent += '  namespace: ${NAMESPACE}\n';
          dbServiceContent += 'spec:\n';
          dbServiceContent += '  selector:\n';
          dbServiceContent += '    app: postgres\n';
          dbServiceContent += '  ports:\n';
          dbServiceContent += '  - port: 5432\n';
          dbServiceContent += '    targetPort: 5432\n';
          dbServiceContent += '  clusterIP: None\n';
          
          fs.writeFileSync(path.join(dbDir, 'service.yaml'), dbServiceContent);
          
          // Crear secretos para la base de datos
          let dbSecretsContent = 'apiVersion: v1\n';
          dbSecretsContent += 'kind: Secret\n';
          dbSecretsContent += 'metadata:\n';
          dbSecretsContent += '  name: db-secrets\n';
          dbSecretsContent += '  namespace: ${NAMESPACE}\n';
          dbSecretsContent += 'type: Opaque\n';
          dbSecretsContent += 'data:\n';
          dbSecretsContent += '  postgres-password: ${POSTGRES_PASSWORD_B64}\n';
          
          fs.writeFileSync(path.join(dbDir, 'secrets.yaml'), dbSecretsContent);
          
          // Crear kustomization para la base de datos
          let dbKustomizationContent = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
          dbKustomizationContent += 'kind: Kustomization\n\n';
          dbKustomizationContent += 'resources:\n';
          dbKustomizationContent += '- statefulset.yaml\n';
          dbKustomizationContent += '- service.yaml\n';
          dbKustomizationContent += '- secrets.yaml\n';
          
          fs.writeFileSync(path.join(dbDir, 'kustomization.yaml'), dbKustomizationContent);
          
          baseKustomizationContent += '- database/\n';
        }
        
        // Crear configuración de Redis si es necesario
        if (config.services.includes('redis')) {
          // Crear directorio de Redis
          const redisDir = path.join(baseDir, 'redis');
          if (!fs.existsSync(redisDir)) {
            fs.mkdirSync(redisDir, { recursive: true });
          }
          
          // Crear deployment para Redis
          let redisDeploymentContent = 'apiVersion: apps/v1\n';
          redisDeploymentContent += 'kind: Deployment\n';
          redisDeploymentContent += 'metadata:\n';
          redisDeploymentContent += '  name: redis\n';
          redisDeploymentContent += '  namespace: ${NAMESPACE}\n';
          redisDeploymentContent += 'spec:\n';
          redisDeploymentContent += '  replicas: 1\n';
          redisDeploymentContent += '  selector:\n';
          redisDeploymentContent += '    matchLabels:\n';
          redisDeploymentContent += '      app: redis\n';
          redisDeploymentContent += '  template:\n';
          redisDeploymentContent += '    metadata:\n';
          redisDeploymentContent += '      labels:\n';
          redisDeploymentContent += '        app: redis\n';
          redisDeploymentContent += '    spec:\n';
          redisDeploymentContent += '      containers:\n';
          redisDeploymentContent += '      - name: redis\n';
          redisDeploymentContent += '        image: redis:6\n';
          redisDeploymentContent += '        ports:\n';
          redisDeploymentContent += '        - containerPort: 6379\n';
          redisDeploymentContent += '        resources:\n';
          redisDeploymentContent += '          limits:\n';
          redisDeploymentContent += '            cpu: 500m\n';
          redisDeploymentContent += '            memory: 512Mi\n';
          redisDeploymentContent += '          requests:\n';
          redisDeploymentContent += '            cpu: 100m\n';
          redisDeploymentContent += '            memory: 128Mi\n';
          
          fs.writeFileSync(path.join(redisDir, 'deployment.yaml'), redisDeploymentContent);
          
          // Crear servicio para Redis
          let redisServiceContent = 'apiVersion: v1\n';
          redisServiceContent += 'kind: Service\n';
          redisServiceContent += 'metadata:\n';
          redisServiceContent += '  name: redis\n';
          redisServiceContent += '  namespace: ${NAMESPACE}\n';
          redisServiceContent += 'spec:\n';
          redisServiceContent += '  selector:\n';
          redisServiceContent += '    app: redis\n';
          redisServiceContent += '  ports:\n';
          redisServiceContent += '  - port: 6379\n';
          redisServiceContent += '    targetPort: 6379\n';
          redisServiceContent += '  type: ClusterIP\n';
          
          fs.writeFileSync(path.join(redisDir, 'service.yaml'), redisServiceContent);
          
          // Crear kustomization para Redis
          let redisKustomizationContent = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
          redisKustomizationContent += 'kind: Kustomization\n\n';
          redisKustomizationContent += 'resources:\n';
          redisKustomizationContent += '- deployment.yaml\n';
          redisKustomizationContent += '- service.yaml\n';
          
          fs.writeFileSync(path.join(redisDir, 'kustomization.yaml'), redisKustomizationContent);
          
          baseKustomizationContent += '- redis/\n';
        }
        
        // Crear configuración de Ingress si es necesario
        if (config.services.includes('ingress')) {
          // Crear directorio de Ingress
          const ingressDir = path.join(baseDir, 'ingress');
          if (!fs.existsSync(ingressDir)) {
            fs.mkdirSync(ingressDir, { recursive: true });
          }
          
          // Crear Ingress
          let ingressContent = 'apiVersion: networking.k8s.io/v1\n';
          ingressContent += 'kind: Ingress\n';
          ingressContent += 'metadata:\n';
          ingressContent += '  name: app-ingress\n';
          ingressContent += '  namespace: ${NAMESPACE}\n';
          ingressContent += '  annotations:\n';
          ingressContent += '    kubernetes.io/ingress.class: nginx\n';
          ingressContent += '    nginx.ingress.kubernetes.io/ssl-redirect: "true"\n';
          ingressContent += '    cert-manager.io/cluster-issuer: letsencrypt-prod\n';
          ingressContent += 'spec:\n';
          ingressContent += '  tls:\n';
          ingressContent += '  - hosts:\n';
          ingressContent += '    - ${FRONTEND_HOST}\n';
          ingressContent += '    - ${BACKEND_HOST}\n';
          ingressContent += '    secretName: app-tls\n';
          ingressContent += '  rules:\n';
          
          if (config.services.includes('frontend')) {
            ingressContent += '  - host: ${FRONTEND_HOST}\n';
            ingressContent += '    http:\n';
            ingressContent += '      paths:\n';
            ingressContent += '      - path: /\n';
            ingressContent += '        pathType: Prefix\n';
            ingressContent += '        backend:\n';
            ingressContent += '          service:\n';
            ingressContent += '            name: frontend\n';
            ingressContent += '            port:\n';
            ingressContent += '              number: 80\n';
          }
          
          if (config.services.includes('backend')) {
            ingressContent += '  - host: ${BACKEND_HOST}\n';
            ingressContent += '    http:\n';
            ingressContent += '      paths:\n';
            ingressContent += '      - path: /\n';
            ingressContent += '        pathType: Prefix\n';
            ingressContent += '        backend:\n';
            ingressContent += '          service:\n';
            ingressContent += '            name: backend\n';
            ingressContent += '            port:\n';
            ingressContent += '              number: 80\n';
          }
          
          fs.writeFileSync(path.join(ingressDir, 'ingress.yaml'), ingressContent);
          
          // Crear kustomization para Ingress
          let ingressKustomizationContent = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
          ingressKustomizationContent += 'kind: Kustomization\n\n';
          ingressKustomizationContent += 'resources:\n';
          ingressKustomizationContent += '- ingress.yaml\n';
          
          fs.writeFileSync(path.join(ingressDir, 'kustomization.yaml'), ingressKustomizationContent);
          
          baseKustomizationContent += '- ingress/\n';
        }
        
        // Escribir kustomization.yaml base
        fs.writeFileSync(path.join(baseDir, 'kustomization.yaml'), baseKustomizationContent);
        
        // Crear kustomization.yaml para cada entorno
        for (const env of environments) {
          const envDir = path.join(overlaysDir, env);
          
          // Crear kustomization.yaml
          let envKustomizationContent = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
          envKustomizationContent += 'kind: Kustomization\n\n';
          envKustomizationContent += 'bases:\n';
          envKustomizationContent += '- ../../base\n\n';
          envKustomizationContent += 'namespace: ' + (config.projectName || 'my-project') + '-' + env + '\n\n';
          
          // Configurar transformadores de variables
          envKustomizationContent += 'configMapGenerator:\n';
          envKustomizationContent += '- name: env-vars\n';
          envKustomizationContent += '  literals:\n';
          envKustomizationContent += '  - NAMESPACE=' + (config.projectName || 'my-project') + '-' + env + '\n';
          
          if (config.services.includes('frontend')) {
            envKustomizationContent += '  - FRONTEND_IMAGE=' + (config.projectName || 'my-project') + '/frontend:' + env + '\n';
          }
          
          if (config.services.includes('backend')) {
            envKustomizationContent += '  - BACKEND_IMAGE=' + (config.projectName || 'my-project') + '/backend:' + env + '\n';
          }
          
          if (config.services.includes('ingress')) {
            if (env === 'prod') {
              envKustomizationContent += '  - FRONTEND_HOST=app.example.com\n';
              envKustomizationContent += '  - BACKEND_HOST=api.example.com\n';
            } else if (env === 'staging') {
              envKustomizationContent += '  - FRONTEND_HOST=staging.app.example.com\n';
              envKustomizationContent += '  - BACKEND_HOST=staging.api.example.com\n';
            } else {
              envKustomizationContent += '  - FRONTEND_HOST=dev.app.example.com\n';
              envKustomizationContent += '  - BACKEND_HOST=dev.api.example.com\n';
            }
          }
          
          if (config.services.includes('backend')) {
            envKustomizationContent += '  - API_URL=https://' + (env === 'prod' ? 'api.example.com' : (env === 'staging' ? 'staging.api.example.com' : 'dev.api.example.com')) + '\n';
          }
          
          // Configurar patches específicos del entorno
          envKustomizationContent += '\npatchesStrategicMerge:\n';
          
          // Crear patches para el entorno
          if (config.services.includes('frontend')) {
            // Crear patch para frontend
            let frontendPatchContent = 'apiVersion: apps/v1\n';
            frontendPatchContent += 'kind: Deployment\n';
            frontendPatchContent += 'metadata:\n';
            frontendPatchContent += '  name: frontend\n';
            frontendPatchContent += 'spec:\n';
            frontendPatchContent += '  replicas: ' + (env === 'prod' ? '3' : (env === 'staging' ? '2' : '1')) + '\n';
            
            const frontendPatchFile = 'frontend-patch.yaml';
            fs.writeFileSync(path.join(envDir, frontendPatchFile), frontendPatchContent);
            envKustomizationContent += '- ' + frontendPatchFile + '\n';
          }
          
          if (config.services.includes('backend')) {
            // Crear patch para backend
            let backendPatchContent = 'apiVersion: apps/v1\n';
            backendPatchContent += 'kind: Deployment\n';
            backendPatchContent += 'metadata:\n';
            backendPatchContent += '  name: backend\n';
            backendPatchContent += 'spec:\n';
            backendPatchContent += '  replicas: ' + (env === 'prod' ? '3' : (env === 'staging' ? '2' : '1')) + '\n';
            
            const backendPatchFile = 'backend-patch.yaml';
            fs.writeFileSync(path.join(envDir, backendPatchFile), backendPatchContent);
            envKustomizationContent += '- ' + backendPatchFile + '\n';
          }
          
          // Escribir kustomization.yaml para el entorno
          fs.writeFileSync(path.join(envDir, 'kustomization.yaml'), envKustomizationContent);
          
          // Crear archivo .env para secretos
          let envFileContent = '# Secretos para el entorno ' + env + '\n\n';
          
          if (config.services.includes('database')) {
            envFileContent += '# Contraseña de la base de datos (codificada en base64)\n';
            envFileContent += 'POSTGRES_PASSWORD_B64=cG9zdGdyZXM=\n\n';
          }
          
          if (config.services.includes('backend')) {
            envFileContent += '# URL de la base de datos (codificada en base64)\n';
            envFileContent += 'DATABASE_URL_B64=cG9zdGdyZXNxbDovL3Bvc3RncmVzOnBvc3RncmVzQHBvc3RncmVzOjU0MzIvYXBw\n\n';
            envFileContent += '# Secreto JWT (codificado en base64)\n';
            envFileContent += 'JWT_SECRET_B64=c2VjcmV0\n';
          }
          
          fs.writeFileSync(path.join(envDir, '.env.example'), envFileContent);
        }
        
        // Crear README.md
        let readmeContent = '# Configuración de Kubernetes\n\n';
        readmeContent += 'Este directorio contiene la configuración de Kubernetes para el proyecto ' + (config.projectName || 'my-project') + '.\n\n';
        readmeContent += '## Estructura\n\n';
        readmeContent += '- `base/`: Configuración base compartida entre todos los entornos\n';
        readmeContent += '- `overlays/`: Configuraciones específicas para cada entorno\n';
        readmeContent += '  - `dev/`: Entorno de desarrollo\n';
        readmeContent += '  - `staging/`: Entorno de pruebas\n';
        readmeContent += '  - `prod/`: Entorno de producción\n\n';
        readmeContent += '## Uso\n\n';
        readmeContent += '### Requisitos previos\n\n';
        readmeContent += '- Kubernetes cluster\n';
        readmeContent += '- kubectl\n';
        readmeContent += '- kustomize\n\n';
        readmeContent += '### Despliegue\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Configurar variables de entorno\n';
        readmeContent += 'cd overlays/dev\n';
        readmeContent += 'cp .env.example .env\n';
        readmeContent += 'source .env\n\n';
        readmeContent += '# Desplegar en el entorno de desarrollo\n';
        readmeContent += 'kubectl apply -k .\n';
        readmeContent += '```\n\n';
        readmeContent += '### Visualización\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Ver los recursos desplegados\n';
        readmeContent += 'kubectl get all -n ' + (config.projectName || 'my-project') + '-dev\n';
        readmeContent += '```\n';
        
        fs.writeFileSync(path.join(k8sDir, 'README.md'), readmeContent);
        
        return k8sDir;
      } catch (error) {
        Logger.error('Error al crear archivos de Kubernetes:', error);
        throw error;
      }
    }
    
    /**
     * Crea archivos de configuración para monitoreo
     * @param config Configuración de monitoreo
     * @returns Ruta a los archivos de monitoreo creados
     */
    private createMonitoringFiles(config: MonitoringConfig): string {
      try {
        const projectDir = process.cwd();
        const monitoringDir = path.join(projectDir, 'monitoring');
        
        if (!fs.existsSync(monitoringDir)) {
          fs.mkdirSync(monitoringDir, { recursive: true });
        }
        
        // Crear directorio de Prometheus
        const prometheusDir = path.join(monitoringDir, 'prometheus');
        if (!fs.existsSync(prometheusDir)) {
          fs.mkdirSync(prometheusDir, { recursive: true });
        }
        
        // Crear prometheus.yml
        let prometheusContent = 'global:\n';
        prometheusContent += '  scrape_interval: 15s\n';
        prometheusContent += '  evaluation_interval: 15s\n\n';
        prometheusContent += 'alerting:\n';
        prometheusContent += '  alertmanagers:\n';
        prometheusContent += '  - static_configs:\n';
        prometheusContent += '    - targets:\n';
        prometheusContent += '      - alertmanager:9093\n\n';
        prometheusContent += 'rule_files:\n';
        prometheusContent += '  - "alert_rules.yml"\n\n';
        prometheusContent += 'scrape_configs:\n';
        prometheusContent += '  - job_name: "prometheus"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '      - targets: ["localhost:9090"]\n\n';
        prometheusContent += '  - job_name: "node"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '      - targets: ["node-exporter:9100"]\n\n';
        prometheusContent += '  - job_name: "cadvisor"\n';
        prometheusContent += '    static_configs:\n';
        prometheusContent += '      - targets: ["cadvisor:8080"]\n\n';
        
        if (config.services.includes('frontend')) {
          prometheusContent += '  - job_name: "frontend"\n';
          prometheusContent += '    static_configs:\n';
          prometheusContent += '      - targets: ["frontend:3000"]\n\n';
        }
        
        if (config.services.includes('backend')) {
          prometheusContent += '  - job_name: "backend"\n';
          prometheusContent += '    static_configs:\n';
          prometheusContent += '      - targets: ["backend:4000"]\n\n';
        }
        
        // Escribir prometheus.yml
        fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);
        
        // Crear alert_rules.yml
        let alertRulesContent = 'groups:\n';
        alertRulesContent += '- name: example\n';
        alertRulesContent += '  rules:\n';
        alertRulesContent += '  - alert: HighCPULoad\n';
        alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High CPU load (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "CPU load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
        
        alertRulesContent += '  - alert: HighMemoryLoad\n';
        alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 > 80\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High memory load (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "Memory load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
        
        alertRulesContent += '  - alert: HighDiskUsage\n';
        alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85\n';
        alertRulesContent += '    for: 5m\n';
        alertRulesContent += '    labels:\n';
        alertRulesContent += '      severity: warning\n';
        alertRulesContent += '    annotations:\n';
        alertRulesContent += '      summary: "High disk usage (instance {{ $labels.instance }})"\n';
        alertRulesContent += '      description: "Disk usage is > 85%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n';
        
        // Escribir alert_rules.yml
        fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);
        
        // Crear directorio de Alertmanager
        const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
        if (!fs.existsSync(alertmanagerDir)) {
          fs.mkdirSync(alertmanagerDir, { recursive: true });
        }
        
        // Crear alertmanager.yml
        let alertmanagerContent = 'global:\n';
        alertmanagerContent += '  resolve_timeout: 5m\n\n';
        alertmanagerContent += 'route:\n';
        alertmanagerContent += '  group_by: [\'alertname\']\n';
        alertmanagerContent += '  group_wait: 10s\n';
        alertmanagerContent += '  group_interval: 10s\n';
        alertmanagerContent += '  repeat_interval: 1h\n';
        alertmanagerContent += '  receiver: \'web.hook\'\n';
        alertmanagerContent += '  routes:\n';
        alertmanagerContent += '  - match:\n';
        alertmanagerContent += '      severity: critical\n';
        alertmanagerContent += '    receiver: \'web.hook\'\n';
        alertmanagerContent += '    repeat_interval: 5m\n\n';
        alertmanagerContent += 'receivers:\n';
        alertmanagerContent += '- name: \'web.hook\'\n';
        alertmanagerContent += '  webhook_configs:\n';
        alertmanagerContent += '  - url: \'http://127.0.0.1:5001/\'\n';
        alertmanagerContent += '    send_resolved: true\n';
        
        // Escribir alertmanager.yml
        fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);
        
        // Crear directorio de Grafana
        const grafanaDir = path.join(monitoringDir, 'grafana');
        if (!fs.existsSync(grafanaDir)) {
          fs.mkdirSync(grafanaDir, { recursive: true });
        }
        
        // Crear directorio de dashboards
        const dashboardsDir = path.join(grafanaDir, 'dashboards');
        if (!fs.existsSync(dashboardsDir)) {
          fs.mkdirSync(dashboardsDir, { recursive: true });
        }
        
        // Crear dashboard para sistema
        let systemDashboardContent = '{\n';
        systemDashboardContent += '  "annotations": {\n';
        systemDashboardContent += '    "list": [\n';
        systemDashboardContent += '      {\n';
        systemDashboardContent += '        "builtIn": 1,\n';
        systemDashboardContent += '        "datasource": "-- Grafana --",\n';
        systemDashboardContent += '        "enable": true,\n';
        systemDashboardContent += '        "hide": true,\n';
        systemDashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
        systemDashboardContent += '        "name": "Annotations & Alerts",\n';
        systemDashboardContent += '        "type": "dashboard"\n';
        systemDashboardContent += '      }\n';
        systemDashboardContent += '    ]\n';
        systemDashboardContent += '  },\n';
        systemDashboardContent += '  "editable": true,\n';
        systemDashboardContent += '  "gnetId": null,\n';
        systemDashboardContent += '  "graphTooltip": 0,\n';
        systemDashboardContent += '  "id": 1,\n';
        systemDashboardContent += '  "links": [],\n';
        systemDashboardContent += '  "panels": [\n';
        systemDashboardContent += '    {\n';
        systemDashboardContent += '      "aliasColors": {},\n';
        systemDashboardContent += '      "bars": false,\n';
        systemDashboardContent += '      "dashLength": 10,\n';
        systemDashboardContent += '      "dashes": false,\n';
        systemDashboardContent += '      "datasource": "Prometheus",\n';
        systemDashboardContent += '      "fieldConfig": {\n';
        systemDashboardContent += '        "defaults": {\n';
        systemDashboardContent += '          "custom": {}\n';
        systemDashboardContent += '        },\n';
        systemDashboardContent += '        "overrides": []\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "fill": 1,\n';
        systemDashboardContent += '      "fillGradient": 0,\n';
        systemDashboardContent += '      "gridPos": {\n';
        systemDashboardContent += '        "h": 8,\n';
        systemDashboardContent += '        "w": 12,\n';
        systemDashboardContent += '        "x": 0,\n';
        systemDashboardContent += '        "y": 0\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "hiddenSeries": false,\n';
        systemDashboardContent += '      "id": 2,\n';
        systemDashboardContent += '      "legend": {\n';
        systemDashboardContent += '        "avg": false,\n';
        systemDashboardContent += '        "current": false,\n';
        systemDashboardContent += '        "max": false,\n';
        systemDashboardContent += '        "min": false,\n';
        systemDashboardContent += '        "show": true,\n';
        systemDashboardContent += '        "total": false,\n';
        systemDashboardContent += '        "values": false\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "lines": true,\n';
        systemDashboardContent += '      "linewidth": 1,\n';
        systemDashboardContent += '      "nullPointMode": "null",\n';
        systemDashboardContent += '      "options": {\n';
        systemDashboardContent += '        "alertThreshold": true\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "percentage": false,\n';
        systemDashboardContent += '      "pluginVersion": "7.3.7",\n';
        systemDashboardContent += '      "pointradius": 2,\n';
        systemDashboardContent += '      "points": false,\n';
        systemDashboardContent += '      "renderer": "flot",\n';
        systemDashboardContent += '      "seriesOverrides": [],\n';
        systemDashboardContent += '      "spaceLength": 10,\n';
        systemDashboardContent += '      "stack": false,\n';
        systemDashboardContent += '      "steppedLine": false,\n';
        systemDashboardContent += '      "targets": [\n';
        systemDashboardContent += '        {\n';
        systemDashboardContent += '          "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\\"idle\\"}[5m])) * 100)",\n';
        systemDashboardContent += '          "interval": "",\n';
        systemDashboardContent += '          "legendFormat": "CPU Usage",\n';
        systemDashboardContent += '          "refId": "A"\n';
        systemDashboardContent += '        }\n';
        systemDashboardContent += '      ],\n';
        systemDashboardContent += '      "thresholds": [],\n';
        systemDashboardContent += '      "timeFrom": null,\n';
        systemDashboardContent += '      "timeRegions": [],\n';
        systemDashboardContent += '      "timeShift": null,\n';
        systemDashboardContent += '      "title": "CPU Usage",\n';
        systemDashboardContent += '      "tooltip": {\n';
        systemDashboardContent += '        "shared": true,\n';
        systemDashboardContent += '        "sort": 0,\n';
        systemDashboardContent += '        "value_type": "individual"\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "type": "graph",\n';
        systemDashboardContent += '      "xaxis": {\n';
        systemDashboardContent += '        "buckets": null,\n';
        systemDashboardContent += '        "mode": "time",\n';
        systemDashboardContent += '        "name": null,\n';
        systemDashboardContent += '        "show": true,\n';
        systemDashboardContent += '        "values": []\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "yaxes": [\n';
        systemDashboardContent += '        {\n';
        systemDashboardContent += '          "format": "percent",\n';
        systemDashboardContent += '          "label": null,\n';
        systemDashboardContent += '          "logBase": 1,\n';
        systemDashboardContent += '          "max": "100",\n';
        systemDashboardContent += '          "min": "0",\n';
        systemDashboardContent += '          "show": true\n';
        systemDashboardContent += '        },\n';
        systemDashboardContent += '        {\n';
        systemDashboardContent += '          "format": "short",\n';
        systemDashboardContent += '          "label": null,\n';
        systemDashboardContent += '          "logBase": 1,\n';
        systemDashboardContent += '          "max": null,\n';
        systemDashboardContent += '          "min": null,\n';
        systemDashboardContent += '          "show": true\n';
        systemDashboardContent += '        }\n';
        systemDashboardContent += '      ],\n';
        systemDashboardContent += '      "yaxis": {\n';
        systemDashboardContent += '        "align": false,\n';
        systemDashboardContent += '        "alignLevel": null\n';
        systemDashboardContent += '      }\n';
        systemDashboardContent += '    },\n';
        systemDashboardContent += '    {\n';
        systemDashboardContent += '      "aliasColors": {},\n';
        systemDashboardContent += '      "bars": false,\n';
        systemDashboardContent += '      "dashLength": 10,\n';
        systemDashboardContent += '      "dashes": false,\n';
        systemDashboardContent += '      "datasource": "Prometheus",\n';
        systemDashboardContent += '      "fieldConfig": {\n';
        systemDashboardContent += '        "defaults": {\n';
        systemDashboardContent += '          "custom": {}\n';
        systemDashboardContent += '        },\n';
        systemDashboardContent += '        "overrides": []\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "fill": 1,\n';
        systemDashboardContent += '      "fillGradient": 0,\n';
        systemDashboardContent += '      "gridPos": {\n';
        systemDashboardContent += '        "h": 8,\n';
        systemDashboardContent += '        "w": 12,\n';
        systemDashboardContent += '        "x": 12,\n';
        systemDashboardContent += '        "y": 0\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "hiddenSeries": false,\n';
        systemDashboardContent += '      "id": 3,\n';
        systemDashboardContent += '      "legend": {\n';
        systemDashboardContent += '        "avg": false,\n';
        systemDashboardContent += '        "current": false,\n';
        systemDashboardContent += '        "max": false,\n';
        systemDashboardContent += '        "min": false,\n';
        systemDashboardContent += '        "show": true,\n';
        systemDashboardContent += '        "total": false,\n';
        systemDashboardContent += '        "values": false\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "lines": true,\n';
        systemDashboardContent += '      "linewidth": 1,\n';
        systemDashboardContent += '      "nullPointMode": "null",\n';
        systemDashboardContent += '      "options": {\n';
        systemDashboardContent += '        "alertThreshold": true\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "percentage": false,\n';
        systemDashboardContent += '      "pluginVersion": "7.3.7",\n';
        systemDashboardContent += '      "pointradius": 2,\n';
        systemDashboardContent += '      "points": false,\n';
        systemDashboardContent += '      "renderer": "flot",\n';
        systemDashboardContent += '      "seriesOverrides": [],\n';
        systemDashboardContent += '      "spaceLength": 10,\n';
        systemDashboardContent += '      "stack": false,\n';
        systemDashboardContent += '      "steppedLine": false,\n';
        systemDashboardContent += '      "targets": [\n';
        systemDashboardContent += '        {\n';
        systemDashboardContent += '          "expr": "(node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100",\n';
        systemDashboardContent += '          "interval": "",\n';
        systemDashboardContent += '          "legendFormat": "Memory Usage",\n';
        systemDashboardContent += '          "refId": "A"\n';
        systemDashboardContent += '        }\n';
        systemDashboardContent += '      ],\n';
        systemDashboardContent += '      "thresholds": [],\n';
        systemDashboardContent += '      "timeFrom": null,\n';
        systemDashboardContent += '      "timeRegions": [],\n';
        systemDashboardContent += '      "timeShift": null,\n';
        systemDashboardContent += '      "title": "Memory Usage",\n';
        systemDashboardContent += '      "tooltip": {\n';
        systemDashboardContent += '        "shared": true,\n';
        systemDashboardContent += '        "sort": 0,\n';
        systemDashboardContent += '        "value_type": "individual"\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "type": "graph",\n';
        systemDashboardContent += '      "xaxis": {\n';
        systemDashboardContent += '        "buckets": null,\n';
        systemDashboardContent += '        "mode": "time",\n';
        systemDashboardContent += '        "name": null,\n';
        systemDashboardContent += '        "show": true,\n';
        systemDashboardContent += '        "values": []\n';
        systemDashboardContent += '      },\n';
        systemDashboardContent += '      "yaxes": [\n';
        systemDashboardContent += '        {\n';
        systemDashboardContent += '          "format": "percent",\n';
        systemDashboardContent += '          "label": null,\n';
        systemDashboardContent += '          "logBase": 1,\n';
        systemDashboardContent += '          "max": "100",\n';
        systemDashboardContent += '          "min": "0",\n';
        systemDashboardContent += '          "show": true\n';
        systemDashboardContent += '        },\n';
        systemDashboardContent += '        {\n';
        systemDashboardContent += '          "format": "short",\n';
        systemDashboardContent += '          "label": null,\n';
        systemDashboardContent += '          "logBase": 1,\n';
        systemDashboardContent += '          "max": null,\n';
        systemDashboardContent += '          "min": null,\n';
        systemDashboardContent += '          "show": true\n';
        systemDashboardContent += '        }\n';
        systemDashboardContent += '      ],\n';
        systemDashboardContent += '      "yaxis": {\n';
        systemDashboardContent += '        "align": false,\n';
        systemDashboardContent += '        "alignLevel": null\n';
        systemDashboardContent += '      }\n';
        systemDashboardContent += '    }\n';
        systemDashboardContent += '  ],\n';
        systemDashboardContent += '  "refresh": "5s",\n';
        systemDashboardContent += '  "schemaVersion": 26,\n';
        systemDashboardContent += '  "style": "dark",\n';
        systemDashboardContent += '  "tags": [],\n';
        systemDashboardContent += '  "templating": {\n';
        systemDashboardContent += '    "list": []\n';
        systemDashboardContent += '  },\n';
        systemDashboardContent += '  "time": {\n';
        systemDashboardContent += '    "from": "now-6h",\n';
        systemDashboardContent += '    "to": "now"\n';
        systemDashboardContent += '  },\n';
        systemDashboardContent += '  "timepicker": {},\n';
        systemDashboardContent += '  "timezone": "",\n';
        systemDashboardContent += '  "title": "System Dashboard",\n';
        systemDashboardContent += '  "uid": "system",\n';
        systemDashboardContent += '  "version": 1\n';
        systemDashboardContent += '}\n';
        
        fs.writeFileSync(path.join(dashboardsDir, 'system-dashboard.json'), systemDashboardContent);
        
        // Crear dashboard para aplicación
        let appDashboardContent = '{\n';
        appDashboardContent += '  "annotations": {\n';
        appDashboardContent += '    "list": [\n';
        appDashboardContent += '      {\n';
        appDashboardContent += '        "builtIn": 1,\n';
        appDashboardContent += '        "datasource": "-- Grafana --",\n';
        appDashboardContent += '        "enable": true,\n';
        appDashboardContent += '        "hide": true,\n';
        appDashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
        appDashboardContent += '        "name": "Annotations & Alerts",\n';
        appDashboardContent += '        "type": "dashboard"\n';
        appDashboardContent += '      }\n';
        appDashboardContent += '    ]\n';
        appDashboardContent += '  },\n';
        appDashboardContent += '  "editable": true,\n';
        appDashboardContent += '  "gnetId": null,\n';
        appDashboardContent += '  "graphTooltip": 0,\n';
        appDashboardContent += '  "id": 2,\n';
        appDashboardContent += '  "links": [],\n';
        appDashboardContent += '  "panels": [\n';
        
        if (config.services.includes('backend')) {
          appDashboardContent += '    {\n';
          appDashboardContent += '      "aliasColors": {},\n';
          appDashboardContent += '      "bars": false,\n';
          appDashboardContent += '      "dashLength": 10,\n';
          appDashboardContent += '      "dashes": false,\n';
          appDashboardContent += '      "datasource": "Prometheus",\n';
          appDashboardContent += '      "fieldConfig": {\n';
          appDashboardContent += '        "defaults": {\n';
          appDashboardContent += '          "custom": {}\n';
          appDashboardContent += '        },\n';
          appDashboardContent += '        "overrides": []\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "fill": 1,\n';
          appDashboardContent += '      "fillGradient": 0,\n';
          appDashboardContent += '      "gridPos": {\n';
          appDashboardContent += '        "h": 8,\n';
          appDashboardContent += '        "w": 12,\n';
          appDashboardContent += '        "x": 0,\n';
          appDashboardContent += '        "y": 0\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "hiddenSeries": false,\n';
          appDashboardContent += '      "id": 2,\n';
          appDashboardContent += '      "legend": {\n';
          appDashboardContent += '        "avg": false,\n';
          appDashboardContent += '        "current": false,\n';
          appDashboardContent += '        "max": false,\n';
          appDashboardContent += '        "min": false,\n';
          appDashboardContent += '        "show": true,\n';
          appDashboardContent += '        "total": false,\n';
          appDashboardContent += '        "values": false\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "lines": true,\n';
          appDashboardContent += '      "linewidth": 1,\n';
          appDashboardContent += '      "nullPointMode": "null",\n';
          appDashboardContent += '      "options": {\n';
          appDashboardContent += '        "alertThreshold": true\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "percentage": false,\n';
          appDashboardContent += '      "pluginVersion": "7.3.7",\n';
          appDashboardContent += '      "pointradius": 2,\n';
          appDashboardContent += '      "points": false,\n';
          appDashboardContent += '      "renderer": "flot",\n';
          appDashboardContent += '      "seriesOverrides": [],\n';
          appDashboardContent += '      "spaceLength": 10,\n';
          appDashboardContent += '      "stack": false,\n';
          appDashboardContent += '      "steppedLine": false,\n';
          appDashboardContent += '      "targets": [\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "expr": "rate(http_requests_total[5m])",\n';
          appDashboardContent += '          "interval": "",\n';
          appDashboardContent += '          "legendFormat": "Requests",\n';
          appDashboardContent += '          "refId": "A"\n';
          appDashboardContent += '        }\n';
          appDashboardContent += '      ],\n';
          appDashboardContent += '      "thresholds": [],\n';
          appDashboardContent += '      "timeFrom": null,\n';
          appDashboardContent += '      "timeRegions": [],\n';
          appDashboardContent += '      "timeShift": null,\n';
          appDashboardContent += '      "title": "Backend Request Rate",\n';
          appDashboardContent += '      "tooltip": {\n';
          appDashboardContent += '        "shared": true,\n';
          appDashboardContent += '        "sort": 0,\n';
          appDashboardContent += '        "value_type": "individual"\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "type": "graph",\n';
          appDashboardContent += '      "xaxis": {\n';
          appDashboardContent += '        "buckets": null,\n';
          appDashboardContent += '        "mode": "time",\n';
          appDashboardContent += '        "name": null,\n';
          appDashboardContent += '        "show": true,\n';
          appDashboardContent += '        "values": []\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "yaxes": [\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "format": "short",\n';
          appDashboardContent += '          "label": null,\n';
          appDashboardContent += '          "logBase": 1,\n';
          appDashboardContent += '          "max": null,\n';
          appDashboardContent += '          "min": null,\n';
          appDashboardContent += '          "show": true\n';
          appDashboardContent += '        },\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "format": "short",\n';
          appDashboardContent += '          "label": null,\n';
          appDashboardContent += '          "logBase": 1,\n';
          appDashboardContent += '          "max": null,\n';
          appDashboardContent += '          "min": null,\n';
          appDashboardContent += '          "show": true\n';
          appDashboardContent += '        }\n';
          appDashboardContent += '      ],\n';
          appDashboardContent += '      "yaxis": {\n';
          appDashboardContent += '        "align": false,\n';
          appDashboardContent += '        "alignLevel": null\n';
          appDashboardContent += '      }\n';
          appDashboardContent += '    },\n';
          appDashboardContent += '    {\n';
          appDashboardContent += '      "aliasColors": {},\n';
          appDashboardContent += '      "bars": false,\n';
          appDashboardContent += '      "dashLength": 10,\n';
          appDashboardContent += '      "dashes": false,\n';
          appDashboardContent += '      "datasource": "Prometheus",\n';
          appDashboardContent += '      "fieldConfig": {\n';
          appDashboardContent += '        "defaults": {\n';
          appDashboardContent += '          "custom": {}\n';
          appDashboardContent += '        },\n';
          appDashboardContent += '        "overrides": []\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "fill": 1,\n';
          appDashboardContent += '      "fillGradient": 0,\n';
          appDashboardContent += '      "gridPos": {\n';
          appDashboardContent += '        "h": 8,\n';
          appDashboardContent += '        "w": 12,\n';
          appDashboardContent += '        "x": 12,\n';
          appDashboardContent += '        "y": 0\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "hiddenSeries": false,\n';
          appDashboardContent += '      "id": 3,\n';
          appDashboardContent += '      "legend": {\n';
          appDashboardContent += '        "avg": false,\n';
          appDashboardContent += '        "current": false,\n';
          appDashboardContent += '        "max": false,\n';
          appDashboardContent += '        "min": false,\n';
          appDashboardContent += '        "show": true,\n';
          appDashboardContent += '        "total": false,\n';
          appDashboardContent += '        "values": false\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "lines": true,\n';
          appDashboardContent += '      "linewidth": 1,\n';
          appDashboardContent += '      "nullPointMode": "null",\n';
          appDashboardContent += '      "options": {\n';
          appDashboardContent += '        "alertThreshold": true\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "percentage": false,\n';
          appDashboardContent += '      "pluginVersion": "7.3.7",\n';
          appDashboardContent += '      "pointradius": 2,\n';
          appDashboardContent += '      "points": false,\n';
          appDashboardContent += '      "renderer": "flot",\n';
          appDashboardContent += '      "seriesOverrides": [],\n';
          appDashboardContent += '      "spaceLength": 10,\n';
          appDashboardContent += '      "stack": false,\n';
          appDashboardContent += '      "steppedLine": false,\n';
          appDashboardContent += '      "targets": [\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "expr": "http_request_duration_seconds{quantile=\\"0.95\\"}",\n';
          appDashboardContent += '          "interval": "",\n';
          appDashboardContent += '          "legendFormat": "95th Percentile",\n';
          appDashboardContent += '          "refId": "A"\n';
          appDashboardContent += '        }\n';
          appDashboardContent += '      ],\n';
          appDashboardContent += '      "thresholds": [],\n';
          appDashboardContent += '      "timeFrom": null,\n';
          appDashboardContent += '      "timeRegions": [],\n';
          appDashboardContent += '      "timeShift": null,\n';
          appDashboardContent += '      "title": "Backend Response Time",\n';
          appDashboardContent += '      "tooltip": {\n';
          appDashboardContent += '        "shared": true,\n';
          appDashboardContent += '        "sort": 0,\n';
          appDashboardContent += '        "value_type": "individual"\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "type": "graph",\n';
          appDashboardContent += '      "xaxis": {\n';
          appDashboardContent += '        "buckets": null,\n';
          appDashboardContent += '        "mode": "time",\n';
          appDashboardContent += '        "name": null,\n';
          appDashboardContent += '        "show": true,\n';
          appDashboardContent += '        "values": []\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "yaxes": [\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "format": "s",\n';
          appDashboardContent += '          "label": null,\n';
          appDashboardContent += '          "logBase": 1,\n';
          appDashboardContent += '          "max": null,\n';
          appDashboardContent += '          "min": null,\n';
          appDashboardContent += '          "show": true\n';
          appDashboardContent += '        },\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "format": "short",\n';
          appDashboardContent += '          "label": null,\n';
          appDashboardContent += '          "logBase": 1,\n';
          appDashboardContent += '          "max": null,\n';
          appDashboardContent += '          "min": null,\n';
          appDashboardContent += '          "show": true\n';
          appDashboardContent += '        }\n';
          appDashboardContent += '      ],\n';
          appDashboardContent += '      "yaxis": {\n';
          appDashboardContent += '        "align": false,\n';
          appDashboardContent += '        "alignLevel": null\n';
          appDashboardContent += '      }\n';
          appDashboardContent += '    },\n';
          appDashboardContent += '    {\n';
          appDashboardContent += '      "aliasColors": {},\n';
          appDashboardContent += '      "bars": false,\n';
          appDashboardContent += '      "dashLength": 10,\n';
          appDashboardContent += '      "dashes": false,\n';
          appDashboardContent += '      "datasource": "Prometheus",\n';
          appDashboardContent += '      "fieldConfig": {\n';
          appDashboardContent += '        "defaults": {\n';
          appDashboardContent += '          "custom": {}\n';
          appDashboardContent += '        },\n';
          appDashboardContent += '        "overrides": []\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "fill": 1,\n';
          appDashboardContent += '      "fillGradient": 0,\n';
          appDashboardContent += '      "gridPos": {\n';
          appDashboardContent += '        "h": 8,\n';
          appDashboardContent += '        "w": 12,\n';
          appDashboardContent += '        "x": 0,\n';
          appDashboardContent += '        "y": 8\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "hiddenSeries": false,\n';
          appDashboardContent += '      "id": 4,\n';
          appDashboardContent += '      "legend": {\n';
          appDashboardContent += '        "avg": false,\n';
          appDashboardContent += '        "current": false,\n';
          appDashboardContent += '        "max": false,\n';
          appDashboardContent += '        "min": false,\n';
          appDashboardContent += '        "show": true,\n';
          appDashboardContent += '        "total": false,\n';
          appDashboardContent += '        "values": false\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "lines": true,\n';
          appDashboardContent += '      "linewidth": 1,\n';
          appDashboardContent += '      "nullPointMode": "null",\n';
          appDashboardContent += '      "options": {\n';
          appDashboardContent += '        "alertThreshold": true\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "percentage": false,\n';
          appDashboardContent += '      "pluginVersion": "7.3.7",\n';
          appDashboardContent += '      "pointradius": 2,\n';
          appDashboardContent += '      "points": false,\n';
          appDashboardContent += '      "renderer": "flot",\n';
          appDashboardContent += '      "seriesOverrides": [],\n';
          appDashboardContent += '      "spaceLength": 10,\n';
          appDashboardContent += '      "stack": false,\n';
          appDashboardContent += '      "steppedLine": false,\n';
          appDashboardContent += '      "targets": [\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "expr": "rate(http_requests_total{status=~\\"5..\\"} [5m])",\n';
          appDashboardContent += '          "interval": "",\n';
          appDashboardContent += '          "legendFormat": "Error Rate",\n';
          appDashboardContent += '          "refId": "A"\n';
          appDashboardContent += '        }\n';
          appDashboardContent += '      ],\n';
          appDashboardContent += '      "thresholds": [],\n';
          appDashboardContent += '      "timeFrom": null,\n';
          appDashboardContent += '      "timeRegions": [],\n';
          appDashboardContent += '      "timeShift": null,\n';
          appDashboardContent += '      "title": "Backend Error Rate",\n';
          appDashboardContent += '      "tooltip": {\n';
          appDashboardContent += '        "shared": true,\n';
          appDashboardContent += '        "sort": 0,\n';
          appDashboardContent += '        "value_type": "individual"\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "type": "graph",\n';
          appDashboardContent += '      "xaxis": {\n';
          appDashboardContent += '        "buckets": null,\n';
          appDashboardContent += '        "mode": "time",\n';
          appDashboardContent += '        "name": null,\n';
          appDashboardContent += '        "show": true,\n';
          appDashboardContent += '        "values": []\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "yaxes": [\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "format": "short",\n';
          appDashboardContent += '          "label": null,\n';
          appDashboardContent += '          "logBase": 1,\n';
          appDashboardContent += '          "max": null,\n';
          appDashboardContent += '          "min": null,\n';
          appDashboardContent += '          "show": true\n';
          appDashboardContent += '        },\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "format": "short",\n';
          appDashboardContent += '          "label": null,\n';
          appDashboardContent += '          "logBase": 1,\n';
          appDashboardContent += '          "max": null,\n';
          appDashboardContent += '          "min": null,\n';
          appDashboardContent += '          "show": true\n';
          appDashboardContent += '        }\n';
          appDashboardContent += '      ],\n';
          appDashboardContent += '      "yaxis": {\n';
          appDashboardContent += '        "align": false,\n';
          appDashboardContent += '        "alignLevel": null\n';
          appDashboardContent += '      }\n';
          appDashboardContent += '    }\n';
        }
        
        if (config.services.includes('frontend')) {
          appDashboardContent += '    {\n';
          appDashboardContent += '      "aliasColors": {},\n';
          appDashboardContent += '      "bars": false,\n';
          appDashboardContent += '      "dashLength": 10,\n';
          appDashboardContent += '      "dashes": false,\n';
          appDashboardContent += '      "datasource": "Prometheus",\n';
          appDashboardContent += '      "fieldConfig": {\n';
          appDashboardContent += '        "defaults": {\n';
          appDashboardContent += '          "custom": {}\n';
          appDashboardContent += '        },\n';
          appDashboardContent += '        "overrides": []\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "fill": 1,\n';
          appDashboardContent += '      "fillGradient": 0,\n';
          appDashboardContent += '      "gridPos": {\n';
          appDashboardContent += '        "h": 8,\n';
          appDashboardContent += '        "w": 12,\n';
          appDashboardContent += '        "x": 12,\n';
          appDashboardContent += '        "y": 8\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "hiddenSeries": false,\n';
          appDashboardContent += '      "id": 5,\n';
          appDashboardContent += '      "legend": {\n';
          appDashboardContent += '        "avg": false,\n';
          appDashboardContent += '        "current": false,\n';
          appDashboardContent += '        "max": false,\n';
          appDashboardContent += '        "min": false,\n';
          appDashboardContent += '        "show": true,\n';
          appDashboardContent += '        "total": false,\n';
          appDashboardContent += '        "values": false\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "lines": true,\n';
          appDashboardContent += '      "linewidth": 1,\n';
          appDashboardContent += '      "nullPointMode": "null",\n';
          appDashboardContent += '      "options": {\n';
          appDashboardContent += '        "alertThreshold": true\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "percentage": false,\n';
          appDashboardContent += '      "pluginVersion": "7.3.7",\n';
          appDashboardContent += '      "pointradius": 2,\n';
          appDashboardContent += '      "points": false,\n';
          appDashboardContent += '      "renderer": "flot",\n';
          appDashboardContent += '      "seriesOverrides": [],\n';
          appDashboardContent += '      "spaceLength": 10,\n';
          appDashboardContent += '      "stack": false,\n';
          appDashboardContent += '      "steppedLine": false,\n';
          appDashboardContent += '      "targets": [\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "expr": "rate(frontend_page_load_time_seconds_sum[5m]) / rate(frontend_page_load_time_seconds_count[5m])",\n';
          appDashboardContent += '          "interval": "",\n';
          appDashboardContent += '          "legendFormat": "Page Load Time",\n';
          appDashboardContent += '          "refId": "A"\n';
          appDashboardContent += '        }\n';
          appDashboardContent += '      ],\n';
          appDashboardContent += '      "thresholds": [],\n';
          appDashboardContent += '      "timeFrom": null,\n';
          appDashboardContent += '      "timeRegions": [],\n';
          appDashboardContent += '      "timeShift": null,\n';
          appDashboardContent += '      "title": "Frontend Page Load Time",\n';
          appDashboardContent += '      "tooltip": {\n';
          appDashboardContent += '        "shared": true,\n';
          appDashboardContent += '        "sort": 0,\n';
          appDashboardContent += '        "value_type": "individual"\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "type": "graph",\n';
          appDashboardContent += '      "xaxis": {\n';
          appDashboardContent += '        "buckets": null,\n';
          appDashboardContent += '        "mode": "time",\n';
          appDashboardContent += '        "name": null,\n';
          appDashboardContent += '        "show": true,\n';
          appDashboardContent += '        "values": []\n';
          appDashboardContent += '      },\n';
          appDashboardContent += '      "yaxes": [\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "format": "s",\n';
          appDashboardContent += '          "label": null,\n';
          appDashboardContent += '          "logBase": 1,\n';
          appDashboardContent += '          "max": null,\n';
          appDashboardContent += '          "min": null,\n';
          appDashboardContent += '          "show": true\n';
          appDashboardContent += '        },\n';
          appDashboardContent += '        {\n';
          appDashboardContent += '          "format": "short",\n';
          appDashboardContent += '          "label": null,\n';
          appDashboardContent += '          "logBase": 1,\n';
          appDashboardContent += '          "max": null,\n';
          appDashboardContent += '          "min": null,\n';
          appDashboardContent += '          "show": true\n';
          appDashboardContent += '        }\n';
          appDashboardContent += '      ],\n';
          appDashboardContent += '      "yaxis": {\n';
          appDashboardContent += '        "align": false,\n';
          appDashboardContent += '        "alignLevel": null\n';
          appDashboardContent += '      }\n';
          appDashboardContent += '    }\n';
        }
        
        appDashboardContent += '  ],\n';
        appDashboardContent += '  "refresh": "5s",\n';
        appDashboardContent += '  "schemaVersion": 26,\n';
        appDashboardContent += '  "style": "dark",\n';
        appDashboardContent += '  "tags": [],\n';
        appDashboardContent += '  "templating": {\n';
        appDashboardContent += '    "list": []\n';
        appDashboardContent += '  },\n';
        appDashboardContent += '  "time": {\n';
        appDashboardContent += '    "from": "now-6h",\n';
        appDashboardContent += '    "to": "now"\n';
        appDashboardContent += '  },\n';
        appDashboardContent += '  "timepicker": {},\n';
        appDashboardContent += '  "timezone": "",\n';
        appDashboardContent += '  "title": "Application Dashboard",\n';
        appDashboardContent += '  "uid": "application",\n';
        appDashboardContent += '  "version": 1\n';
        appDashboardContent += '}\n';
        
        fs.writeFileSync(path.join(dashboardsDir, 'app-dashboard.json'), appDashboardContent);
        
        // Crear datasources.yml
        let datasourcesContent = 'apiVersion: 1\n\n';
        datasourcesContent += 'datasources:\n';
        datasourcesContent += '  - name: Prometheus\n';
        datasourcesContent += '    type: prometheus\n';
        datasourcesContent += '    access: proxy\n';
        datasourcesContent += '    url: http://prometheus:9090\n';
        datasourcesContent += '    isDefault: true\n';
        datasourcesContent += '    editable: true\n';
        
        // Crear directorio de provisioning
        const provisioningDir = path.join(grafanaDir, 'provisioning');
        if (!fs.existsSync(provisioningDir)) {
          fs.mkdirSync(provisioningDir, { recursive: true });
        }
        
        // Crear directorio de datasources
        const datasourcesDir = path.join(provisioningDir, 'datasources');
        if (!fs.existsSync(datasourcesDir)) {
          fs.mkdirSync(datasourcesDir, { recursive: true });
        }
        
        // Escribir datasources.yml
        fs.writeFileSync(path.join(datasourcesDir, 'datasources.yml'), datasourcesContent);
        
        // Crear directorio de dashboards provisioning
        const dashboardsProvDir = path.join(provisioningDir, 'dashboards');
        if (!fs.existsSync(dashboardsProvDir)) {
          fs.mkdirSync(dashboardsProvDir, { recursive: true });
        }
        
        // Crear dashboard.yml
        let dashboardProvContent = 'apiVersion: 1\n\n';
        dashboardProvContent += 'providers:\n';
        dashboardProvContent += '  - name: \'default\'\n';
        dashboardProvContent += '    orgId: 1\n';
        dashboardProvContent += '    folder: \'\'\n';
        dashboardProvContent += '    type: file\n';
        dashboardProvContent += '    disableDeletion: false\n';
        dashboardProvContent += '    editable: true\n';
        dashboardProvContent += '    options:\n';
        dashboardProvContent += '      path: /var/lib/grafana/dashboards\n';
        
        // Escribir dashboard.yml
        fs.writeFileSync(path.join(dashboardsProvDir, 'dashboards.yml'), dashboardProvContent);
        
        // Crear docker-compose.yml
        let dockerComposeContent = 'version: "3.8"\n\n';
        dockerComposeContent += 'services:\n';
        dockerComposeContent += '  prometheus:\n';
        dockerComposeContent += '    image: prom/prometheus:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
        dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
        dockerComposeContent += '      - prometheus_data:/prometheus\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
        dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
        dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
        dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9090:9090"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  alertmanager:\n';
        dockerComposeContent += '    image: prom/alertmanager:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
        dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
        dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9093:9093"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  grafana:\n';
        dockerComposeContent += '    image: grafana/grafana:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./grafana/provisioning:/etc/grafana/provisioning\n';
        dockerComposeContent += '      - ./grafana/dashboards:/var/lib/grafana/dashboards\n';
        dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
        dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
        dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "3000:3000"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  node-exporter:\n';
        dockerComposeContent += '    image: prom/node-exporter:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - /proc:/host/proc:ro\n';
        dockerComposeContent += '      - /sys:/host/sys:ro\n';
        dockerComposeContent += '      - /:/rootfs:ro\n';
        dockerComposeContent += '    command:\n';
        dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
        dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
        dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9100:9100"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  cadvisor:\n';
        dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - /:/rootfs:ro\n';
        dockerComposeContent += '      - /var/run:/var/run:ro\n';
        dockerComposeContent += '      - /sys:/sys:ro\n';
        dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "8080:8080"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - monitoring-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += 'networks:\n';
        dockerComposeContent += '  monitoring-network:\n';
        dockerComposeContent += '    driver: bridge\n\n';
        
        dockerComposeContent += 'volumes:\n';
        dockerComposeContent += '  prometheus_data:\n';
        dockerComposeContent += '    driver: local\n';
        dockerComposeContent += '  alertmanager_data:\n';
        dockerComposeContent += '    driver: local\n';
        dockerComposeContent += '  grafana_data:\n';
        dockerComposeContent += '    driver: local\n';
        
        // Escribir docker-compose.yml
        fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);
        
        // Crear README.md
        let readmeContent = '# Monitoreo de Aplicación\n\n';
        readmeContent += 'Este directorio contiene la configuración para monitorear la aplicación utilizando Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
        readmeContent += '## Componentes\n\n';
        readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
        readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
        readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
        readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
        readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
        readmeContent += '## Inicio Rápido\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Iniciar el stack de monitoreo\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += '## Acceso\n\n';
        readmeContent += '- **Prometheus**: http://localhost:9090\n';
        readmeContent += '- **Alertmanager**: http://localhost:9093\n';
        readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
        readmeContent += '- **Node Exporter**: http://localhost:9100\n';
        readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
        readmeContent += '## Personalización\n\n';
        readmeContent += '### Prometheus\n\n';
        readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
        readmeContent += '### Alertmanager\n\n';
        readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
        readmeContent += '### Grafana\n\n';
        readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/provisioning/dashboards/dashboards.yml` si es necesario.\n';
        
        // Escribir README.md
        fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);
        
        return monitoringDir;
      } catch (error) {
        Logger.error('Error al crear archivos de monitoreo:', error);
        throw error;
      }
    }
    
    /**
     * Crea archivos de configuración para logging
     * @param config Configuración de logging
     * @returns Ruta a los archivos de logging creados
     */
    private createLoggingFiles(config: LoggingConfig): string {
      try {
        const projectDir = process.cwd();
        const loggingDir = path.join(projectDir, 'logging');
        
        if (!fs.existsSync(loggingDir)) {
          fs.mkdirSync(loggingDir, { recursive: true });
        }
        
        // Crear directorio de ELK
        const elkDir = path.join(loggingDir, 'elk');
        if (!fs.existsSync(elkDir)) {
          fs.mkdirSync(elkDir, { recursive: true });
        }
        
        // Crear docker-compose.yml para ELK
        let dockerComposeContent = 'version: "3.8"\n\n';
        dockerComposeContent += 'services:\n';
        dockerComposeContent += '  elasticsearch:\n';
        dockerComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - discovery.type=single-node\n';
        dockerComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "9200:9200"\n';
        dockerComposeContent += '      - "9300:9300"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - elk-network\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  logstash:\n';
        dockerComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "5000:5000"\n';
        dockerComposeContent += '      - "9600:9600"\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - elk-network\n';
        dockerComposeContent += '    depends_on:\n';
        dockerComposeContent += '      - elasticsearch\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  kibana:\n';
        dockerComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
        dockerComposeContent += '    ports:\n';
        dockerComposeContent += '      - "5601:5601"\n';
        dockerComposeContent += '    environment:\n';
        dockerComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - elk-network\n';
        dockerComposeContent += '    depends_on:\n';
        dockerComposeContent += '      - elasticsearch\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += '  filebeat:\n';
        dockerComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
        dockerComposeContent += '    user: root\n';
        dockerComposeContent += '    volumes:\n';
        dockerComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
        dockerComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
        dockerComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
        dockerComposeContent += '    networks:\n';
        dockerComposeContent += '      - elk-network\n';
        dockerComposeContent += '    depends_on:\n';
        dockerComposeContent += '      - elasticsearch\n';
        dockerComposeContent += '      - logstash\n';
        dockerComposeContent += '    restart: unless-stopped\n\n';
        
        dockerComposeContent += 'networks:\n';
        dockerComposeContent += '  elk-network:\n';
        dockerComposeContent += '    driver: bridge\n\n';
        
        dockerComposeContent += 'volumes:\n';
        dockerComposeContent += '  elasticsearch_data:\n';
        dockerComposeContent += '    driver: local\n';
        
        // Escribir docker-compose.yml
        fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), dockerComposeContent);
        
        // Crear directorio de logstash
        const logstashDir = path.join(elkDir, 'logstash');
        if (!fs.existsSync(logstashDir)) {
          fs.mkdirSync(logstashDir, { recursive: true });
        }
        
        // Crear directorio de pipeline
        const pipelineDir = path.join(logstashDir, 'pipeline');
        if (!fs.existsSync(pipelineDir)) {
          fs.mkdirSync(pipelineDir, { recursive: true });
        }
        
        // Crear logstash.conf
        let logstashConfContent = 'input {\n';
        logstashConfContent += '  beats {\n';
        logstashConfContent += '    port => 5000\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n\n';
        logstashConfContent += 'filter {\n';
        logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  } else {\n';
        logstashConfContent += '    mutate {\n';
        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
        logstashConfContent += '    }\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '}\n\n';
        logstashConfContent += 'output {\n';
        logstashConfContent += '  elasticsearch {\n';
        logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
        logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
        logstashConfContent += '  }\n';
        logstashConfContent += '  stdout { codec => rubydebug }\n';
        logstashConfContent += '}\n';
        
        // Escribir logstash.conf
        fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);
        
        // Crear directorio de filebeat
        const filebeatDir = path.join(elkDir, 'filebeat');
        if (!fs.existsSync(filebeatDir)) {
          fs.mkdirSync(filebeatDir, { recursive: true });
        }
        
        // Crear filebeat.yml
        let filebeatContent = 'filebeat.inputs:\n';
        filebeatContent += '- type: container\n';
        filebeatContent += '  paths:\n';
        filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
        filebeatContent += '  json.message_key: log\n';
        filebeatContent += '  json.keys_under_root: true\n';
        filebeatContent += '  processors:\n';
        filebeatContent += '    - add_docker_metadata: ~\n\n';
        filebeatContent += 'processors:\n';
        filebeatContent += '  - add_host_metadata: ~\n';
        filebeatContent += '  - add_cloud_metadata: ~\n\n';
        filebeatContent += 'output.logstash:\n';
        filebeatContent += '  hosts: ["logstash:5000"]\n';
        
        // Escribir filebeat.yml
        fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);
        
        // Crear directorio de fluentd
        const fluentdDir = path.join(loggingDir, 'fluentd');
        if (!fs.existsSync(fluentdDir)) {
          fs.mkdirSync(fluentdDir, { recursive: true });
        }
        
        // Crear docker-compose.yml para Fluentd
        let fluentdComposeContent = 'version: "3.8"\n\n';
        fluentdComposeContent += 'services:\n';
        fluentdComposeContent += '  fluentd:\n';
        fluentdComposeContent += '    image: fluent/fluentd:v1.12\n';
        fluentdComposeContent += '    volumes:\n';
        fluentdComposeContent += '      - ./fluent.conf:/fluentd/etc/fluent.conf\n';
        fluentdComposeContent += '      - fluentd_data:/fluentd/log\n';
        fluentdComposeContent += '    ports:\n';
        fluentdComposeContent += '      - "24224:24224"\n';
        fluentdComposeContent += '      - "24224:24224/udp"\n';
        fluentdComposeContent += '    networks:\n';
        fluentdComposeContent += '      - fluentd-network\n';
        fluentdComposeContent += '    restart: unless-stopped\n\n';
        
        fluentdComposeContent += 'networks:\n';
        fluentdComposeContent += '  fluentd-network:\n';
        fluentdComposeContent += '    driver: bridge\n\n';
        
        fluentdComposeContent += 'volumes:\n';
        fluentdComposeContent += '  fluentd_data:\n';
        fluentdComposeContent += '    driver: local\n';
        
        // Escribir docker-compose.yml para Fluentd
        fs.writeFileSync(path.join(fluentdDir, 'docker-compose.yml'), fluentdComposeContent);
        
        // Crear fluent.conf
        let fluentConfContent = '<source>\n';
        fluentConfContent += '  @type forward\n';
        fluentConfContent += '  port 24224\n';
        fluentConfContent += '  bind 0.0.0.0\n';
        fluentConfContent += '</source>\n\n';
        fluentConfContent += '<match *.**>\n';
        fluentConfContent += '  @type file\n';
        fluentConfContent += '  path /fluentd/log/${tag}/%Y/%m/%d.%H.%M\n';
        fluentConfContent += '  append true\n';
        fluentConfContent += '  <buffer tag,time>\n';
        fluentConfContent += '    timekey 1h\n';
        fluentConfContent += '    timekey_use_utc true\n';
        fluentConfContent += '    timekey_wait 10m\n';
        fluentConfContent += '  </buffer>\n';
        fluentConfContent += '</match>\n';
        
        // Escribir fluent.conf
        fs.writeFileSync(path.join(fluentdDir, 'fluent.conf'), fluentConfContent);
        
        // Crear directorio de Loki
        const lokiDir = path.join(loggingDir, 'loki');
        if (!fs.existsSync(lokiDir)) {
          fs.mkdirSync(lokiDir, { recursive: true });
        }
        
        // Crear docker-compose.yml para Loki
        let lokiComposeContent = 'version: "3.8"\n\n';
        lokiComposeContent += 'services:\n';
        lokiComposeContent += '  loki:\n';
        lokiComposeContent += '    image: grafana/loki:2.3.0\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./loki-config.yaml:/etc/loki/local-config.yaml\n';
        lokiComposeContent += '      - loki_data:/loki\n';
        lokiComposeContent += '    ports:\n';
        lokiComposeContent += '      - "3100:3100"\n';
        lokiComposeContent += '    command: -config.file=/etc/loki/local-config.yaml\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += '  promtail:\n';
        lokiComposeContent += '    image: grafana/promtail:2.3.0\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./promtail-config.yaml:/etc/promtail/config.yaml\n';
        lokiComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
        lokiComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
        lokiComposeContent += '    command: -config.file=/etc/promtail/config.yaml\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    depends_on:\n';
        lokiComposeContent += '      - loki\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += '  grafana:\n';
        lokiComposeContent += '    image: grafana/grafana:latest\n';
        lokiComposeContent += '    volumes:\n';
        lokiComposeContent += '      - ./grafana/provisioning:/etc/grafana/provisioning\n';
        lokiComposeContent += '      - grafana_data:/var/lib/grafana\n';
        lokiComposeContent += '    environment:\n';
        lokiComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
        lokiComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
        lokiComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
        lokiComposeContent += '    ports:\n';
        lokiComposeContent += '      - "3000:3000"\n';
        lokiComposeContent += '    networks:\n';
        lokiComposeContent += '      - loki-network\n';
        lokiComposeContent += '    restart: unless-stopped\n\n';
        
        lokiComposeContent += 'networks:\n';
        lokiComposeContent += '  loki-network:\n';
        lokiComposeContent += '    driver: bridge\n\n';
        
        lokiComposeContent += 'volumes:\n';
        lokiComposeContent += '  loki_data:\n';
        lokiComposeContent += '    driver: local\n';
        lokiComposeContent += '  grafana_data:\n';
        lokiComposeContent += '    driver: local\n';
        
        // Escribir docker-compose.yml para Loki
        fs.writeFileSync(path.join(lokiDir, 'docker-compose.yml'), lokiComposeContent);
        
        // Crear loki-config.yaml
        let lokiConfigContent = 'auth_enabled: false\n\n';
        lokiConfigContent += 'server:\n';
        lokiConfigContent += '  http_listen_port: 3100\n\n';
        lokiConfigContent += 'ingester:\n';
        lokiConfigContent += '  lifecycler:\n';
        lokiConfigContent += '    address: 127.0.0.1\n';
        lokiConfigContent += '    ring:\n';
        lokiConfigContent += '      kvstore:\n';
        lokiConfigContent += '        store: inmemory\n';
        lokiConfigContent += '      replication_factor: 1\n';
        lokiConfigContent += '    final_sleep: 0s\n';
        lokiConfigContent += '  chunk_idle_period: 5m\n';
        lokiConfigContent += '  chunk_retain_period: 30s\n\n';
        lokiConfigContent += 'schema_config:\n';
        lokiConfigContent += '  configs:\n';
        lokiConfigContent += '    - from: 2020-10-24\n';
        lokiConfigContent += '      store: boltdb-shipper\n';
        lokiConfigContent += '      object_store: filesystem\n';
        lokiConfigContent += '      schema: v11\n';
        lokiConfigContent += '      index:\n';
        lokiConfigContent += '        prefix: index_\n';
        lokiConfigContent += '        period: 24h\n\n';
        lokiConfigContent += 'storage_config:\n';
        lokiConfigContent += '  boltdb_shipper:\n';
        lokiConfigContent += '    active_index_directory: /loki/boltdb-shipper-active\n';
        lokiConfigContent += '    cache_location: /loki/boltdb-shipper-cache\n';
        lokiConfigContent += '    cache_ttl: 24h\n';
        lokiConfigContent += '    shared_store: filesystem\n';
        lokiConfigContent += '  filesystem:\n';
        lokiConfigContent += '    directory: /loki/chunks\n\n';
        lokiConfigContent += 'limits_config:\n';
        lokiConfigContent += '  enforce_metric_name: false\n';
        lokiConfigContent += '  reject_old_samples: true\n';
        lokiConfigContent += '  reject_old_samples_max_age: 168h\n\n';
        lokiConfigContent += 'chunk_store_config:\n';
        lokiConfigContent += '  max_look_back_period: 0s\n\n';
        lokiConfigContent += 'table_manager:\n';
        lokiConfigContent += '  retention_deletes_enabled: false\n';
        lokiConfigContent += '  retention_period: 0s\n\n';
        lokiConfigContent += 'compactor:\n';
        lokiConfigContent += '  working_directory: /loki/boltdb-shipper-compactor\n';
        lokiConfigContent += '  shared_store: filesystem\n';
        
        // Escribir loki-config.yaml
        fs.writeFileSync(path.join(lokiDir, 'loki-config.yaml'), lokiConfigContent);
        
        // Crear promtail-config.yaml
        let promtailConfigContent = 'server:\n';
        promtailConfigContent += '  http_listen_port: 9080\n';
        promtailConfigContent += '  grpc_listen_port: 0\n\n';
        promtailConfigContent += 'positions:\n';
        promtailConfigContent += '  filename: /tmp/positions.yaml\n\n';
        promtailConfigContent += 'clients:\n';
        promtailConfigContent += '  - url: http://loki:3100/loki/api/v1/push\n\n';
        promtailConfigContent += 'scrape_configs:\n';
        promtailConfigContent += '  - job_name: docker\n';
        promtailConfigContent += '    docker_sd_configs:\n';
        promtailConfigContent += '      - host: unix:///var/run/docker.sock\n';
        promtailConfigContent += '        refresh_interval: 5s\n';
        promtailConfigContent += '    relabel_configs:\n';
        promtailConfigContent += '      - source_labels: [\'__meta_docker_container_name\']\n';
        promtailConfigContent += '        regex: \'/(.+)\'\n';
        promtailConfigContent += '        target_label: \'container\'\n';
        promtailConfigContent += '      - source_labels: [\'__meta_docker_container_log_stream\']\n';
        promtailConfigContent += '        target_label: \'stream\'\n';
        
        // Escribir promtail-config.yaml
        fs.writeFileSync(path.join(lokiDir, 'promtail-config.yaml'), promtailConfigContent);
        
        // Crear directorio de grafana
        const grafanaDir = path.join(lokiDir, 'grafana');
        if (!fs.existsSync(grafanaDir)) {
          fs.mkdirSync(grafanaDir, { recursive: true });
        }
        
        // Crear directorio de provisioning
        const provisioningDir = path.join(grafanaDir, 'provisioning');
        if (!fs.existsSync(provisioningDir)) {
          fs.mkdirSync(provisioningDir, { recursive: true });
        }
        
        // Crear directorio de datasources
        const datasourcesDir = path.join(provisioningDir, 'datasources');
        if (!fs.existsSync(datasourcesDir)) {
          fs.mkdirSync(datasourcesDir, { recursive: true });
        }
        
        // Crear datasources.yml
        let datasourcesContent = 'apiVersion: 1\n\n';
        datasourcesContent += 'datasources:\n';
        datasourcesContent += '  - name: Loki\n';
        datasourcesContent += '    type: loki\n';
        datasourcesContent += '    access: proxy\n';
        datasourcesContent += '    url: http://loki:3100\n';
        datasourcesContent += '    isDefault: true\n';
        datasourcesContent += '    editable: true\n';
        
        // Escribir datasources.yml
        fs.writeFileSync(path.join(datasourcesDir, 'datasources.yml'), datasourcesContent);
        
        // Crear README.md
        let readmeContent = '# Logging Stack\n\n';
        readmeContent += 'Este directorio contiene diferentes opciones para implementar un sistema de logging en la aplicación.\n\n';
        readmeContent += '## Opciones Disponibles\n\n';
        readmeContent += '### ELK Stack (Elasticsearch, Logstash, Kibana)\n\n';
        readmeContent += 'El stack ELK es una solución completa para recolectar, procesar, almacenar y visualizar logs.\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Iniciar el stack ELK\n';
        readmeContent += 'cd elk\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += 'Acceso:\n';
        readmeContent += '- Elasticsearch: http://localhost:9200\n';
        readmeContent += '- Kibana: http://localhost:5601\n\n';
        readmeContent += '### Fluentd\n\n';
        readmeContent += 'Fluentd es un recolector de datos de código abierto para una capa de logging unificada.\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Iniciar Fluentd\n';
        readmeContent += 'cd fluentd\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += '### Loki Stack (Loki, Promtail, Grafana)\n\n';
        readmeContent += 'Loki es un sistema de agregación de logs inspirado en Prometheus, diseñado para ser muy eficiente en costos y fácil de operar.\n\n';
        readmeContent += '```bash\n';
        readmeContent += '# Iniciar el stack Loki\n';
        readmeContent += 'cd loki\n';
        readmeContent += 'docker-compose up -d\n';
        readmeContent += '```\n\n';
        readmeContent += 'Acceso:\n';
        readmeContent += '- Grafana: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
        readmeContent += '- Loki API: http://localhost:3100\n\n';
        readmeContent += '## Integración con Aplicaciones\n\n';
        readmeContent += '### Docker Logging\n\n';
        readmeContent += 'Para enviar logs de contenedores Docker a cualquiera de estos sistemas, puedes configurar el driver de logging en tu docker-compose.yml:\n\n';
        readmeContent += '```yaml\n';
        readmeContent += 'services:\n';
        readmeContent += '  app:\n';
        readmeContent += '    # ... otras configuraciones\n';
        readmeContent += '    logging:\n';
        readmeContent += '      driver: "fluentd" # o "json-file" para ELK/Loki\n';
        readmeContent += '      options:\n';
        readmeContent += '        fluentd-address: localhost:24224\n';
        readmeContent += '        tag: app.logs\n';
        readmeContent += '```\n\n';
        readmeContent += '### Logging desde Aplicaciones\n\n';
        readmeContent += 'Para Node.js, puedes usar bibliotecas como winston o pino con transportes específicos para cada sistema de logging.\n\n';
        readmeContent += 'Para Java, puedes configurar logback o log4j2 para enviar logs a estos sistemas.\n\n';
        readmeContent += 'Para Python, puedes usar la biblioteca logging con manejadores personalizados.\n';
        
        // Escribir README.md
        fs.writeFileSync(path.join(loggingDir, 'README.md'), readmeContent);
        
        return loggingDir;
      } catch (error) {
        Logger.error('Error al crear archivos de logging:', error);
        throw error;
      }
    }
    
    /**
     * Crea archivos de configuración para CI/CD
     * @param config Configuración de CI/CD
     * @returns Ruta a los archivos de CI/CD creados
     */
    private createCICDFiles(config: CICDConfig): string {
      try {
        const projectDir = process.cwd();
        const cicdDir = path.join(projectDir, '.github');
        
        if (!fs.existsSync(cicdDir)) {
          fs.mkdirSync(cicdDir, { recursive: true });
        }
        
        // Crear directorio de workflows
        const workflowsDir = path.join(cicdDir, 'workflows');
        if (!fs.existsSync(workflowsDir)) {
          fs.mkdirSync(workflowsDir, { recursive: true });
        }
        
        // Crear CI workflow
        let ciWorkflowContent = 'name: CI\n\n';
        ciWorkflowContent += 'on:\n';
        ciWorkflowContent += '  push:\n';
        ciWorkflowContent += '    branches: [ main, develop ]\n';
        ciWorkflowContent += '  pull_request:\n';
        ciWorkflowContent += '    branches: [ main, develop ]\n\n';
        ciWorkflowContent += 'jobs:\n';
        
        if (config.services.includes('backend')) {
          ciWorkflowContent += '  backend-ci:\n';
          ciWorkflowContent += '    runs-on: ubuntu-latest\n';
          ciWorkflowContent += '    steps:\n';
          ciWorkflowContent += '      - uses: actions/checkout@v2\n';
          ciWorkflowContent += '      - name: Set up Node.js\n';
          ciWorkflowContent += '        uses: actions/setup-node@v2\n';
          ciWorkflowContent += '        with:\n';
          ciWorkflowContent += '          node-version: 16\n';
          ciWorkflowContent += '          cache: \'npm\'\n';
          ciWorkflowContent += '          cache-dependency-path: backend/package-lock.json\n';
          ciWorkflowContent += '      - name: Install dependencies\n';
          ciWorkflowContent += '        run: cd backend && npm ci\n';
          ciWorkflowContent += '      - name: Run linter\n';
          ciWorkflowContent += '        run: cd backend && npm run lint\n';
          ciWorkflowContent += '      - name: Run tests\n';
          ciWorkflowContent += '        run: cd backend && npm test\n';
          ciWorkflowContent += '      - name: Build\n';
          ciWorkflowContent += '        run: cd backend && npm run build\n\n';
        }
        
        if (config.services.includes('frontend')) {
          ciWorkflowContent += '  frontend-ci:\n';
          ciWorkflowContent += '    runs-on: ubuntu-latest\n';
          ciWorkflowContent += '    steps:\n';
          ciWorkflowContent += '      - uses: actions/checkout@v2\n';
          ciWorkflowContent += '      - name: Set up Node.js\n';
          ciWorkflowContent += '        uses: actions/setup-node@v2\n';
          ciWorkflowContent += '        with:\n';
          ciWorkflowContent += '          node-version: 16\n';
          ciWorkflowContent += '          cache: \'npm\'\n';
          ciWorkflowContent += '          cache-dependency-path: frontend/package-lock.json\n';
          ciWorkflowContent += '      - name: Install dependencies\n';
          ciWorkflowContent += '        run: cd frontend && npm ci\n';
          ciWorkflowContent += '      - name: Run linter\n';
          ciWorkflowContent += '        run: cd frontend && npm run lint\n';
          ciWorkflowContent += '      - name: Run tests\n';
          ciWorkflowContent += '        run: cd frontend && npm test -- --watchAll=false\n';
          ciWorkflowContent += '      - name: Build\n';
          ciWorkflowContent += '        run: cd frontend && npm run build\n\n';
        }
        
        // Escribir CI workflow
        fs.writeFileSync(path.join(workflowsDir, 'ci.yml'), ciWorkflowContent);
        
        // Crear CD workflow
        let cdWorkflowContent = 'name: CD\n\n';
        cdWorkflowContent += 'on:\n';
        cdWorkflowContent += '  push:\n';
        cdWorkflowContent += '    branches: [ main ]\n\n';
        cdWorkflowContent += 'jobs:\n';
        
        if (config.services.includes('backend')) {
          cdWorkflowContent += '  deploy-backend:\n';
          cdWorkflowContent += '    runs-on: ubuntu-latest\n';
          cdWorkflowContent += '    steps:\n';
          cdWorkflowContent += '      - uses: actions/checkout@v2\n';
          cdWorkflowContent += '      - name: Set up Node.js\n';
          cdWorkflowContent += '        uses: actions/setup-node@v2\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          node-version: 16\n';
          cdWorkflowContent += '          cache: \'npm\'\n';
          cdWorkflowContent += '          cache-dependency-path: backend/package-lock.json\n';
          cdWorkflowContent += '      - name: Install dependencies\n';
          cdWorkflowContent += '        run: cd backend && npm ci\n';
          cdWorkflowContent += '      - name: Build\n';
          cdWorkflowContent += '        run: cd backend && npm run build\n';
          cdWorkflowContent += '      - name: Set up Docker Buildx\n';
          cdWorkflowContent += '        uses: docker/setup-buildx-action@v1\n';
          cdWorkflowContent += '      - name: Login to DockerHub\n';
          cdWorkflowContent += '        uses: docker/login-action@v1\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
          cdWorkflowContent += '          password: ${{ secrets.DOCKERHUB_TOKEN }}\n';
          cdWorkflowContent += '      - name: Build and push backend image\n';
          cdWorkflowContent += '        uses: docker/build-push-action@v2\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          context: ./backend\n';
          cdWorkflowContent += '          push: true\n';
          cdWorkflowContent += '          tags: ${{ secrets.DOCKERHUB_USERNAME }}/backend:latest\n\n';
        }
        
        if (config.services.includes('frontend')) {
          cdWorkflowContent += '  deploy-frontend:\n';
          cdWorkflowContent += '    runs-on: ubuntu-latest\n';
          cdWorkflowContent += '    steps:\n';
          cdWorkflowContent += '      - uses: actions/checkout@v2\n';
          cdWorkflowContent += '      - name: Set up Node.js\n';
          cdWorkflowContent += '        uses: actions/setup-node@v2\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          node-version: 16\n';
          cdWorkflowContent += '          cache: \'npm\'\n';
          cdWorkflowContent += '          cache-dependency-path: frontend/package-lock.json\n';
          cdWorkflowContent += '      - name: Install dependencies\n';
          cdWorkflowContent += '        run: cd frontend && npm ci\n';
          cdWorkflowContent += '      - name: Build\n';
          cdWorkflowContent += '        run: cd frontend && npm run build\n';
          cdWorkflowContent += '      - name: Set up Docker Buildx\n';
          cdWorkflowContent += '        uses: docker/setup-buildx-action@v1\n';
          cdWorkflowContent += '      - name: Login to DockerHub\n';
          cdWorkflowContent += '        uses: docker/login-action@v1\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
          cdWorkflowContent += '          password: ${{ secrets.DOCKERHUB_TOKEN }}\n';
          cdWorkflowContent += '      - name: Build and push frontend image\n';
          cdWorkflowContent += '        uses: docker/build-push-action@v2\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          context: ./frontend\n';
          cdWorkflowContent += '          push: true\n';
          cdWorkflowContent += '          tags: ${{ secrets.DOCKERHUB_USERNAME }}/frontend:latest\n\n';
        }
        
        if (config.deploymentPlatform === 'kubernetes') {
          cdWorkflowContent += '  deploy-to-kubernetes:\n';
          cdWorkflowContent += '    needs: [';
          
          if (config.services.includes('backend')) {
            cdWorkflowContent += 'deploy-backend';
          }
          
          if (config.services.includes('backend') && config.services.includes('frontend')) {
            cdWorkflowContent += ', ';
          }
          
          if (config.services.includes('frontend')) {
            cdWorkflowContent += 'deploy-frontend';
          }
          
          cdWorkflowContent += ']\n';
          cdWorkflowContent += '    runs-on: ubuntu-latest\n';
          cdWorkflowContent += '    steps:\n';
          cdWorkflowContent += '      - uses: actions/checkout@v2\n';
          cdWorkflowContent += '      - name: Set up kubectl\n';
          cdWorkflowContent += '        uses: azure/setup-kubectl@v1\n';
          cdWorkflowContent += '      - name: Set up kubeconfig\n';
          cdWorkflowContent += '        run: |\n';
          cdWorkflowContent += '          mkdir -p $HOME/.kube\n';
          cdWorkflowContent += '          echo "${{ secrets.KUBECONFIG }}" > $HOME/.kube/config\n';
          cdWorkflowContent += '          chmod 600 $HOME/.kube/config\n';
          cdWorkflowContent += '      - name: Deploy to Kubernetes\n';
          cdWorkflowContent += '        run: |\n';
          cdWorkflowContent += '          kubectl apply -f kubernetes/\n';
          cdWorkflowContent += '          kubectl rollout restart deployment backend-deployment\n';
          cdWorkflowContent += '          kubectl rollout restart deployment frontend-deployment\n';
          cdWorkflowContent += '      - name: Verify deployment\n';
          cdWorkflowContent += '        run: |\n';
          cdWorkflowContent += '          kubectl rollout status deployment/backend-deployment\n';
          cdWorkflowContent += '          kubectl rollout status deployment/frontend-deployment\n';
        } else if (config.deploymentPlatform === 'aws') {
          cdWorkflowContent += '  deploy-to-aws:\n';
          cdWorkflowContent += '    needs: [';
          
          if (config.services.includes('backend')) {
            cdWorkflowContent += 'deploy-backend';
          }
          
          if (config.services.includes('backend') && config.services.includes('frontend')) {
            cdWorkflowContent += ', ';
          }
          
          if (config.services.includes('frontend')) {
            cdWorkflowContent += 'deploy-frontend';
          }
          
          cdWorkflowContent += ']\n';
          cdWorkflowContent += '    runs-on: ubuntu-latest\n';
          cdWorkflowContent += '    steps:\n';
          cdWorkflowContent += '      - uses: actions/checkout@v2\n';
          cdWorkflowContent += '      - name: Configure AWS credentials\n';
          cdWorkflowContent += '        uses: aws-actions/configure-aws-credentials@v1\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
          cdWorkflowContent += '          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
          cdWorkflowContent += '          aws-region: ${{ secrets.AWS_REGION }}\n';
          cdWorkflowContent += '      - name: Deploy to ECS\n';
          cdWorkflowContent += '        run: |\n';
          cdWorkflowContent += '          aws ecs update-service --cluster ${{ secrets.ECS_CLUSTER }} --service ${{ secrets.ECS_SERVICE }} --force-new-deployment\n';
          cdWorkflowContent += '      - name: Verify deployment\n';
          cdWorkflowContent += '        run: |\n';
          cdWorkflowContent += '          aws ecs describe-services --cluster ${{ secrets.ECS_CLUSTER }} --services ${{ secrets.ECS_SERVICE }}\n';
        } else if (config.deploymentPlatform === 'azure') {
          cdWorkflowContent += '  deploy-to-azure:\n';
          cdWorkflowContent += '    needs: [';
          
          if (config.services.includes('backend')) {
            cdWorkflowContent += 'deploy-backend';
          }
          
          if (config.services.includes('backend') && config.services.includes('frontend')) {
            cdWorkflowContent += ', ';
          }
          
          if (config.services.includes('frontend')) {
            cdWorkflowContent += 'deploy-frontend';
          }
          
          cdWorkflowContent += ']\n';
          cdWorkflowContent += '    runs-on: ubuntu-latest\n';
          cdWorkflowContent += '    steps:\n';
          cdWorkflowContent += '      - uses: actions/checkout@v2\n';
          cdWorkflowContent += '      - name: Login to Azure\n';
          cdWorkflowContent += '        uses: azure/login@v1\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          creds: ${{ secrets.AZURE_CREDENTIALS }}\n';
          cdWorkflowContent += '      - name: Deploy to Azure Container Instances\n';
          cdWorkflowContent += '        uses: azure/aci-deploy@v1\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}\n';
          cdWorkflowContent += '          dns-name-label: ${{ secrets.AZURE_DNS_LABEL }}\n';
          cdWorkflowContent += '          image: ${{ secrets.DOCKERHUB_USERNAME }}/backend:latest\n';
          cdWorkflowContent += '          name: backend\n';
          cdWorkflowContent += '          location: ${{ secrets.AZURE_LOCATION }}\n';
          cdWorkflowContent += '      - name: Deploy frontend to Azure Container Instances\n';
          cdWorkflowContent += '        uses: azure/aci-deploy@v1\n';
          cdWorkflowContent += '        with:\n';
          cdWorkflowContent += '          resource-group: ${{ secrets.AZURE_RESOURCE_GROUP }}\n';
          cdWorkflowContent += '          dns-name-label: ${{ secrets.AZURE_DNS_LABEL_FRONTEND }}\n';
          cdWorkflowContent += '          image: ${{ secrets.DOCKERHUB_USERNAME }}/frontend:latest\n';
          cdWorkflowContent += '          name: frontend\n';
          cdWorkflowContent += '          location: ${{ secrets.AZURE_LOCATION }}\n';
        }
        
        // Escribir CD workflow
        fs.writeFileSync(path.join(workflowsDir, 'cd.yml'), cdWorkflowContent);
        
        // Crear workflow para pruebas de seguridad
        let securityWorkflowContent = 'name: Security Scan\n\n';
        securityWorkflowContent += 'on:\n';
        securityWorkflowContent += '  push:\n';
        securityWorkflowContent += '    branches: [ main, develop ]\n';
        securityWorkflowContent += '  pull_request:\n';
        securityWorkflowContent += '    branches: [ main, develop ]\n';
        securityWorkflowContent += '  schedule:\n';
        securityWorkflowContent += '    - cron: \'0 0 * * 0\'\n\n';
        securityWorkflowContent += 'jobs:\n';
        securityWorkflowContent += '  security-scan:\n';
        securityWorkflowContent += '    runs-on: ubuntu-latest\n';
        securityWorkflowContent += '    steps:\n';
        securityWorkflowContent += '      - uses: actions/checkout@v2\n';
        securityWorkflowContent += '      - name: Run OWASP ZAP scan\n';
        securityWorkflowContent += '        uses: zaproxy/action-baseline@v0.6.1\n';
        securityWorkflowContent += '        with:\n';
        securityWorkflowContent += '          target: \'https://example.com\'\n\n';
        securityWorkflowContent += '  dependency-check:\n';
        securityWorkflowContent += '    runs-on: ubuntu-latest\n';
        securityWorkflowContent += '    steps:\n';
        securityWorkflowContent += '      - uses: actions/checkout@v2\n';
        
        if (config.services.includes('backend')) {
          securityWorkflowContent += '      - name: Set up Node.js\n';
          securityWorkflowContent += '        uses: actions/setup-node@v2\n';
          securityWorkflowContent += '        with:\n';
          securityWorkflowContent += '          node-version: 16\n';
          securityWorkflowContent += '          cache: \'npm\'\n';
          securityWorkflowContent += '          cache-dependency-path: backend/package-lock.json\n';
          securityWorkflowContent += '      - name: Check backend dependencies\n';
          securityWorkflowContent += '        run: cd backend && npm audit\n';
        }
        
        if (config.services.includes('frontend')) {
          securityWorkflowContent += '      - name: Set up Node.js for frontend\n';
          securityWorkflowContent += '        uses: actions/setup-node@v2\n';
          securityWorkflowContent += '        with:\n';
          securityWorkflowContent += '          node-version: 16\n';
          securityWorkflowContent += '          cache: \'npm\'\n';
          securityWorkflowContent += '          cache-dependency-path: frontend/package-lock.json\n';
          securityWorkflowContent += '      - name: Check frontend dependencies\n';
          securityWorkflowContent += '        run: cd frontend && npm audit\n';
        }
        
        securityWorkflowContent += '  docker-scan:\n';
        securityWorkflowContent += '    runs-on: ubuntu-latest\n';
        securityWorkflowContent += '    steps:\n';
        securityWorkflowContent += '      - uses: actions/checkout@v2\n';
        securityWorkflowContent += '      - name: Build backend image\n';
        securityWorkflowContent += '        run: docker build -t backend:test ./backend\n';
        securityWorkflowContent += '      - name: Scan backend image\n';
        securityWorkflowContent += '        uses: aquasecurity/trivy-action@master\n';
        securityWorkflowContent += '        with:\n';
        securityWorkflowContent += '          image-ref: \'backend:test\'\n';
        securityWorkflowContent += '          format: \'table\'\n';
        securityWorkflowContent += '          exit-code: \'1\'\n';
        securityWorkflowContent += '          ignore-unfixed: true\n';
        securityWorkflowContent += '          vuln-type: \'os,library\'\n';
        securityWorkflowContent += '          severity: \'CRITICAL,HIGH\'\n';
        
        if (config.services.includes('frontend')) {
          securityWorkflowContent += '      - name: Build frontend image\n';
          securityWorkflowContent += '        run: docker build -t frontend:test ./frontend\n';
          securityWorkflowContent += '      - name: Scan frontend image\n';
          securityWorkflowContent += '        uses: aquasecurity/trivy-action@master\n';
          securityWorkflowContent += '        with:\n';
          securityWorkflowContent += '          image-ref: \'frontend:test\'\n';
          securityWorkflowContent += '          format: \'table\'\n';
          securityWorkflowContent += '          exit-code: \'1\'\n';
          securityWorkflowContent += '          ignore-unfixed: true\n';
          securityWorkflowContent += '          vuln-type: \'os,library\'\n';
          securityWorkflowContent += '          severity: \'CRITICAL,HIGH\'\n';
        }
        
        // Escribir security workflow
        fs.writeFileSync(path.join(workflowsDir, 'security.yml'), securityWorkflowContent);
        
        // Crear workflow para pruebas de rendimiento
        let performanceWorkflowContent = 'name: Performance Tests\n\n';
        performanceWorkflowContent += 'on:\n';
        performanceWorkflowContent += '  workflow_dispatch:\n';
        performanceWorkflowContent += '  schedule:\n';
        performanceWorkflowContent += '    - cron: \'0 0 * * 1\'\n\n';
        performanceWorkflowContent += 'jobs:\n';
        performanceWorkflowContent += '  k6-load-test:\n';
        performanceWorkflowContent += '    runs-on: ubuntu-latest\n';
        performanceWorkflowContent += '    steps:\n';
        performanceWorkflowContent += '      - uses: actions/checkout@v2\n';
        performanceWorkflowContent += '      - name: Run k6 load test\n';
        performanceWorkflowContent += '        uses: grafana/k6-action@v0.2.0\n';
        performanceWorkflowContent += '        with:\n';
        performanceWorkflowContent += '          filename: performance/load-test.js\n\n';
        performanceWorkflowContent += '  lighthouse-test:\n';
        performanceWorkflowContent += '    runs-on: ubuntu-latest\n';
        performanceWorkflowContent += '    steps:\n';
        performanceWorkflowContent += '      - uses: actions/checkout@v2\n';
        performanceWorkflowContent += '      - name: Run Lighthouse CI\n';
        performanceWorkflowContent += '        uses: treosh/lighthouse-ci-action@v8\n';
        performanceWorkflowContent += '        with:\n';
        performanceWorkflowContent += '          urls: |\n';
        performanceWorkflowContent += '            https://example.com\n';
        performanceWorkflowContent += '          budgetPath: ./lighthouse/budget.json\n';
        performanceWorkflowContent += '          uploadArtifacts: true\n';
        
        // Escribir performance workflow
        fs.writeFileSync(path.join(workflowsDir, 'performance.yml'), performanceWorkflowContent);
        
        // Crear directorio de performance
        const performanceDir = path.join(projectDir, 'performance');
        if (!fs.existsSync(performanceDir)) {
          fs.mkdirSync(performanceDir, { recursive: true });
        }
        
        // Crear load-test.js
        let loadTestContent = 'import http from \'k6/http\';\n';
        loadTestContent += 'import { sleep } from \'k6\';\n';
        loadTestContent += 'import { check, group } from \'k6\';\n\n';
        loadTestContent += 'export const options = {\n';
        loadTestContent += '  stages: [\n';
        loadTestContent += '    { duration: \'30s\', target: 20 },\n';
        loadTestContent += '    { duration: \'1m\', target: 20 },\n';
        loadTestContent += '    { duration: \'30s\', target: 0 },\n';
        loadTestContent += '  ],\n';
        loadTestContent += '  thresholds: {\n';
        loadTestContent += '    http_req_duration: [\'p(95)<500\'],\n';
        loadTestContent += '    http_req_failed: [\'rate<0.01\'],\n';
        loadTestContent += '  },\n';
        loadTestContent += '};\n\n';
        loadTestContent += 'export default function () {\n';
        loadTestContent += '  group(\'API endpoints\', () => {\n';
        loadTestContent += '    const baseUrl = \'https://example.com/api\';\n\n';
        loadTestContent += '    group(\'Get users\', () => {\n';
        loadTestContent += '      const res = http.get(`${baseUrl}/users`);\n';
        loadTestContent += '      check(res, {\n';
        loadTestContent += '        \'status is 200\': (r) => r.status === 200,\n';
        loadTestContent += '        \'response time < 200ms\': (r) => r.timings.duration < 200,\n';
        loadTestContent += '      });\n';
        loadTestContent += '    });\n\n';
        loadTestContent += '    group(\'Create user\', () => {\n';
        loadTestContent += '      const payload = JSON.stringify({\n';
        loadTestContent += '        name: \'Test User\',\n';
        loadTestContent += '        email: `test${Math.floor(Math.random() * 10000)}@example.com`,\n';
        loadTestContent += '      });\n\n';
        loadTestContent += '      const params = {\n';
        loadTestContent += '        headers: {\n';
        loadTestContent += '          \'Content-Type\': \'application/json\',\n';
        loadTestContent += '        },\n';
        loadTestContent += '      };\n\n';
        loadTestContent += '      const res = http.post(`${baseUrl}/users`, payload, params);\n';
        loadTestContent += '      check(res, {\n';
        loadTestContent += '        \'status is 201\': (r) => r.status === 201,\n';
        loadTestContent += '        \'response time < 300ms\': (r) => r.timings.duration < 300,\n';
        loadTestContent += '      });\n';
        loadTestContent += '    });\n';
        loadTestContent += '  });\n\n';
        loadTestContent += '  sleep(1);\n';
        loadTestContent += '}\n';
        
        // Escribir load-test.js
        fs.writeFileSync(path.join(performanceDir, 'load-test.js'), loadTestContent);
        
        // Crear directorio de lighthouse
        const lighthouseDir = path.join(projectDir, 'lighthouse');
        if (!fs.existsSync(lighthouseDir)) {
          fs.mkdirSync(lighthouseDir, { recursive: true });
        }
        
        // Crear budget.json
        let budgetContent = '[\n';
        budgetContent += '  {\n';
        budgetContent += '    "path": "/*",\n';
        budgetContent += '    "timings": [\n';
        budgetContent += '      {\n';
        budgetContent += '        "metric": "interactive",\n';
        budgetContent += '        "budget": 3000\n';
        budgetContent += '      },\n';
        budgetContent += '      {\n';
        budgetContent += '        "metric": "first-contentful-paint",\n';
        budgetContent += '        "budget": 1800\n';
        budgetContent += '      }\n';
        budgetContent += '    ],\n';
        budgetContent += '    "resourceSizes": [\n';
        budgetContent += '      {\n';
        budgetContent += '        "resourceType": "script",\n';
        budgetContent += '        "budget": 300\n';
        budgetContent += '      },\n';
        budgetContent += '      {\n';
        budgetContent += '        "resourceType": "total",\n';
        budgetContent += '        "budget": 1000\n';
        budgetContent += '      }\n';
        budgetContent += '    ],\n';
        budgetContent += '    "resourceCounts": [\n';
        budgetContent += '      {\n';
        budgetContent += '        "resourceType": "third-party",\n';
        budgetContent += '        "budget": 10\n';
        budgetContent += '      }\n';
        budgetContent += '    ]\n';
        budgetContent += '  }\n';
        budgetContent += ']\n';
        
        // Escribir budget.json
        fs.writeFileSync(path.join(lighthouseDir, 'budget.json'), budgetContent);
        
        // Crear README.md
        let readmeContent = '# CI/CD Pipeline\n\n';
        readmeContent += 'Este directorio contiene la configuración para los pipelines de CI/CD utilizando GitHub Actions.\n\n';
        readmeContent += '## Workflows\n\n';
        readmeContent += '### CI (Integración Continua)\n\n';
        readmeContent += 'El workflow de CI se ejecuta en cada push a las ramas `main` y `develop`, así como en los pull requests a estas ramas.\n\n';
        readmeContent += 'Incluye:\n';
        readmeContent += '- Instalación de dependencias\n';
        readmeContent += '- Linting\n';
        readmeContent += '- Pruebas unitarias\n';
        readmeContent += '- Construcción del proyecto\n\n';
        readmeContent += '### CD (Despliegue Continuo)\n\n';
        readmeContent += 'El workflow de CD se ejecuta en cada push a la rama `main`.\n\n';
        readmeContent += 'Incluye:\n';
        readmeContent += '- Construcción del proyecto\n';
        readmeContent += '- Construcción y publicación de imágenes Docker\n';
        readmeContent += '- Despliegue a la plataforma configurada\n\n';
        readmeContent += '### Security Scan (Análisis de Seguridad)\n\n';
        readmeContent += 'El workflow de seguridad se ejecuta en cada push a las ramas `main` y `develop`, así como en los pull requests a estas ramas. También se ejecuta semanalmente.\n\n';
        readmeContent += 'Incluye:\n';
        readmeContent += '- Escaneo OWASP ZAP\n';
        readmeContent += '- Verificación de dependencias\n';
        readmeContent += '- Escaneo de imágenes Docker con Trivy\n\n';
        readmeContent += '### Performance Tests (Pruebas de Rendimiento)\n\n';
        readmeContent += 'El workflow de rendimiento se puede ejecutar manualmente o está programado para ejecutarse semanalmente.\n\n';
        readmeContent += 'Incluye:\n';
        readmeContent += '- Pruebas de carga con k6\n';
        readmeContent += '- Análisis de rendimiento web con Lighthouse\n\n';
        readmeContent += '## Configuración\n\n';
        readmeContent += 'Para utilizar estos workflows, necesitas configurar los siguientes secretos en tu repositorio de GitHub:\n\n';
        readmeContent += '- `DOCKERHUB_USERNAME`: Tu nombre de usuario de DockerHub\n';
        readmeContent += '- `DOCKERHUB_TOKEN`: Tu token de acceso de DockerHub\n';
        
        if (config.deploymentPlatform === 'kubernetes') {
          readmeContent += '- `KUBECONFIG`: Tu archivo kubeconfig codificado en base64\n';
        } else if (config.deploymentPlatform === 'aws') {
          readmeContent += '- `AWS_ACCESS_KEY_ID`: Tu ID de clave de acceso de AWS\n';
          readmeContent += '- `AWS_SECRET_ACCESS_KEY`: Tu clave de acceso secreta de AWS\n';
          readmeContent += '- `AWS_REGION`: La región de AWS donde se desplegará la aplicación\n';
          readmeContent += '- `ECS_CLUSTER`: El nombre del cluster de ECS\n';
          readmeContent += '- `ECS_SERVICE`: El nombre del servicio de ECS\n';
        } else if (config.deploymentPlatform === 'azure') {
          readmeContent += '- `AZURE_CREDENTIALS`: Tus credenciales de Azure\n';
          readmeContent += '- `AZURE_RESOURCE_GROUP`: El nombre del grupo de recursos de Azure\n';
          readmeContent += '- `AZURE_DNS_LABEL`: La etiqueta DNS para el backend\n';
          readmeContent += '- `AZURE_DNS_LABEL_FRONTEND`: La etiqueta DNS para el frontend\n';
          readmeContent += '- `AZURE_LOCATION`: La ubicación de Azure donde se desplegará la aplicación\n';
        }
        
        // Escribir README.md
        fs.writeFileSync(path.join(cicdDir, 'README.md'), readmeContent);
        
        return cicdDir;
      } catch (error) {
        Logger.error('Error al crear archivos de CI/CD:', error);
        throw error;
      }
    }
    
    /**
     * Crea archivos de configuración para Kubernetes
     * @param config Configuración de Kubernetes
     * @returns Ruta a los archivos de Kubernetes creados
     */
    private createKubernetesFiles(config: KubernetesConfig): string {
      try {
        const projectDir = process.cwd();
        const kubernetesDir = path.join(projectDir, 'kubernetes');
        
        if (!fs.existsSync(kubernetesDir)) {
          fs.mkdirSync(kubernetesDir, { recursive: true });
        }
        
        // Crear namespace.yaml
        let namespaceContent = 'apiVersion: v1\n';
        namespaceContent += 'kind: Namespace\n';
        namespaceContent += 'metadata:\n';
        namespaceContent += `  name: ${config.namespace}\n`;
        
        // Escribir namespace.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'namespace.yaml'), namespaceContent);
        
        if (config.services.includes('backend')) {
          // Crear backend-deployment.yaml
          let backendDeploymentContent = 'apiVersion: apps/v1\n';
          backendDeploymentContent += 'kind: Deployment\n';
          backendDeploymentContent += 'metadata:\n';
          backendDeploymentContent += '  name: backend-deployment\n';
          backendDeploymentContent += `  namespace: ${config.namespace}\n`;
          backendDeploymentContent += 'spec:\n';
          backendDeploymentContent += '  replicas: 3\n';
          backendDeploymentContent += '  selector:\n';
          backendDeploymentContent += '    matchLabels:\n';
          backendDeploymentContent += '      app: backend\n';
          backendDeploymentContent += '  template:\n';
          backendDeploymentContent += '    metadata:\n';
          backendDeploymentContent += '      labels:\n';
          backendDeploymentContent += '        app: backend\n';
          backendDeploymentContent += '    spec:\n';
          backendDeploymentContent += '      containers:\n';
          backendDeploymentContent += '      - name: backend\n';
          backendDeploymentContent += '        image: ${DOCKERHUB_USERNAME}/backend:latest\n';
          backendDeploymentContent += '        ports:\n';
          backendDeploymentContent += '        - containerPort: 3000\n';
          backendDeploymentContent += '        resources:\n';
          backendDeploymentContent += '          limits:\n';
          backendDeploymentContent += '            cpu: "500m"\n';
          backendDeploymentContent += '            memory: "512Mi"\n';
          backendDeploymentContent += '          requests:\n';
          backendDeploymentContent += '            cpu: "200m"\n';
          backendDeploymentContent += '            memory: "256Mi"\n';
          backendDeploymentContent += '        env:\n';
          backendDeploymentContent += '        - name: NODE_ENV\n';
          backendDeploymentContent += '          value: "production"\n';
          backendDeploymentContent += '        - name: DATABASE_URL\n';
          backendDeploymentContent += '          valueFrom:\n';
          backendDeploymentContent += '            secretKeyRef:\n';
          backendDeploymentContent += '              name: backend-secrets\n';
          backendDeploymentContent += '              key: DATABASE_URL\n';
          backendDeploymentContent += '        livenessProbe:\n';
          backendDeploymentContent += '          httpGet:\n';
          backendDeploymentContent += '            path: /health\n';
          backendDeploymentContent += '            port: 3000\n';
          backendDeploymentContent += '          initialDelaySeconds: 30\n';
          backendDeploymentContent += '          periodSeconds: 10\n';
          backendDeploymentContent += '        readinessProbe:\n';
          backendDeploymentContent += '          httpGet:\n';
          backendDeploymentContent += '            path: /health\n';
          backendDeploymentContent += '            port: 3000\n';
          backendDeploymentContent += '          initialDelaySeconds: 5\n';
          backendDeploymentContent += '          periodSeconds: 10\n';
          
          // Escribir backend-deployment.yaml
          fs.writeFileSync(path.join(kubernetesDir, 'backend-deployment.yaml'), backendDeploymentContent);
          
          // Crear backend-service.yaml
          let backendServiceContent = 'apiVersion: v1\n';
          backendServiceContent += 'kind: Service\n';
          backendServiceContent += 'metadata:\n';
          backendServiceContent += '  name: backend-service\n';
          backendServiceContent += `  namespace: ${config.namespace}\n`;
          backendServiceContent += 'spec:\n';
          backendServiceContent += '  selector:\n';
          backendServiceContent += '    app: backend\n';
          backendServiceContent += '  ports:\n';
          backendServiceContent += '  - port: 80\n';
          backendServiceContent += '    targetPort: 3000\n';
          backendServiceContent += '  type: ClusterIP\n';
          
          // Escribir backend-service.yaml
          fs.writeFileSync(path.join(kubernetesDir, 'backend-service.yaml'), backendServiceContent);
          
          // Crear backend-hpa.yaml (Horizontal Pod Autoscaler)
          let backendHpaContent = 'apiVersion: autoscaling/v2\n';
          backendHpaContent += 'kind: HorizontalPodAutoscaler\n';
          backendHpaContent += 'metadata:\n';
          backendHpaContent += '  name: backend-hpa\n';
          backendHpaContent += `  namespace: ${config.namespace}\n`;
          backendHpaContent += 'spec:\n';
          backendHpaContent += '  scaleTargetRef:\n';
          backendHpaContent += '    apiVersion: apps/v1\n';
          backendHpaContent += '    kind: Deployment\n';
          backendHpaContent += '    name: backend-deployment\n';
          backendHpaContent += '  minReplicas: 3\n';
          backendHpaContent += '  maxReplicas: 10\n';
          backendHpaContent += '  metrics:\n';
          backendHpaContent += '  - type: Resource\n';
          backendHpaContent += '    resource:\n';
          backendHpaContent += '      name: cpu\n';
          backendHpaContent += '      target:\n';
          backendHpaContent += '        type: Utilization\n';
          backendHpaContent += '        averageUtilization: 70\n';
          
          // Escribir backend-hpa.yaml
          fs.writeFileSync(path.join(kubernetesDir, 'backend-hpa.yaml'), backendHpaContent);
          
          // Crear backend-secrets.yaml
          let backendSecretsContent = 'apiVersion: v1\n';
          backendSecretsContent += 'kind: Secret\n';
          backendSecretsContent += 'metadata:\n';
          backendSecretsContent += '  name: backend-secrets\n';
          backendSecretsContent += `  namespace: ${config.namespace}\n`;
          backendSecretsContent += 'type: Opaque\n';
          backendSecretsContent += 'data:\n';
          backendSecretsContent += '  # Base64 encoded secrets\n';
          backendSecretsContent += '  DATABASE_URL: cG9zdGdyZXM6Ly91c2VyOnBhc3N3b3JkQGRiOjU0MzIvZGJuYW1l\n';
          
          // Escribir backend-secrets.yaml
          fs.writeFileSync(path.join(kubernetesDir, 'backend-secrets.yaml'), backendSecretsContent);
        }
        
        if (config.services.includes('frontend')) {
          // Crear frontend-deployment.yaml
          let frontendDeploymentContent = 'apiVersion: apps/v1\n';
          frontendDeploymentContent += 'kind: Deployment\n';
          frontendDeploymentContent += 'metadata:\n';
          frontendDeploymentContent += '  name: frontend-deployment\n';
          frontendDeploymentContent += `  namespace: ${config.namespace}\n`;
          frontendDeploymentContent += 'spec:\n';
          frontendDeploymentContent += '  replicas: 3\n';
          frontendDeploymentContent += '  selector:\n';
          frontendDeploymentContent += '    matchLabels:\n';
          frontendDeploymentContent += '      app: frontend\n';
          frontendDeploymentContent += '  template:\n';
          frontendDeploymentContent += '    metadata:\n';
          frontendDeploymentContent += '      labels:\n';
          frontendDeploymentContent += '        app: frontend\n';
          frontendDeploymentContent += '    spec:\n';
          frontendDeploymentContent += '      containers:\n';
          frontendDeploymentContent += '      - name: frontend\n';
          frontendDeploymentContent += '        image: ${DOCKERHUB_USERNAME}/frontend:latest\n';
          frontendDeploymentContent += '        ports:\n';
          frontendDeploymentContent += '        - containerPort: 80\n';
          frontendDeploymentContent += '        resources:\n';
          frontendDeploymentContent += '          limits:\n';
          frontendDeploymentContent += '            cpu: "300m"\n';
          frontendDeploymentContent += '            memory: "256Mi"\n';
          frontendDeploymentContent += '          requests:\n';
          frontendDeploymentContent += '            cpu: "100m"\n';
          frontendDeploymentContent += '            memory: "128Mi"\n';
          frontendDeploymentContent += '        env:\n';
          frontendDeploymentContent += '        - name: REACT_APP_API_URL\n';
          frontendDeploymentContent += '          value: "http://backend-service"\n';
          frontendDeploymentContent += '        livenessProbe:\n';
          frontendDeploymentContent += '          httpGet:\n';
          frontendDeploymentContent += '            path: /\n';
          frontendDeploymentContent += '            port: 80\n';
          frontendDeploymentContent += '          initialDelaySeconds: 30\n';
          frontendDeploymentContent += '          periodSeconds: 10\n';
          frontendDeploymentContent += '        readinessProbe:\n';
          frontendDeploymentContent += '          httpGet:\n';
          frontendDeploymentContent += '            path: /\n';
          frontendDeploymentContent += '            port: 80\n';
          frontendDeploymentContent += '          initialDelaySeconds: 5\n';
          frontendDeploymentContent += '          periodSeconds: 10\n';
          
          // Escribir frontend-deployment.yaml
          fs.writeFileSync(path.join(kubernetesDir, 'frontend-deployment.yaml'), frontendDeploymentContent);
          
          // Crear frontend-service.yaml
          let frontendServiceContent = 'apiVersion: v1\n';
          frontendServiceContent += 'kind: Service\n';
          frontendServiceContent += 'metadata:\n';
          frontendServiceContent += '  name: frontend-service\n';
          frontendServiceContent += `  namespace: ${config.namespace}\n`;
          frontendServiceContent += 'spec:\n';
          frontendServiceContent += '  selector:\n';
          frontendServiceContent += '    app: frontend\n';
          frontendServiceContent += '  ports:\n';
          frontendServiceContent += '  - port: 80\n';
          frontendServiceContent += '    targetPort: 80\n';
          frontendServiceContent += '  type: ClusterIP\n';
          
          // Escribir frontend-service.yaml
          fs.writeFileSync(path.join(kubernetesDir, 'frontend-service.yaml'), frontendServiceContent);
          
          // Crear frontend-hpa.yaml (Horizontal Pod Autoscaler)
          let frontendHpaContent = 'apiVersion: autoscaling/v2\n';
          frontendHpaContent += 'kind: HorizontalPodAutoscaler\n';
          frontendHpaContent += 'metadata:\n';
          frontendHpaContent += '  name: frontend-hpa\n';
          frontendHpaContent += `  namespace: ${config.namespace}\n`;
          frontendHpaContent += 'spec:\n';
          frontendHpaContent += '  scaleTargetRef:\n';
          frontendHpaContent += '    apiVersion: apps/v1\n';
          frontendHpaContent += '    kind: Deployment\n';
          frontendHpaContent += '    name: frontend-deployment\n';
          frontendHpaContent += '  minReplicas: 3\n';
          frontendHpaContent += '  maxReplicas: 10\n';
          frontendHpaContent += '  metrics:\n';
          frontendHpaContent += '  - type: Resource\n';
          frontendHpaContent += '    resource:\n';
          frontendHpaContent += '      name: cpu\n';
          frontendHpaContent += '      target:\n';
          frontendHpaContent += '        type: Utilization\n';
          frontendHpaContent += '        averageUtilization: 70\n';
          
          // Escribir frontend-hpa.yaml
          fs.writeFileSync(path.join(kubernetesDir, 'frontend-hpa.yaml'), frontendHpaContent);
        }
        
        // Crear ingress.yaml
        let ingressContent = 'apiVersion: networking.k8s.io/v1\n';
        ingressContent += 'kind: Ingress\n';
        ingressContent += 'metadata:\n';
        ingressContent += '  name: app-ingress\n';
        ingressContent += `  namespace: ${config.namespace}\n`;
        ingressContent += '  annotations:\n';
        ingressContent += '    kubernetes.io/ingress.class: "nginx"\n';
        ingressContent += '    cert-manager.io/cluster-issuer: "letsencrypt-prod"\n';
        ingressContent += 'spec:\n';
        ingressContent += '  tls:\n';
        ingressContent += '  - hosts:\n';
        ingressContent += '    - example.com\n';
        ingressContent += '    - api.example.com\n';
        ingressContent += '    secretName: app-tls\n';
        ingressContent += '  rules:\n';
        ingressContent += '  - host: example.com\n';
        ingressContent += '    http:\n';
        ingressContent += '      paths:\n';
        ingressContent += '      - path: /\n';
        ingressContent += '        pathType: Prefix\n';
        ingressContent += '        backend:\n';
        ingressContent += '          service:\n';
        ingressContent += '            name: frontend-service\n';
        ingressContent += '            port:\n';
        ingressContent += '              number: 80\n';
        ingressContent += '  - host: api.example.com\n';
        ingressContent += '    http:\n';
        ingressContent += '      paths:\n';
        ingressContent += '      - path: /\n';
        ingressContent += '        pathType: Prefix\n';
        ingressContent += '        backend:\n';
        ingressContent += '          service:\n';
        ingressContent += '            name: backend-service\n';
        ingressContent += '            port:\n';
        ingressContent += '              number: 80\n';
        
        // Escribir ingress.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'ingress.yaml'), ingressContent);
        
        // Crear configmap.yaml
        let configMapContent = 'apiVersion: v1\n';
        configMapContent += 'kind: ConfigMap\n';
        configMapContent += 'metadata:\n';
        configMapContent += '  name: app-config\n';
        configMapContent += `  namespace: ${config.namespace}\n`;
        configMapContent += 'data:\n';
        configMapContent += '  API_URL: "http://backend-service"\n';
        configMapContent += '  LOG_LEVEL: "info"\n';
        
        // Escribir configmap.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'configmap.yaml'), configMapContent);
        
        // Crear persistent-volume.yaml si se requiere almacenamiento
        if (config.storage) {
          let pvContent = 'apiVersion: v1\n';
          pvContent += 'kind: PersistentVolumeClaim\n';
          pvContent += 'metadata:\n';
          pvContent += '  name: app-data\n';
          pvContent += `  namespace: ${config.namespace}\n`;
          pvContent += 'spec:\n';
          pvContent += '  accessModes:\n';
          pvContent += '    - ReadWriteOnce\n';
          pvContent += '  resources:\n';
          pvContent += '    requests:\n';
          pvContent += '      storage: 10Gi\n';
          pvContent += '  storageClassName: standard\n';
          
          // Escribir persistent-volume.yaml
          fs.writeFileSync(path.join(kubernetesDir, 'persistent-volume.yaml'), pvContent);
        }
        
        // Crear network-policy.yaml
        let networkPolicyContent = 'apiVersion: networking.k8s.io/v1\n';
        networkPolicyContent += 'kind: NetworkPolicy\n';
        networkPolicyContent += 'metadata:\n';
        networkPolicyContent += '  name: backend-network-policy\n';
        networkPolicyContent += `  namespace: ${config.namespace}\n`;
        networkPolicyContent += 'spec:\n';
        networkPolicyContent += '  podSelector:\n';
        networkPolicyContent += '    matchLabels:\n';
        networkPolicyContent += '      app: backend\n';
        networkPolicyContent += '  policyTypes:\n';
        networkPolicyContent += '  - Ingress\n';
        networkPolicyContent += '  - Egress\n';
        networkPolicyContent += '  ingress:\n';
        networkPolicyContent += '  - from:\n';
        networkPolicyContent += '    - podSelector:\n';
        networkPolicyContent += '        matchLabels:\n';
        networkPolicyContent += '          app: frontend\n';
        networkPolicyContent += '    ports:\n';
        networkPolicyContent += '    - protocol: TCP\n';
        networkPolicyContent += '      port: 3000\n';
        networkPolicyContent += '  egress:\n';
        networkPolicyContent += '  - to:\n';
        networkPolicyContent += '    - podSelector: {}\n';
        networkPolicyContent += '    ports:\n';
        networkPolicyContent += '    - protocol: TCP\n';
        networkPolicyContent += '      port: 5432\n';
        
        // Escribir network-policy.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'network-policy.yaml'), networkPolicyContent);
        
        // Crear resource-quota.yaml
        let resourceQuotaContent = 'apiVersion: v1\n';
        resourceQuotaContent += 'kind: ResourceQuota\n';
        resourceQuotaContent += 'metadata:\n';
        resourceQuotaContent += '  name: app-quota\n';
        resourceQuotaContent += `  namespace: ${config.namespace}\n`;
        resourceQuotaContent += 'spec:\n';
        resourceQuotaContent += '  hard:\n';
        resourceQuotaContent += '    pods: "20"\n';
        resourceQuotaContent += '    requests.cpu: "4"\n';
        resourceQuotaContent += '    requests.memory: 8Gi\n';
        resourceQuotaContent += '    limits.cpu: "8"\n';
        resourceQuotaContent += '    limits.memory: 16Gi\n';
        
        // Escribir resource-quota.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'resource-quota.yaml'), resourceQuotaContent);
        
        // Crear service-account.yaml
        let serviceAccountContent = 'apiVersion: v1\n';
        serviceAccountContent += 'kind: ServiceAccount\n';
        serviceAccountContent += 'metadata:\n';
        serviceAccountContent += '  name: app-service-account\n';
        serviceAccountContent += `  namespace: ${config.namespace}\n`;
        
        // Escribir service-account.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'service-account.yaml'), serviceAccountContent);
        
        // Crear role.yaml y role-binding.yaml
        let roleContent = 'apiVersion: rbac.authorization.k8s.io/v1\n';
        roleContent += 'kind: Role\n';
        roleContent += 'metadata:\n';
        roleContent += '  name: app-role\n';
        roleContent += `  namespace: ${config.namespace}\n`;
        roleContent += 'rules:\n';
        roleContent += '- apiGroups: ["", "apps", "autoscaling"]\n';
        roleContent += '  resources: ["deployments", "services", "pods", "horizontalpodautoscalers"]\n';
        roleContent += '  verbs: ["get", "list", "watch"]\n';
        
        // Escribir role.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'role.yaml'), roleContent);
        
        let roleBindingContent = 'apiVersion: rbac.authorization.k8s.io/v1\n';
        roleBindingContent += 'kind: RoleBinding\n';
        roleBindingContent += 'metadata:\n';
        roleBindingContent += '  name: app-role-binding\n';
        roleBindingContent += `  namespace: ${config.namespace}\n`;
        roleBindingContent += 'subjects:\n';
        roleBindingContent += '- kind: ServiceAccount\n';
        roleBindingContent += '  name: app-service-account\n';
        roleBindingContent += `  namespace: ${config.namespace}\n`;
        roleBindingContent += 'roleRef:\n';
        roleBindingContent += '  kind: Role\n';
        roleBindingContent += '  name: app-role\n';
        roleBindingContent += '  apiGroup: rbac.authorization.k8s.io\n';
        
        // Escribir role-binding.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'role-binding.yaml'), roleBindingContent);
        
        // Crear kustomization.yaml
        let kustomizationContent = 'apiVersion: kustomize.config.k8s.io/v1beta1\n';
        kustomizationContent += 'kind: Kustomization\n';
        kustomizationContent += 'resources:\n';
        kustomizationContent += '- namespace.yaml\n';
        
        if (config.services.includes('backend')) {
          kustomizationContent += '- backend-deployment.yaml\n';
          kustomizationContent += '- backend-service.yaml\n';
          kustomizationContent += '- backend-hpa.yaml\n';
          kustomizationContent += '- backend-secrets.yaml\n';
        }
        
        if (config.services.includes('frontend')) {
          kustomizationContent += '- frontend-deployment.yaml\n';
          kustomizationContent += '- frontend-service.yaml\n';
          kustomizationContent += '- frontend-hpa.yaml\n';
        }
        
        kustomizationContent += '- ingress.yaml\n';
        kustomizationContent += '- configmap.yaml\n';
        
        if (config.storage) {
          kustomizationContent += '- persistent-volume.yaml\n';
        }
        
        kustomizationContent += '- network-policy.yaml\n';
        kustomizationContent += '- resource-quota.yaml\n';
        kustomizationContent += '- service-account.yaml\n';
        kustomizationContent += '- role.yaml\n';
        kustomizationContent += '- role-binding.yaml\n';
        
        // Escribir kustomization.yaml
        fs.writeFileSync(path.join(kubernetesDir, 'kustomization.yaml'), kustomizationContent);
        
        // Crear README.md
        let readmeContent = '# Kubernetes Configuration\n\n';
        readmeContent += 'Este directorio contiene la configuración de Kubernetes para desplegar la aplicación en un clúster.\n\n';
        readmeContent += '## Estructura\n\n';
        readmeContent += '- `namespace.yaml`: Define el namespace para la aplicación\n';
        
        if (config.services.includes('backend')) {
          readmeContent += '- `backend-deployment.yaml`: Deployment para el backend\n';
          readmeContent += '- `backend-service.yaml`: Servicio para exponer el backend\n';
          readmeContent += '- `backend-hpa.yaml`: Horizontal Pod Autoscaler para el backend\n';
          readmeContent += '- `backend-secrets.yaml`: Secretos para el backend\n';
        }
        
        if (config.services.includes('frontend')) {
          readmeContent += '- `frontend-deployment.yaml`: Deployment para el frontend\n';
          readmeContent += '- `frontend-service.yaml`: Servicio para exponer el frontend\n';
          readmeContent += '- `frontend-hpa.yaml`: Horizontal Pod Autoscaler para el frontend\n';
        }
        
        readmeContent += '- `ingress.yaml`: Ingress para exponer la aplicación externamente\n';
        readmeContent += '- `configmap.yaml`: ConfigMap para configuración de la aplicación\n';
        
        if (config.storage) {
          readmeContent += '- `persistent-volume.yaml`: Persistent Volume Claim para almacenamiento\n';
        }
        
        readmeContent += '- `network-policy.yaml`: Políticas de red para controlar el tráfico\n';
        readmeContent += '- `resource-quota.yaml`: Cuotas de recursos para el namespace\n';
        readmeContent += '- `service-account.yaml`: Cuenta de servicio para la aplicación\n';
        readmeContent += '- `role.yaml`: Rol RBAC para la aplicación\n';
        readmeContent += '- `role-binding.yaml`: Vinculación de rol para la cuenta de servicio\n';
        readmeContent += '- `kustomization.yaml`: Configuración de Kustomize para aplicar todos los recursos\n\n';
        
        readmeContent += '## Despliegue\n\n';
        readmeContent += 'Para desplegar la aplicación en un clúster de Kubernetes, ejecuta:\n\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl apply -k .\n';
        readmeContent += '```\n\n';
        
        readmeContent += 'Para eliminar la aplicación del clúster, ejecuta:\n\n';
        readmeContent += '```bash\n';
        readmeContent += 'kubectl delete -k .\n';
        readmeContent += '```\n\n';
        
        readmeContent += '## Monitoreo\n\n';
        readmeContent += 'Para monitorear los pods, ejecuta:\n\n';
        readmeContent += '```bash\n';
        readmeContent += `kubectl get pods -n ${config.namespace} -w\n`;
        readmeContent += '```\n\n';
        
        readmeContent += 'Para ver los logs de un pod específico, ejecuta:\n\n';
        readmeContent += '```bash\n';
        readmeContent += `kubectl logs -f <nombre-del-pod> -n ${config.namespace}\n`;
        readmeContent += '```\n\n';
        
        readmeContent += '## Escalado\n\n';
        readmeContent += 'Los Horizontal Pod Autoscalers (HPA) escalarán automáticamente los pods según la carga de CPU.\n\n';
        readmeContent += 'Para escalar manualmente, puedes ejecutar:\n\n';
        readmeContent += '```bash\n';
        readmeContent += `kubectl scale deployment <nombre-del-deployment> --replicas=<número-de-réplicas> -n ${config.namespace}\n`;
        readmeContent += '```\n';
        
        // Escribir README.md
        fs.writeFileSync(path.join(kubernetesDir, 'README.md'), readmeContent);
        
        return kubernetesDir;
      } catch (error) {
        Logger.error('Error al crear archivos de Kubernetes:', error);
        throw error;
      }
    }
    
    /**
     * Crea archivos de configuración para Terraform
     * @param config Configuración de Terraform
     * @returns Ruta a los archivos de Terraform creados
     */
    private createTerraformFiles(config: TerraformConfig): string {
      try {
        const projectDir = process.cwd();
        const terraformDir = path.join(projectDir, 'terraform');
        
        if (!fs.existsSync(terraformDir)) {
          fs.mkdirSync(terraformDir, { recursive: true });
        }
        
        // Crear variables.tf
        let variablesContent = 'variable "region" {\n';
        variablesContent += '  description = "The AWS region to deploy to"\n';
        variablesContent += `  default     = "${config.region}"\n`;
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "environment" {\n';
        variablesContent += '  description = "The environment (dev, staging, prod)"\n';
        variablesContent += `  default     = "${config.environment}"\n`;
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "project_name" {\n';
        variablesContent += '  description = "The name of the project"\n';
        variablesContent += `  default     = "${config.projectName}"\n`;
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "vpc_cidr" {\n';
        variablesContent += '  description = "The CIDR block for the VPC"\n';
        variablesContent += '  default     = "10.0.0.0/16"\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "public_subnet_cidrs" {\n';
        variablesContent += '  description = "The CIDR blocks for the public subnets"\n';
        variablesContent += '  type        = list(string)\n';
        variablesContent += '  default     = ["10.0.1.0/24", "10.0.2.0/24"]\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "private_subnet_cidrs" {\n';
        variablesContent += '  description = "The CIDR blocks for the private subnets"\n';
        variablesContent += '  type        = list(string)\n';
        variablesContent += '  default     = ["10.0.3.0/24", "10.0.4.0/24"]\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "availability_zones" {\n';
        variablesContent += '  description = "The availability zones to deploy to"\n';
        variablesContent += '  type        = list(string)\n';
        variablesContent += `  default     = ["${config.region}a", "${config.region}b"]\n`;
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "instance_type" {\n';
        variablesContent += '  description = "The EC2 instance type"\n';
        variablesContent += '  default     = "t3.micro"\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "db_instance_class" {\n';
        variablesContent += '  description = "The RDS instance class"\n';
        variablesContent += '  default     = "db.t3.micro"\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "db_name" {\n';
        variablesContent += '  description = "The name of the database"\n';
        variablesContent += `  default     = "${config.projectName}_db"\n`;
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "db_username" {\n';
        variablesContent += '  description = "The username for the database"\n';
        variablesContent += '  default     = "admin"\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "db_password" {\n';
        variablesContent += '  description = "The password for the database"\n';
        variablesContent += '  sensitive   = true\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "domain_name" {\n';
        variablesContent += '  description = "The domain name for the application"\n';
        variablesContent += '  default     = "example.com"\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "backend_container_port" {\n';
        variablesContent += '  description = "The port the backend container listens on"\n';
        variablesContent += '  default     = 3000\n';
        variablesContent += '}\n\n';
        
        variablesContent += 'variable "frontend_container_port" {\n';
        variablesContent += '  description = "The port the frontend container listens on"\n';
        variablesContent += '  default     = 80\n';
        variablesContent += '}\n';
        
                // Escribir variables.tf
                fs.writeFileSync(path.join(terraformDir, 'variables.tf'), variablesContent);
        
                // Crear main.tf
                let mainContent = 'provider "aws" {\n';
                mainContent += '  region = var.region\n';
                mainContent += '}\n\n';
                
                mainContent += 'terraform {\n';
                mainContent += '  required_version = ">= 1.0.0"\n';
                mainContent += '  required_providers {\n';
                mainContent += '    aws = {\n';
                mainContent += '      source  = "hashicorp/aws"\n';
                mainContent += '      version = "~> 4.0"\n';
                mainContent += '    }\n';
                mainContent += '  }\n';
                mainContent += '  backend "s3" {\n';
                mainContent += '    bucket = "${var.project_name}-terraform-state"\n';
                mainContent += '    key    = "${var.environment}/terraform.tfstate"\n';
                mainContent += '    region = var.region\n';
                mainContent += '  }\n';
                mainContent += '}\n\n';
                
                mainContent += 'module "vpc" {\n';
                mainContent += '  source = "./modules/vpc"\n';
                mainContent += '  \n';
                mainContent += '  project_name         = var.project_name\n';
                mainContent += '  environment          = var.environment\n';
                mainContent += '  vpc_cidr             = var.vpc_cidr\n';
                mainContent += '  public_subnet_cidrs  = var.public_subnet_cidrs\n';
                mainContent += '  private_subnet_cidrs = var.private_subnet_cidrs\n';
                mainContent += '  availability_zones   = var.availability_zones\n';
                mainContent += '}\n\n';
                
                mainContent += 'module "security_groups" {\n';
                mainContent += '  source = "./modules/security_groups"\n';
                mainContent += '  \n';
                mainContent += '  project_name = var.project_name\n';
                mainContent += '  environment  = var.environment\n';
                mainContent += '  vpc_id       = module.vpc.vpc_id\n';
                mainContent += '}\n\n';
                
                if (config.services.includes('database')) {
                  mainContent += 'module "database" {\n';
                  mainContent += '  source = "./modules/database"\n';
                  mainContent += '  \n';
                  mainContent += '  project_name      = var.project_name\n';
                  mainContent += '  environment       = var.environment\n';
                  mainContent += '  db_instance_class = var.db_instance_class\n';
                  mainContent += '  db_name           = var.db_name\n';
                  mainContent += '  db_username       = var.db_username\n';
                  mainContent += '  db_password       = var.db_password\n';
                  mainContent += '  subnet_ids        = module.vpc.private_subnet_ids\n';
                  mainContent += '  security_group_id = module.security_groups.db_security_group_id\n';
                  mainContent += '}\n\n';
                }
                
                if (config.services.includes('backend')) {
                  mainContent += 'module "backend" {\n';
                  mainContent += '  source = "./modules/backend"\n';
                  mainContent += '  \n';
                  mainContent += '  project_name          = var.project_name\n';
                  mainContent += '  environment           = var.environment\n';
                  mainContent += '  vpc_id                = module.vpc.vpc_id\n';
                  mainContent += '  subnet_ids            = module.vpc.private_subnet_ids\n';
                  mainContent += '  security_group_id     = module.security_groups.backend_security_group_id\n';
                  mainContent += '  backend_container_port = var.backend_container_port\n';
                  
                  if (config.services.includes('database')) {
                    mainContent += '  db_host               = module.database.db_host\n';
                    mainContent += '  db_name               = var.db_name\n';
                    mainContent += '  db_username           = var.db_username\n';
                    mainContent += '  db_password           = var.db_password\n';
                  }
                  
                  mainContent += '}\n\n';
                }
                
                if (config.services.includes('frontend')) {
                  mainContent += 'module "frontend" {\n';
                  mainContent += '  source = "./modules/frontend"\n';
                  mainContent += '  \n';
                  mainContent += '  project_name           = var.project_name\n';
                  mainContent += '  environment            = var.environment\n';
                  mainContent += '  vpc_id                 = module.vpc.vpc_id\n';
                  mainContent += '  subnet_ids             = module.vpc.public_subnet_ids\n';
                  mainContent += '  security_group_id      = module.security_groups.frontend_security_group_id\n';
                  mainContent += '  frontend_container_port = var.frontend_container_port\n';
                  
                  if (config.services.includes('backend')) {
                    mainContent += '  backend_url            = module.backend.backend_url\n';
                  }
                  
                  mainContent += '}\n\n';
                }
                
                mainContent += 'module "load_balancer" {\n';
                mainContent += '  source = "./modules/load_balancer"\n';
                mainContent += '  \n';
                mainContent += '  project_name      = var.project_name\n';
                mainContent += '  environment       = var.environment\n';
                mainContent += '  vpc_id            = module.vpc.vpc_id\n';
                mainContent += '  public_subnet_ids = module.vpc.public_subnet_ids\n';
                
                if (config.services.includes('backend')) {
                  mainContent += '  backend_target_group = module.backend.target_group\n';
                }
                
                if (config.services.includes('frontend')) {
                  mainContent += '  frontend_target_group = module.frontend.target_group\n';
                }
                
                mainContent += '}\n\n';
                
                mainContent += 'module "dns" {\n';
                mainContent += '  source = "./modules/dns"\n';
                mainContent += '  \n';
                mainContent += '  domain_name     = var.domain_name\n';
                mainContent += '  load_balancer_dns_name = module.load_balancer.dns_name\n';
                mainContent += '  load_balancer_zone_id  = module.load_balancer.zone_id\n';
                mainContent += '}\n';
                
                // Escribir main.tf
                fs.writeFileSync(path.join(terraformDir, 'main.tf'), mainContent);
                
                // Crear outputs.tf
                let outputsContent = 'output "vpc_id" {\n';
                outputsContent += '  value = module.vpc.vpc_id\n';
                outputsContent += '}\n\n';
                
                outputsContent += 'output "public_subnet_ids" {\n';
                outputsContent += '  value = module.vpc.public_subnet_ids\n';
                outputsContent += '}\n\n';
                
                outputsContent += 'output "private_subnet_ids" {\n';
                outputsContent += '  value = module.vpc.private_subnet_ids\n';
                outputsContent += '}\n\n';
                
                if (config.services.includes('database')) {
                  outputsContent += 'output "db_host" {\n';
                  outputsContent += '  value = module.database.db_host\n';
                  outputsContent += '}\n\n';
                }
                
                if (config.services.includes('backend')) {
                  outputsContent += 'output "backend_url" {\n';
                  outputsContent += '  value = module.backend.backend_url\n';
                  outputsContent += '}\n\n';
                }
                
                if (config.services.includes('frontend')) {
                  outputsContent += 'output "frontend_url" {\n';
                  outputsContent += '  value = module.frontend.frontend_url\n';
                  outputsContent += '}\n\n';
                }
                
                outputsContent += 'output "load_balancer_dns_name" {\n';
                outputsContent += '  value = module.load_balancer.dns_name\n';
                outputsContent += '}\n\n';
                
                outputsContent += 'output "website_url" {\n';
                outputsContent += '  value = "https://${var.domain_name}"\n';
                outputsContent += '}\n';
                
                // Escribir outputs.tf
                fs.writeFileSync(path.join(terraformDir, 'outputs.tf'), outputsContent);
                
                // Crear terraform.tfvars
                let tfvarsContent = 'region      = "' + config.region + '"\n';
                tfvarsContent += 'environment = "' + config.environment + '"\n';
                tfvarsContent += 'project_name = "' + config.projectName + '"\n';
                tfvarsContent += 'vpc_cidr    = "10.0.0.0/16"\n';
                tfvarsContent += 'public_subnet_cidrs  = ["10.0.1.0/24", "10.0.2.0/24"]\n';
                tfvarsContent += 'private_subnet_cidrs = ["10.0.3.0/24", "10.0.4.0/24"]\n';
                tfvarsContent += 'availability_zones   = ["' + config.region + 'a", "' + config.region + 'b"]\n';
                tfvarsContent += 'instance_type = "t3.micro"\n';
                tfvarsContent += 'db_instance_class = "db.t3.micro"\n';
                tfvarsContent += 'db_name     = "' + config.projectName + '_db"\n';
                tfvarsContent += 'db_username = "admin"\n';
                tfvarsContent += '# db_password = "CHANGE_ME" # Establecer en variables de entorno o en un archivo seguro\n';
                tfvarsContent += 'domain_name = "example.com"\n';
                tfvarsContent += 'backend_container_port = 3000\n';
                tfvarsContent += 'frontend_container_port = 80\n';
                
                // Escribir terraform.tfvars
                fs.writeFileSync(path.join(terraformDir, 'terraform.tfvars'), tfvarsContent);
                
                // Crear directorios de módulos
                const modulesDir = path.join(terraformDir, 'modules');
                if (!fs.existsSync(modulesDir)) {
                  fs.mkdirSync(modulesDir, { recursive: true });
                }
                
                // Crear módulo VPC
                const vpcDir = path.join(modulesDir, 'vpc');
                if (!fs.existsSync(vpcDir)) {
                  fs.mkdirSync(vpcDir, { recursive: true });
                }
                
                // Crear vpc/main.tf
                let vpcMainContent = 'resource "aws_vpc" "main" {\n';
                vpcMainContent += '  cidr_block           = var.vpc_cidr\n';
                vpcMainContent += '  enable_dns_hostnames = true\n';
                vpcMainContent += '  enable_dns_support   = true\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  tags = {\n';
                vpcMainContent += '    Name        = "${var.project_name}-${var.environment}-vpc"\n';
                vpcMainContent += '    Environment = var.environment\n';
                vpcMainContent += '    Project     = var.project_name\n';
                vpcMainContent += '    Terraform   = "true"\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_internet_gateway" "main" {\n';
                vpcMainContent += '  vpc_id = aws_vpc.main.id\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  tags = {\n';
                vpcMainContent += '    Name        = "${var.project_name}-${var.environment}-igw"\n';
                vpcMainContent += '    Environment = var.environment\n';
                vpcMainContent += '    Project     = var.project_name\n';
                vpcMainContent += '    Terraform   = "true"\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_subnet" "public" {\n';
                vpcMainContent += '  count                   = length(var.public_subnet_cidrs)\n';
                vpcMainContent += '  vpc_id                  = aws_vpc.main.id\n';
                vpcMainContent += '  cidr_block              = var.public_subnet_cidrs[count.index]\n';
                vpcMainContent += '  availability_zone       = var.availability_zones[count.index]\n';
                vpcMainContent += '  map_public_ip_on_launch = true\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  tags = {\n';
                vpcMainContent += '    Name        = "${var.project_name}-${var.environment}-public-subnet-${count.index + 1}"\n';
                vpcMainContent += '    Environment = var.environment\n';
                vpcMainContent += '    Project     = var.project_name\n';
                vpcMainContent += '    Terraform   = "true"\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_subnet" "private" {\n';
                vpcMainContent += '  count                   = length(var.private_subnet_cidrs)\n';
                vpcMainContent += '  vpc_id                  = aws_vpc.main.id\n';
                vpcMainContent += '  cidr_block              = var.private_subnet_cidrs[count.index]\n';
                vpcMainContent += '  availability_zone       = var.availability_zones[count.index]\n';
                vpcMainContent += '  map_public_ip_on_launch = false\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  tags = {\n';
                vpcMainContent += '    Name        = "${var.project_name}-${var.environment}-private-subnet-${count.index + 1}"\n';
                vpcMainContent += '    Environment = var.environment\n';
                vpcMainContent += '    Project     = var.project_name\n';
                vpcMainContent += '    Terraform   = "true"\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_eip" "nat" {\n';
                vpcMainContent += '  domain = "vpc"\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  tags = {\n';
                vpcMainContent += '    Name        = "${var.project_name}-${var.environment}-nat-eip"\n';
                vpcMainContent += '    Environment = var.environment\n';
                vpcMainContent += '    Project     = var.project_name\n';
                vpcMainContent += '    Terraform   = "true"\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_nat_gateway" "main" {\n';
                vpcMainContent += '  allocation_id = aws_eip.nat.id\n';
                vpcMainContent += '  subnet_id     = aws_subnet.public[0].id\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  tags = {\n';
                vpcMainContent += '    Name        = "${var.project_name}-${var.environment}-nat-gateway"\n';
                vpcMainContent += '    Environment = var.environment\n';
                vpcMainContent += '    Project     = var.project_name\n';
                vpcMainContent += '    Terraform   = "true"\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_route_table" "public" {\n';
                vpcMainContent += '  vpc_id = aws_vpc.main.id\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  route {\n';
                vpcMainContent += '    cidr_block = "0.0.0.0/0"\n';
                vpcMainContent += '    gateway_id = aws_internet_gateway.main.id\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  tags = {\n';
                vpcMainContent += '    Name        = "${var.project_name}-${var.environment}-public-route-table"\n';
                vpcMainContent += '    Environment = var.environment\n';
                vpcMainContent += '    Project     = var.project_name\n';
                vpcMainContent += '    Terraform   = "true"\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_route_table" "private" {\n';
                vpcMainContent += '  vpc_id = aws_vpc.main.id\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  route {\n';
                vpcMainContent += '    cidr_block     = "0.0.0.0/0"\n';
                vpcMainContent += '    nat_gateway_id = aws_nat_gateway.main.id\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '  \n';
                vpcMainContent += '  tags = {\n';
                vpcMainContent += '    Name        = "${var.project_name}-${var.environment}-private-route-table"\n';
                vpcMainContent += '    Environment = var.environment\n';
                vpcMainContent += '    Project     = var.project_name\n';
                vpcMainContent += '    Terraform   = "true"\n';
                vpcMainContent += '  }\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_route_table_association" "public" {\n';
                vpcMainContent += '  count          = length(var.public_subnet_cidrs)\n';
                vpcMainContent += '  subnet_id      = aws_subnet.public[count.index].id\n';
                vpcMainContent += '  route_table_id = aws_route_table.public.id\n';
                vpcMainContent += '}\n\n';
                
                vpcMainContent += 'resource "aws_route_table_association" "private" {\n';
                vpcMainContent += '  count          = length(var.private_subnet_cidrs)\n';
                vpcMainContent += '  subnet_id      = aws_subnet.private[count.index].id\n';
                vpcMainContent += '  route_table_id = aws_route_table.private.id\n';
                vpcMainContent += '}\n';
                
                // Escribir vpc/main.tf
                fs.writeFileSync(path.join(vpcDir, 'main.tf'), vpcMainContent);
                
                // Crear vpc/variables.tf
                let vpcVariablesContent = 'variable "project_name" {\n';
                vpcVariablesContent += '  description = "The name of the project"\n';
                vpcVariablesContent += '}\n\n';
                
                vpcVariablesContent += 'variable "environment" {\n';
                vpcVariablesContent += '  description = "The environment (dev, staging, prod)"\n';
                vpcVariablesContent += '}\n\n';
                
                vpcVariablesContent += 'variable "vpc_cidr" {\n';
                vpcVariablesContent += '  description = "The CIDR block for the VPC"\n';
                vpcVariablesContent += '}\n\n';
                
                vpcVariablesContent += 'variable "public_subnet_cidrs" {\n';
                vpcVariablesContent += '  description = "The CIDR blocks for the public subnets"\n';
                vpcVariablesContent += '  type        = list(string)\n';
                vpcVariablesContent += '}\n\n';
                
                vpcVariablesContent += 'variable "private_subnet_cidrs" {\n';
                vpcVariablesContent += '  description = "The CIDR blocks for the private subnets"\n';
                vpcVariablesContent += '  type        = list(string)\n';
                vpcVariablesContent += '}\n\n';
                
                vpcVariablesContent += 'variable "availability_zones" {\n';
                vpcVariablesContent += '  description = "The availability zones to deploy to"\n';
                vpcVariablesContent += '  type        = list(string)\n';
                vpcVariablesContent += '}\n';
                
                // Escribir vpc/variables.tf
                fs.writeFileSync(path.join(vpcDir, 'variables.tf'), vpcVariablesContent);
                
                // Crear vpc/outputs.tf
                let vpcOutputsContent = 'output "vpc_id" {\n';
                vpcOutputsContent += '  value = aws_vpc.main.id\n';
                vpcOutputsContent += '}\n\n';
                
                vpcOutputsContent += 'output "public_subnet_ids" {\n';
                vpcOutputsContent += '  value = aws_subnet.public[*].id\n';
                vpcOutputsContent += '}\n\n';
                
                vpcOutputsContent += 'output "private_subnet_ids" {\n';
                vpcOutputsContent += '  value = aws_subnet.private[*].id\n';
                vpcOutputsContent += '}\n';
                
                // Escribir vpc/outputs.tf
                fs.writeFileSync(path.join(vpcDir, 'outputs.tf'), vpcOutputsContent);
                
                // Crear módulo Security Groups
                const sgDir = path.join(modulesDir, 'security_groups');
                if (!fs.existsSync(sgDir)) {
                  fs.mkdirSync(sgDir, { recursive: true });
                }
                
                // Crear security_groups/main.tf
                let sgMainContent = 'resource "aws_security_group" "alb" {\n';
                sgMainContent += '  name        = "${var.project_name}-${var.environment}-alb-sg"\n';
                sgMainContent += '  description = "Security group for ALB"\n';
                sgMainContent += '  vpc_id      = var.vpc_id\n';
                sgMainContent += '  \n';
                sgMainContent += '  ingress {\n';
                sgMainContent += '    from_port   = 80\n';
                sgMainContent += '    to_port     = 80\n';
                sgMainContent += '    protocol    = "tcp"\n';
                sgMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                sgMainContent += '  }\n';
                sgMainContent += '  \n';
                sgMainContent += '  ingress {\n';
                sgMainContent += '    from_port   = 443\n';
                sgMainContent += '    to_port     = 443\n';
                sgMainContent += '    protocol    = "tcp"\n';
                sgMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                sgMainContent += '  }\n';
                sgMainContent += '  \n';
                sgMainContent += '  egress {\n';
                sgMainContent += '    from_port   = 0\n';
                sgMainContent += '    to_port     = 0\n';
                sgMainContent += '    protocol    = "-1"\n';
                sgMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                sgMainContent += '  }\n';
                sgMainContent += '  \n';
                sgMainContent += '  tags = {\n';
                sgMainContent += '    Name        = "${var.project_name}-${var.environment}-alb-sg"\n';
                sgMainContent += '    Environment = var.environment\n';
                sgMainContent += '    Project     = var.project_name\n';
                sgMainContent += '    Terraform   = "true"\n';
                sgMainContent += '  }\n';
                sgMainContent += '}\n\n';
                
                if (config.services.includes('frontend')) {
                  sgMainContent += 'resource "aws_security_group" "frontend" {\n';
                  sgMainContent += '  name        = "${var.project_name}-${var.environment}-frontend-sg"\n';
                  sgMainContent += '  description = "Security group for frontend"\n';
                  sgMainContent += '  vpc_id      = var.vpc_id\n';
                  sgMainContent += '  \n';
                  sgMainContent += '  ingress {\n';
                  sgMainContent += '    from_port       = 80\n';
                  sgMainContent += '    to_port         = 80\n';
                  sgMainContent += '    protocol        = "tcp"\n';
                  sgMainContent += '    security_groups = [aws_security_group.alb.id]\n';
                  sgMainContent += '  }\n';
                  sgMainContent += '  \n';
                  sgMainContent += '  egress {\n';
                  sgMainContent += '    from_port   = 0\n';
                  sgMainContent += '    to_port     = 0\n';
                  sgMainContent += '    protocol    = "-1"\n';
                  sgMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                  sgMainContent += '  }\n';
                  sgMainContent += '  \n';
                  sgMainContent += '  tags = {\n';
                  sgMainContent += '    Name        = "${var.project_name}-${var.environment}-frontend-sg"\n';
                  sgMainContent += '    Environment = var.environment\n';
                  sgMainContent += '    Project     = var.project_name\n';
                  sgMainContent += '    Terraform   = "true"\n';
                  sgMainContent += '  }\n';
                  sgMainContent += '}\n\n';
                }
                
                if (config.services.includes('backend')) {
                  sgMainContent += 'resource "aws_security_group" "backend" {\n';
                  sgMainContent += '  name        = "${var.project_name}-${var.environment}-backend-sg"\n';
                  sgMainContent += '  description = "Security group for backend"\n';
                  sgMainContent += '  vpc_id      = var.vpc_id\n';
                  sgMainContent += '  \n';
                  sgMainContent += '  ingress {\n';
                  sgMainContent += '    from_port       = 3000\n';
                  sgMainContent += '    to_port         = 3000\n';
                  sgMainContent += '    protocol        = "tcp"\n';
                  sgMainContent += '    security_groups = [aws_security_group.alb.id]\n';
                  sgMainContent += '  }\n';
                  
                  if (config.services.includes('frontend')) {
                    sgMainContent += '  \n';
                    sgMainContent += '  ingress {\n';
                    sgMainContent += '    from_port       = 3000\n';
                    sgMainContent += '    to_port         = 3000\n';
                    sgMainContent += '    protocol        = "tcp"\n';
                    sgMainContent += '    security_groups = [aws_security_group.frontend.id]\n';
                    sgMainContent += '  }\n';
                  }
                  
                  sgMainContent += '  \n';
                  sgMainContent += '  egress {\n';
                  sgMainContent += '    from_port   = 0\n';
                  sgMainContent += '    to_port     = 0\n';
                  sgMainContent += '    protocol    = "-1"\n';
                  sgMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                  sgMainContent += '  }\n';
                  sgMainContent += '  \n';
                  sgMainContent += '  tags = {\n';
                  sgMainContent += '    Name        = "${var.project_name}-${var.environment}-backend-sg"\n';
                  sgMainContent += '    Environment = var.environment\n';
                  sgMainContent += '    Project     = var.project_name\n';
                  sgMainContent += '    Terraform   = "true"\n';
                  sgMainContent += '  }\n';
                  sgMainContent += '}\n\n';
                }
                
                if (config.services.includes('database')) {
                  sgMainContent += 'resource "aws_security_group" "db" {\n';
                  sgMainContent += '  name        = "${var.project_name}-${var.environment}-db-sg"\n';
                  sgMainContent += '  description = "Security group for database"\n';
                  sgMainContent += '  vpc_id      = var.vpc_id\n';
                  sgMainContent += '  \n';
                  
                  if (config.services.includes('backend')) {
                    sgMainContent += '  ingress {\n';
                    sgMainContent += '    from_port       = 5432\n';
                    sgMainContent += '    to_port         = 5432\n';
                    sgMainContent += '    protocol        = "tcp"\n';
                    sgMainContent += '    security_groups = [aws_security_group.backend.id]\n';
                    sgMainContent += '  }\n';
                  } else {
                    sgMainContent += '  ingress {\n';
                    sgMainContent += '    from_port   = 5432\n';
                    sgMainContent += '    to_port     = 5432\n';
                    sgMainContent += '    protocol    = "tcp"\n';
                    sgMainContent += '    cidr_blocks = ["10.0.0.0/16"]\n';
                    sgMainContent += '  }\n';
                  }
                  
                  sgMainContent += '  \n';
                  sgMainContent += '  egress {\n';
                  sgMainContent += '    from_port   = 0\n';
                  sgMainContent += '    to_port     = 0\n';
                  sgMainContent += '    protocol    = "-1"\n';
                  sgMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                  sgMainContent += '  }\n';
                  sgMainContent += '  \n';
                  sgMainContent += '  tags = {\n';
                  sgMainContent += '    Name        = "${var.project_name}-${var.environment}-db-sg"\n';
                  sgMainContent += '    Environment = var.environment\n';
                  sgMainContent += '    Project     = var.project_name\n';
                  sgMainContent += '    Terraform   = "true"\n';
                  sgMainContent += '  }\n';
                  sgMainContent += '}\n';
                }
                
                // Escribir security_groups/main.tf
                fs.writeFileSync(path.join(sgDir, 'main.tf'), sgMainContent);
                
                // Crear security_groups/variables.tf
                let sgVariablesContent = 'variable "project_name" {\n';
                sgVariablesContent += '  description = "The name of the project"\n';
                sgVariablesContent += '}\n\n';
                
                sgVariablesContent += 'variable "environment" {\n';
                sgVariablesContent += '  description = "The environment (dev, staging, prod)"\n';
                sgVariablesContent += '}\n\n';
                
                sgVariablesContent += 'variable "vpc_id" {\n';
                sgVariablesContent += '  description = "The ID of the VPC"\n';
                sgVariablesContent += '}\n';
                
                // Escribir security_groups/variables.tf
                fs.writeFileSync(path.join(sgDir, 'variables.tf'), sgVariablesContent);
                
                // Crear security_groups/outputs.tf
                let sgOutputsContent = 'output "alb_security_group_id" {\n';
                sgOutputsContent += '  value = aws_security_group.alb.id\n';
                sgOutputsContent += '}\n\n';
                
                if (config.services.includes('frontend')) {
                  sgOutputsContent += 'output "frontend_security_group_id" {\n';
                  sgOutputsContent += '  value = aws_security_group.frontend.id\n';
                  sgOutputsContent += '}\n\n';
                }
                
                if (config.services.includes('backend')) {
                  sgOutputsContent += 'output "backend_security_group_id" {\n';
                  sgOutputsContent += '  value = aws_security_group.backend.id\n';
                  sgOutputsContent += '}\n\n';
                }
                
                if (config.services.includes('database')) {
                  sgOutputsContent += 'output "db_security_group_id" {\n';
                  sgOutputsContent += '  value = aws_security_group.db.id\n';
                  sgOutputsContent += '}\n';
                }
                
                // Escribir security_groups/outputs.tf
                fs.writeFileSync(path.join(sgDir, 'outputs.tf'), sgOutputsContent);
                
                // Crear módulo Database si es necesario
                if (config.services.includes('database')) {
                  const dbDir = path.join(modulesDir, 'database');
                  if (!fs.existsSync(dbDir)) {
                    fs.mkdirSync(dbDir, { recursive: true });
                  }
                  
                  // Crear database/main.tf
                  let dbMainContent = 'resource "aws_db_subnet_group" "main" {\n';
                  dbMainContent += '  name        = "${var.project_name}-${var.environment}-db-subnet-group"\n';
                  dbMainContent += '  description = "Database subnet group for ${var.project_name}"\n';
                  dbMainContent += '  subnet_ids  = var.subnet_ids\n';
                  dbMainContent += '  \n';
                  dbMainContent += '  tags = {\n';
                  dbMainContent += '    Name        = "${var.project_name}-${var.environment}-db-subnet-group"\n';
                  dbMainContent += '    Environment = var.environment\n';
                  dbMainContent += '    Project     = var.project_name\n';
                  dbMainContent += '    Terraform   = "true"\n';
                  dbMainContent += '  }\n';
                  dbMainContent += '}\n\n';
                  
                  dbMainContent += 'resource "aws_db_instance" "main" {\n';
                  dbMainContent += '  identifier             = "${var.project_name}-${var.environment}-db"\n';
                  dbMainContent += '  engine                 = "postgres"\n';
                  dbMainContent += '  engine_version         = "13.4"\n';
                  dbMainContent += '  instance_class         = var.db_instance_class\n';
                  dbMainContent += '  allocated_storage      = 20\n';
                  dbMainContent += '  max_allocated_storage  = 100\n';
                  dbMainContent += '  storage_type           = "gp2"\n';
                  dbMainContent += '  storage_encrypted      = true\n';
                  dbMainContent += '  db_name                = var.db_name\n';
                  dbMainContent += '  username               = var.db_username\n';
                  dbMainContent += '  password               = var.db_password\n';
                  dbMainContent += '  db_subnet_group_name   = aws_db_subnet_group.main.name\n';
                  dbMainContent += '  vpc_security_group_ids = [var.security_group_id]\n';
                  dbMainContent += '  parameter_group_name   = "default.postgres13"\n';
                  dbMainContent += '  publicly_accessible    = false\n';
                  dbMainContent += '  skip_final_snapshot    = true\n';
                  dbMainContent += '  backup_retention_period = 7\n';
                  dbMainContent += '  backup_window          = "03:00-04:00"\n';
                  dbMainContent += '  maintenance_window     = "Mon:04:00-Mon:05:00"\n';
                  dbMainContent += '  multi_az               = var.environment == "prod" ? true : false\n';
                  dbMainContent += '  \n';
                  dbMainContent += '  tags = {\n';
                  dbMainContent += '    Name        = "${var.project_name}-${var.environment}-db"\n';
                  dbMainContent += '    Environment = var.environment\n';
                  dbMainContent += '    Project     = var.project_name\n';
                  dbMainContent += '    Terraform   = "true"\n';
                  dbMainContent += '  }\n';
                  dbMainContent += '}\n';
                  
                  // Escribir database/main.tf
                  fs.writeFileSync(path.join(dbDir, 'main.tf'), dbMainContent);
                  
                  // Crear database/variables.tf
                  let dbVariablesContent = 'variable "project_name" {\n';
                  dbVariablesContent += '  description = "The name of the project"\n';
                  dbVariablesContent += '}\n\n';
                  
                  dbVariablesContent += 'variable "environment" {\n';
                  dbVariablesContent += '  description = "The environment (dev, staging, prod)"\n';
                  dbVariablesContent += '}\n\n';
                  
                  dbVariablesContent += 'variable "db_instance_class" {\n';
                  dbVariablesContent += '  description = "The RDS instance class"\n';
                  dbVariablesContent += '}\n\n';
                  
                  dbVariablesContent += 'variable "db_name" {\n';
                  dbVariablesContent += '  description = "The name of the database"\n';
                  dbVariablesContent += '}\n\n';
                  
                  dbVariablesContent += 'variable "db_username" {\n';
                  dbVariablesContent += '  description = "The username for the database"\n';
                  dbVariablesContent += '}\n\n';
                  
                  dbVariablesContent += 'variable "db_password" {\n';
                  dbVariablesContent += '  description = "The password for the database"\n';
                  dbVariablesContent += '  sensitive   = true\n';
                  dbVariablesContent += '}\n\n';
                  
                  dbVariablesContent += 'variable "subnet_ids" {\n';
                  dbVariablesContent += '  description = "The subnet IDs for the database"\n';
                  dbVariablesContent += '  type        = list(string)\n';
                  dbVariablesContent += '}\n\n';
                  
                  dbVariablesContent += 'variable "security_group_id" {\n';
                  dbVariablesContent += '  description = "The security group ID for the database"\n';
                  dbVariablesContent += '}\n';
                  
                  // Escribir database/variables.tf
                  fs.writeFileSync(path.join(dbDir, 'variables.tf'), dbVariablesContent);
                  
                  // Crear database/outputs.tf
                  let dbOutputsContent = 'output "db_host" {\n';
                  dbOutputsContent += '  value = aws_db_instance.main.address\n';
                  dbOutputsContent += '}\n\n';
                  
                  dbOutputsContent += 'output "db_port" {\n';
                  dbOutputsContent += '  value = aws_db_instance.main.port\n';
                  dbOutputsContent += '}\n\n';
                  
                  dbOutputsContent += 'output "db_name" {\n';
                  dbOutputsContent += '  value = aws_db_instance.main.db_name\n';
                  dbOutputsContent += '}\n\n';
                  
                  dbOutputsContent += 'output "db_username" {\n';
                  dbOutputsContent += '  value = aws_db_instance.main.username\n';
                  dbOutputsContent += '}\n';
                  
                  // Escribir database/outputs.tf
                  fs.writeFileSync(path.join(dbDir, 'outputs.tf'), dbOutputsContent);
                }
                
                // Crear módulo Backend si es necesario
                if (config.services.includes('backend')) {
                  const backendDir = path.join(modulesDir, 'backend');
                  if (!fs.existsSync(backendDir)) {
                    fs.mkdirSync(backendDir, { recursive: true });
                  }
                  
                  // Crear backend/main.tf
                  let backendMainContent = 'resource "aws_ecr_repository" "backend" {\n';
                  backendMainContent += '  name                 = "${var.project_name}-${var.environment}-backend"\n';
                  backendMainContent += '  image_tag_mutability = "MUTABLE"\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  image_scanning_configuration {\n';
                  backendMainContent += '    scan_on_push = true\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  tags = {\n';
                  backendMainContent += '    Name        = "${var.project_name}-${var.environment}-backend"\n';
                  backendMainContent += '    Environment = var.environment\n';
                  backendMainContent += '    Project     = var.project_name\n';
                  backendMainContent += '    Terraform   = "true"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_ecs_cluster" "backend" {\n';
                  backendMainContent += '  name = "${var.project_name}-${var.environment}-backend-cluster"\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  setting {\n';
                  backendMainContent += '    name  = "containerInsights"\n';
                  backendMainContent += '    value = "enabled"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  tags = {\n';
                  backendMainContent += '    Name        = "${var.project_name}-${var.environment}-backend-cluster"\n';
                  backendMainContent += '    Environment = var.environment\n';
                  backendMainContent += '    Project     = var.project_name\n';
                  backendMainContent += '    Terraform   = "true"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_cloudwatch_log_group" "backend" {\n';
                  backendMainContent += '  name              = "/ecs/${var.project_name}-${var.environment}-backend"\n';
                  backendMainContent += '  retention_in_days = 30\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  tags = {\n';
                  backendMainContent += '    Name        = "${var.project_name}-${var.environment}-backend-logs"\n';
                  backendMainContent += '    Environment = var.environment\n';
                  backendMainContent += '    Project     = var.project_name\n';
                  backendMainContent += '    Terraform   = "true"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_iam_role" "ecs_task_execution" {\n';
                  backendMainContent += '  name = "${var.project_name}-${var.environment}-ecs-task-execution"\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  assume_role_policy = jsonencode({\n';
                  backendMainContent += '    Version = "2012-10-17"\n';
                  backendMainContent += '    Statement = [\n';
                  backendMainContent += '      {\n';
                  backendMainContent += '        Action = "sts:AssumeRole"\n';
                  backendMainContent += '        Effect = "Allow"\n';
                  backendMainContent += '        Principal = {\n';
                  backendMainContent += '          Service = "ecs-tasks.amazonaws.com"\n';
                  backendMainContent += '        }\n';
                  backendMainContent += '      }\n';
                  backendMainContent += '    ]\n';
                  backendMainContent += '  })\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  tags = {\n';
                  backendMainContent += '    Name        = "${var.project_name}-${var.environment}-ecs-task-execution"\n';
                  backendMainContent += '    Environment = var.environment\n';
                  backendMainContent += '    Project     = var.project_name\n';
                  backendMainContent += '    Terraform   = "true"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_iam_role_policy_attachment" "ecs_task_execution" {\n';
                  backendMainContent += '  role       = aws_iam_role.ecs_task_execution.name\n';
                  backendMainContent += '  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_iam_role" "ecs_task" {\n';
                  backendMainContent += '  name = "${var.project_name}-${var.environment}-ecs-task"\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  assume_role_policy = jsonencode({\n';
                  backendMainContent += '    Version = "2012-10-17"\n';
                  backendMainContent += '    Statement = [\n';
                  backendMainContent += '      {\n';
                  backendMainContent += '        Action = "sts:AssumeRole"\n';
                  backendMainContent += '        Effect = "Allow"\n';
                  backendMainContent += '        Principal = {\n';
                  backendMainContent += '          Service = "ecs-tasks.amazonaws.com"\n';
                  backendMainContent += '        }\n';
                  backendMainContent += '      }\n';
                  backendMainContent += '    ]\n';
                  backendMainContent += '  })\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  tags = {\n';
                  backendMainContent += '    Name        = "${var.project_name}-${var.environment}-ecs-task"\n';
                  backendMainContent += '    Environment = var.environment\n';
                  backendMainContent += '    Project     = var.project_name\n';
                  backendMainContent += '    Terraform   = "true"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_iam_policy" "backend_task" {\n';
                  backendMainContent += '  name        = "${var.project_name}-${var.environment}-backend-task-policy"\n';
                  backendMainContent += '  description = "Policy for backend ECS task"\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  policy = jsonencode({\n';
                  backendMainContent += '    Version = "2012-10-17"\n';
                  backendMainContent += '    Statement = [\n';
                  backendMainContent += '      {\n';
                  backendMainContent += '        Effect = "Allow"\n';
                  backendMainContent += '        Action = [\n';
                  backendMainContent += '          "logs:CreateLogStream",\n';
                  backendMainContent += '          "logs:PutLogEvents"\n';
                  backendMainContent += '        ]\n';
                  backendMainContent += '        Resource = "*"\n';
                  backendMainContent += '      }\n';
                  backendMainContent += '    ]\n';
                  backendMainContent += '  })\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_iam_role_policy_attachment" "backend_task" {\n';
                  backendMainContent += '  role       = aws_iam_role.ecs_task.name\n';
                  backendMainContent += '  policy_arn = aws_iam_policy.backend_task.arn\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_ecs_task_definition" "backend" {\n';
                  backendMainContent += '  family                   = "${var.project_name}-${var.environment}-backend"\n';
                  backendMainContent += '  network_mode             = "awsvpc"\n';
                  backendMainContent += '  requires_compatibilities = ["FARGATE"]\n';
                  backendMainContent += '  cpu                      = 256\n';
                  backendMainContent += '  memory                   = 512\n';
                  backendMainContent += '  execution_role_arn       = aws_iam_role.ecs_task_execution.arn\n';
                  backendMainContent += '  task_role_arn            = aws_iam_role.ecs_task.arn\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  container_definitions = jsonencode([\n';
                  backendMainContent += '    {\n';
                  backendMainContent += '      name      = "backend"\n';
                  backendMainContent += '      image     = "${aws_ecr_repository.backend.repository_url}:latest"\n';
                  backendMainContent += '      essential = true\n';
                  backendMainContent += '      portMappings = [\n';
                  backendMainContent += '        {\n';
                  backendMainContent += '          containerPort = var.backend_container_port\n';
                  backendMainContent += '          hostPort      = var.backend_container_port\n';
                  backendMainContent += '          protocol      = "tcp"\n';
                  backendMainContent += '        }\n';
                  backendMainContent += '      ]\n';
                  backendMainContent += '      environment = [\n';
                  backendMainContent += '        {\n';
                  backendMainContent += '          name  = "NODE_ENV"\n';
                  backendMainContent += '          value = var.environment\n';
                  backendMainContent += '        }\n';
                  
                  if (config.services.includes('database')) {
                    backendMainContent += '        ,\n';
                    backendMainContent += '        {\n';
                    backendMainContent += '          name  = "DB_HOST"\n';
                    backendMainContent += '          value = var.db_host\n';
                    backendMainContent += '        },\n';
                    backendMainContent += '        {\n';
                    backendMainContent += '          name  = "DB_PORT"\n';
                    backendMainContent += '          value = "5432"\n';
                    backendMainContent += '        },\n';
                    backendMainContent += '        {\n';
                    backendMainContent += '          name  = "DB_NAME"\n';
                    backendMainContent += '          value = var.db_name\n';
                    backendMainContent += '        },\n';
                    backendMainContent += '        {\n';
                    backendMainContent += '          name  = "DB_USER"\n';
                    backendMainContent += '          value = var.db_username\n';
                    backendMainContent += '        },\n';
                    backendMainContent += '        {\n';
                    backendMainContent += '          name  = "DB_PASSWORD"\n';
                    backendMainContent += '          value = var.db_password\n';
                    backendMainContent += '        }\n';
                  }
                  
                  backendMainContent += '      ]\n';
                  backendMainContent += '      logConfiguration = {\n';
                  backendMainContent += '        logDriver = "awslogs"\n';
                  backendMainContent += '        options = {\n';
                  backendMainContent += '          "awslogs-group"         = aws_cloudwatch_log_group.backend.name\n';
                  backendMainContent += '          "awslogs-region"        = var.region\n';
                  backendMainContent += '          "awslogs-stream-prefix" = "ecs"\n';
                  backendMainContent += '        }\n';
                  backendMainContent += '      }\n';
                  backendMainContent += '    }\n';
                  backendMainContent += '  ])\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  tags = {\n';
                  backendMainContent += '    Name        = "${var.project_name}-${var.environment}-backend-task"\n';
                  backendMainContent += '    Environment = var.environment\n';
                  backendMainContent += '    Project     = var.project_name\n';
                  backendMainContent += '    Terraform   = "true"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_lb_target_group" "backend" {\n';
                  backendMainContent += '  name        = "${var.project_name}-${var.environment}-backend"\n';
                  backendMainContent += '  port        = var.backend_container_port\n';
                  backendMainContent += '  protocol    = "HTTP"\n';
                  backendMainContent += '  vpc_id      = var.vpc_id\n';
                  backendMainContent += '  target_type = "ip"\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  health_check {\n';
                  backendMainContent += '    path                = "/health"\n';
                  backendMainContent += '    port                = "traffic-port"\n';
                  backendMainContent += '    healthy_threshold   = 3\n';
                  backendMainContent += '    unhealthy_threshold = 3\n';
                  backendMainContent += '    timeout             = 5\n';
                  backendMainContent += '    interval            = 30\n';
                  backendMainContent += '    matcher             = "200"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  tags = {\n';
                  backendMainContent += '    Name        = "${var.project_name}-${var.environment}-backend-tg"\n';
                  backendMainContent += '    Environment = var.environment\n';
                  backendMainContent += '    Project     = var.project_name\n';
                  backendMainContent += '    Terraform   = "true"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_ecs_service" "backend" {\n';
                  backendMainContent += '  name            = "${var.project_name}-${var.environment}-backend"\n';
                  backendMainContent += '  cluster         = aws_ecs_cluster.backend.id\n';
                  backendMainContent += '  task_definition = aws_ecs_task_definition.backend.arn\n';
                  backendMainContent += '  desired_count   = 2\n';
                  backendMainContent += '  launch_type     = "FARGATE"\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  network_configuration {\n';
                  backendMainContent += '    subnets         = var.subnet_ids\n';
                  backendMainContent += '    security_groups = [var.security_group_id]\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  load_balancer {\n';
                  backendMainContent += '    target_group_arn = aws_lb_target_group.backend.arn\n';
                  backendMainContent += '    container_name   = "backend"\n';
                  backendMainContent += '    container_port   = var.backend_container_port\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  depends_on = [aws_lb_target_group.backend]\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  tags = {\n';
                  backendMainContent += '    Name        = "${var.project_name}-${var.environment}-backend-service"\n';
                  backendMainContent += '    Environment = var.environment\n';
                  backendMainContent += '    Project     = var.project_name\n';
                  backendMainContent += '    Terraform   = "true"\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_appautoscaling_target" "backend" {\n';
                  backendMainContent += '  max_capacity       = 10\n';
                  backendMainContent += '  min_capacity       = 2\n';
                  backendMainContent += '  resource_id        = "service/${aws_ecs_cluster.backend.name}/${aws_ecs_service.backend.name}"\n';
                  backendMainContent += '  scalable_dimension = "ecs:service:DesiredCount"\n';
                  backendMainContent += '  service_namespace  = "ecs"\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_appautoscaling_policy" "backend_cpu" {\n';
                  backendMainContent += '  name               = "${var.project_name}-${var.environment}-backend-cpu"\n';
                  backendMainContent += '  policy_type        = "TargetTrackingScaling"\n';
                  backendMainContent += '  resource_id        = aws_appautoscaling_target.backend.resource_id\n';
                  backendMainContent += '  scalable_dimension = aws_appautoscaling_target.backend.scalable_dimension\n';
                  backendMainContent += '  service_namespace  = aws_appautoscaling_target.backend.service_namespace\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  target_tracking_scaling_policy_configuration {\n';
                  backendMainContent += '    predefined_metric_specification {\n';
                  backendMainContent += '      predefined_metric_type = "ECSServiceAverageCPUUtilization"\n';
                  backendMainContent += '    }\n';
                  backendMainContent += '    target_value = 70.0\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_appautoscaling_policy" "backend_memory" {\n';
                  backendMainContent += '  name               = "${var.project_name}-${var.environment}-backend-memory"\n';
                  backendMainContent += '  policy_type        = "TargetTrackingScaling"\n';
                  backendMainContent += '  resource_id        = aws_appautoscaling_target.backend.resource_id\n';
                  backendMainContent += '  scalable_dimension = aws_appautoscaling_target.backend.scalable_dimension\n';
                  backendMainContent += '  service_namespace  = aws_appautoscaling_target.backend.service_namespace\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  target_tracking_scaling_policy_configuration {\n';
                  backendMainContent += '    predefined_metric_specification {\n';
                  backendMainContent += '      predefined_metric_type = "ECSServiceAverageMemoryUtilization"\n';
                  backendMainContent += '    }\n';
                  backendMainContent += '    target_value = 70.0\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n\n';
                  
                  backendMainContent += 'resource "aws_lb_listener_rule" "backend" {\n';
                  backendMainContent += '  listener_arn = var.alb_listener_arn\n';
                  backendMainContent += '  priority     = 100\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  action {\n';
                  backendMainContent += '    type             = "forward"\n';
                  backendMainContent += '    target_group_arn = aws_lb_target_group.backend.arn\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '  \n';
                  backendMainContent += '  condition {\n';
                  backendMainContent += '    path_pattern {\n';
                  backendMainContent += '      values = ["/api/*"]\n';
                  backendMainContent += '    }\n';
                  backendMainContent += '  }\n';
                  backendMainContent += '}\n';
                  
                  // Escribir backend/main.tf
                  fs.writeFileSync(path.join(backendDir, 'main.tf'), backendMainContent);
                  
                  // Crear backend/variables.tf
                  let backendVariablesContent = 'variable "project_name" {\n';
                  backendVariablesContent += '  description = "The name of the project"\n';
                  backendVariablesContent += '}\n\n';
                  
                  backendVariablesContent += 'variable "environment" {\n';
                  backendVariablesContent += '  description = "The environment (dev, staging, prod)"\n';
                  backendVariablesContent += '}\n\n';
                  
                  backendVariablesContent += 'variable "region" {\n';
                  backendVariablesContent += '  description = "The AWS region"\n';
                  backendVariablesContent += '}\n\n';
                  
                  backendVariablesContent += 'variable "vpc_id" {\n';
                  backendVariablesContent += '  description = "The ID of the VPC"\n';
                  backendVariablesContent += '}\n\n';
                  
                  backendVariablesContent += 'variable "subnet_ids" {\n';
                  backendVariablesContent += '  description = "The subnet IDs for the backend"\n';
                  backendVariablesContent += '  type        = list(string)\n';
                  backendVariablesContent += '}\n\n';
                  
                  backendVariablesContent += 'variable "security_group_id" {\n';
                  backendVariablesContent += '  description = "The security group ID for the backend"\n';
                  backendVariablesContent += '}\n\n';
                  
                  backendVariablesContent += 'variable "alb_listener_arn" {\n';
                  backendVariablesContent += '  description = "The ARN of the ALB listener"\n';
                  backendVariablesContent += '}\n\n';
                  
                  backendVariablesContent += 'variable "backend_container_port" {\n';
                  backendVariablesContent += '  description = "The port the backend container listens on"\n';
                  backendVariablesContent += '  default     = 3000\n';
                  backendVariablesContent += '}\n';
                  
                  if (config.services.includes('database')) {
                    backendVariablesContent += '\n';
                    backendVariablesContent += 'variable "db_host" {\n';
                    backendVariablesContent += '  description = "The database host"\n';
                    backendVariablesContent += '}\n\n';
                    
                    backendVariablesContent += 'variable "db_name" {\n';
                    backendVariablesContent += '  description = "The database name"\n';
                    backendVariablesContent += '}\n\n';
                    
                    backendVariablesContent += 'variable "db_username" {\n';
                    backendVariablesContent += '  description = "The database username"\n';
                    backendVariablesContent += '}\n\n';
                    
                    backendVariablesContent += 'variable "db_password" {\n';
                    backendVariablesContent += '  description = "The database password"\n';
                    backendVariablesContent += '  sensitive   = true\n';
                    backendVariablesContent += '}\n';
                  }
                  
                  // Escribir backend/variables.tf
                  fs.writeFileSync(path.join(backendDir, 'variables.tf'), backendVariablesContent);
                  
                  // Crear backend/outputs.tf
                  let backendOutputsContent = 'output "ecr_repository_url" {\n';
                  backendOutputsContent += '  value = aws_ecr_repository.backend.repository_url\n';
                  backendOutputsContent += '}\n\n';
                  
                  backendOutputsContent += 'output "ecs_cluster_name" {\n';
                  backendOutputsContent += '  value = aws_ecs_cluster.backend.name\n';
                  backendOutputsContent += '}\n\n';
                  
                  backendOutputsContent += 'output "ecs_service_name" {\n';
                  backendOutputsContent += '  value = aws_ecs_service.backend.name\n';
                  backendOutputsContent += '}\n\n';
                  
                  backendOutputsContent += 'output "target_group_arn" {\n';
                  backendOutputsContent += '  value = aws_lb_target_group.backend.arn\n';
                  backendOutputsContent += '}\n';
                  
                  // Escribir backend/outputs.tf
                  fs.writeFileSync(path.join(backendDir, 'outputs.tf'), backendOutputsContent);
                }
                
                // Crear módulo Frontend si es necesario
                if (config.services.includes('frontend')) {
                  const frontendDir = path.join(modulesDir, 'frontend');
                  if (!fs.existsSync(frontendDir)) {
                    fs.mkdirSync(frontendDir, { recursive: true });
                  }
                  
                  // Crear frontend/main.tf
                  let frontendMainContent = 'resource "aws_s3_bucket" "frontend" {\n';
                  frontendMainContent += '  bucket = "${var.project_name}-${var.environment}-frontend"\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  tags = {\n';
                  frontendMainContent += '    Name        = "${var.project_name}-${var.environment}-frontend"\n';
                  frontendMainContent += '    Environment = var.environment\n';
                  frontendMainContent += '    Project     = var.project_name\n';
                  frontendMainContent += '    Terraform   = "true"\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '}\n\n';
                  
                  frontendMainContent += 'resource "aws_s3_bucket_website_configuration" "frontend" {\n';
                  frontendMainContent += '  bucket = aws_s3_bucket.frontend.id\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  index_document {\n';
                  frontendMainContent += '    suffix = "index.html"\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  error_document {\n';
                  frontendMainContent += '    key = "index.html"\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '}\n\n';
                  
                  frontendMainContent += 'resource "aws_s3_bucket_public_access_block" "frontend" {\n';
                  frontendMainContent += '  bucket = aws_s3_bucket.frontend.id\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  block_public_acls       = true\n';
                  frontendMainContent += '  block_public_policy     = true\n';
                  frontendMainContent += '  ignore_public_acls      = true\n';
                  frontendMainContent += '  restrict_public_buckets = true\n';
                  frontendMainContent += '}\n\n';
                  
                  frontendMainContent += 'resource "aws_cloudfront_origin_access_identity" "frontend" {\n';
                  frontendMainContent += '  comment = "${var.project_name}-${var.environment}-frontend"\n';
                  frontendMainContent += '}\n\n';
                  
                  frontendMainContent += 'data "aws_iam_policy_document" "s3_policy" {\n';
                  frontendMainContent += '  statement {\n';
                  frontendMainContent += '    actions   = ["s3:GetObject"]\n';
                  frontendMainContent += '    resources = ["${aws_s3_bucket.frontend.arn}/*"]\n';
                  frontendMainContent += '    \n';
                  frontendMainContent += '    principals {\n';
                  frontendMainContent += '      type        = "AWS"\n';
                  frontendMainContent += '      identifiers = [aws_cloudfront_origin_access_identity.frontend.iam_arn]\n';
                  frontendMainContent += '    }\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '}\n\n';
                  
                  frontendMainContent += 'resource "aws_s3_bucket_policy" "frontend" {\n';
                  frontendMainContent += '  bucket = aws_s3_bucket.frontend.id\n';
                  frontendMainContent += '  policy = data.aws_iam_policy_document.s3_policy.json\n';
                  frontendMainContent += '}\n\n';
                  
                  frontendMainContent += 'resource "aws_cloudfront_distribution" "frontend" {\n';
                  frontendMainContent += '  enabled             = true\n';
                  frontendMainContent += '  is_ipv6_enabled     = true\n';
                  frontendMainContent += '  default_root_object = "index.html"\n';
                  frontendMainContent += '  aliases             = var.domain_name != "" ? [var.domain_name] : []\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  origin {\n';
                  frontendMainContent += '    domain_name = aws_s3_bucket.frontend.bucket_regional_domain_name\n';
                  frontendMainContent += '    origin_id   = "S3-${aws_s3_bucket.frontend.bucket}"\n';
                  frontendMainContent += '    \n';
                  frontendMainContent += '    s3_origin_config {\n';
                  frontendMainContent += '      origin_access_identity = aws_cloudfront_origin_access_identity.frontend.cloudfront_access_identity_path\n';
                  frontendMainContent += '    }\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  custom_error_response {\n';
                  frontendMainContent += '    error_code         = 403\n';
                  frontendMainContent += '    response_code      = 200\n';
                  frontendMainContent += '    response_page_path = "/index.html"\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  custom_error_response {\n';
                  frontendMainContent += '    error_code         = 404\n';
                  frontendMainContent += '    response_code      = 200\n';
                  frontendMainContent += '    response_page_path = "/index.html"\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  default_cache_behavior {\n';
                  frontendMainContent += '    allowed_methods  = ["GET", "HEAD", "OPTIONS"]\n';
                  frontendMainContent += '    cached_methods   = ["GET", "HEAD"]\n';
                  frontendMainContent += '    target_origin_id = "S3-${aws_s3_bucket.frontend.bucket}"\n';
                  frontendMainContent += '    \n';
                  frontendMainContent += '    forwarded_values {\n';
                  frontendMainContent += '      query_string = false\n';
                  frontendMainContent += '      \n';
                  frontendMainContent += '      cookies {\n';
                  frontendMainContent += '        forward = "none"\n';
                  frontendMainContent += '      }\n';
                  frontendMainContent += '    }\n';
                  frontendMainContent += '    \n';
                  frontendMainContent += '    viewer_protocol_policy = "redirect-to-https"\n';
                  frontendMainContent += '    min_ttl                = 0\n';
                  frontendMainContent += '    default_ttl            = 3600\n';
                  frontendMainContent += '    max_ttl                = 86400\n';
                  frontendMainContent += '    compress               = true\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  ordered_cache_behavior {\n';
                  frontendMainContent += '    path_pattern     = "/static/*"\n';
                  frontendMainContent += '    allowed_methods  = ["GET", "HEAD", "OPTIONS"]\n';
                  frontendMainContent += '    cached_methods   = ["GET", "HEAD"]\n';
                  frontendMainContent += '    target_origin_id = "S3-${aws_s3_bucket.frontend.bucket}"\n';
                  frontendMainContent += '    \n';
                  frontendMainContent += '    forwarded_values {\n';
                  frontendMainContent += '      query_string = false\n';
                  frontendMainContent += '      \n';
                  frontendMainContent += '      cookies {\n';
                  frontendMainContent += '        forward = "none"\n';
                  frontendMainContent += '      }\n';
                  frontendMainContent += '    }\n';
                  frontendMainContent += '    \n';
                  frontendMainContent += '    viewer_protocol_policy = "redirect-to-https"\n';
                  frontendMainContent += '    min_ttl                = 0\n';
                  frontendMainContent += '    default_ttl            = 86400\n';
                  frontendMainContent += '    max_ttl                = 31536000\n';
                  frontendMainContent += '    compress               = true\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  price_class = "PriceClass_100"\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  restrictions {\n';
                  frontendMainContent += '    geo_restriction {\n';
                  frontendMainContent += '      restriction_type = "none"\n';
                  frontendMainContent += '    }\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  viewer_certificate {\n';
                  frontendMainContent += '    cloudfront_default_certificate = var.domain_name == "" ? true : false\n';
                  frontendMainContent += '    acm_certificate_arn            = var.domain_name != "" ? var.certificate_arn : null\n';
                  frontendMainContent += '    ssl_support_method             = var.domain_name != "" ? "sni-only" : null\n';
                  frontendMainContent += '    minimum_protocol_version       = var.domain_name != "" ? "TLSv1.2_2019" : null\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '  \n';
                  frontendMainContent += '  tags = {\n';
                  frontendMainContent += '    Name        = "${var.project_name}-${var.environment}-frontend-distribution"\n';
                  frontendMainContent += '    Environment = var.environment\n';
                  frontendMainContent += '    Project     = var.project_name\n';
                  frontendMainContent += '    Terraform   = "true"\n';
                  frontendMainContent += '  }\n';
                  frontendMainContent += '}\n';
                  
                  // Escribir frontend/main.tf
                  fs.writeFileSync(path.join(frontendDir, 'main.tf'), frontendMainContent);
                  
                  // Crear frontend/variables.tf
                  let frontendVariablesContent = 'variable "project_name" {\n';
                  frontendVariablesContent += '  description = "The name of the project"\n';
                  frontendVariablesContent += '}\n\n';
                  
                  frontendVariablesContent += 'variable "environment" {\n';
                  frontendVariablesContent += '  description = "The environment (dev, staging, prod)"\n';
                  frontendVariablesContent += '}\n\n';
                  
                  frontendVariablesContent += 'variable "domain_name" {\n';
                  frontendVariablesContent += '  description = "The domain name for the frontend"\n';
                  frontendVariablesContent += '  default     = ""\n';
                  frontendVariablesContent += '}\n\n';
                  
                  frontendVariablesContent += 'variable "certificate_arn" {\n';
                  frontendVariablesContent += '  description = "The ARN of the ACM certificate for the domain"\n';
                  frontendVariablesContent += '  default     = ""\n';
                  frontendVariablesContent += '}\n';
                  
                  // Escribir frontend/variables.tf
                  fs.writeFileSync(path.join(frontendDir, 'variables.tf'), frontendVariablesContent);
                  
                  // Crear frontend/outputs.tf
                  let frontendOutputsContent = 'output "s3_bucket_name" {\n';
                  frontendOutputsContent += '  value = aws_s3_bucket.frontend.bucket\n';
                  frontendOutputsContent += '}\n\n';
                  
                  frontendOutputsContent += 'output "cloudfront_distribution_id" {\n';
                  frontendOutputsContent += '  value = aws_cloudfront_distribution.frontend.id\n';
                  frontendOutputsContent += '}\n\n';
                  
                  frontendOutputsContent += 'output "cloudfront_domain_name" {\n';
                  frontendOutputsContent += '  value = aws_cloudfront_distribution.frontend.domain_name\n';
                  frontendOutputsContent += '}\n';
                  
                  // Escribir frontend/outputs.tf
                  fs.writeFileSync(path.join(frontendDir, 'outputs.tf'), frontendOutputsContent);
                }
                
                // Crear módulo ALB
                const albDir = path.join(modulesDir, 'alb');
                if (!fs.existsSync(albDir)) {
                  fs.mkdirSync(albDir, { recursive: true });
                }
                
                // Crear alb/main.tf
                let albMainContent = 'resource "aws_lb" "main" {\n';
                albMainContent += '  name               = "${var.project_name}-${var.environment}-alb"\n';
                albMainContent += '  internal           = false\n';
                albMainContent += '  load_balancer_type = "application"\n';
                albMainContent += '  security_groups    = [var.security_group_id]\n';
                albMainContent += '  subnets            = var.subnet_ids\n';
                albMainContent += '  \n';
                albMainContent += '  enable_deletion_protection = var.environment == "prod" ? true : false\n';
                albMainContent += '  \n';
                albMainContent += '  tags = {\n';
                albMainContent += '    Name        = "${var.project_name}-${var.environment}-alb"\n';
                albMainContent += '    Environment = var.environment\n';
                albMainContent += '    Project     = var.project_name\n';
                albMainContent += '    Terraform   = "true"\n';
                albMainContent += '  }\n';
                albMainContent += '}\n\n';
                
                albMainContent += 'resource "aws_lb_listener" "http" {\n';
                albMainContent += '  load_balancer_arn = aws_lb.main.arn\n';
                albMainContent += '  port              = "80"\n';
                albMainContent += '  protocol          = "HTTP"\n';
                albMainContent += '  \n';
                albMainContent += '  default_action {\n';
                albMainContent += '    type = "redirect"\n';
                albMainContent += '    \n';
                albMainContent += '    redirect {\n';
                albMainContent += '      port        = "443"\n';
                albMainContent += '      protocol    = "HTTPS"\n';
                albMainContent += '      status_code = "HTTP_301"\n';
                albMainContent += '    }\n';
                albMainContent += '  }\n';
                albMainContent += '}\n\n';
                
                albMainContent += 'resource "aws_lb_listener" "https" {\n';
                albMainContent += '  load_balancer_arn = aws_lb.main.arn\n';
                albMainContent += '  port              = "443"\n';
                albMainContent += '  protocol          = "HTTPS"\n';
                albMainContent += '  ssl_policy        = "ELBSecurityPolicy-2016-08"\n';
                albMainContent += '  certificate_arn   = var.certificate_arn != "" ? var.certificate_arn : aws_acm_certificate.self_signed[0].arn\n';
                albMainContent += '  \n';
                albMainContent += '  default_action {\n';
                albMainContent += '    type = "fixed-response"\n';
                albMainContent += '    \n';
                albMainContent += '    fixed_response {\n';
                albMainContent += '      content_type = "text/plain"\n';
                albMainContent += '      message_body = "Service Unavailable"\n';
                albMainContent += '      status_code  = "503"\n';
                albMainContent += '    }\n';
                albMainContent += '  }\n';
                albMainContent += '}\n\n';
                
                albMainContent += 'resource "tls_private_key" "self_signed" {\n';
                albMainContent += '  count     = var.certificate_arn == "" ? 1 : 0\n';
                albMainContent += '  algorithm = "RSA"\n';
                albMainContent += '}\n\n';
                
                albMainContent += 'resource "tls_self_signed_cert" "self_signed" {\n';
                albMainContent += '  count           = var.certificate_arn == "" ? 1 : 0\n';
                albMainContent += '  private_key_pem = tls_private_key.self_signed[0].private_key_pem\n';
                albMainContent += '  \n';
                albMainContent += '  subject {\n';
                albMainContent += '    common_name  = "example.com"\n';
                albMainContent += '    organization = "Example Organization"\n';
                albMainContent += '  }\n';
                albMainContent += '  \n';
                albMainContent += '  validity_period_hours = 8760\n';
                albMainContent += '  \n';
                albMainContent += '  allowed_uses = [\n';
                albMainContent += '    "key_encipherment",\n';
                albMainContent += '    "digital_signature",\n';
                albMainContent += '    "server_auth",\n';
                albMainContent += '  ]\n';
                albMainContent += '}\n\n';
                
                albMainContent += 'resource "aws_acm_certificate" "self_signed" {\n';
                albMainContent += '  count            = var.certificate_arn == "" ? 1 : 0\n';
                albMainContent += '  private_key      = tls_private_key.self_signed[0].private_key_pem\n';
                albMainContent += '  certificate_body = tls_self_signed_cert.self_signed[0].cert_pem\n';
                albMainContent += '}\n';
                
                // Escribir alb/main.tf
                fs.writeFileSync(path.join(albDir, 'main.tf'), albMainContent);
                
                // Crear alb/variables.tf
                let albVariablesContent = 'variable "project_name" {\n';
                albVariablesContent += '  description = "The name of the project"\n';
                albVariablesContent += '}\n\n';
                
                albVariablesContent += 'variable "environment" {\n';
                albVariablesContent += '  description = "The environment (dev, staging, prod)"\n';
                albVariablesContent += '}\n\n';
                
                albVariablesContent += 'variable "subnet_ids" {\n';
                albVariablesContent += '  description = "The subnet IDs for the ALB"\n';
                albVariablesContent += '  type        = list(string)\n';
                albVariablesContent += '}\n\n';
                
                albVariablesContent += 'variable "security_group_id" {\n';
                albVariablesContent += '  description = "The security group ID for the ALB"\n';
                albVariablesContent += '}\n\n';
                
                albVariablesContent += 'variable "certificate_arn" {\n';
                albVariablesContent += '  description = "The ARN of the ACM certificate for the ALB"\n';
                albVariablesContent += '  default     = ""\n';
                albVariablesContent += '}\n';
                
                // Escribir alb/variables.tf
                fs.writeFileSync(path.join(albDir, 'variables.tf'), albVariablesContent);
                
                // Crear alb/outputs.tf
                let albOutputsContent = 'output "alb_id" {\n';
                albOutputsContent += '  value = aws_lb.main.id\n';
                albOutputsContent += '}\n\n';
                
                albOutputsContent += 'output "alb_dns_name" {\n';
                albOutputsContent += '  value = aws_lb.main.dns_name\n';
                albOutputsContent += '}\n\n';
                
                albOutputsContent += 'output "alb_zone_id" {\n';
                albOutputsContent += '  value = aws_lb.main.zone_id\n';
                albOutputsContent += '}\n\n';
                
                albOutputsContent += 'output "http_listener_arn" {\n';
                albOutputsContent += '  value = aws_lb_listener.http.arn\n';
                albOutputsContent += '}\n\n';
                
                albOutputsContent += 'output "https_listener_arn" {\n';
                albOutputsContent += '  value = aws_lb_listener.https.arn\n';
                albOutputsContent += '}\n';
                
                // Escribir alb/outputs.tf
                fs.writeFileSync(path.join(albDir, 'outputs.tf'), albOutputsContent);
                
                // Crear archivos principales de Terraform
                
                // Crear main.tf
                let mainContent = 'provider "aws" {\n';
                mainContent += '  region = var.region\n';
                mainContent += '}\n\n';
                
                mainContent += 'module "vpc" {\n';
                mainContent += '  source = "./modules/vpc"\n';
                mainContent += '  \n';
                mainContent += '  project_name        = var.project_name\n';
                mainContent += '  environment         = var.environment\n';
                mainContent += '  vpc_cidr            = var.vpc_cidr\n';
                mainContent += '  public_subnet_cidrs = var.public_subnet_cidrs\n';
                mainContent += '  private_subnet_cidrs = var.private_subnet_cidrs\n';
                mainContent += '  availability_zones  = var.availability_zones\n';
                mainContent += '}\n\n';
                
                mainContent += 'module "security_groups" {\n';
                mainContent += '  source = "./modules/security_groups"\n';
                mainContent += '  \n';
                mainContent += '  project_name = var.project_name\n';
                mainContent += '  environment  = var.environment\n';
                mainContent += '  vpc_id       = module.vpc.vpc_id\n';
                mainContent += '}\n\n';
                
                mainContent += 'module "alb" {\n';
                mainContent += '  source = "./modules/alb"\n';
                mainContent += '  \n';
                mainContent += '  project_name     = var.project_name\n';
                mainContent += '  environment      = var.environment\n';
                mainContent += '  subnet_ids       = module.vpc.public_subnet_ids\n';
                mainContent += '  security_group_id = module.security_groups.alb_security_group_id\n';
                mainContent += '  certificate_arn  = var.certificate_arn\n';
                mainContent += '}\n';
                
                if (config.services.includes('database')) {
                  mainContent += '\n';
                  mainContent += 'module "database" {\n';
                  mainContent += '  source = "./modules/database"\n';
                  mainContent += '  \n';
                  mainContent += '  project_name     = var.project_name\n';
                  mainContent += '  environment      = var.environment\n';
                  mainContent += '  db_instance_class = var.db_instance_class\n';
                  mainContent += '  db_name          = var.db_name\n';
                  mainContent += '  db_username      = var.db_username\n';
                  mainContent += '  db_password      = var.db_password\n';
                  mainContent += '  subnet_ids       = module.vpc.private_subnet_ids\n';
                  mainContent += '  security_group_id = module.security_groups.database_security_group_id\n';
                  mainContent += '}\n';
                }
                
                if (config.services.includes('backend')) {
                  mainContent += '\n';
                  mainContent += 'module "backend" {\n';
                  mainContent += '  source = "./modules/backend"\n';
                  mainContent += '  \n';
                  mainContent += '  project_name     = var.project_name\n';
                  mainContent += '  environment      = var.environment\n';
                  mainContent += '  region           = var.region\n';
                  mainContent += '  vpc_id           = module.vpc.vpc_id\n';
                  mainContent += '  subnet_ids       = module.vpc.private_subnet_ids\n';
                  mainContent += '  security_group_id = module.security_groups.backend_security_group_id\n';
                  mainContent += '  alb_listener_arn = module.alb.https_listener_arn\n';
                  
                  if (config.services.includes('database')) {
                    mainContent += '  db_host          = module.database.db_instance_endpoint\n';
                    mainContent += '  db_name          = var.db_name\n';
                    mainContent += '  db_username      = var.db_username\n';
                    mainContent += '  db_password      = var.db_password\n';
                  }
                  
                  mainContent += '}\n';
                }
                
                if (config.services.includes('frontend')) {
                  mainContent += '\n';
                  mainContent += 'module "frontend" {\n';
                  mainContent += '  source = "./modules/frontend"\n';
                  mainContent += '  \n';
                  mainContent += '  project_name    = var.project_name\n';
                  mainContent += '  environment     = var.environment\n';
                  mainContent += '  domain_name     = var.domain_name\n';
                  mainContent += '  certificate_arn = var.certificate_arn\n';
                  mainContent += '}\n';
                }
                
                // Escribir main.tf
                fs.writeFileSync(path.join(terraformDir, 'main.tf'), mainContent);
                
                // Crear variables.tf
                let variablesContent = 'variable "project_name" {\n';
                variablesContent += '  description = "The name of the project"\n';
                variablesContent += '  type        = string\n';
                variablesContent += '}\n\n';
                
                variablesContent += 'variable "environment" {\n';
                variablesContent += '  description = "The environment (dev, staging, prod)"\n';
                variablesContent += '  type        = string\n';
                variablesContent += '}\n\n';
                
                variablesContent += 'variable "region" {\n';
                variablesContent += '  description = "The AWS region"\n';
                variablesContent += '  type        = string\n';
                variablesContent += '  default     = "us-east-1"\n';
                variablesContent += '}\n\n';
                
                variablesContent += 'variable "vpc_cidr" {\n';
                variablesContent += '  description = "The CIDR block for the VPC"\n';
                variablesContent += '  type        = string\n';
                variablesContent += '  default     = "10.0.0.0/16"\n';
                variablesContent += '}\n\n';
                
                variablesContent += 'variable "public_subnet_cidrs" {\n';
                variablesContent += '  description = "The CIDR blocks for the public subnets"\n';
                variablesContent += '  type        = list(string)\n';
                variablesContent += '  default     = ["10.0.1.0/24", "10.0.2.0/24"]\n';
                variablesContent += '}\n\n';
                
                variablesContent += 'variable "private_subnet_cidrs" {\n';
                variablesContent += '  description = "The CIDR blocks for the private subnets"\n';
                variablesContent += '  type        = list(string)\n';
                variablesContent += '  default     = ["10.0.3.0/24", "10.0.4.0/24"]\n';
                variablesContent += '}\n\n';
                
                variablesContent += 'variable "availability_zones" {\n';
                variablesContent += '  description = "The availability zones to use"\n';
                variablesContent += '  type        = list(string)\n';
                variablesContent += '  default     = ["us-east-1a", "us-east-1b"]\n';
                variablesContent += '}\n\n';
                
                variablesContent += 'variable "domain_name" {\n';
                variablesContent += '  description = "The domain name for the application"\n';
                variablesContent += '  type        = string\n';
                variablesContent += '  default     = ""\n';
                variablesContent += '}\n\n';
                
                variablesContent += 'variable "certificate_arn" {\n';
                variablesContent += '  description = "The ARN of the ACM certificate for the domain"\n';
                variablesContent += '  type        = string\n';
                variablesContent += '  default     = ""\n';
                variablesContent += '}\n';
                
                if (config.services.includes('database')) {
                  variablesContent += '\n';
                  variablesContent += 'variable "db_instance_class" {\n';
                  variablesContent += '  description = "The instance class for the RDS instance"\n';
                  variablesContent += '  type        = string\n';
                  variablesContent += '  default     = "db.t3.micro"\n';
                  variablesContent += '}\n\n';
                  
                  variablesContent += 'variable "db_name" {\n';
                  variablesContent += '  description = "The name of the database"\n';
                  variablesContent += '  type        = string\n';
                  variablesContent += '}\n\n';
                  
                  variablesContent += 'variable "db_username" {\n';
                  variablesContent += '  description = "The username for the database"\n';
                  variablesContent += '  type        = string\n';
                  variablesContent += '}\n\n';
                  
                  variablesContent += 'variable "db_password" {\n';
                  variablesContent += '  description = "The password for the database"\n';
                  variablesContent += '  type        = string\n';
                  variablesContent += '  sensitive   = true\n';
                  variablesContent += '}\n';
                }
                
                // Escribir variables.tf
                fs.writeFileSync(path.join(terraformDir, 'variables.tf'), variablesContent);
                
                // Crear outputs.tf
                let outputsContent = 'output "vpc_id" {\n';
                outputsContent += '  value = module.vpc.vpc_id\n';
                outputsContent += '}\n\n';
                
                outputsContent += 'output "alb_dns_name" {\n';
                outputsContent += '  value = module.alb.alb_dns_name\n';
                outputsContent += '}\n';
                
                if (config.services.includes('backend')) {
                  outputsContent += '\n';
                  outputsContent += 'output "backend_ecr_repository_url" {\n';
                  outputsContent += '  value = module.backend.ecr_repository_url\n';
                  outputsContent += '}\n';
                }
                
                if (config.services.includes('frontend')) {
                  outputsContent += '\n';
                  outputsContent += 'output "frontend_s3_bucket_name" {\n';
                  outputsContent += '  value = module.frontend.s3_bucket_name\n';
                  outputsContent += '}\n\n';
                  
                  outputsContent += 'output "cloudfront_domain_name" {\n';
                  outputsContent += '  value = module.frontend.cloudfront_domain_name\n';
                  outputsContent += '}\n';
                }
                
                if (config.services.includes('database')) {
                  outputsContent += '\n';
                  outputsContent += 'output "db_instance_endpoint" {\n';
                  outputsContent += '  value = module.database.db_instance_endpoint\n';
                  outputsContent += '}\n';
                }
                
                // Escribir outputs.tf
                fs.writeFileSync(path.join(terraformDir, 'outputs.tf'), outputsContent);
                
                // Crear terraform.tfvars
                let tfvarsContent = 'project_name = "' + config.projectName.toLowerCase().replace(/[^a-z0-9]/g, '-') + '"\n';
                tfvarsContent += 'environment  = "dev"\n';
                tfvarsContent += 'region       = "us-east-1"\n';
                
                if (config.services.includes('database')) {
                  tfvarsContent += 'db_name      = "app"\n';
                  tfvarsContent += 'db_username  = "admin"\n';
                  tfvarsContent += '# db_password = "CHANGE_ME" # Uncomment and set a secure password\n';
                }
                
                // Escribir terraform.tfvars
                fs.writeFileSync(path.join(terraformDir, 'terraform.tfvars'), tfvarsContent);
                
                // Crear backend.tf
                let backendTfContent = 'terraform {\n';
                backendTfContent += '  required_version = ">= 1.0.0"\n\n';
                
                backendTfContent += '  required_providers {\n';
                backendTfContent += '    aws = {\n';
                backendTfContent += '      source  = "hashicorp/aws"\n';
                backendTfContent += '      version = "~> 4.0"\n';
                backendTfContent += '    }\n';
                backendTfContent += '  }\n';
                backendTfContent += '  \n';
                backendTfContent += '  # Uncomment this block to use S3 as a backend\n';
                backendTfContent += '  # backend "s3" {\n';
                backendTfContent += '  #   bucket         = "terraform-state-bucket-name"\n';
                backendTfContent += '  #   key            = "terraform.tfstate"\n';
                backendTfContent += '  #   region         = "us-east-1"\n';
                backendTfContent += '  #   encrypt        = true\n';
                backendTfContent += '  #   dynamodb_table = "terraform-locks"\n';
                backendTfContent += '  # }\n';
                backendTfContent += '}\n';
                
                // Escribir backend.tf
                fs.writeFileSync(path.join(terraformDir, 'backend.tf'), backendTfContent);
                
                // Crear README.md para Terraform
                let readmeContent = '# Terraform Infrastructure\n\n';
                readmeContent += 'Este directorio contiene la configuración de Terraform para desplegar la infraestructura del proyecto en AWS.\n\n';
                
                readmeContent += '## Estructura\n\n';
                readmeContent += '```\n';
                readmeContent += '.\n';
                readmeContent += '├── main.tf           # Configuración principal\n';
                readmeContent += '├── variables.tf      # Definición de variables\n';
                readmeContent += '├── outputs.tf        # Outputs de Terraform\n';
                readmeContent += '├── terraform.tfvars  # Valores de variables\n';
                readmeContent += '├── backend.tf        # Configuración del backend\n';
                readmeContent += '└── modules/          # Módulos de Terraform\n';
                readmeContent += '    ├── vpc/          # Módulo para la VPC\n';
                readmeContent += '    ├── security_groups/ # Módulo para grupos de seguridad\n';
                readmeContent += '    ├── alb/          # Módulo para el Application Load Balancer\n';
                
                if (config.services.includes('database')) {
                  readmeContent += '    ├── database/     # Módulo para la base de datos\n';
                }
                
                if (config.services.includes('backend')) {
                  readmeContent += '    ├── backend/      # Módulo para el backend\n';
                }
                
                if (config.services.includes('frontend')) {
                  readmeContent += '    └── frontend/     # Módulo para el frontend\n';
                }
                
                readmeContent += '```\n\n';
                
                readmeContent += '## Requisitos\n\n';
                readmeContent += '- Terraform >= 1.0.0\n';
                readmeContent += '- AWS CLI configurado con credenciales válidas\n\n';
                
                readmeContent += '## Uso\n\n';
                readmeContent += '1. Inicializar Terraform:\n\n';
                readmeContent += '```bash\n';
                readmeContent += 'terraform init\n';
                readmeContent += '```\n\n';
                
                readmeContent += '2. Revisar el plan de ejecución:\n\n';
                readmeContent += '```bash\n';
                readmeContent += 'terraform plan\n';
                readmeContent += '```\n\n';
                
                readmeContent += '3. Aplicar los cambios:\n\n';
                readmeContent += '```bash\n';
                readmeContent += 'terraform apply\n';
                readmeContent += '```\n\n';
                
                readmeContent += '4. Para destruir la infraestructura:\n\n';
                readmeContent += '```bash\n';
                readmeContent += 'terraform destroy\n';
                readmeContent += '```\n\n';
                
                readmeContent += '## Notas\n\n';
                readmeContent += '- Antes de aplicar en producción, asegúrate de configurar un backend remoto (S3) descomentando y configurando la sección en `backend.tf`.\n';
                readmeContent += '- Modifica `terraform.tfvars` para personalizar la configuración según tus necesidades.\n';
                
                if (config.services.includes('database')) {
                  readmeContent += '- Asegúrate de establecer una contraseña segura para la base de datos en `terraform.tfvars`.\n';
                }
                
                // Escribir README.md
                fs.writeFileSync(path.join(terraformDir, 'README.md'), readmeContent);
              }
              
              return terraformDir;
            } catch (error) {
              console.error('Error al crear archivos de Terraform:', error);
              throw error;
            }
          }
          
          /**
           * Crea archivos de configuración para CI/CD
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de CI/CD
           */
          async createCICDFiles(projectDir, config) {
            try {
              const cicdDir = path.join(projectDir, 'cicd');
              if (!fs.existsSync(cicdDir)) {
                fs.mkdirSync(cicdDir, { recursive: true });
              }
              
              // Crear directorios para diferentes sistemas de CI/CD
              const githubDir = path.join(cicdDir, 'github');
              if (!fs.existsSync(githubDir)) {
                fs.mkdirSync(githubDir, { recursive: true });
              }
              
              const githubWorkflowsDir = path.join(githubDir, 'workflows');
              if (!fs.existsSync(githubWorkflowsDir)) {
                fs.mkdirSync(githubWorkflowsDir, { recursive: true });
              }
              
              // Crear GitHub Actions workflow para CI
              let ciWorkflowContent = 'name: CI\n\n';
              ciWorkflowContent += 'on:\n';
              ciWorkflowContent += '  push:\n';
              ciWorkflowContent += '    branches: [ main, develop ]\n';
              ciWorkflowContent += '  pull_request:\n';
              ciWorkflowContent += '    branches: [ main, develop ]\n\n';
              ciWorkflowContent += 'jobs:\n';
              
              if (config.services.includes('backend')) {
                ciWorkflowContent += '  backend-ci:\n';
                ciWorkflowContent += '    runs-on: ubuntu-latest\n';
                ciWorkflowContent += '    defaults:\n';
                ciWorkflowContent += '      run:\n';
                ciWorkflowContent += '        working-directory: ./backend\n\n';
                ciWorkflowContent += '    steps:\n';
                ciWorkflowContent += '    - uses: actions/checkout@v3\n\n';
                
                if (config.backendLanguage === 'node') {
                  ciWorkflowContent += '    - name: Setup Node.js\n';
                  ciWorkflowContent += '      uses: actions/setup-node@v3\n';
                  ciWorkflowContent += '      with:\n';
                  ciWorkflowContent += '        node-version: 18\n';
                  ciWorkflowContent += '        cache: \'npm\'\n';
                  ciWorkflowContent += '        cache-dependency-path: ./backend/package-lock.json\n\n';
                  
                  ciWorkflowContent += '    - name: Install dependencies\n';
                  ciWorkflowContent += '      run: npm ci\n\n';
                  
                  ciWorkflowContent += '    - name: Lint\n';
                  ciWorkflowContent += '      run: npm run lint\n\n';
                  
                  ciWorkflowContent += '    - name: Test\n';
                  ciWorkflowContent += '      run: npm test\n\n';
                  
                  ciWorkflowContent += '    - name: Build\n';
                  ciWorkflowContent += '      run: npm run build\n';
                } else if (config.backendLanguage === 'python') {
                  ciWorkflowContent += '    - name: Setup Python\n';
                  ciWorkflowContent += '      uses: actions/setup-python@v4\n';
                  ciWorkflowContent += '      with:\n';
                  ciWorkflowContent += '        python-version: 3.9\n';
                  ciWorkflowContent += '        cache: \'pip\'\n\n';
                  
                  ciWorkflowContent += '    - name: Install dependencies\n';
                  ciWorkflowContent += '      run: |\n';
                  ciWorkflowContent += '        python -m pip install --upgrade pip\n';
                  ciWorkflowContent += '        pip install -r requirements.txt\n';
                  ciWorkflowContent += '        pip install pytest flake8\n\n';
                  
                  ciWorkflowContent += '    - name: Lint\n';
                  ciWorkflowContent += '      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n\n';
                  
                  ciWorkflowContent += '    - name: Test\n';
                  ciWorkflowContent += '      run: pytest\n';
                } else if (config.backendLanguage === 'go') {
                  ciWorkflowContent += '    - name: Setup Go\n';
                  ciWorkflowContent += '      uses: actions/setup-go@v4\n';
                  ciWorkflowContent += '      with:\n';
                  ciWorkflowContent += '        go-version: 1.19\n\n';
                  
                  ciWorkflowContent += '    - name: Install dependencies\n';
                  ciWorkflowContent += '      run: go mod download\n\n';
                  
                  ciWorkflowContent += '    - name: Lint\n';
                  ciWorkflowContent += '      uses: golangci/golangci-lint-action@v3\n';
                  ciWorkflowContent += '      with:\n';
                  ciWorkflowContent += '        version: v1.50.1\n';
                  ciWorkflowContent += '        working-directory: ./backend\n\n';
                  
                  ciWorkflowContent += '    - name: Test\n';
                  ciWorkflowContent += '      run: go test ./...\n\n';
                  
                  ciWorkflowContent += '    - name: Build\n';
                  ciWorkflowContent += '      run: go build -v ./...\n';
                }
              }
              
              if (config.services.includes('frontend')) {
                if (config.services.includes('backend')) {
                  ciWorkflowContent += '\n';
                }
                
                ciWorkflowContent += '  frontend-ci:\n';
                ciWorkflowContent += '    runs-on: ubuntu-latest\n';
                ciWorkflowContent += '    defaults:\n';
                ciWorkflowContent += '      run:\n';
                ciWorkflowContent += '        working-directory: ./frontend\n\n';
                ciWorkflowContent += '    steps:\n';
                ciWorkflowContent += '    - uses: actions/checkout@v3\n\n';
                
                ciWorkflowContent += '    - name: Setup Node.js\n';
                ciWorkflowContent += '      uses: actions/setup-node@v3\n';
                ciWorkflowContent += '      with:\n';
                ciWorkflowContent += '        node-version: 18\n';
                ciWorkflowContent += '        cache: \'npm\'\n';
                ciWorkflowContent += '        cache-dependency-path: ./frontend/package-lock.json\n\n';
                
                ciWorkflowContent += '    - name: Install dependencies\n';
                ciWorkflowContent += '      run: npm ci\n\n';
                
                ciWorkflowContent += '    - name: Lint\n';
                ciWorkflowContent += '      run: npm run lint\n\n';
                
                ciWorkflowContent += '    - name: Test\n';
                ciWorkflowContent += '      run: npm test\n\n';
                
                ciWorkflowContent += '    - name: Build\n';
                ciWorkflowContent += '      run: npm run build\n';
              }
              
              // Escribir workflow de CI
              fs.writeFileSync(path.join(githubWorkflowsDir, 'ci.yml'), ciWorkflowContent);
              
              // Crear GitHub Actions workflow para CD
              let cdWorkflowContent = 'name: CD\n\n';
              cdWorkflowContent += 'on:\n';
              cdWorkflowContent += '  push:\n';
              cdWorkflowContent += '    branches: [ main ]\n\n';
              cdWorkflowContent += 'jobs:\n';
              
              if (config.services.includes('backend')) {
                cdWorkflowContent += '  deploy-backend:\n';
                cdWorkflowContent += '    runs-on: ubuntu-latest\n';
                cdWorkflowContent += '    defaults:\n';
                cdWorkflowContent += '      run:\n';
                cdWorkflowContent += '        working-directory: ./backend\n\n';
                cdWorkflowContent += '    steps:\n';
                cdWorkflowContent += '    - uses: actions/checkout@v3\n\n';
                
                cdWorkflowContent += '    - name: Configure AWS credentials\n';
                cdWorkflowContent += '      uses: aws-actions/configure-aws-credentials@v2\n';
                cdWorkflowContent += '      with:\n';
                cdWorkflowContent += '        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
                cdWorkflowContent += '        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
                cdWorkflowContent += '        aws-region: us-east-1\n\n';
                
                cdWorkflowContent += '    - name: Login to Amazon ECR\n';
                cdWorkflowContent += '      id: login-ecr\n';
                cdWorkflowContent += '      uses: aws-actions/amazon-ecr-login@v1\n\n';
                
                cdWorkflowContent += '    - name: Build, tag, and push image to Amazon ECR\n';
                cdWorkflowContent += '      env:\n';
                cdWorkflowContent += '        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}\n';
                cdWorkflowContent += '        ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY_NAME }}\n';
                cdWorkflowContent += '        IMAGE_TAG: ${{ github.sha }}\n';
                cdWorkflowContent += '      run: |\n';
                cdWorkflowContent += '        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .\n';
                cdWorkflowContent += '        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\n';
                cdWorkflowContent += '        docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest\n';
                cdWorkflowContent += '        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest\n\n';
                
                cdWorkflowContent += '    - name: Update ECS service\n';
                cdWorkflowContent += '      run: |\n';
                cdWorkflowContent += '        aws ecs update-service --cluster ${{ secrets.ECS_CLUSTER_NAME }} --service ${{ secrets.ECS_SERVICE_NAME }} --force-new-deployment\n';
              }
              
              if (config.services.includes('frontend')) {
                if (config.services.includes('backend')) {
                  cdWorkflowContent += '\n';
                }
                
                cdWorkflowContent += '  deploy-frontend:\n';
                cdWorkflowContent += '    runs-on: ubuntu-latest\n';
                cdWorkflowContent += '    defaults:\n';
                cdWorkflowContent += '      run:\n';
                cdWorkflowContent += '        working-directory: ./frontend\n\n';
                cdWorkflowContent += '    steps:\n';
                cdWorkflowContent += '    - uses: actions/checkout@v3\n\n';
                
                cdWorkflowContent += '    - name: Setup Node.js\n';
                cdWorkflowContent += '      uses: actions/setup-node@v3\n';
                cdWorkflowContent += '      with:\n';
                cdWorkflowContent += '        node-version: 18\n';
                cdWorkflowContent += '        cache: \'npm\'\n';
                cdWorkflowContent += '        cache-dependency-path: ./frontend/package-lock.json\n\n';
                
                cdWorkflowContent += '    - name: Install dependencies\n';
                cdWorkflowContent += '      run: npm ci\n\n';
                
                cdWorkflowContent += '    - name: Build\n';
                cdWorkflowContent += '      run: npm run build\n\n';
                
                cdWorkflowContent += '    - name: Configure AWS credentials\n';
                cdWorkflowContent += '      uses: aws-actions/configure-aws-credentials@v2\n';
                cdWorkflowContent += '      with:\n';
                cdWorkflowContent += '        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n';
                cdWorkflowContent += '        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n';
                cdWorkflowContent += '        aws-region: us-east-1\n\n';
                
                cdWorkflowContent += '    - name: Deploy to S3\n';
                cdWorkflowContent += '      run: |\n';
                cdWorkflowContent += '        aws s3 sync ./build/ s3://${{ secrets.S3_BUCKET_NAME }} --delete\n\n';
                
                cdWorkflowContent += '    - name: Invalidate CloudFront cache\n';
                cdWorkflowContent += '      run: |\n';
                cdWorkflowContent += '        aws cloudfront create-invalidation --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} --paths "/*"\n';
              }
              
              // Escribir workflow de CD
              fs.writeFileSync(path.join(githubWorkflowsDir, 'cd.yml'), cdWorkflowContent);
              
              // Crear directorio para GitLab CI
              const gitlabDir = path.join(cicdDir, 'gitlab');
              if (!fs.existsSync(gitlabDir)) {
                fs.mkdirSync(gitlabDir, { recursive: true });
              }
              
              // Crear archivo .gitlab-ci.yml
              let gitlabCiContent = 'stages:\n';
              gitlabCiContent += '  - test\n';
              gitlabCiContent += '  - build\n';
              gitlabCiContent += '  - deploy\n\n';
              
              gitlabCiContent += 'variables:\n';
              gitlabCiContent += '  AWS_REGION: us-east-1\n\n';
              
              if (config.services.includes('backend')) {
                gitlabCiContent += 'backend-test:\n';
                gitlabCiContent += '  stage: test\n';
                
                if (config.backendLanguage === 'node') {
                  gitlabCiContent += '  image: node:18-alpine\n';
                } else if (config.backendLanguage === 'python') {
                  gitlabCiContent += '  image: python:3.9-alpine\n';
                } else if (config.backendLanguage === 'go') {
                  gitlabCiContent += '  image: golang:1.19-alpine\n';
                }
                
                gitlabCiContent += '  script:\n';
                gitlabCiContent += '    - cd backend\n';
                
                if (config.backendLanguage === 'node') {
                  gitlabCiContent += '    - npm ci\n';
                  gitlabCiContent += '    - npm run lint\n';
                  gitlabCiContent += '    - npm test\n';
                  gitlabCiContent += '    - npm run build\n';
                } else if (config.backendLanguage === 'python') {
                  gitlabCiContent += '    - pip install -r requirements.txt\n';
                  gitlabCiContent += '    - pip install pytest flake8\n';
                  gitlabCiContent += '    - flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n';
                  gitlabCiContent += '    - pytest\n';
                } else if (config.backendLanguage === 'go') {
                  gitlabCiContent += '    - go mod download\n';
                  gitlabCiContent += '    - go test ./...\n';
                  gitlabCiContent += '    - go build -v ./...\n';
                }
                
                gitlabCiContent += '  only:\n';
                gitlabCiContent += '    - main\n';
                gitlabCiContent += '    - develop\n';
                gitlabCiContent += '    - merge_requests\n\n';
                
                gitlabCiContent += 'backend-build:\n';
                gitlabCiContent += '  stage: build\n';
                gitlabCiContent += '  image: docker:20.10.16\n';
                gitlabCiContent += '  services:\n';
                gitlabCiContent += '    - docker:20.10.16-dind\n';
                gitlabCiContent += '  variables:\n';
                gitlabCiContent += '    DOCKER_TLS_CERTDIR: "/certs"\n';
                gitlabCiContent += '  before_script:\n';
                gitlabCiContent += '    - apk add --no-cache aws-cli\n';
                gitlabCiContent += '    - aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REGISTRY\n';
                gitlabCiContent += '  script:\n';
                gitlabCiContent += '    - cd backend\n';
                gitlabCiContent += '    - docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$CI_COMMIT_SHA .\n';
                gitlabCiContent += '    - docker push $ECR_REGISTRY/$ECR_REPOSITORY:$CI_COMMIT_SHA\n';
                gitlabCiContent += '    - docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$CI_COMMIT_SHA $ECR_REGISTRY/$ECR_REPOSITORY:latest\n';
                gitlabCiContent += '    - docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest\n';
                gitlabCiContent += '  only:\n';
                gitlabCiContent += '    - main\n\n';
                
                gitlabCiContent += 'backend-deploy:\n';
                gitlabCiContent += '  stage: deploy\n';
                gitlabCiContent += '  image: alpine:3.16\n';
                gitlabCiContent += '  before_script:\n';
                gitlabCiContent += '    - apk add --no-cache aws-cli\n';
                gitlabCiContent += '  script:\n';
                gitlabCiContent += '    - aws ecs update-service --cluster $ECS_CLUSTER_NAME --service $ECS_SERVICE_NAME --force-new-deployment --region $AWS_REGION\n';
                gitlabCiContent += '  only:\n';
                gitlabCiContent += '    - main\n';
              }
              
              if (config.services.includes('frontend')) {
                if (config.services.includes('backend')) {
                  gitlabCiContent += '\n';
                }
                
                gitlabCiContent += 'frontend-test:\n';
                gitlabCiContent += '  stage: test\n';
                gitlabCiContent += '  image: node:18-alpine\n';
                gitlabCiContent += '  script:\n';
                gitlabCiContent += '    - cd frontend\n';
                gitlabCiContent += '    - npm ci\n';
                gitlabCiContent += '    - npm run lint\n';
                gitlabCiContent += '    - npm test\n';
                gitlabCiContent += '  only:\n';
                gitlabCiContent += '    - main\n';
                gitlabCiContent += '    - develop\n';
                gitlabCiContent += '    - merge_requests\n\n';
                
                gitlabCiContent += 'frontend-build:\n';
                gitlabCiContent += '  stage: build\n';
                gitlabCiContent += '  image: node:18-alpine\n';
                gitlabCiContent += '  script:\n';
                gitlabCiContent += '    - cd frontend\n';
                gitlabCiContent += '    - npm ci\n';
                gitlabCiContent += '    - npm run build\n';
                gitlabCiContent += '    - apk add --no-cache aws-cli\n';
                gitlabCiContent += '    - aws s3 sync ./build/ s3://$S3_BUCKET_NAME --delete\n';
                gitlabCiContent += '  only:\n';
                gitlabCiContent += '    - main\n\n';
                
                gitlabCiContent += 'frontend-deploy:\n';
                gitlabCiContent += '  stage: deploy\n';
                gitlabCiContent += '  image: alpine:3.16\n';
                gitlabCiContent += '  before_script:\n';
                gitlabCiContent += '    - apk add --no-cache aws-cli\n';
                gitlabCiContent += '  script:\n';
                gitlabCiContent += '    - aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_DISTRIBUTION_ID --paths "/*" --region $AWS_REGION\n';
                gitlabCiContent += '  only:\n';
                gitlabCiContent += '    - main\n';
              }
              
              // Escribir archivo .gitlab-ci.yml
              fs.writeFileSync(path.join(gitlabDir, '.gitlab-ci.yml'), gitlabCiContent);
              
              // Crear directorio para Jenkins
              const jenkinsDir = path.join(cicdDir, 'jenkins');
              if (!fs.existsSync(jenkinsDir)) {
                fs.mkdirSync(jenkinsDir, { recursive: true });
              }
              
              // Crear Jenkinsfile
              let jenkinsfileContent = 'pipeline {\n';
              jenkinsfileContent += '  agent any\n\n';
              jenkinsfileContent += '  environment {\n';
              jenkinsfileContent += '    AWS_REGION = \'us-east-1\'\n';
              
              if (config.services.includes('backend')) {
                jenkinsfileContent += '    ECR_REGISTRY = credentials(\'ecr-registry\')\n';
                jenkinsfileContent += '    ECR_REPOSITORY = credentials(\'ecr-repository-name\')\n';
                jenkinsfileContent += '    ECS_CLUSTER_NAME = credentials(\'ecs-cluster-name\')\n';
                jenkinsfileContent += '    ECS_SERVICE_NAME = credentials(\'ecs-service-name\')\n';
              }
              
              if (config.services.includes('frontend')) {
                jenkinsfileContent += '    S3_BUCKET_NAME = credentials(\'s3-bucket-name\')\n';
                jenkinsfileContent += '    CLOUDFRONT_DISTRIBUTION_ID = credentials(\'cloudfront-distribution-id\')\n';
              }
              
              jenkinsfileContent += '  }\n\n';
              jenkinsfileContent += '  stages {\n';
              jenkinsfileContent += '    stage(\'Checkout\') {\n';
              jenkinsfileContent += '      steps {\n';
              jenkinsfileContent += '        checkout scm\n';
              jenkinsfileContent += '      }\n';
              jenkinsfileContent += '    }\n\n';
              
              if (config.services.includes('backend')) {
                jenkinsfileContent += '    stage(\'Test Backend\') {\n';
                jenkinsfileContent += '      steps {\n';
                jenkinsfileContent += '        dir(\'backend\') {\n';
                
                if (config.backendLanguage === 'node') {
                  jenkinsfileContent += '          sh \'npm ci\'\n';
                  jenkinsfileContent += '          sh \'npm run lint\'\n';
                  jenkinsfileContent += '          sh \'npm test\'\n';
                } else if (config.backendLanguage === 'python') {
                  jenkinsfileContent += '          sh \'pip install -r requirements.txt\'\n';
                  jenkinsfileContent += '          sh \'pip install pytest flake8\'\n';
                  jenkinsfileContent += '          sh \'flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\'\n';
                  jenkinsfileContent += '          sh \'pytest\'\n';
                } else if (config.backendLanguage === 'go') {
                  jenkinsfileContent += '          sh \'go mod download\'\n';
                  jenkinsfileContent += '          sh \'go test ./...\'\n';
                }
                
                jenkinsfileContent += '        }\n';
                jenkinsfileContent += '      }\n';
                jenkinsfileContent += '    }\n\n';
                
                jenkinsfileContent += '    stage(\'Build and Push Backend\') {\n';
                jenkinsfileContent += '      when {\n';
                jenkinsfileContent += '        branch \'main\'\n';
                jenkinsfileContent += '      }\n';
                jenkinsfileContent += '      steps {\n';
                jenkinsfileContent += '        dir(\'backend\') {\n';
                jenkinsfileContent += '          sh \'aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin ${ECR_REGISTRY}\'\n';
                jenkinsfileContent += '          sh \'docker build -t ${ECR_REGISTRY}/${ECR_REPOSITORY}:${BUILD_NUMBER} .\'\n';
                jenkinsfileContent += '          sh \'docker push ${ECR_REGISTRY}/${ECR_REPOSITORY}:${BUILD_NUMBER}\'\n';
                jenkinsfileContent += '          sh \'docker tag ${ECR_REGISTRY}/${ECR_REPOSITORY}:${BUILD_NUMBER} ${ECR_REGISTRY}/${ECR_REPOSITORY}:latest\'\n';
                jenkinsfileContent += '          sh \'docker push ${ECR_REGISTRY}/${ECR_REPOSITORY}:latest\'\n';
                jenkinsfileContent += '        }\n';
                jenkinsfileContent += '      }\n';
                jenkinsfileContent += '    }\n\n';
                
                jenkinsfileContent += '    stage(\'Deploy Backend\') {\n';
                jenkinsfileContent += '      when {\n';
                jenkinsfileContent += '        branch \'main\'\n';
                jenkinsfileContent += '      }\n';
                jenkinsfileContent += '      steps {\n';
                jenkinsfileContent += '        sh \'aws ecs update-service --cluster ${ECS_CLUSTER_NAME} --service ${ECS_SERVICE_NAME} --force-new-deployment --region ${AWS_REGION}\'\n';
                jenkinsfileContent += '      }\n';
                jenkinsfileContent += '    }\n\n';
              }
              
              if (config.services.includes('frontend')) {
                jenkinsfileContent += '    stage(\'Test Frontend\') {\n';
                jenkinsfileContent += '      steps {\n';
                jenkinsfileContent += '        dir(\'frontend\') {\n';
                jenkinsfileContent += '          sh \'npm ci\'\n';
                jenkinsfileContent += '          sh \'npm run lint\'\n';
                jenkinsfileContent += '          sh \'npm test\'\n';
                jenkinsfileContent += '        }\n';
                jenkinsfileContent += '      }\n';
                jenkinsfileContent += '    }\n\n';
                
                jenkinsfileContent += '    stage(\'Build and Deploy Frontend\') {\n';
                jenkinsfileContent += '      when {\n';
                jenkinsfileContent += '        branch \'main\'\n';
                jenkinsfileContent += '      }\n';
                jenkinsfileContent += '      steps {\n';
                jenkinsfileContent += '        dir(\'frontend\') {\n';
                jenkinsfileContent += '          sh \'npm ci\'\n';
                jenkinsfileContent += '          sh \'npm run build\'\n';
                jenkinsfileContent += '          sh \'aws s3 sync ./build/ s3://${S3_BUCKET_NAME} --delete --region ${AWS_REGION}\'\n';
                jenkinsfileContent += '          sh \'aws cloudfront create-invalidation --distribution-id ${CLOUDFRONT_DISTRIBUTION_ID} --paths "/*" --region ${AWS_REGION}\'\n';
                jenkinsfileContent += '        }\n';
                jenkinsfileContent += '      }\n';
                jenkinsfileContent += '    }\n';
              }
              
              jenkinsfileContent += '  }\n';
              jenkinsfileContent += '}\n';
              
              // Escribir Jenkinsfile
              fs.writeFileSync(path.join(jenkinsDir, 'Jenkinsfile'), jenkinsfileContent);
              
              // Crear README.md para CI/CD
              let readmeContent = '# CI/CD Configuración\n\n';
              readmeContent += 'Este directorio contiene configuraciones para diferentes sistemas de CI/CD.\n\n';
              
              readmeContent += '## GitHub Actions\n\n';
              readmeContent += 'Los workflows de GitHub Actions se encuentran en el directorio `.github/workflows/`.\n\n';
              readmeContent += '### Workflows\n\n';
              readmeContent += '- `ci.yml`: Ejecuta pruebas y linting en cada push y pull request a las ramas `main` y `develop`.\n';
              readmeContent += '- `cd.yml`: Despliega la aplicación cuando se hace push a la rama `main`.\n\n';
              readmeContent += '### Configuración\n\n';
              readmeContent += 'Para usar GitHub Actions, necesitas configurar los siguientes secretos en tu repositorio:\n\n';
              
              if (config.services.includes('backend')) {
                readmeContent += '- `AWS_ACCESS_KEY_ID`: ID de clave de acceso de AWS\n';
                readmeContent += '- `AWS_SECRET_ACCESS_KEY`: Clave de acceso secreta de AWS\n';
                readmeContent += '- `ECR_REPOSITORY_NAME`: Nombre del repositorio ECR\n';
                readmeContent += '- `ECS_CLUSTER_NAME`: Nombre del cluster ECS\n';
                readmeContent += '- `ECS_SERVICE_NAME`: Nombre del servicio ECS\n';
              }
              
              if (config.services.includes('frontend')) {
                readmeContent += '- `S3_BUCKET_NAME`: Nombre del bucket S3\n';
                readmeContent += '- `CLOUDFRONT_DISTRIBUTION_ID`: ID de la distribución CloudFront\n';
              }
              
              readmeContent += '\n## GitLab CI\n\n';
              readmeContent += 'La configuración de GitLab CI se encuentra en el archivo `.gitlab-ci.yml`.\n\n';
              readmeContent += '### Configuración\n\n';
              readmeContent += 'Para usar GitLab CI, necesitas configurar las siguientes variables en tu proyecto GitLab:\n\n';
              
              if (config.services.includes('backend')) {
                readmeContent += '- `AWS_ACCESS_KEY_ID`: ID de clave de acceso de AWS\n';
                readmeContent += '- `AWS_SECRET_ACCESS_KEY`: Clave de acceso secreta de AWS\n';
                readmeContent += '- `ECR_REGISTRY`: URL del registro ECR\n';
                readmeContent += '- `ECR_REPOSITORY`: Nombre del repositorio ECR\n';
                readmeContent += '- `ECS_CLUSTER_NAME`: Nombre del cluster ECS\n';
                readmeContent += '- `ECS_SERVICE_NAME`: Nombre del servicio ECS\n';
              }
              
              if (config.services.includes('frontend')) {
                readmeContent += '- `S3_BUCKET_NAME`: Nombre del bucket S3\n';
                readmeContent += '- `CLOUDFRONT_DISTRIBUTION_ID`: ID de la distribución CloudFront\n';
              }
              
              readmeContent += '\n## Jenkins\n\n';
              readmeContent += 'La configuración de Jenkins se encuentra en el archivo `Jenkinsfile`.\n\n';
              readmeContent += '### Configuración\n\n';
              readmeContent += 'Para usar Jenkins, necesitas configurar las siguientes credenciales en tu servidor Jenkins:\n\n';
              
              if (config.services.includes('backend')) {
                readmeContent += '- `ecr-registry`: URL del registro ECR\n';
                readmeContent += '- `ecr-repository-name`: Nombre del repositorio ECR\n';
                readmeContent += '- `ecs-cluster-name`: Nombre del cluster ECS\n';
                readmeContent += '- `ecs-service-name`: Nombre del servicio ECS\n';
              }
              
              if (config.services.includes('frontend')) {
                readmeContent += '- `s3-bucket-name`: Nombre del bucket S3\n';
                readmeContent += '- `cloudfront-distribution-id`: ID de la distribución CloudFront\n';
              }
              
              readmeContent += '\nAdemás, necesitas configurar las credenciales de AWS en tu servidor Jenkins.\n';
              
              // Escribir README.md
              fs.writeFileSync(path.join(cicdDir, 'README.md'), readmeContent);
              
              // Crear directorio para GitHub Actions
              const githubActionsDir = path.join(projectDir, '.github');
              if (!fs.existsSync(githubActionsDir)) {
                fs.mkdirSync(githubActionsDir, { recursive: true });
              }
              
              const workflowsDir = path.join(githubActionsDir, 'workflows');
              if (!fs.existsSync(workflowsDir)) {
                fs.mkdirSync(workflowsDir, { recursive: true });
              }
              
              // Copiar archivos de GitHub Actions
              fs.copyFileSync(
                path.join(githubWorkflowsDir, 'ci.yml'),
                path.join(workflowsDir, 'ci.yml')
              );
              
              fs.copyFileSync(
                path.join(githubWorkflowsDir, 'cd.yml'),
                path.join(workflowsDir, 'cd.yml')
              );
              
              return cicdDir;
            } catch (error) {
              console.error('Error al crear archivos de CI/CD:', error);
              throw error;
            }
          }
          
          /**
           * Crea archivos de configuración para monitoreo
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de monitoreo
           */
          async createMonitoringFiles(projectDir, config) {
            try {
              const monitoringDir = path.join(projectDir, 'monitoring');
              if (!fs.existsSync(monitoringDir)) {
                fs.mkdirSync(monitoringDir, { recursive: true });
              }
              
              // Crear directorio para Prometheus
              const prometheusDir = path.join(monitoringDir, 'prometheus');
              if (!fs.existsSync(prometheusDir)) {
                fs.mkdirSync(prometheusDir, { recursive: true });
              }
              
              // Crear prometheus.yml
              let prometheusContent = 'global:\n';
              prometheusContent += '  scrape_interval: 15s\n';
              prometheusContent += '  evaluation_interval: 15s\n\n';
              prometheusContent += 'alerting:\n';
              prometheusContent += '  alertmanagers:\n';
              prometheusContent += '    - static_configs:\n';
              prometheusContent += '        - targets: [\'alertmanager:9093\']\n\n';
              prometheusContent += 'rule_files:\n';
              prometheusContent += '  - "alert_rules.yml"\n\n';
              prometheusContent += 'scrape_configs:\n';
              prometheusContent += '  - job_name: \'prometheus\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '      - targets: [\'localhost:9090\']\n\n';
              prometheusContent += '  - job_name: \'node-exporter\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '      - targets: [\'node-exporter:9100\']\n\n';
              prometheusContent += '  - job_name: \'cadvisor\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '      - targets: [\'cadvisor:8080\']\n';
              
              if (config.services.includes('backend')) {
                prometheusContent += '\n  - job_name: \'backend\'\n';
                prometheusContent += '    metrics_path: \'/metrics\'\n';
                prometheusContent += '    static_configs:\n';
                prometheusContent += '      - targets: [\'backend:3000\']\n';
              }
              
              // Escribir prometheus.yml
              fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);
              
              // Crear alert_rules.yml
              let alertRulesContent = 'groups:\n';
              alertRulesContent += '- name: example\n';
              alertRulesContent += '  rules:\n';
              alertRulesContent += '  - alert: HighCPULoad\n';
              alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High CPU load (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "CPU load is > 80%\\n  VALUE = {{ $value }}%\\n  LABELS: {{ $labels }}"\n\n';
              
              alertRulesContent += '  - alert: HighMemoryLoad\n';
              alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 > 80\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High memory load (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "Memory load is > 80%\\n  VALUE = {{ $value }}%\\n  LABELS: {{ $labels }}"\n\n';
              
              alertRulesContent += '  - alert: HighDiskUsage\n';
              alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High disk usage (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "Disk usage is > 85%\\n  VALUE = {{ $value }}%\\n  LABELS: {{ $labels }}"\n';
              
              // Escribir alert_rules.yml
              fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);

              // Crear directorio para Alertmanager
              const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
              if (!fs.existsSync(alertmanagerDir)) {
                fs.mkdirSync(alertmanagerDir, { recursive: true });
              }

              // Crear alertmanager.yml
              let alertmanagerContent = 'global:\n';
              alertmanagerContent += '  resolve_timeout: 5m\n';
              alertmanagerContent += '  smtp_smarthost: "smtp.example.com:587"\n';
              alertmanagerContent += '  smtp_from: "alertmanager@example.com"\n';
              alertmanagerContent += '  smtp_auth_username: "alertmanager"\n';
              alertmanagerContent += '  smtp_auth_password: "password"\n\n';
              alertmanagerContent += 'route:\n';
              alertmanagerContent += '  group_by: [\'alertname\', \'instance\']\n';
              alertmanagerContent += '  group_wait: 30s\n';
              alertmanagerContent += '  group_interval: 5m\n';
              alertmanagerContent += '  repeat_interval: 1h\n';
              alertmanagerContent += '  receiver: \'email\'\n\n';
              alertmanagerContent += 'receivers:\n';
              alertmanagerContent += '- name: \'email\'\n';
              alertmanagerContent += '  email_configs:\n';
              alertmanagerContent += '  - to: "alerts@example.com"\n';
              alertmanagerContent += '    send_resolved: true\n\n';
              alertmanagerContent += 'inhibit_rules:\n';
              alertmanagerContent += '  - source_match:\n';
              alertmanagerContent += '      severity: \'critical\'\n';
              alertmanagerContent += '    target_match:\n';
              alertmanagerContent += '      severity: \'warning\'\n';
              alertmanagerContent += '    equal: [\'alertname\', \'instance\']\n';

              // Escribir alertmanager.yml
              fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);

              // Crear directorio para Grafana
              const grafanaDir = path.join(monitoringDir, 'grafana');
              if (!fs.existsSync(grafanaDir)) {
                fs.mkdirSync(grafanaDir, { recursive: true });
              }

              // Crear datasources.yml
              let datasourcesContent = 'apiVersion: 1\n\n';
              datasourcesContent += 'datasources:\n';
              datasourcesContent += '  - name: Prometheus\n';
              datasourcesContent += '    type: prometheus\n';
              datasourcesContent += '    access: proxy\n';
              datasourcesContent += '    url: http://prometheus:9090\n';
              datasourcesContent += '    isDefault: true\n';
              datasourcesContent += '    editable: true\n';

              // Escribir datasources.yml
              fs.writeFileSync(path.join(grafanaDir, 'datasources.yml'), datasourcesContent);

              // Crear directorio para dashboards
              const dashboardsDir = path.join(grafanaDir, 'dashboards');
              if (!fs.existsSync(dashboardsDir)) {
                fs.mkdirSync(dashboardsDir, { recursive: true });
              }

              // Crear dashboard.json
              let dashboardContent = '{\n';
              dashboardContent += '  "annotations": {\n';
              dashboardContent += '    "list": [\n';
              dashboardContent += '      {\n';
              dashboardContent += '        "builtIn": 1,\n';
              dashboardContent += '        "datasource": "-- Grafana --",\n';
              dashboardContent += '        "enable": true,\n';
              dashboardContent += '        "hide": true,\n';
              dashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
              dashboardContent += '        "name": "Annotations & Alerts",\n';
              dashboardContent += '        "type": "dashboard"\n';
              dashboardContent += '      }\n';
              dashboardContent += '    ]\n';
              dashboardContent += '  },\n';
              dashboardContent += '  "editable": true,\n';
              dashboardContent += '  "gnetId": null,\n';
              dashboardContent += '  "graphTooltip": 0,\n';
              dashboardContent += '  "id": 1,\n';
              dashboardContent += '  "links": [],\n';
              dashboardContent += '  "panels": [\n';
              dashboardContent += '    {\n';
              dashboardContent += '      "alert": {\n';
              dashboardContent += '        "conditions": [\n';
              dashboardContent += '          {\n';
              dashboardContent += '            "evaluator": {\n';
              dashboardContent += '              "params": [\n';
              dashboardContent += '                80\n';
              dashboardContent += '              ],\n';
              dashboardContent += '              "type": "gt"\n';
              dashboardContent += '            },\n';
              dashboardContent += '            "operator": {\n';
              dashboardContent += '              "type": "and"\n';
              dashboardContent += '            },\n';
              dashboardContent += '            "query": {\n';
              dashboardContent += '              "params": [\n';
              dashboardContent += '                "A",\n';
              dashboardContent += '                "5m",\n';
              dashboardContent += '                "now"\n';
              dashboardContent += '              ]\n';
              dashboardContent += '            },\n';
              dashboardContent += '            "reducer": {\n';
              dashboardContent += '              "params": [],\n';
              dashboardContent += '              "type": "avg"\n';
              dashboardContent += '            },\n';
              dashboardContent += '            "type": "query"\n';
              dashboardContent += '          }\n';
              dashboardContent += '        ],\n';
              dashboardContent += '        "executionErrorState": "alerting",\n';
              dashboardContent += '        "frequency": "60s",\n';
              dashboardContent += '        "handler": 1,\n';
              dashboardContent += '        "name": "CPU Usage alert",\n';
              dashboardContent += '        "noDataState": "no_data",\n';
              dashboardContent += '        "notifications": []\n';
              dashboardContent += '      },\n';
              dashboardContent += '      "aliasColors": {},\n';
              dashboardContent += '      "bars": false,\n';
              dashboardContent += '      "dashLength": 10,\n';
              dashboardContent += '      "dashes": false,\n';
              dashboardContent += '      "datasource": "Prometheus",\n';
              dashboardContent += '      "fieldConfig": {\n';
              dashboardContent += '        "defaults": {\n';
              dashboardContent += '          "custom": {}\n';
              dashboardContent += '        },\n';
              dashboardContent += '        "overrides": []\n';
              dashboardContent += '      },\n';
              dashboardContent += '      "fill": 1,\n';
              dashboardContent += '      "fillGradient": 0,\n';
              dashboardContent += '      "gridPos": {\n';
              dashboardContent += '        "h": 9,\n';
              dashboardContent += '        "w": 12,\n';
              dashboardContent += '        "x": 0,\n';
              dashboardContent += '        "y": 0\n';
              dashboardContent += '      },\n';
              dashboardContent += '      "hiddenSeries": false,\n';
              dashboardContent += '      "id": 2,\n';
              dashboardContent += '      "legend": {\n';
              dashboardContent += '        "avg": false,\n';
              dashboardContent += '        "current": false,\n';
              dashboardContent += '        "max": false,\n';
              dashboardContent += '        "min": false,\n';
              dashboardContent += '        "show": true,\n';
              dashboardContent += '        "total": false,\n';
              dashboardContent += '        "values": false\n';
              dashboardContent += '      },\n';
              dashboardContent += '      "lines": true,\n';
              dashboardContent += '      "linewidth": 1,\n';
              dashboardContent += '      "nullPointMode": "null",\n';
              dashboardContent += '      "options": {\n';
              dashboardContent += '        "alertThreshold": true\n';
              dashboardContent += '      },\n';
              dashboardContent += '      "percentage": false,\n';
              dashboardContent += '      "pointradius": 2,\n';
              dashboardContent += '      "points": false,\n';
              dashboardContent += '      "renderer": "flot",\n';
              dashboardContent += '      "seriesOverrides": [],\n';
              dashboardContent += '      "spaceLength": 10,\n';
              dashboardContent += '      "stack": false,\n';
              dashboardContent += '      "steppedLine": false,\n';
              dashboardContent += '      "targets": [\n';
              dashboardContent += '        {\n';
              dashboardContent += '          "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\\"idle\\"}[5m])) * 100)",\n';
              dashboardContent += '          "interval": "",\n';
              dashboardContent += '          "legendFormat": "",\n';
              dashboardContent += '          "refId": "A"\n';
              dashboardContent += '        }\n';
              dashboardContent += '      ],\n';
              dashboardContent += '      "thresholds": [\n';
              dashboardContent += '        {\n';
              dashboardContent += '          "colorMode": "critical",\n';
              dashboardContent += '          "fill": true,\n';
              dashboardContent += '          "line": true,\n';
              dashboardContent += '          "op": "gt",\n';
              dashboardContent += '          "value": 80\n';
              dashboardContent += '        }\n';
              dashboardContent += '      ],\n';
              dashboardContent += '      "timeFrom": null,\n';
              dashboardContent += '      "timeRegions": [],\n';
              dashboardContent += '      "timeShift": null,\n';
              dashboardContent += '      "title": "CPU Usage",\n';
              dashboardContent += '      "tooltip": {\n';
              dashboardContent += '        "shared": true,\n';
              dashboardContent += '        "sort": 0,\n';
              dashboardContent += '        "value_type": "individual"\n';
              dashboardContent += '      },\n';
              dashboardContent += '      "type": "graph",\n';
              dashboardContent += '      "xaxis": {\n';
              dashboardContent += '        "buckets": null,\n';
              dashboardContent += '        "mode": "time",\n';
              dashboardContent += '        "name": null,\n';
              dashboardContent += '        "show": true,\n';
              dashboardContent += '        "values": []\n';
              dashboardContent += '      },\n';
              dashboardContent += '      "yaxes": [\n';
              dashboardContent += '        {\n';
              dashboardContent += '          "format": "percent",\n';
              dashboardContent += '          "label": null,\n';
              dashboardContent += '          "logBase": 1,\n';
              dashboardContent += '          "max": null,\n';
              dashboardContent += '          "min": null,\n';
              dashboardContent += '          "show": true\n';
              dashboardContent += '        },\n';
              dashboardContent += '        {\n';
              dashboardContent += '          "format": "short",\n';
              dashboardContent += '          "label": null,\n';
              dashboardContent += '          "logBase": 1,\n';
              dashboardContent += '          "max": null,\n';
              dashboardContent += '          "min": null,\n';
              dashboardContent += '          "show": true\n';
              dashboardContent += '        }\n';
              dashboardContent += '      ],\n';
              dashboardContent += '      "yaxis": {\n';
              dashboardContent += '        "align": false,\n';
              dashboardContent += '        "alignLevel": null\n';
              dashboardContent += '      }\n';
              dashboardContent += '    }\n';
              dashboardContent += '  ],\n';
              dashboardContent += '  "schemaVersion": 26,\n';
              dashboardContent += '  "style": "dark",\n';
              dashboardContent += '  "tags": [],\n';
              dashboardContent += '  "templating": {\n';
              dashboardContent += '    "list": []\n';
              dashboardContent += '  },\n';
              dashboardContent += '  "time": {\n';
              dashboardContent += '    "from": "now-6h",\n';
              dashboardContent += '    "to": "now"\n';
              dashboardContent += '  },\n';
              dashboardContent += '  "timepicker": {},\n';
              dashboardContent += '  "timezone": "",\n';
              dashboardContent += '  "title": "System Monitoring",\n';
              dashboardContent += '  "uid": "system-monitoring",\n';
              dashboardContent += '  "version": 1\n';
              dashboardContent += '}\n';

              // Escribir dashboard.json
              fs.writeFileSync(path.join(dashboardsDir, 'dashboard.json'), dashboardContent);

              // Crear dashboard.yml
              let dashboardYamlContent = 'apiVersion: 1\n\n';
              dashboardYamlContent += 'providers:\n';
              dashboardYamlContent += '  - name: \'default\'\n';
              dashboardYamlContent += '    orgId: 1\n';
              dashboardYamlContent += '    folder: \'\'\n';
              dashboardYamlContent += '    type: file\n';
              dashboardYamlContent += '    disableDeletion: false\n';
              dashboardYamlContent += '    editable: true\n';
              dashboardYamlContent += '    options:\n';
              dashboardYamlContent += '      path: /etc/grafana/dashboards\n';

              // Escribir dashboard.yml
              fs.writeFileSync(path.join(grafanaDir, 'dashboard.yml'), dashboardYamlContent);

              // Crear docker-compose.yml para monitoreo
              let dockerComposeContent = 'version: "3.8"\n\n';
              dockerComposeContent += 'services:\n';
              dockerComposeContent += '  prometheus:\n';
              dockerComposeContent += '    image: prom/prometheus:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
              dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
              dockerComposeContent += '      - prometheus_data:/prometheus\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
              dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
              dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
              dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9090:9090"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  alertmanager:\n';
              dockerComposeContent += '    image: prom/alertmanager:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
              dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
              dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9093:9093"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  grafana:\n';
              dockerComposeContent += '    image: grafana/grafana:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
              dockerComposeContent += '      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml\n';
              dockerComposeContent += '      - ./grafana/dashboards:/etc/grafana/dashboards\n';
              dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
              dockerComposeContent += '    environment:\n';
              dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
              dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
              dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "3000:3000"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  node-exporter:\n';
              dockerComposeContent += '    image: prom/node-exporter:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - /proc:/host/proc:ro\n';
              dockerComposeContent += '      - /sys:/host/sys:ro\n';
              dockerComposeContent += '      - /:/rootfs:ro\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
              dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
              dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9100:9100"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  cadvisor:\n';
              dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - /:/rootfs:ro\n';
              dockerComposeContent += '      - /var/run:/var/run:ro\n';
              dockerComposeContent += '      - /sys:/sys:ro\n';
              dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "8080:8080"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += 'networks:\n';
              dockerComposeContent += '  monitoring-network:\n';
              dockerComposeContent += '    driver: bridge\n\n';
              
              dockerComposeContent += 'volumes:\n';
              dockerComposeContent += '  prometheus_data:\n';
              dockerComposeContent += '    driver: local\n';
              dockerComposeContent += '  alertmanager_data:\n';
              dockerComposeContent += '    driver: local\n';
              dockerComposeContent += '  grafana_data:\n';
              dockerComposeContent += '    driver: local\n';

              // Escribir docker-compose.yml
              fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);

              // Crear README.md
              let readmeContent = '# Monitoreo y Observabilidad\n\n';
              readmeContent += 'Este directorio contiene la configuración para un stack de monitoreo completo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
              readmeContent += '## Componentes\n\n';
              readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
              readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
              readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
              readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
              readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
              readmeContent += '## Inicio Rápido\n\n';
              readmeContent += '```bash\n';
              readmeContent += '# Iniciar el stack de monitoreo\n';
              readmeContent += 'docker-compose up -d\n';
              readmeContent += '```\n\n';
              readmeContent += '## Acceso\n\n';
              readmeContent += '- **Prometheus**: http://localhost:9090\n';
              readmeContent += '- **Alertmanager**: http://localhost:9093\n';
              readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
              readmeContent += '- **Node Exporter**: http://localhost:9100\n';
              readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
              readmeContent += '## Personalización\n\n';
              readmeContent += '### Prometheus\n\n';
              readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
              readmeContent += '### Alertmanager\n\n';
              readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
              readmeContent += '### Grafana\n\n';
              readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/dashboard.yml` si es necesario.\n';

              // Escribir README.md
              fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);

              // Crear directorio para ELK stack
              const elkDir = path.join(monitoringDir, 'elk');
              if (!fs.existsSync(elkDir)) {
                fs.mkdirSync(elkDir, { recursive: true });
              }

              // Crear docker-compose.yml para ELK stack
              let elkComposeContent = 'version: "3.8"\n\n';
              elkComposeContent += 'services:\n';
              elkComposeContent += '  elasticsearch:\n';
              elkComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
              elkComposeContent += '    environment:\n';
              elkComposeContent += '      - discovery.type=single-node\n';
              elkComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
              elkComposeContent += '    volumes:\n';
              elkComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
              elkComposeContent += '    ports:\n';
              elkComposeContent += '      - "9200:9200"\n';
              elkComposeContent += '      - "9300:9300"\n';
              elkComposeContent += '    networks:\n';
              elkComposeContent += '      - elk-network\n';
              elkComposeContent += '    restart: unless-stopped\n\n';
              
              elkComposeContent += '  logstash:\n';
              elkComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
              elkComposeContent += '    volumes:\n';
              elkComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
              elkComposeContent += '    ports:\n';
              elkComposeContent += '      - "5000:5000"\n';
              elkComposeContent += '      - "9600:9600"\n';
              elkComposeContent += '    environment:\n';
              elkComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
              elkComposeContent += '    networks:\n';
              elkComposeContent += '      - elk-network\n';
              elkComposeContent += '    depends_on:\n';
              elkComposeContent += '      - elasticsearch\n';
              elkComposeContent += '    restart: unless-stopped\n\n';
              
              elkComposeContent += '  kibana:\n';
              elkComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
              elkComposeContent += '    ports:\n';
              elkComposeContent += '      - "5601:5601"\n';
              elkComposeContent += '    environment:\n';
              elkComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
              elkComposeContent += '    networks:\n';
              elkComposeContent += '      - elk-network\n';
              elkComposeContent += '    depends_on:\n';
              elkComposeContent += '      - elasticsearch\n';
              elkComposeContent += '    restart: unless-stopped\n\n';
              
              elkComposeContent += '  filebeat:\n';
              elkComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
              elkComposeContent += '    user: root\n';
              elkComposeContent += '    volumes:\n';
              elkComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
              elkComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
              elkComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
              elkComposeContent += '    networks:\n';
              elkComposeContent += '      - elk-network\n';
              elkComposeContent += '    depends_on:\n';
              elkComposeContent += '      - elasticsearch\n';
              elkComposeContent += '      - logstash\n';
              elkComposeContent += '    restart: unless-stopped\n\n';
              
              elkComposeContent += 'networks:\n';
              elkComposeContent += '  elk-network:\n';
              elkComposeContent += '    driver: bridge\n\n';
              
              elkComposeContent += 'volumes:\n';
              elkComposeContent += '  elasticsearch_data:\n';
              elkComposeContent += '    driver: local\n';

              // Escribir docker-compose.yml para ELK stack
              fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), elkComposeContent);

              // Crear directorio para Logstash pipeline
              const logstashDir = path.join(elkDir, 'logstash');
              if (!fs.existsSync(logstashDir)) {
                fs.mkdirSync(logstashDir, { recursive: true });
              }

              const pipelineDir = path.join(logstashDir, 'pipeline');
              if (!fs.existsSync(pipelineDir)) {
                fs.mkdirSync(pipelineDir, { recursive: true });
              }

              // Crear logstash.conf
              let logstashConfContent = 'input {\n';
              logstashConfContent += '  beats {\n';
              logstashConfContent += '    port => 5000\n';
              logstashConfContent += '  }\n';
              logstashConfContent += '}\n\n';
              logstashConfContent += 'filter {\n';
              logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
              logstashConfContent += '    mutate {\n';
              logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
              logstashConfContent += '    }\n';
              logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
              logstashConfContent += '    mutate {\n';
              logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
              logstashConfContent += '    }\n';
              logstashConfContent += '  } else {\n';
              logstashConfContent += '    mutate {\n';
              logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
              logstashConfContent += '    }\n';
              logstashConfContent += '  }\n';
              logstashConfContent += '}\n\n';
              logstashConfContent += 'output {\n';
              logstashConfContent += '  elasticsearch {\n';
              logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
              logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
              logstashConfContent += '  }\n';
              logstashConfContent += '}\n';

              // Escribir logstash.conf
              fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);

              // Crear directorio para Filebeat
              const filebeatDir = path.join(elkDir, 'filebeat');
              if (!fs.existsSync(filebeatDir)) {
                fs.mkdirSync(filebeatDir, { recursive: true });
              }

              // Crear filebeat.yml
              let filebeatContent = 'filebeat.inputs:\n';
              filebeatContent += '- type: container\n';
              filebeatContent += '  paths:\n';
              filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
              filebeatContent += '  processors:\n';
              filebeatContent += '    - add_docker_metadata: ~\n\n';
              filebeatContent += 'processors:\n';
              filebeatContent += '  - add_host_metadata: ~\n';
              filebeatContent += '  - add_cloud_metadata: ~\n\n';
              filebeatContent += 'output.logstash:\n';
              filebeatContent += '  hosts: ["logstash:5000"]\n';

              // Escribir filebeat.yml
              fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);

              // Crear README.md para ELK stack
              let elkReadmeContent = '# ELK Stack\n\n';
              elkReadmeContent += 'Este directorio contiene la configuración para un stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat para la recolección de logs.\n\n';
              elkReadmeContent += '## Componentes\n\n';
              elkReadmeContent += '- **Elasticsearch**: Motor de búsqueda y análisis\n';
              elkReadmeContent += '- **Logstash**: Procesamiento de datos y logs\n';
              elkReadmeContent += '- **Kibana**: Visualización de datos\n';
              elkReadmeContent += '- **Filebeat**: Recolector de logs\n\n';
              elkReadmeContent += '## Inicio Rápido\n\n';
              elkReadmeContent += '```bash\n';
              elkReadmeContent += '# Iniciar el stack ELK\n';
              elkReadmeContent += 'docker-compose up -d\n';
              elkReadmeContent += '```\n\n';
              elkReadmeContent += '## Acceso\n\n';
              elkReadmeContent += '- **Elasticsearch**: http://localhost:9200\n';
              elkReadmeContent += '- **Kibana**: http://localhost:5601\n';
              elkReadmeContent += '- **Logstash**: http://localhost:9600\n\n';
              elkReadmeContent += '## Personalización\n\n';
              elkReadmeContent += '### Logstash\n\n';
              elkReadmeContent += 'Edita `logstash/pipeline/logstash.conf` para modificar el procesamiento de logs.\n\n';
              elkReadmeContent += '### Filebeat\n\n';
              elkReadmeContent += 'Edita `filebeat/filebeat.yml` para configurar la recolección de logs.\n';

              // Escribir README.md para ELK stack
              fs.writeFileSync(path.join(elkDir, 'README.md'), elkReadmeContent);

              // Crear directorio para Loki
              const lokiDir = path.join(monitoringDir, 'loki');
              if (!fs.existsSync(lokiDir)) {
                fs.mkdirSync(lokiDir, { recursive: true });
              }

              // Crear docker-compose.yml para Loki
              let lokiComposeContent = 'version: "3.8"\n\n';
              lokiComposeContent += 'services:\n';
              lokiComposeContent += '  loki:\n';
              lokiComposeContent += '    image: grafana/loki:latest\n';
              lokiComposeContent += '    ports:\n';
              lokiComposeContent += '      - "3100:3100"\n';
              lokiComposeContent += '    volumes:\n';
              lokiComposeContent += '      - ./loki-config.yaml:/etc/loki/local-config.yaml\n';
              lokiComposeContent += '      - loki_data:/loki\n';
              lokiComposeContent += '    command: -config.file=/etc/loki/local-config.yaml\n';
              lokiComposeContent += '    networks:\n';
              lokiComposeContent += '      - loki-network\n';
              lokiComposeContent += '    restart: unless-stopped\n\n';
              
              lokiComposeContent += '  promtail:\n';
              lokiComposeContent += '    image: grafana/promtail:latest\n';
              lokiComposeContent += '    volumes:\n';
              lokiComposeContent += '      - ./promtail-config.yaml:/etc/promtail/config.yaml\n';
              lokiComposeContent += '      - /var/log:/var/log\n';
              lokiComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers\n';
              lokiComposeContent += '    command: -config.file=/etc/promtail/config.yaml\n';
              lokiComposeContent += '    networks:\n';
              lokiComposeContent += '      - loki-network\n';
              lokiComposeContent += '    depends_on:\n';
              lokiComposeContent += '      - loki\n';
              lokiComposeContent += '    restart: unless-stopped\n\n';
              
              lokiComposeContent += 'networks:\n';
              lokiComposeContent += '  loki-network:\n';
              lokiComposeContent += '    driver: bridge\n\n';
              
              lokiComposeContent += 'volumes:\n';
              lokiComposeContent += '  loki_data:\n';
              lokiComposeContent += '    driver: local\n';

              // Escribir docker-compose.yml para Loki
              fs.writeFileSync(path.join(lokiDir, 'docker-compose.yml'), lokiComposeContent);

              // Crear loki-config.yaml
              let lokiConfigContent = 'auth_enabled: false\n\n';
              lokiConfigContent += 'server:\n';
              lokiConfigContent += '  http_listen_port: 3100\n\n';
              lokiConfigContent += 'ingester:\n';
              lokiConfigContent += '  lifecycler:\n';
              lokiConfigContent += '    address: 127.0.0.1\n';
              lokiConfigContent += '    ring:\n';
              lokiConfigContent += '      kvstore:\n';
              lokiConfigContent += '        store: inmemory\n';
              lokiConfigContent += '      replication_factor: 1\n';
              lokiConfigContent += '    final_sleep: 0s\n';
              lokiConfigContent += '  chunk_idle_period: 5m\n';
              lokiConfigContent += '  chunk_retain_period: 30s\n\n';
              lokiConfigContent += 'schema_config:\n';
              lokiConfigContent += '  configs:\n';
              lokiConfigContent += '    - from: 2020-10-24\n';
              lokiConfigContent += '      store: boltdb-shipper\n';
              lokiConfigContent += '      object_store: filesystem\n';
              lokiConfigContent += '      schema: v11\n';
              lokiConfigContent += '      index:\n';
              lokiConfigContent += '        prefix: index_\n';
              lokiConfigContent += '        period: 24h\n\n';
              lokiConfigContent += 'storage_config:\n';
              lokiConfigContent += '  boltdb_shipper:\n';
              lokiConfigContent += '    active_index_directory: /loki/boltdb-shipper-active\n';
              lokiConfigContent += '    cache_location: /loki/boltdb-shipper-cache\n';
              lokiConfigContent += '    cache_ttl: 24h\n';
              lokiConfigContent += '    shared_store: filesystem\n';
              lokiConfigContent += '  filesystem:\n';
              lokiConfigContent += '    directory: /loki/chunks\n\n';
              lokiConfigContent += 'limits_config:\n';
              lokiConfigContent += '  reject_old_samples: true\n';
              lokiConfigContent += '  reject_old_samples_max_age: 168h\n\n';
              lokiConfigContent += 'chunk_store_config:\n';
              lokiConfigContent += '  max_look_back_period: 0s\n\n';
              lokiConfigContent += 'table_manager:\n';
              lokiConfigContent += '  retention_deletes_enabled: false\n';
              lokiConfigContent += '  retention_period: 0s\n\n';
              lokiConfigContent += 'compactor:\n';
              lokiConfigContent += '  working_directory: /loki/boltdb-shipper-compactor\n';
              lokiConfigContent += '  shared_store: filesystem\n';

              // Escribir loki-config.yaml
              fs.writeFileSync(path.join(lokiDir, 'loki-config.yaml'), lokiConfigContent);

              // Crear promtail-config.yaml
              let promtailConfigContent = 'server:\n';
              promtailConfigContent += '  http_listen_port: 9080\n';
              promtailConfigContent += '  grpc_listen_port: 0\n\n';
              promtailConfigContent += 'positions:\n';
              promtailConfigContent += '  filename: /tmp/positions.yaml\n\n';
              promtailConfigContent += 'clients:\n';
              promtailConfigContent += '  - url: http://loki:3100/loki/api/v1/push\n\n';
              promtailConfigContent += 'scrape_configs:\n';
              promtailConfigContent += '  - job_name: system\n';
              promtailConfigContent += '    static_configs:\n';
              promtailConfigContent += '      - targets:\n';
              promtailConfigContent += '          - localhost\n';
              promtailConfigContent += '        labels:\n';
              promtailConfigContent += '          job: varlogs\n';
              promtailConfigContent += '          __path__: /var/log/*log\n\n';
              promtailConfigContent += '  - job_name: containers\n';
              promtailConfigContent += '    static_configs:\n';
              promtailConfigContent += '      - targets:\n';
              promtailConfigContent += '          - localhost\n';
              promtailConfigContent += '        labels:\n';
              promtailConfigContent += '          job: containerlogs\n';
              promtailConfigContent += '          __path__: /var/lib/docker/containers/*/*log\n';
              promtailConfigContent += '    pipeline_stages:\n';
              promtailConfigContent += '      - json:\n';
              promtailConfigContent += '          expressions:\n';
              promtailConfigContent += '            stream: stream\n';
              promtailConfigContent += '            attrs: attrs\n';
              promtailConfigContent += '            tag: attrs.tag\n';
              promtailConfigContent += '      - labels:\n';
              promtailConfigContent += '          stream:\n';
              promtailConfigContent += '          tag:\n';

              // Escribir promtail-config.yaml
              fs.writeFileSync(path.join(lokiDir, 'promtail-config.yaml'), promtailConfigContent);

              // Crear README.md para Loki
              let lokiReadmeContent = '# Loki Stack\n\n';
              lokiReadmeContent += 'Este directorio contiene la configuración para un stack Loki con Promtail para la recolección de logs.\n\n';
              lokiReadmeContent += '## Componentes\n\n';
              lokiReadmeContent += '- **Loki**: Sistema de agregación de logs\n';
              lokiReadmeContent += '- **Promtail**: Agente para enviar logs a Loki\n\n';
              lokiReadmeContent += '## Inicio Rápido\n\n';
              lokiReadmeContent += '```bash\n';
              lokiReadmeContent += '# Iniciar el stack Loki\n';
              lokiReadmeContent += 'docker-compose up -d\n';
              lokiReadmeContent += '```\n\n';
              lokiReadmeContent += '## Acceso\n\n';
              lokiReadmeContent += '- **Loki API**: http://localhost:3100\n\n';
              lokiReadmeContent += '## Integración con Grafana\n\n';
              lokiReadmeContent += 'Para visualizar los logs en Grafana, añade un datasource de tipo Loki con la URL `http://loki:3100`.\n\n';
              lokiReadmeContent += '## Personalización\n\n';
              lokiReadmeContent += '### Loki\n\n';
              lokiReadmeContent += 'Edita `loki-config.yaml` para modificar la configuración de Loki.\n\n';
              lokiReadmeContent += '### Promtail\n\n';
              lokiReadmeContent += 'Edita `promtail-config.yaml` para configurar la recolección de logs.\n';

              // Escribir README.md para Loki
              fs.writeFileSync(path.join(lokiDir, 'README.md'), lokiReadmeContent);

              // Crear directorio para Jaeger
              const jaegerDir = path.join(monitoringDir, 'jaeger');
              if (!fs.existsSync(jaegerDir)) {
                fs.mkdirSync(jaegerDir, { recursive: true });
              }

              // Crear docker-compose.yml para Jaeger
              let jaegerComposeContent = 'version: "3.8"\n\n';
              jaegerComposeContent += 'services:\n';
              jaegerComposeContent += '  jaeger:\n';
              jaegerComposeContent += '    image: jaegertracing/all-in-one:latest\n';
              jaegerComposeContent += '    ports:\n';
              jaegerComposeContent += '      - "6831:6831/udp"\n';
              jaegerComposeContent += '      - "6832:6832/udp"\n';
              jaegerComposeContent += '      - "5778:5778"\n';
              jaegerComposeContent += '      - "16686:16686"\n';
              jaegerComposeContent += '      - "14268:14268"\n';
              jaegerComposeContent += '      - "14250:14250"\n';
              jaegerComposeContent += '      - "9411:9411"\n';
              jaegerComposeContent += '    environment:\n';
              jaegerComposeContent += '      - COLLECTOR_ZIPKIN_HOST_PORT=9411\n';
              jaegerComposeContent += '    networks:\n';
              jaegerComposeContent += '      - jaeger-network\n';
              jaegerComposeContent += '    restart: unless-stopped\n\n';
              
              jaegerComposeContent += 'networks:\n';
              jaegerComposeContent += '  jaeger-network:\n';
              jaegerComposeContent += '    driver: bridge\n';

              // Escribir docker-compose.yml para Jaeger
              fs.writeFileSync(path.join(jaegerDir, 'docker-compose.yml'), jaegerComposeContent);

              // Crear README.md para Jaeger
              let jaegerReadmeContent = '# Jaeger\n\n';
              jaegerReadmeContent += 'Este directorio contiene la configuración para Jaeger, un sistema de trazabilidad distribuida.\n\n';
              jaegerReadmeContent += '## Inicio Rápido\n\n';
              jaegerReadmeContent += '```bash\n';
              jaegerReadmeContent += '# Iniciar Jaeger\n';
              jaegerReadmeContent += 'docker-compose up -d\n';
              jaegerReadmeContent += '```\n\n';
              jaegerReadmeContent += '## Acceso\n\n';
              jaegerReadmeContent += '- **Jaeger UI**: http://localhost:16686\n\n';
              jaegerReadmeContent += '## Puertos\n\n';
              jaegerReadmeContent += '- **6831**: Puerto UDP para recibir spans en formato Jaeger Thrift\n';
              jaegerReadmeContent += '- **6832**: Puerto UDP para recibir spans en formato Jaeger Thrift compacto\n';
              jaegerReadmeContent += '- **5778**: Puerto para servir configuraciones\n';
              jaegerReadmeContent += '- **16686**: Puerto para la interfaz de usuario\n';
              jaegerReadmeContent += '- **14268**: Puerto para recibir spans directamente desde clientes\n';
              jaegerReadmeContent += '- **14250**: Puerto para recibir spans en formato Jaeger Thrift sobre gRPC\n';
              jaegerReadmeContent += '- **9411**: Puerto para compatibilidad con Zipkin\n\n';
              jaegerReadmeContent += '## Integración con Aplicaciones\n\n';
              jaegerReadmeContent += '### Node.js\n\n';
              jaegerReadmeContent += '```javascript\n';
              jaegerReadmeContent += 'const { JaegerExporter } = require(\'@opentelemetry/exporter-jaeger\');\n';
              jaegerReadmeContent += 'const { BatchSpanProcessor } = require(\'@opentelemetry/sdk-trace-base\');\n';
              jaegerReadmeContent += 'const { NodeTracerProvider } = require(\'@opentelemetry/sdk-trace-node\');\n';
              jaegerReadmeContent += 'const { registerInstrumentations } = require(\'@opentelemetry/instrumentation\');\n';
              jaegerReadmeContent += 'const { ExpressInstrumentation } = require(\'@opentelemetry/instrumentation-express\');\n';
              jaegerReadmeContent += 'const { HttpInstrumentation } = require(\'@opentelemetry/instrumentation-http\');\n\n';
              jaegerReadmeContent += 'const provider = new NodeTracerProvider();\n\n';
              jaegerReadmeContent += 'const exporter = new JaegerExporter({\n';
              jaegerReadmeContent += '  serviceName: \'my-service\',\n';
              jaegerReadmeContent += '  host: \'localhost\',\n';
              jaegerReadmeContent += '  port: 6832,\n';
              jaegerReadmeContent += '});\n\n';
              jaegerReadmeContent += 'provider.addSpanProcessor(new BatchSpanProcessor(exporter));\n';
              jaegerReadmeContent += 'provider.register();\n\n';
              jaegerReadmeContent += 'registerInstrumentations({\n';
              jaegerReadmeContent += '  instrumentations: [\n';
              jaegerReadmeContent += '    new HttpInstrumentation(),\n';
              jaegerReadmeContent += '    new ExpressInstrumentation(),\n';
              jaegerReadmeContent += '  ],\n';
              jaegerReadmeContent += '});\n';
              jaegerReadmeContent += '```\n';

              // Escribir README.md para Jaeger
              fs.writeFileSync(path.join(jaegerDir, 'README.md'), jaegerReadmeContent);

              // Crear directorio para SonarQube
              const sonarqubeDir = path.join(monitoringDir, 'sonarqube');
              if (!fs.existsSync(sonarqubeDir)) {
                fs.mkdirSync(sonarqubeDir, { recursive: true });
              }

              // Crear docker-compose.yml para SonarQube
              let sonarqubeComposeContent = 'version: "3.8"\n\n';
              sonarqubeComposeContent += 'services:\n';
              sonarqubeComposeContent += '  sonarqube:\n';
              sonarqubeComposeContent += '    image: sonarqube:latest\n';
              sonarqubeComposeContent += '    ports:\n';
              sonarqubeComposeContent += '      - "9000:9000"\n';
              sonarqubeComposeContent += '    environment:\n';
              sonarqubeComposeContent += '      - SONAR_JDBC_URL=jdbc:postgresql://db:5432/sonar\n';
              sonarqubeComposeContent += '      - SONAR_JDBC_USERNAME=sonar\n';
              sonarqubeComposeContent += '      - SONAR_JDBC_PASSWORD=sonar\n';
              sonarqubeComposeContent += '    volumes:\n';
              sonarqubeComposeContent += '      - sonarqube_data:/opt/sonarqube/data\n';
              sonarqubeComposeContent += '      - sonarqube_extensions:/opt/sonarqube/extensions\n';
              sonarqubeComposeContent += '      - sonarqube_logs:/opt/sonarqube/logs\n';
              sonarqubeComposeContent += '    networks:\n';
              sonarqubeComposeContent += '      - sonarqube-network\n';
              sonarqubeComposeContent += '    depends_on:\n';
              sonarqubeComposeContent += '      - db\n';
              sonarqubeComposeContent += '    restart: unless-stopped\n\n';
              
              sonarqubeComposeContent += '  db:\n';
              sonarqubeComposeContent += '    image: postgres:13\n';
              sonarqubeComposeContent += '    environment:\n';
              sonarqubeComposeContent += '      - POSTGRES_USER=sonar\n';
              sonarqubeComposeContent += '      - POSTGRES_PASSWORD=sonar\n';
              sonarqubeComposeContent += '      - POSTGRES_DB=sonar\n';
              sonarqubeComposeContent += '    volumes:\n';
              sonarqubeComposeContent += '      - postgresql_data:/var/lib/postgresql/data\n';
              sonarqubeComposeContent += '    networks:\n';
              sonarqubeComposeContent += '      - sonarqube-network\n';
              sonarqubeComposeContent += '    restart: unless-stopped\n\n';
              
              sonarqubeComposeContent += 'networks:\n';
              sonarqubeComposeContent += '  sonarqube-network:\n';
              sonarqubeComposeContent += '    driver: bridge\n\n';
              
              sonarqubeComposeContent += 'volumes:\n';
              sonarqubeComposeContent += '  sonarqube_data:\n';
              sonarqubeComposeContent += '    driver: local\n';
              sonarqubeComposeContent += '  sonarqube_extensions:\n';
              sonarqubeComposeContent += '    driver: local\n';
              sonarqubeComposeContent += '  sonarqube_logs:\n';
              sonarqubeComposeContent += '    driver: local\n';
              sonarqubeComposeContent += '  postgresql_data:\n';
              sonarqubeComposeContent += '    driver: local\n';

              // Escribir docker-compose.yml para SonarQube
              fs.writeFileSync(path.join(sonarqubeDir, 'docker-compose.yml'), sonarqubeComposeContent);

              // Crear sonar-project.properties
              let sonarProjectContent = '# Información del proyecto\n';
              sonarProjectContent += 'sonar.projectKey=my-project\n';
              sonarProjectContent += 'sonar.projectName=My Project\n';
              sonarProjectContent += 'sonar.projectVersion=1.0.0\n\n';
              sonarProjectContent += '# Ruta al código fuente\n';
              sonarProjectContent += 'sonar.sources=src\n\n';
              sonarProjectContent += '# Lenguaje\n';
              sonarProjectContent += 'sonar.language=js\n\n';
              sonarProjectContent += '# Encoding del código fuente\n';
              sonarProjectContent += 'sonar.sourceEncoding=UTF-8\n\n';
              sonarProjectContent += '# Exclusiones\n';
              sonarProjectContent += 'sonar.exclusions=node_modules/**,**/*.test.js,**/*.spec.js\n\n';
              sonarProjectContent += '# Cobertura de código\n';
              sonarProjectContent += 'sonar.javascript.lcov.reportPaths=coverage/lcov.info\n';

              // Escribir sonar-project.properties
              fs.writeFileSync(path.join(sonarqubeDir, 'sonar-project.properties'), sonarProjectContent);

              // Crear README.md para SonarQube
              let sonarqubeReadmeContent = '# SonarQube\n\n';
              sonarqubeReadmeContent += 'Este directorio contiene la configuración para SonarQube, una plataforma de análisis estático de código.\n\n';
              sonarqubeReadmeContent += '## Inicio Rápido\n\n';
              sonarqubeReadmeContent += '```bash\n';
              sonarqubeReadmeContent += '# Iniciar SonarQube\n';
              sonarqubeReadmeContent += 'docker-compose up -d\n';
              sonarqubeReadmeContent += '```\n\n';
              sonarqubeReadmeContent += '## Acceso\n\n';
              sonarqubeReadmeContent += '- **SonarQube UI**: http://localhost:9000\n';
              sonarqubeReadmeContent += '  - Usuario por defecto: admin\n';
              sonarqubeReadmeContent += '  - Contraseña por defecto: admin\n\n';
              sonarqubeReadmeContent += '## Análisis de Código\n\n';
              sonarqubeReadmeContent += '### Usando SonarScanner\n\n';
              sonarqubeReadmeContent += '1. Descarga e instala SonarScanner desde https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/\n';
              sonarqubeReadmeContent += '2. Copia el archivo `sonar-project.properties` a la raíz de tu proyecto\n';
              sonarqubeReadmeContent += '3. Ejecuta el análisis:\n\n';
              sonarqubeReadmeContent += '```bash\n';
              sonarqubeReadmeContent += 'sonar-scanner\n';
              sonarqubeReadmeContent += '```\n\n';
              sonarqubeReadmeContent += '### Usando Maven\n\n';
              sonarqubeReadmeContent += '```bash\n';
              sonarqubeReadmeContent += 'mvn clean verify sonar:sonar\n';
              sonarqubeReadmeContent += '```\n\n';
              sonarqubeReadmeContent += '### Usando Gradle\n\n';
              sonarqubeReadmeContent += '```bash\n';
              sonarqubeReadmeContent += './gradlew sonarqube\n';
              sonarqubeReadmeContent += '```\n\n';
              sonarqubeReadmeContent += '## Integración con CI/CD\n\n';
              sonarqubeReadmeContent += '### GitHub Actions\n\n';
              sonarqubeReadmeContent += '```yaml\n';
              sonarqubeReadmeContent += 'name: SonarQube Analysis\n\n';
              sonarqubeReadmeContent += 'on:\n';
              sonarqubeReadmeContent += '  push:\n';
              sonarqubeReadmeContent += '    branches: [ main ]\n';
              sonarqubeReadmeContent += '  pull_request:\n';
              sonarqubeReadmeContent += '    branches: [ main ]\n\n';
              sonarqubeReadmeContent += 'jobs:\n';
              sonarqubeReadmeContent += '  sonarqube:\n';
              sonarqubeReadmeContent += '    runs-on: ubuntu-latest\n';
              sonarqubeReadmeContent += '    steps:\n';
              sonarqubeReadmeContent += '    - uses: actions/checkout@v2\n';
              sonarqubeReadmeContent += '      with:\n';
              sonarqubeReadmeContent += '        fetch-depth: 0\n';
              sonarqubeReadmeContent += '    - name: SonarQube Scan\n';
              sonarqubeReadmeContent += '      uses: SonarSource/sonarqube-scan-action@master\n';
              sonarqubeReadmeContent += '      env:\n';
              sonarqubeReadmeContent += '        SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n';
              sonarqubeReadmeContent += '        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n';
              sonarqubeReadmeContent += '```\n';

              // Escribir README.md para SonarQube
              fs.writeFileSync(path.join(sonarqubeDir, 'README.md'), sonarqubeReadmeContent);

              return monitoringDir;
            } catch (error) {
              console.error('Error al crear archivos de monitoreo:', error);
              throw error;
            }
          }

          /**
           * Crea archivos de configuración para seguridad
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de seguridad
           */
          async createSecurityFiles(projectDir, config) {
            try {
              const securityDir = path.join(projectDir, 'security');
              if (!fs.existsSync(securityDir)) {
                fs.mkdirSync(securityDir, { recursive: true });
              }

              // Crear README.md para seguridad
              let readmeContent = '# Seguridad\n\n';
              readmeContent += 'Este directorio contiene configuraciones y herramientas relacionadas con la seguridad del proyecto.\n\n';
              readmeContent += '## Contenido\n\n';
              readmeContent += '- **auth/**: Configuración de autenticación y autorización\n';
              readmeContent += '- **certs/**: Certificados SSL/TLS\n';
              readmeContent += '- **policies/**: Políticas de seguridad\n';
              readmeContent += '- **scanning/**: Herramientas de escaneo de vulnerabilidades\n';
              readmeContent += '- **secrets/**: Gestión de secretos\n\n';
              readmeContent += '## Mejores Prácticas\n\n';
              readmeContent += '- Nunca almacene secretos (contraseñas, tokens, claves API) en el código fuente\n';
              readmeContent += '- Utilice herramientas de análisis estático de código para identificar vulnerabilidades\n';
              readmeContent += '- Mantenga todas las dependencias actualizadas\n';
              readmeContent += '- Implemente autenticación de múltiples factores (MFA) cuando sea posible\n';
              readmeContent += '- Aplique el principio de menor privilegio para todos los usuarios y servicios\n';
              readmeContent += '- Cifre los datos sensibles tanto en reposo como en tránsito\n';
              readmeContent += '- Realice auditorías de seguridad periódicas\n';

              // Escribir README.md
              fs.writeFileSync(path.join(securityDir, 'README.md'), readmeContent);

              // Crear directorio para autenticación
              const authDir = path.join(securityDir, 'auth');
              if (!fs.existsSync(authDir)) {
                fs.mkdirSync(authDir, { recursive: true });
              }

              // Crear auth-config.json
              const authConfig = {
                "auth": {
                  "providers": [
                    {
                      "name": "local",
                      "enabled": true,
                      "options": {
                        "usernameField": "email",
                        "passwordField": "password",
                        "session": true
                      }
                    },
                    {
                      "name": "oauth2",
                      "enabled": false,
                      "options": {
                        "clientID": "your-client-id",
                        "clientSecret": "your-client-secret",
                        "callbackURL": "http://localhost:3000/auth/oauth2/callback",
                        "authorizationURL": "https://provider.com/oauth2/authorize",
                        "tokenURL": "https://provider.com/oauth2/token",
                        "scope": ["profile", "email"]
                      }
                    },
                    {
                      "name": "jwt",
                      "enabled": true,
                      "options": {
                        "secret": "REPLACE_WITH_SECURE_SECRET",
                        "expiresIn": "1d",
                        "algorithm": "HS256"
                      }
                    }
                  ],
                  "session": {
                    "secret": "REPLACE_WITH_SECURE_SECRET",
                    "resave": false,
                    "saveUninitialized": false,
                    "cookie": {
                      "secure": true,
                      "httpOnly": true,
                      "maxAge": 86400000
                    }
                  }
                }
              };

              // Escribir auth-config.json
              fs.writeFileSync(
                path.join(authDir, 'auth-config.json'),
                JSON.stringify(authConfig, null, 2)
              );

              // Crear README.md para autenticación
              let authReadmeContent = '# Autenticación y Autorización\n\n';
              authReadmeContent += 'Este directorio contiene la configuración para la autenticación y autorización del proyecto.\n\n';
              authReadmeContent += '## Configuración\n\n';
              authReadmeContent += 'El archivo `auth-config.json` contiene la configuración para los diferentes proveedores de autenticación:\n\n';
              authReadmeContent += '- **Local**: Autenticación basada en usuario y contraseña almacenados localmente\n';
              authReadmeContent += '- **OAuth2**: Autenticación mediante proveedores externos (Google, GitHub, etc.)\n';
              authReadmeContent += '- **JWT**: Autenticación basada en tokens JWT\n\n';
              authReadmeContent += '## Implementación\n\n';
              authReadmeContent += '### Express.js\n\n';
              authReadmeContent += '```javascript\n';
              authReadmeContent += 'const express = require(\'express\');\n';
              authReadmeContent += 'const passport = require(\'passport\');\n';
              authReadmeContent += 'const LocalStrategy = require(\'passport-local\').Strategy;\n';
              authReadmeContent += 'const JwtStrategy = require(\'passport-jwt\').Strategy;\n';
              authReadmeContent += 'const ExtractJwt = require(\'passport-jwt\').ExtractJwt;\n';
              authReadmeContent += 'const session = require(\'express-session\');\n';
              authReadmeContent += 'const authConfig = require(\'./auth-config.json\').auth;\n\n';
              authReadmeContent += 'const app = express();\n\n';
              authReadmeContent += '// Configuración de sesión\n';
              authReadmeContent += 'app.use(session(authConfig.session));\n\n';
              authReadmeContent += '// Inicializar Passport\n';
              authReadmeContent += 'app.use(passport.initialize());\n';
              authReadmeContent += 'app.use(passport.session());\n\n';
              authReadmeContent += '// Estrategia Local\n';
              authReadmeContent += 'passport.use(new LocalStrategy({\n';
              authReadmeContent += '  usernameField: authConfig.providers[0].options.usernameField,\n';
              authReadmeContent += '  passwordField: authConfig.providers[0].options.passwordField\n';
              authReadmeContent += '}, (username, password, done) => {\n';
              authReadmeContent += '  // Implementar verificación de usuario y contraseña\n';
              authReadmeContent += '}));\n\n';
              authReadmeContent += '// Estrategia JWT\n';
              authReadmeContent += 'passport.use(new JwtStrategy({\n';
              authReadmeContent += '  jwtFromRequest: ExtractJwt.fromAuthHeaderAsBearerToken(),\n';
              authReadmeContent += '  secretOrKey: authConfig.providers[2].options.secret\n';
              authReadmeContent += '}, (payload, done) => {\n';
              authReadmeContent += '  // Implementar verificación de token\n';
              authReadmeContent += '}));\n';
              authReadmeContent += '```\n\n';
              authReadmeContent += '## Seguridad\n\n';
              authReadmeContent += '- Reemplaza todos los secretos por valores seguros generados aleatoriamente\n';
              authReadmeContent += '- Almacena los secretos en variables de entorno o en un gestor de secretos\n';
              authReadmeContent += '- Nunca almacenes contraseñas en texto plano, utiliza algoritmos de hash seguros como bcrypt\n';
              authReadmeContent += '- Implementa límites de intentos de inicio de sesión para prevenir ataques de fuerza bruta\n';
              authReadmeContent += '- Utiliza HTTPS para todas las comunicaciones\n';

              // Escribir README.md para autenticación
              fs.writeFileSync(path.join(authDir, 'README.md'), authReadmeContent);

              // Crear directorio para certificados
              const certsDir = path.join(securityDir, 'certs');
              if (!fs.existsSync(certsDir)) {
                fs.mkdirSync(certsDir, { recursive: true });
              }

              // Crear README.md para certificados
              let certsReadmeContent = '# Certificados SSL/TLS\n\n';
              certsReadmeContent += 'Este directorio está destinado a almacenar certificados SSL/TLS para el proyecto.\n\n';
              certsReadmeContent += '## Generación de Certificados Autofirmados\n\n';
              certsReadmeContent += 'Para desarrollo local, puedes generar certificados autofirmados utilizando OpenSSL:\n\n';
              certsReadmeContent += '```bash\n';
              certsReadmeContent += '# Generar clave privada\n';
              certsReadmeContent += 'openssl genrsa -out server.key 2048\n\n';
              certsReadmeContent += '# Generar solicitud de firma de certificado (CSR)\n';
              certsReadmeContent += 'openssl req -new -key server.key -out server.csr\n\n';
              certsReadmeContent += '# Generar certificado autofirmado\n';
              certsReadmeContent += 'openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt\n';
              certsReadmeContent += '```\n\n';
              certsReadmeContent += '## Uso con Express.js\n\n';
              certsReadmeContent += '```javascript\n';
              certsReadmeContent += 'const https = require(\'https\');\n';
              certsReadmeContent += 'const fs = require(\'fs\');\n';
              certsReadmeContent += 'const express = require(\'express\');\n\n';
              certsReadmeContent += 'const app = express();\n\n';
              certsReadmeContent += '// Configuración de certificados\n';
              certsReadmeContent += 'const options = {\n';
              certsReadmeContent += '  key: fs.readFileSync(\'path/to/server.key\'),\n';
              certsReadmeContent += '  cert: fs.readFileSync(\'path/to/server.crt\')\n';
              certsReadmeContent += '};\n\n';
              certsReadmeContent += '// Crear servidor HTTPS\n';
              certsReadmeContent += 'https.createServer(options, app).listen(443, () => {\n';
              certsReadmeContent += '  console.log(\'Servidor HTTPS iniciado en el puerto 443\');\n';
              certsReadmeContent += '});\n';
              certsReadmeContent += '```\n\n';
              certsReadmeContent += '## Certificados para Producción\n\n';
              certsReadmeContent += 'Para entornos de producción, se recomienda utilizar certificados emitidos por una Autoridad de Certificación (CA) confiable como Let\'s Encrypt.\n\n';
              certsReadmeContent += '### Let\'s Encrypt con Certbot\n\n';
              certsReadmeContent += '```bash\n';
              certsReadmeContent += '# Instalar Certbot\n';
              certsReadmeContent += 'sudo apt-get update\n';
              certsReadmeContent += 'sudo apt-get install certbot\n\n';
              certsReadmeContent += '# Obtener certificado\n';
              certsReadmeContent += 'sudo certbot certonly --standalone -d example.com -d www.example.com\n';
              certsReadmeContent += '```\n\n';
              certsReadmeContent += '## Seguridad\n\n';
              certsReadmeContent += '- Nunca incluyas claves privadas en el control de versiones\n';
              certsReadmeContent += '- Configura permisos restrictivos para los archivos de certificados\n';
              certsReadmeContent += '- Renueva los certificados antes de que expiren\n';
              certsReadmeContent += '- Utiliza algoritmos de cifrado fuertes (TLS 1.2 o superior)\n';
              certsReadmeContent += '- Configura HSTS (HTTP Strict Transport Security) para forzar conexiones HTTPS\n';

              // Escribir README.md para certificados
              fs.writeFileSync(path.join(certsDir, 'README.md'), certsReadmeContent);

              // Crear directorio para políticas de seguridad
              const policiesDir = path.join(securityDir, 'policies');
              if (!fs.existsSync(policiesDir)) {
                fs.mkdirSync(policiesDir, { recursive: true });
              }

              // Crear security-policy.md
              let securityPolicyContent = '# Política de Seguridad\n\n';
              securityPolicyContent += '## Propósito\n\n';
              securityPolicyContent += 'Esta política de seguridad establece las directrices y requisitos para proteger los sistemas, datos y recursos del proyecto.\n\n';
              securityPolicyContent += '## Alcance\n\n';
              securityPolicyContent += 'Esta política se aplica a todos los desarrolladores, administradores y usuarios que interactúan con el proyecto.\n\n';
              securityPolicyContent += '## Política\n\n';
              securityPolicyContent += '### 1. Gestión de Acceso\n\n';
              securityPolicyContent += '- Todos los usuarios deben tener cuentas individuales con credenciales únicas\n';
              securityPolicyContent += '- Se debe aplicar el principio de menor privilegio para todos los accesos\n';
              securityPolicyContent += '- Los accesos deben ser revisados periódicamente y revocados cuando ya no sean necesarios\n';
              securityPolicyContent += '- Se debe implementar autenticación de múltiples factores (MFA) para accesos privilegiados\n\n';
              securityPolicyContent += '### 2. Protección de Datos\n\n';
              securityPolicyContent += '- Los datos sensibles deben estar cifrados tanto en reposo como en tránsito\n';
              securityPolicyContent += '- Se deben realizar copias de seguridad periódicas de los datos críticos\n';
              securityPolicyContent += '- Los datos de producción no deben utilizarse en entornos de desarrollo o prueba sin anonimización\n';
              securityPolicyContent += '- Se debe implementar un proceso de eliminación segura de datos cuando ya no sean necesarios\n\n';
              securityPolicyContent += '### 3. Desarrollo Seguro\n\n';
              securityPolicyContent += '- Todo el código debe pasar por revisiones de seguridad antes de ser desplegado\n';
              securityPolicyContent += '- Se deben utilizar herramientas de análisis estático de código para identificar vulnerabilidades\n';
              securityPolicyContent += '- Las dependencias deben ser actualizadas regularmente para incluir parches de seguridad\n';
              securityPolicyContent += '- Los secretos no deben almacenarse en el código fuente\n\n';
              securityPolicyContent += '### 4. Gestión de Incidentes\n\n';
              securityPolicyContent += '- Los incidentes de seguridad deben ser reportados inmediatamente\n';
              securityPolicyContent += '- Se debe mantener un registro de todos los incidentes de seguridad\n';
              securityPolicyContent += '- Se deben realizar análisis post-incidente para identificar mejoras\n';
              securityPolicyContent += '- Se debe tener un plan de respuesta a incidentes documentado y probado\n\n';
              securityPolicyContent += '### 5. Cumplimiento\n\n';
              securityPolicyContent += '- El proyecto debe cumplir con todas las leyes y regulaciones aplicables\n';
              securityPolicyContent += '- Se deben realizar auditorías de seguridad periódicas\n';
              securityPolicyContent += '- Se deben documentar y abordar todas las no conformidades\n';
              securityPolicyContent += '- Se debe mantener un registro de todas las actividades de cumplimiento\n\n';
              securityPolicyContent += '## Responsabilidades\n\n';
              securityPolicyContent += '- **Desarrolladores**: Seguir prácticas de desarrollo seguro, reportar vulnerabilidades\n';
              securityPolicyContent += '- **Administradores**: Implementar controles de seguridad, gestionar accesos\n';
              securityPolicyContent += '- **Usuarios**: Proteger sus credenciales, reportar actividades sospechosas\n';
              securityPolicyContent += '- **Responsable de Seguridad**: Supervisar el cumplimiento, gestionar incidentes\n\n';
              securityPolicyContent += '## Revisión\n\n';
              securityPolicyContent += 'Esta política debe ser revisada y actualizada al menos una vez al año o cuando se produzcan cambios significativos en el proyecto.\n';

              // Escribir security-policy.md
              fs.writeFileSync(path.join(policiesDir, 'security-policy.md'), securityPolicyContent);

              // Crear README.md para políticas
              let policiesReadmeContent = '# Políticas de Seguridad\n\n';
              policiesReadmeContent += 'Este directorio contiene las políticas de seguridad del proyecto.\n\n';
              policiesReadmeContent += '## Contenido\n\n';
              policiesReadmeContent += '- [Política de Seguridad](./security-policy.md): Directrices generales de seguridad\n';
              policiesReadmeContent += '- [Política de Contraseñas](./password-policy.md): Requisitos para contraseñas seguras\n';
              policiesReadmeContent += '- [Política de Acceso](./access-policy.md): Gestión de accesos y privilegios\n';
              policiesReadmeContent += '- [Política de Respuesta a Incidentes](./incident-response-policy.md): Procedimientos para gestionar incidentes de seguridad\n\n';
              policiesReadmeContent += '## Implementación\n\n';
              policiesReadmeContent += 'Estas políticas deben ser implementadas mediante controles técnicos y procedimientos operativos. Algunos ejemplos incluyen:\n\n';
              policiesReadmeContent += '- Configuración de requisitos de complejidad de contraseñas\n';
              policiesReadmeContent += '- Implementación de sistemas de gestión de acceso\n';
              policiesReadmeContent += '- Configuración de herramientas de monitoreo y alerta\n';
              policiesReadmeContent += '- Establecimiento de procedimientos de revisión y auditoría\n\n';
              policiesReadmeContent += '## Cumplimiento\n\n';
              policiesReadmeContent += 'El cumplimiento de estas políticas es obligatorio para todos los miembros del equipo y usuarios del sistema. El incumplimiento puede resultar en acciones disciplinarias o restricciones de acceso.\n';

              // Escribir README.md para políticas
              fs.writeFileSync(path.join(policiesDir, 'README.md'), policiesReadmeContent);

              // Crear directorio para escaneo de vulnerabilidades
              const scanningDir = path.join(securityDir, 'scanning');
              if (!fs.existsSync(scanningDir)) {
                fs.mkdirSync(scanningDir, { recursive: true });
              }

              // Crear README.md para escaneo
              let scanningReadmeContent = '# Escaneo de Vulnerabilidades\n\n';
              scanningReadmeContent += 'Este directorio contiene configuraciones y scripts para el escaneo de vulnerabilidades en el proyecto.\n\n';
              scanningReadmeContent += '## Herramientas\n\n';
              scanningReadmeContent += '### OWASP Dependency-Check\n\n';
              scanningReadmeContent += 'Analiza las dependencias del proyecto para identificar vulnerabilidades conocidas.\n\n';
              scanningReadmeContent += '```bash\n';
              scanningReadmeContent += '# Instalar Dependency-Check\n';
              scanningReadmeContent += 'npm install -g dependency-check\n\n';
              scanningReadmeContent += '# Ejecutar escaneo\n';
              scanningReadmeContent += 'dependency-check --project "Mi Proyecto" --scan ./package.json --out ./reports\n';
              scanningReadmeContent += '```\n\n';
              scanningReadmeContent += '### SonarQube\n\n';
              scanningReadmeContent += 'Realiza análisis estático de código para identificar vulnerabilidades, bugs y code smells.\n\n';
              scanningReadmeContent += '```bash\n';
              scanningReadmeContent += '# Ejecutar SonarQube Scanner\n';
              scanningReadmeContent += 'sonar-scanner \\\n';
              scanningReadmeContent += '  -Dsonar.projectKey=mi-proyecto \\\n';
              scanningReadmeContent += '  -Dsonar.sources=. \\\n';
              scanningReadmeContent += '  -Dsonar.host.url=http://localhost:9000 \\\n';
              scanningReadmeContent += '  -Dsonar.login=mi-token\n';
              scanningReadmeContent += '```\n\n';
              scanningReadmeContent += '### OWASP ZAP\n\n';
              scanningReadmeContent += 'Realiza pruebas de penetración automatizadas para identificar vulnerabilidades en aplicaciones web.\n\n';
              scanningReadmeContent += '```bash\n';
              scanningReadmeContent += '# Ejecutar escaneo básico\n';
              scanningReadmeContent += 'zap-cli quick-scan --self-contained --start-options \'-config api.disablekey=true\' https://example.com\n';
              scanningReadmeContent += '```\n\n';
              scanningReadmeContent += '## Integración Continua\n\n';
              scanningReadmeContent += 'Estas herramientas deben integrarse en el pipeline de CI/CD para realizar escaneos automáticos en cada build o pull request.\n\n';
              scanningReadmeContent += '### GitHub Actions\n\n';
              scanningReadmeContent += '```yaml\n';
              scanningReadmeContent += 'name: Security Scan\n\n';
              scanningReadmeContent += 'on:\n';
              scanningReadmeContent += '  push:\n';
              scanningReadmeContent += '    branches: [ main ]\n';
              scanningReadmeContent += '  pull_request:\n';
              scanningReadmeContent += '    branches: [ main ]\n\n';
              scanningReadmeContent += 'jobs:\n';
              scanningReadmeContent += '  security-scan:\n';
              scanningReadmeContent += '    runs-on: ubuntu-latest\n';
              scanningReadmeContent += '    steps:\n';
              scanningReadmeContent += '    - uses: actions/checkout@v2\n';
              scanningReadmeContent += '    - name: Run Dependency-Check\n';
              scanningReadmeContent += '      uses: dependency-check/Dependency-Check_Action@main\n';
              scanningReadmeContent += '      with:\n';
              scanningReadmeContent += '        project: \'Mi Proyecto\'\n';
              scanningReadmeContent += '        path: \'.\'\n';
              scanningReadmeContent += '        format: \'HTML\'\n';
              scanningReadmeContent += '        out: \'reports\'\n';
              scanningReadmeContent += '    - name: Upload Report\n';
              scanningReadmeContent += '      uses: actions/upload-artifact@v2\n';
              scanningReadmeContent += '      with:\n';
              scanningReadmeContent += '        name: Dependency-Check Report\n';
              scanningReadmeContent += '        path: reports\n';
              scanningReadmeContent += '```\n\n';
              scanningReadmeContent += '## Reportes\n\n';
              scanningReadmeContent += 'Los reportes de escaneo deben ser revisados regularmente y las vulnerabilidades identificadas deben ser priorizadas y corregidas según su severidad.\n';

              // Escribir README.md para escaneo
              fs.writeFileSync(path.join(scanningDir, 'README.md'), scanningReadmeContent);

              // Crear directorio para gestión de secretos
              const secretsDir = path.join(securityDir, 'secrets');
              if (!fs.existsSync(secretsDir)) {
                fs.mkdirSync(secretsDir, { recursive: true });
              }

              // Crear README.md para secretos
              let secretsReadmeContent = '# Gestión de Secretos\n\n';
              secretsReadmeContent += 'Este directorio contiene información sobre la gestión segura de secretos en el proyecto.\n\n';
              secretsReadmeContent += '## Mejores Prácticas\n\n';
              secretsReadmeContent += '- Nunca almacene secretos en el código fuente o en archivos de configuración versionados\n';
              secretsReadmeContent += '- Utilice variables de entorno o gestores de secretos para almacenar información sensible\n';
              secretsReadmeContent += '- Rote los secretos regularmente\n';
              secretsReadmeContent += '- Utilice secretos diferentes para cada entorno (desarrollo, pruebas, producción)\n';
              secretsReadmeContent += '- Limite el acceso a los secretos según el principio de menor privilegio\n\n';
              secretsReadmeContent += '## Herramientas\n\n';
              secretsReadmeContent += '### HashiCorp Vault\n\n';
              secretsReadmeContent += 'Vault es una herramienta para gestionar secretos y proteger datos sensibles.\n\n';
              secretsReadmeContent += '```bash\n';
              secretsReadmeContent += '# Iniciar Vault en modo desarrollo\n';
              secretsReadmeContent += 'vault server -dev\n\n';
              secretsReadmeContent += '# Almacenar un secreto\n';
              secretsReadmeContent += 'vault kv put secret/mi-app/config api-key=12345 db-password=secret\n\n';
              secretsReadmeContent += '# Obtener un secreto\n';
              secretsReadmeContent += 'vault kv get secret/mi-app/config\n';
              secretsReadmeContent += '```\n\n';
              secretsReadmeContent += '### AWS Secrets Manager\n\n';
              secretsReadmeContent += 'Servicio de AWS para gestionar secretos en la nube.\n\n';
              secretsReadmeContent += '```javascript\n';
              secretsReadmeContent += 'const AWS = require(\'aws-sdk\');\n';
              secretsReadmeContent += 'const secretsManager = new AWS.SecretsManager();\n\n';
              secretsReadmeContent += '// Obtener un secreto\n';
              secretsReadmeContent += 'secretsManager.getSecretValue({ SecretId: \'mi-secreto\' }, (err, data) => {\n';
              secretsReadmeContent += '  if (err) {\n';
              secretsReadmeContent += '    console.error(\'Error al obtener el secreto:\', err);\n';
              secretsReadmeContent += '    return;\n';
              secretsReadmeContent += '  }\n';
              secretsReadmeContent += '  \n';
              secretsReadmeContent += '  const secret = JSON.parse(data.SecretString);\n';
              secretsReadmeContent += '  console.log(\'Secreto obtenido:\', secret);\n';
              secretsReadmeContent += '});\n';
              secretsReadmeContent += '```\n\n';
              secretsReadmeContent += '### dotenv\n\n';
              secretsReadmeContent += 'Biblioteca para cargar variables de entorno desde un archivo .env.\n\n';
              secretsReadmeContent += '```bash\n';
              secretsReadmeContent += '# Instalar dotenv\n';
              secretsReadmeContent += 'npm install dotenv\n';
              secretsReadmeContent += '```\n\n';
              secretsReadmeContent += '```javascript\n';
              secretsReadmeContent += '// Cargar variables de entorno\n';
              secretsReadmeContent += 'require(\'dotenv\').config();\n\n';
              secretsReadmeContent += '// Acceder a las variables\n';
              secretsReadmeContent += 'const apiKey = process.env.API_KEY;\n';
              secretsReadmeContent += 'const dbPassword = process.env.DB_PASSWORD;\n';
              secretsReadmeContent += '```\n\n';
              secretsReadmeContent += '## Ejemplo de .env\n\n';
              secretsReadmeContent += '```\n';
              secretsReadmeContent += '# Archivo .env (NO INCLUIR EN CONTROL DE VERSIONES)\n';
              secretsReadmeContent += 'API_KEY=mi-clave-api\n';
              secretsReadmeContent += 'DB_PASSWORD=mi-contraseña-db\n';
              secretsReadmeContent += 'JWT_SECRET=mi-secreto-jwt\n';
              secretsReadmeContent += '```\n\n';
              secretsReadmeContent += '## Ejemplo de .env.example\n\n';
              secretsReadmeContent += '```\n';
              secretsReadmeContent += '# Archivo .env.example (SÍ INCLUIR EN CONTROL DE VERSIONES)\n';
              secretsReadmeContent += 'API_KEY=\n';
              secretsReadmeContent += 'DB_PASSWORD=\n';
              secretsReadmeContent += 'JWT_SECRET=\n';
              secretsReadmeContent += '```\n';

              // Escribir README.md para secretos
              fs.writeFileSync(path.join(secretsDir, 'README.md'), secretsReadmeContent);

              // Crear .env.example
              let envExampleContent = '# Ejemplo de archivo .env\n';
              envExampleContent += '# Copie este archivo a .env y complete los valores\n\n';
              envExampleContent += '# API Keys\n';
              envExampleContent += 'API_KEY=\n\n';
              envExampleContent += '# Base de Datos\n';
              envExampleContent += 'DB_HOST=localhost\n';
              envExampleContent += 'DB_PORT=5432\n';
              envExampleContent += 'DB_NAME=mi_db\n';
              envExampleContent += 'DB_USER=\n';
              envExampleContent += 'DB_PASSWORD=\n\n';
              envExampleContent += '# JWT\n';
              envExampleContent += 'JWT_SECRET=\n';
              envExampleContent += 'JWT_EXPIRES_IN=1d\n\n';
              envExampleContent += '# Servidor\n';
              envExampleContent += 'PORT=3000\n';
              envExampleContent += 'NODE_ENV=development\n';

              // Escribir .env.example
              fs.writeFileSync(path.join(secretsDir, '.env.example'), envExampleContent);

              return securityDir;
            } catch (error) {
              console.error('Error al crear archivos de seguridad:', error);
              throw error;
            }
          }

          /**
           * Crea archivos de configuración para CI/CD
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de CI/CD
           */
          async createCICDFiles(projectDir, config) {
            try {
              const cicdDir = path.join(projectDir, 'cicd');
              if (!fs.existsSync(cicdDir)) {
                fs.mkdirSync(cicdDir, { recursive: true });
              }

              // Crear README.md para CI/CD
              let readmeContent = '# CI/CD\n\n';
              readmeContent += 'Este directorio contiene configuraciones y scripts para la integración continua y el despliegue continuo del proyecto.\n\n';
              readmeContent += '## Contenido\n\n';
              readmeContent += '- **github/**: Configuraciones para GitHub Actions\n';
              readmeContent += '- **jenkins/**: Configuraciones para Jenkins\n';
              readmeContent += '- **gitlab/**: Configuraciones para GitLab CI/CD\n';
              readmeContent += '- **azure/**: Configuraciones para Azure DevOps\n';
              readmeContent += '- **scripts/**: Scripts de automatización para CI/CD\n\n';
              readmeContent += '## Flujo de CI/CD\n\n';
              readmeContent += '1. **Integración Continua (CI)**:\n';
              readmeContent += '   - Compilación del código\n';
              readmeContent += '   - Ejecución de pruebas unitarias e integración\n';
              readmeContent += '   - Análisis estático de código\n';
              readmeContent += '   - Escaneo de vulnerabilidades\n\n';
              readmeContent += '2. **Entrega Continua (CD)**:\n';
              readmeContent += '   - Construcción de artefactos (imágenes Docker, paquetes)\n';
              readmeContent += '   - Despliegue en entorno de pruebas\n';
              readmeContent += '   - Pruebas de aceptación\n\n';
              readmeContent += '3. **Despliegue Continuo**:\n';
              readmeContent += '   - Despliegue en entorno de producción\n';
              readmeContent += '   - Pruebas de humo\n';
              readmeContent += '   - Monitoreo\n\n';
              readmeContent += '## Mejores Prácticas\n\n';
              readmeContent += '- Mantener los pipelines como código\n';
              readmeContent += '- Automatizar todas las etapas posibles\n';
              readmeContent += '- Implementar estrategias de despliegue seguras (canary, blue-green)\n';
              readmeContent += '- Incluir pruebas de seguridad en el pipeline\n';
              readmeContent += '- Notificar fallos y éxitos a los equipos relevantes\n';

              // Escribir README.md
              fs.writeFileSync(path.join(cicdDir, 'README.md'), readmeContent);

              // Crear directorio para GitHub Actions
              const githubDir = path.join(cicdDir, 'github');
              if (!fs.existsSync(githubDir)) {
                fs.mkdirSync(githubDir, { recursive: true });
              }

              // Crear workflow para GitHub Actions
              let workflowContent = 'name: CI/CD Pipeline\n\n';
              workflowContent += 'on:\n';
              workflowContent += '  push:\n';
              workflowContent += '    branches: [ main, develop ]\n';
              workflowContent += '  pull_request:\n';
              workflowContent += '    branches: [ main, develop ]\n\n';
              workflowContent += 'jobs:\n';
              workflowContent += '  build-and-test:\n';
              workflowContent += '    runs-on: ubuntu-latest\n';
              workflowContent += '    steps:\n';
              workflowContent += '    - uses: actions/checkout@v2\n';
              workflowContent += '    - name: Set up Node.js\n';
              workflowContent += '      uses: actions/setup-node@v2\n';
              workflowContent += '      with:\n';
              workflowContent += '        node-version: \'14\'\n';
              workflowContent += '        cache: \'npm\'\n';
              workflowContent += '    - name: Install dependencies\n';
              workflowContent += '      run: npm ci\n';
              workflowContent += '    - name: Lint\n';
              workflowContent += '      run: npm run lint\n';
              workflowContent += '    - name: Build\n';
              workflowContent += '      run: npm run build\n';
              workflowContent += '    - name: Test\n';
              workflowContent += '      run: npm test\n';
              workflowContent += '    - name: Upload build artifacts\n';
              workflowContent += '      uses: actions/upload-artifact@v2\n';
              workflowContent += '      with:\n';
              workflowContent += '        name: build-artifacts\n';
              workflowContent += '        path: dist/\n\n';
              workflowContent += '  security-scan:\n';
              workflowContent += '    runs-on: ubuntu-latest\n';
              workflowContent += '    needs: build-and-test\n';
              workflowContent += '    steps:\n';
              workflowContent += '    - uses: actions/checkout@v2\n';
              workflowContent += '    - name: Set up Node.js\n';
              workflowContent += '      uses: actions/setup-node@v2\n';
              workflowContent += '      with:\n';
              workflowContent += '        node-version: \'14\'\n';
              workflowContent += '    - name: Install dependencies\n';
              workflowContent += '      run: npm ci\n';
              workflowContent += '    - name: Run security audit\n';
              workflowContent += '      run: npm audit --audit-level=high\n';
              workflowContent += '    - name: Run OWASP Dependency-Check\n';
              workflowContent += '      uses: dependency-check/Dependency-Check_Action@main\n';
              workflowContent += '      with:\n';
              workflowContent += '        project: \'My Project\'\n';
              workflowContent += '        path: \'.\'\n';
              workflowContent += '        format: \'HTML\'\n';
              workflowContent += '        out: \'reports\'\n';
              workflowContent += '    - name: Upload security reports\n';
              workflowContent += '      uses: actions/upload-artifact@v2\n';
              workflowContent += '      with:\n';
              workflowContent += '        name: security-reports\n';
              workflowContent += '        path: reports/\n\n';
              workflowContent += '  docker-build:\n';
              workflowContent += '    runs-on: ubuntu-latest\n';
              workflowContent += '    needs: [build-and-test, security-scan]\n';
              workflowContent += '    if: github.event_name == \'push\' && (github.ref == \'refs/heads/main\' || github.ref == \'refs/heads/develop\')\n';
              workflowContent += '    steps:\n';
              workflowContent += '    - uses: actions/checkout@v2\n';
              workflowContent += '    - name: Download build artifacts\n';
              workflowContent += '      uses: actions/download-artifact@v2\n';
              workflowContent += '      with:\n';
              workflowContent += '        name: build-artifacts\n';
              workflowContent += '        path: dist/\n';
              workflowContent += '    - name: Set up Docker Buildx\n';
              workflowContent += '      uses: docker/setup-buildx-action@v1\n';
              workflowContent += '    - name: Login to DockerHub\n';
              workflowContent += '      uses: docker/login-action@v1\n';
              workflowContent += '      with:\n';
              workflowContent += '        username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
              workflowContent += '        password: ${{ secrets.DOCKERHUB_TOKEN }}\n';
              workflowContent += '    - name: Extract branch name\n';
              workflowContent += '      shell: bash\n';
              workflowContent += '      run: echo "##[set-output name=branch;]$(echo ${GITHUB_REF#refs/heads/})"\n';
              workflowContent += '      id: extract_branch\n';
              workflowContent += '    - name: Build and push Docker image\n';
              workflowContent += '      uses: docker/build-push-action@v2\n';
              workflowContent += '      with:\n';
              workflowContent += '        context: .\n';
              workflowContent += '        push: true\n';
              workflowContent += '        tags: |\n';
              workflowContent += '          myorg/myapp:${{ steps.extract_branch.outputs.branch }}\n';
              workflowContent += '          myorg/myapp:${{ steps.extract_branch.outputs.branch }}-${{ github.sha }}\n\n';
              workflowContent += '  deploy-staging:\n';
              workflowContent += '    runs-on: ubuntu-latest\n';
              workflowContent += '    needs: docker-build\n';
              workflowContent += '    if: github.ref == \'refs/heads/develop\'\n';
              workflowContent += '    environment: staging\n';
              workflowContent += '    steps:\n';
              workflowContent += '    - uses: actions/checkout@v2\n';
              workflowContent += '    - name: Deploy to staging\n';
              workflowContent += '      run: |\n';
              workflowContent += '        echo "Deploying to staging environment"\n';
              workflowContent += '        # Add deployment script here\n';
              workflowContent += '    - name: Run smoke tests\n';
              workflowContent += '      run: |\n';
              workflowContent += '        echo "Running smoke tests"\n';
              workflowContent += '        # Add smoke test script here\n\n';
              workflowContent += '  deploy-production:\n';
              workflowContent += '    runs-on: ubuntu-latest\n';
              workflowContent += '    needs: docker-build\n';
              workflowContent += '    if: github.ref == \'refs/heads/main\'\n';
              workflowContent += '    environment: production\n';
              workflowContent += '    steps:\n';
              workflowContent += '    - uses: actions/checkout@v2\n';
              workflowContent += '    - name: Deploy to production\n';
              workflowContent += '      run: |\n';
              workflowContent += '        echo "Deploying to production environment"\n';
              workflowContent += '        # Add deployment script here\n';
              workflowContent += '    - name: Run smoke tests\n';
              workflowContent += '      run: |\n';
              workflowContent += '        echo "Running smoke tests"\n';
              workflowContent += '        # Add smoke test script here\n';

              // Crear directorio workflows
              const workflowsDir = path.join(githubDir, 'workflows');
              if (!fs.existsSync(workflowsDir)) {
                fs.mkdirSync(workflowsDir, { recursive: true });
              }

              // Escribir workflow
              fs.writeFileSync(path.join(workflowsDir, 'ci-cd.yml'), workflowContent);

              // Crear README.md para GitHub Actions
              let githubReadmeContent = '# GitHub Actions\n\n';
              githubReadmeContent += 'Este directorio contiene configuraciones para GitHub Actions, el sistema de CI/CD integrado en GitHub.\n\n';
              githubReadmeContent += '## Workflows\n\n';
              githubReadmeContent += '- **ci-cd.yml**: Pipeline principal de CI/CD\n\n';
              githubReadmeContent += '## Configuración\n\n';
              githubReadmeContent += 'Para utilizar estos workflows, debes:\n\n';
              githubReadmeContent += '1. Copiar el directorio `.github` a la raíz de tu repositorio\n';
              githubReadmeContent += '2. Configurar los siguientes secretos en tu repositorio de GitHub:\n';
              githubReadmeContent += '   - `DOCKERHUB_USERNAME`: Tu nombre de usuario de DockerHub\n';
              githubReadmeContent += '   - `DOCKERHUB_TOKEN`: Tu token de acceso a DockerHub\n\n';
              githubReadmeContent += '## Personalización\n\n';
              githubReadmeContent += 'Puedes personalizar los workflows según tus necesidades:\n\n';
              githubReadmeContent += '- Modifica los triggers (eventos que inician el workflow)\n';
              githubReadmeContent += '- Ajusta los entornos y condiciones de despliegue\n';
              githubReadmeContent += '- Añade pasos adicionales para pruebas, análisis o notificaciones\n';

              // Escribir README.md para GitHub Actions
              fs.writeFileSync(path.join(githubDir, 'README.md'), githubReadmeContent);

              // Crear directorio para Jenkins
              const jenkinsDir = path.join(cicdDir, 'jenkins');
              if (!fs.existsSync(jenkinsDir)) {
                fs.mkdirSync(jenkinsDir, { recursive: true });
              }

              // Crear Jenkinsfile
              let jenkinsfileContent = 'pipeline {\n';
              jenkinsfileContent += '    agent {\n';
              jenkinsfileContent += '        docker {\n';
              jenkinsfileContent += '            image \'node:14-alpine\'\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '    }\n';
              jenkinsfileContent += '    stages {\n';
              jenkinsfileContent += '        stage(\'Checkout\') {\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                checkout scm\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        stage(\'Install\') {\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                sh \'npm ci\'\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        stage(\'Lint\') {\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                sh \'npm run lint\'\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        stage(\'Test\') {\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                sh \'npm test\'\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '            post {\n';
              jenkinsfileContent += '                always {\n';
              jenkinsfileContent += '                    junit \'test-results.xml\'\n';
              jenkinsfileContent += '                }\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        stage(\'Build\') {\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                sh \'npm run build\'\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        stage(\'Security Scan\') {\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                sh \'npm audit --audit-level=high\'\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        stage(\'Docker Build\') {\n';
              jenkinsfileContent += '            when {\n';
              jenkinsfileContent += '                anyOf {\n';
              jenkinsfileContent += '                    branch \'main\'\n';
              jenkinsfileContent += '                    branch \'develop\'\n';
              jenkinsfileContent += '                }\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                script {\n';
              jenkinsfileContent += '                    def branchName = env.BRANCH_NAME\n';
              jenkinsfileContent += '                    def dockerImage = docker.build("myorg/myapp:${branchName}-${env.BUILD_NUMBER}")\n';
              jenkinsfileContent += '                    docker.withRegistry(\'https://registry.hub.docker.com\', \'docker-hub-credentials\') {\n';
              jenkinsfileContent += '                        dockerImage.push()\n';
              jenkinsfileContent += '                        dockerImage.push("${branchName}")\n';
              jenkinsfileContent += '                    }\n';
              jenkinsfileContent += '                }\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        stage(\'Deploy to Staging\') {\n';
              jenkinsfileContent += '            when {\n';
              jenkinsfileContent += '                branch \'develop\'\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                echo \'Deploying to staging environment\'\n';
              jenkinsfileContent += '                // Add deployment script here\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        stage(\'Deploy to Production\') {\n';
              jenkinsfileContent += '            when {\n';
              jenkinsfileContent += '                branch \'main\'\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '            steps {\n';
              jenkinsfileContent += '                echo \'Deploying to production environment\'\n';
              jenkinsfileContent += '                // Add deployment script here\n';
              jenkinsfileContent += '            }\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '    }\n';
              jenkinsfileContent += '    post {\n';
              jenkinsfileContent += '        always {\n';
              jenkinsfileContent += '            cleanWs()\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        success {\n';
              jenkinsfileContent += '            echo \'Pipeline completed successfully!\'\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '        failure {\n';
              jenkinsfileContent += '            echo \'Pipeline failed!\'\n';
              jenkinsfileContent += '        }\n';
              jenkinsfileContent += '    }\n';
              jenkinsfileContent += '}\n';

              // Escribir Jenkinsfile
              fs.writeFileSync(path.join(jenkinsDir, 'Jenkinsfile'), jenkinsfileContent);

              // Crear README.md para Jenkins
              let jenkinsReadmeContent = '# Jenkins\n\n';
              jenkinsReadmeContent += 'Este directorio contiene configuraciones para Jenkins, un servidor de automatización de código abierto.\n\n';
              jenkinsReadmeContent += '## Archivos\n\n';
              jenkinsReadmeContent += '- **Jenkinsfile**: Define el pipeline de CI/CD\n\n';
              jenkinsReadmeContent += '## Configuración\n\n';
              jenkinsReadmeContent += 'Para utilizar este pipeline, debes:\n\n';
              jenkinsReadmeContent += '1. Instalar Jenkins (https://www.jenkins.io/doc/book/installing/)\n';
              jenkinsReadmeContent += '2. Instalar los siguientes plugins:\n';
              jenkinsReadmeContent += '   - Pipeline\n';
              jenkinsReadmeContent += '   - Docker Pipeline\n';
              jenkinsReadmeContent += '   - Git Integration\n';
              jenkinsReadmeContent += '3. Crear un nuevo pipeline en Jenkins y configurarlo para usar el Jenkinsfile de este repositorio\n';
              jenkinsReadmeContent += '4. Configurar las credenciales de Docker Hub en Jenkins con el ID "docker-hub-credentials"\n\n';
              jenkinsReadmeContent += '## Personalización\n\n';
              jenkinsReadmeContent += 'Puedes personalizar el pipeline según tus necesidades:\n\n';
              jenkinsReadmeContent += '- Modifica los agentes (entornos de ejecución)\n';
              jenkinsReadmeContent += '- Ajusta las etapas y pasos\n';
              jenkinsReadmeContent += '- Añade notificaciones (Slack, Email, etc.)\n';

              // Escribir README.md para Jenkins
              fs.writeFileSync(path.join(jenkinsDir, 'README.md'), jenkinsReadmeContent);

              // Crear directorio para GitLab CI/CD
              const gitlabDir = path.join(cicdDir, 'gitlab');
              if (!fs.existsSync(gitlabDir)) {
                fs.mkdirSync(gitlabDir, { recursive: true });
              }

              // Crear .gitlab-ci.yml
              let gitlabCiContent = 'stages:\n';
              gitlabCiContent += '  - build\n';
              gitlabCiContent += '  - test\n';
              gitlabCiContent += '  - security\n';
              gitlabCiContent += '  - package\n';
              gitlabCiContent += '  - deploy\n\n';
              gitlabCiContent += 'variables:\n';
              gitlabCiContent += '  DOCKER_DRIVER: overlay2\n';
              gitlabCiContent += '  DOCKER_TLS_CERTDIR: ""\n\n';
              gitlabCiContent += 'cache:\n';
              gitlabCiContent += '  paths:\n';
              gitlabCiContent += '    - node_modules/\n\n';
              gitlabCiContent += 'build:\n';
              gitlabCiContent += '  stage: build\n';
              gitlabCiContent += '  image: node:14-alpine\n';
              gitlabCiContent += '  script:\n';
              gitlabCiContent += '    - npm ci\n';
              gitlabCiContent += '    - npm run build\n';
              gitlabCiContent += '  artifacts:\n';
              gitlabCiContent += '    paths:\n';
              gitlabCiContent += '      - dist/\n\n';
              gitlabCiContent += 'lint:\n';
              gitlabCiContent += '  stage: test\n';
              gitlabCiContent += '  image: node:14-alpine\n';
              gitlabCiContent += '  script:\n';
              gitlabCiContent += '    - npm ci\n';
              gitlabCiContent += '    - npm run lint\n\n';
              gitlabCiContent += 'unit_test:\n';
              gitlabCiContent += '  stage: test\n';
              gitlabCiContent += '  image: node:14-alpine\n';
              gitlabCiContent += '  script:\n';
              gitlabCiContent += '    - npm ci\n';
              gitlabCiContent += '    - npm test\n';
              gitlabCiContent += '  artifacts:\n';
              gitlabCiContent += '    paths:\n';
              gitlabCiContent += '      - coverage/\n';
              gitlabCiContent += '    reports:\n';
              gitlabCiContent += '      junit: test-results.xml\n\n';
              gitlabCiContent += 'security_scan:\n';
              gitlabCiContent += '  stage: security\n';
              gitlabCiContent += '  image: node:14-alpine\n';
              gitlabCiContent += '  script:\n';
              gitlabCiContent += '    - npm ci\n';
              gitlabCiContent += '    - npm audit --audit-level=high\n\n';
              gitlabCiContent += 'dependency_scanning:\n';
              gitlabCiContent += '  stage: security\n';
              gitlabCiContent += '  image: owasp/dependency-check:latest\n';
              gitlabCiContent += '  script:\n';
              gitlabCiContent += '    - /usr/share/dependency-check/bin/dependency-check.sh --scan . --format XML --out dependency-check-report.xml\n';
              gitlabCiContent += '  artifacts:\n';
              gitlabCiContent += '    paths:\n';
              gitlabCiContent += '      - dependency-check-report.xml\n\n';
              gitlabCiContent += 'docker_build:\n';
              gitlabCiContent += '  stage: package\n';
              gitlabCiContent += '  image: docker:latest\n';
              gitlabCiContent += '  services:\n';
              gitlabCiContent += '    - docker:dind\n';
              gitlabCiContent += '  script:\n';
              gitlabCiContent += '    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n';
              gitlabCiContent += '    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG .\n';
              gitlabCiContent += '    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG\n';
              gitlabCiContent += '    - if [ "$CI_COMMIT_REF_NAME" = "main" ]; then docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG $CI_REGISTRY_IMAGE:latest && docker push $CI_REGISTRY_IMAGE:latest; fi\n';
              gitlabCiContent += '  only:\n';
              gitlabCiContent += '    - main\n';
              gitlabCiContent += '    - develop\n\n';
              gitlabCiContent += 'deploy_staging:\n';
              gitlabCiContent += '  stage: deploy\n';
              gitlabCiContent += '  image: alpine:latest\n';
              gitlabCiContent += '  script:\n';
              gitlabCiContent += '    - echo "Deploying to staging environment"\n';
              gitlabCiContent += '    # Add deployment script here\n';
              gitlabCiContent += '  environment:\n';
              gitlabCiContent += '    name: staging\n';
              gitlabCiContent += '    url: https://staging.example.com\n';
              gitlabCiContent += '  only:\n';
              gitlabCiContent += '    - develop\n\n';
              gitlabCiContent += 'deploy_production:\n';
              gitlabCiContent += '  stage: deploy\n';
              gitlabCiContent += '  image: alpine:latest\n';
              gitlabCiContent += '  script:\n';
              gitlabCiContent += '    - echo "Deploying to production environment"\n';
              gitlabCiContent += '    # Add deployment script here\n';
              gitlabCiContent += '  environment:\n';
              gitlabCiContent += '    name: production\n';
              gitlabCiContent += '    url: https://example.com\n';
              gitlabCiContent += '  only:\n';
              gitlabCiContent += '    - main\n';
              gitlabCiContent += '  when: manual\n';

              // Escribir .gitlab-ci.yml
              fs.writeFileSync(path.join(gitlabDir, '.gitlab-ci.yml'), gitlabCiContent);

              // Crear README.md para GitLab CI/CD
              let gitlabReadmeContent = '# GitLab CI/CD\n\n';
              gitlabReadmeContent += 'Este directorio contiene configuraciones para GitLab CI/CD, el sistema de CI/CD integrado en GitLab.\n\n';
              gitlabReadmeContent += '## Archivos\n\n';
              gitlabReadmeContent += '- **.gitlab-ci.yml**: Define el pipeline de CI/CD\n\n';
              gitlabReadmeContent += '## Configuración\n\n';
              gitlabReadmeContent += 'Para utilizar este pipeline, debes:\n\n';
              gitlabReadmeContent += '1. Copiar el archivo `.gitlab-ci.yml` a la raíz de tu repositorio en GitLab\n';
              gitlabReadmeContent += '2. Configurar un runner de GitLab (https://docs.gitlab.com/runner/)\n';
              gitlabReadmeContent += '3. Configurar las variables de entorno necesarias en la configuración de CI/CD de tu proyecto\n\n';
              gitlabReadmeContent += '## Personalización\n\n';
              gitlabReadmeContent += 'Puedes personalizar el pipeline según tus necesidades:\n\n';
              gitlabReadmeContent += '- Modifica las etapas y trabajos\n';
              gitlabReadmeContent += '- Ajusta las condiciones de ejecución\n';
              gitlabReadmeContent += '- Añade más entornos de despliegue\n';

              // Escribir README.md para GitLab CI/CD
              fs.writeFileSync(path.join(gitlabDir, 'README.md'), gitlabReadmeContent);

              // Crear directorio para Azure DevOps
              const azureDir = path.join(cicdDir, 'azure');
              if (!fs.existsSync(azureDir)) {
                fs.mkdirSync(azureDir, { recursive: true });
              }

              // Crear azure-pipelines.yml
              let azurePipelinesContent = 'trigger:\n';
              azurePipelinesContent += '  branches:\n';
              azurePipelinesContent += '    include:\n';
              azurePipelinesContent += '    - main\n';
              azurePipelinesContent += '    - develop\n\n';
              azurePipelinesContent += 'pool:\n';
              azurePipelinesContent += '  vmImage: \'ubuntu-latest\'\n\n';
              azurePipelinesContent += 'stages:\n';
              azurePipelinesContent += '- stage: Build\n';
              azurePipelinesContent += '  jobs:\n';
              azurePipelinesContent += '  - job: BuildJob\n';
              azurePipelinesContent += '    steps:\n';
              azurePipelinesContent += '    - task: NodeTool@0\n';
              azurePipelinesContent += '      inputs:\n';
              azurePipelinesContent += '        versionSpec: \'14.x\'\n';
              azurePipelinesContent += '      displayName: \'Install Node.js\'\n';
              azurePipelinesContent += '    - script: |\n';
              azurePipelinesContent += '        npm ci\n';
              azurePipelinesContent += '      displayName: \'Install dependencies\'\n';
              azurePipelinesContent += '    - script: |\n';
              azurePipelinesContent += '        npm run lint\n';
              azurePipelinesContent += '      displayName: \'Lint\'\n';
              azurePipelinesContent += '    - script: |\n';
              azurePipelinesContent += '        npm run build\n';
              azurePipelinesContent += '      displayName: \'Build\'\n';
              azurePipelinesContent += '    - script: |\n';
              azurePipelinesContent += '        npm test\n';
              azurePipelinesContent += '      displayName: \'Test\'\n';
              azurePipelinesContent += '    - task: PublishTestResults@2\n';
              azurePipelinesContent += '      inputs:\n';
              azurePipelinesContent += '        testResultsFormat: \'JUnit\'\n';
              azurePipelinesContent += '        testResultsFiles: \'**/test-results.xml\'\n';
              azurePipelinesContent += '      displayName: \'Publish test results\'\n';
              azurePipelinesContent += '    - task: PublishBuildArtifacts@1\n';
              azurePipelinesContent += '      inputs:\n';
              azurePipelinesContent += '        pathtoPublish: \'dist\'\n';
              azurePipelinesContent += '        artifactName: \'dist\'\n';
              azurePipelinesContent += '      displayName: \'Publish build artifacts\'\n\n';
              azurePipelinesContent += '- stage: Security\n';
              azurePipelinesContent += '  dependsOn: Build\n';
              azurePipelinesContent += '  jobs:\n';
              azurePipelinesContent += '  - job: SecurityScan\n';
              azurePipelinesContent += '    steps:\n';
              azurePipelinesContent += '    - task: NodeTool@0\n';
              azurePipelinesContent += '      inputs:\n';
              azurePipelinesContent += '        versionSpec: \'14.x\'\n';
              azurePipelinesContent += '      displayName: \'Install Node.js\'\n';
              azurePipelinesContent += '    - script: |\n';
              azurePipelinesContent += '        npm ci\n';
              azurePipelinesContent += '        npm audit --audit-level=high\n';
              azurePipelinesContent += '      displayName: \'Run security audit\'\n';
              azurePipelinesContent += '    - task: PublishBuildArtifacts@1\n';
              azurePipelinesContent += '      inputs:\n';
              azurePipelinesContent += '        pathtoPublish: \'reports\'\n';
              azurePipelinesContent += '        artifactName: \'security-reports\'\n';
              azurePipelinesContent += '      displayName: \'Publish security reports\'\n';
              azurePipelinesContent += '      condition: succeededOrFailed()\n\n';
              azurePipelinesContent += '- stage: Docker\n';
              azurePipelinesContent += '  dependsOn: Security\n';
              azurePipelinesContent += '  condition: and(succeeded(), in(variables[\'Build.SourceBranch\'], \'refs/heads/main\', \'refs/heads/develop\'))\n';
              azurePipelinesContent += '  jobs:\n';
              azurePipelinesContent += '  - job: DockerBuild\n';
              azurePipelinesContent += '    steps:\n';
              azurePipelinesContent += '    - task: DownloadBuildArtifacts@0\n';
              azurePipelinesContent += '      inputs:\n';
              azurePipelinesContent += '        buildType: \'current\'\n';
              azurePipelinesContent += '        downloadType: \'single\'\n';
              azurePipelinesContent += '        artifactName: \'dist\'\n';
              azurePipelinesContent += '        downloadPath: \'$(System.ArtifactsDirectory)\'\n';
              azurePipelinesContent += '      displayName: \'Download build artifacts\'\n';
              azurePipelinesContent += '    - task: Docker@2\n';
              azurePipelinesContent += '      inputs:\n';
              azurePipelinesContent += '        containerRegistry: \'dockerhub-connection\'\n';
              azurePipelinesContent += '        repository: \'myorg/myapp\'\n';
              azurePipelinesContent += '        command: \'buildAndPush\'\n';
              azurePipelinesContent += '        Dockerfile: \'Dockerfile\'\n';
              azurePipelinesContent += '        tags: |\n';
              azurePipelinesContent += '          $(Build.SourceBranchName)\n';
              azurePipelinesContent += '          $(Build.SourceBranchName)-$(Build.BuildId)\n';
              azurePipelinesContent += '      displayName: \'Build and push Docker image\'\n\n';
              azurePipelinesContent += '- stage: DeployStaging\n';
              azurePipelinesContent += '  dependsOn: Docker\n';
              azurePipelinesContent += '  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/develop\'))\n';
              azurePipelinesContent += '  jobs:\n';
              azurePipelinesContent += '  - deployment: DeployStaging\n';
              azurePipelinesContent += '    environment: \'staging\'\n';
              azurePipelinesContent += '    strategy:\n';
              azurePipelinesContent += '      runOnce:\n';
              azurePipelinesContent += '        deploy:\n';
              azurePipelinesContent += '          steps:\n';
              azurePipelinesContent += '          - script: |\n';
              azurePipelinesContent += '              echo "Deploying to staging environment"\n';
              azurePipelinesContent += '              # Add deployment script here\n';
              azurePipelinesContent += '            displayName: \'Deploy to staging\'\n';
              azurePipelinesContent += '          - script: |\n';
              azurePipelinesContent += '              echo "Running smoke tests"\n';
              azurePipelinesContent += '              # Add smoke test script here\n';
              azurePipelinesContent += '            displayName: \'Run smoke tests\'\n\n';
              azurePipelinesContent += '- stage: DeployProduction\n';
              azurePipelinesContent += '  dependsOn: Docker\n';
              azurePipelinesContent += '  condition: and(succeeded(), eq(variables[\'Build.SourceBranch\'], \'refs/heads/main\'))\n';
              azurePipelinesContent += '  jobs:\n';
              azurePipelinesContent += '  - deployment: DeployProduction\n';
              azurePipelinesContent += '    environment: \'production\'\n';
              azurePipelinesContent += '    strategy:\n';
              azurePipelinesContent += '      runOnce:\n';
              azurePipelinesContent += '        deploy:\n';
              azurePipelinesContent += '          steps:\n';
              azurePipelinesContent += '          - script: |\n';
              azurePipelinesContent += '              echo "Deploying to production environment"\n';
              azurePipelinesContent += '              # Add deployment script here\n';
              azurePipelinesContent += '            displayName: \'Deploy to production\'\n';
              azurePipelinesContent += '          - script: |\n';
              azurePipelinesContent += '              echo "Running smoke tests"\n';
              azurePipelinesContent += '              # Add smoke test script here\n';
              azurePipelinesContent += '            displayName: \'Run smoke tests\'\n';

              // Escribir azure-pipelines.yml
              fs.writeFileSync(path.join(azureDir, 'azure-pipelines.yml'), azurePipelinesContent);

              // Crear README.md para Azure DevOps
              let azureReadmeContent = '# Azure DevOps\n\n';
              azureReadmeContent += 'Este directorio contiene configuraciones para Azure DevOps, la plataforma de CI/CD de Microsoft.\n\n';
              azureReadmeContent += '## Archivos\n\n';
              azureReadmeContent += '- **azure-pipelines.yml**: Define el pipeline de CI/CD\n\n';
              azureReadmeContent += '## Configuración\n\n';
              azureReadmeContent += 'Para utilizar este pipeline, debes:\n\n';
              azureReadmeContent += '1. Copiar el archivo `azure-pipelines.yml` a la raíz de tu repositorio\n';
              azureReadmeContent += '2. Crear un proyecto en Azure DevOps y conectarlo a tu repositorio\n';
              azureReadmeContent += '3. Configurar una conexión de servicio a Docker Hub con el nombre "dockerhub-connection"\n';
              azureReadmeContent += '4. Crear los entornos "staging" y "production" en Azure DevOps\n\n';
              azureReadmeContent += '## Personalización\n\n';
              azureReadmeContent += 'Puedes personalizar el pipeline según tus necesidades:\n\n';
              azureReadmeContent += '- Modifica las etapas y trabajos\n';
              azureReadmeContent += '- Ajusta las condiciones de ejecución\n';
              azureReadmeContent += '- Añade más tareas y scripts\n';

              // Escribir README.md para Azure DevOps
              fs.writeFileSync(path.join(azureDir, 'README.md'), azureReadmeContent);

              // Crear directorio para scripts
              const scriptsDir = path.join(cicdDir, 'scripts');
              if (!fs.existsSync(scriptsDir)) {
                fs.mkdirSync(scriptsDir, { recursive: true });
              }

              // Crear script de despliegue
              let deployScriptContent = '#!/bin/bash\n\n';
              deployScriptContent += '# Script de despliegue para entornos\n\n';
              deployScriptContent += 'set -e\n\n';
              deployScriptContent += '# Parámetros\n';
              deployScriptContent += 'ENVIRONMENT=$1\n';
              deployScriptContent += 'VERSION=$2\n\n';
              deployScriptContent += '# Validar parámetros\n';
              deployScriptContent += 'if [ -z "$ENVIRONMENT" ] || [ -z "$VERSION" ]; then\n';
              deployScriptContent += '  echo "Uso: $0 <environment> <version>"\n';
              deployScriptContent += '  echo "Ejemplo: $0 staging 1.0.0"\n';
              deployScriptContent += '  exit 1\n';
              deployScriptContent += 'fi\n\n';
              deployScriptContent += '# Configuración según entorno\n';
              deployScriptContent += 'case "$ENVIRONMENT" in\n';
              deployScriptContent += '  "development")\n';
              deployScriptContent += '    DEPLOY_URL="https://dev.example.com"\n';
              deployScriptContent += '    ;;  \n';
              deployScriptContent += '  "staging")\n';
              deployScriptContent += '    DEPLOY_URL="https://staging.example.com"\n';
              deployScriptContent += '    ;;  \n';
              deployScriptContent += '  "production")\n';
              deployScriptContent += '    DEPLOY_URL="https://example.com"\n';
              deployScriptContent += '    ;;  \n';
              deployScriptContent += '  *)\n';
              deployScriptContent += '    echo "Entorno no válido: $ENVIRONMENT"\n';
              deployScriptContent += '    exit 1\n';
              deployScriptContent += '    ;;  \n';
              deployScriptContent += 'esac\n\n';
              deployScriptContent += 'echo "Desplegando versión $VERSION en $ENVIRONMENT..."\n\n';
              deployScriptContent += '# Descargar imagen Docker\n';
              deployScriptContent += 'echo "Descargando imagen myorg/myapp:$VERSION..."\n';
              deployScriptContent += 'docker pull myorg/myapp:$VERSION\n\n';
              deployScriptContent += '# Detener y eliminar contenedor existente si existe\n';
              deployScriptContent += 'if docker ps -a | grep -q myapp-$ENVIRONMENT; then\n';
              deployScriptContent += '  echo "Deteniendo contenedor existente..."\n';
              deployScriptContent += '  docker stop myapp-$ENVIRONMENT || true\n';
              deployScriptContent += '  docker rm myapp-$ENVIRONMENT || true\n';
              deployScriptContent += 'fi\n\n';
              deployScriptContent += '# Iniciar nuevo contenedor\n';
              deployScriptContent += 'echo "Iniciando nuevo contenedor..."\n';
              deployScriptContent += 'docker run -d \\\n';
              deployScriptContent += '  --name myapp-$ENVIRONMENT \\\n';
              deployScriptContent += '  -p 3000:3000 \\\n';
              deployScriptContent += '  -e NODE_ENV=$ENVIRONMENT \\\n';
              deployScriptContent += '  myorg/myapp:$VERSION\n\n';
              deployScriptContent += '# Verificar despliegue\n';
              deployScriptContent += 'echo "Verificando despliegue..."\n';
              deployScriptContent += 'sleep 5\n';
              deployScriptContent += 'if docker ps | grep -q myapp-$ENVIRONMENT; then\n';
              deployScriptContent += '  echo "Despliegue exitoso en $DEPLOY_URL"\n';
              deployScriptContent += 'else\n';
              deployScriptContent += '  echo "Error en el despliegue"\n';
              deployScriptContent += '  exit 1\n';
              deployScriptContent += 'fi\n';

              // Escribir script de despliegue
              fs.writeFileSync(path.join(scriptsDir, 'deploy.sh'), deployScriptContent);
              
              // Crear script de despliegue para Windows
              let deployScriptWindowsContent = '@echo off\n\n';
              deployScriptWindowsContent += 'REM Script de despliegue para entornos en Windows\n\n';
              deployScriptWindowsContent += 'setlocal enabledelayedexpansion\n\n';
              deployScriptWindowsContent += 'REM Parámetros\n';
              deployScriptWindowsContent += 'set ENVIRONMENT=%1\n';
              deployScriptWindowsContent += 'set VERSION=%2\n\n';
              deployScriptWindowsContent += 'REM Validar parámetros\n';
              deployScriptWindowsContent += 'if "%ENVIRONMENT%"=="" (\n';
              deployScriptWindowsContent += '  echo Uso: %0 ^<environment^> ^<version^>\n';
              deployScriptWindowsContent += '  echo Ejemplo: %0 staging 1.0.0\n';
              deployScriptWindowsContent += '  exit /b 1\n';
              deployScriptWindowsContent += ')\n\n';
              deployScriptWindowsContent += 'if "%VERSION%"=="" (\n';
              deployScriptWindowsContent += '  echo Uso: %0 ^<environment^> ^<version^>\n';
              deployScriptWindowsContent += '  echo Ejemplo: %0 staging 1.0.0\n';
              deployScriptWindowsContent += '  exit /b 1\n';
              deployScriptWindowsContent += ')\n\n';
              deployScriptWindowsContent += 'REM Configuración según entorno\n';
              deployScriptWindowsContent += 'if "%ENVIRONMENT%"=="development" (\n';
              deployScriptWindowsContent += '  set DEPLOY_URL=https://dev.example.com\n';
              deployScriptWindowsContent += ') else if "%ENVIRONMENT%"=="staging" (\n';
              deployScriptWindowsContent += '  set DEPLOY_URL=https://staging.example.com\n';
              deployScriptWindowsContent += ') else if "%ENVIRONMENT%"=="production" (\n';
              deployScriptWindowsContent += '  set DEPLOY_URL=https://example.com\n';
              deployScriptWindowsContent += ') else (\n';
              deployScriptWindowsContent += '  echo Entorno no válido: %ENVIRONMENT%\n';
              deployScriptWindowsContent += '  exit /b 1\n';
              deployScriptWindowsContent += ')\n\n';
              deployScriptWindowsContent += 'echo Desplegando versión %VERSION% en %ENVIRONMENT%...\n\n';
              deployScriptWindowsContent += 'REM Descargar imagen Docker\n';
              deployScriptWindowsContent += 'echo Descargando imagen myorg/myapp:%VERSION%...\n';
              deployScriptWindowsContent += 'docker pull myorg/myapp:%VERSION%\n\n';
              deployScriptWindowsContent += 'REM Detener y eliminar contenedor existente si existe\n';
              deployScriptWindowsContent += 'docker ps -a | findstr "myapp-%ENVIRONMENT%" > nul\n';
              deployScriptWindowsContent += 'if %ERRORLEVEL% == 0 (\n';
              deployScriptWindowsContent += '  echo Deteniendo contenedor existente...\n';
              deployScriptWindowsContent += '  docker stop myapp-%ENVIRONMENT% 2>nul || echo No se pudo detener el contenedor\n';
              deployScriptWindowsContent += '  docker rm myapp-%ENVIRONMENT% 2>nul || echo No se pudo eliminar el contenedor\n';
              deployScriptWindowsContent += ')\n\n';
              deployScriptWindowsContent += 'REM Iniciar nuevo contenedor\n';
              deployScriptWindowsContent += 'echo Iniciando nuevo contenedor...\n';
              deployScriptWindowsContent += 'docker run -d ^\n';
              deployScriptWindowsContent += '  --name myapp-%ENVIRONMENT% ^\n';
              deployScriptWindowsContent += '  -p 3000:3000 ^\n';
              deployScriptWindowsContent += '  -e NODE_ENV=%ENVIRONMENT% ^\n';
              deployScriptWindowsContent += '  myorg/myapp:%VERSION%\n\n';
              deployScriptWindowsContent += 'REM Verificar despliegue\n';
              deployScriptWindowsContent += 'echo Verificando despliegue...\n';
              deployScriptWindowsContent += 'timeout /t 5 /nobreak > nul\n';
              deployScriptWindowsContent += 'docker ps | findstr "myapp-%ENVIRONMENT%" > nul\n';
              deployScriptWindowsContent += 'if %ERRORLEVEL% == 0 (\n';
              deployScriptWindowsContent += '  echo Despliegue exitoso en %DEPLOY_URL%\n';
              deployScriptWindowsContent += ') else (\n';
              deployScriptWindowsContent += '  echo Error en el despliegue\n';
              deployScriptWindowsContent += '  exit /b 1\n';
              deployScriptWindowsContent += ')\n';

              // Escribir script de despliegue para Windows
              fs.writeFileSync(path.join(scriptsDir, 'deploy.bat'), deployScriptWindowsContent);

              // Crear script de pruebas de humo
              let smokeTestScriptContent = '#!/bin/bash\n\n';
              smokeTestScriptContent += '# Script de pruebas de humo\n\n';
              smokeTestScriptContent += 'set -e\n\n';
              smokeTestScriptContent += '# Parámetros\n';
              smokeTestScriptContent += 'URL=$1\n\n';
              smokeTestScriptContent += '# Validar parámetros\n';
              smokeTestScriptContent += 'if [ -z "$URL" ]; then\n';
              smokeTestScriptContent += '  echo "Uso: $0 <url>"\n';
              smokeTestScriptContent += '  echo "Ejemplo: $0 https://example.com"\n';
              smokeTestScriptContent += '  exit 1\n';
              smokeTestScriptContent += 'fi\n\n';
              smokeTestScriptContent += 'echo "Ejecutando pruebas de humo en $URL..."\n\n';
              smokeTestScriptContent += '# Verificar que el servidor responde\n';
              smokeTestScriptContent += 'echo "Verificando conexión..."\n';
              smokeTestScriptContent += 'curl -s -o /dev/null -w "%{http_code}" $URL | grep -q 200\n';
              smokeTestScriptContent += 'if [ $? -ne 0 ]; then\n';
              smokeTestScriptContent += '  echo "Error: No se pudo conectar al servidor"\n';
              smokeTestScriptContent += '  exit 1\n';
              smokeTestScriptContent += 'fi\n\n';
              smokeTestScriptContent += '# Verificar API\n';
              smokeTestScriptContent += 'echo "Verificando API..."\n';
              smokeTestScriptContent += 'curl -s -o /dev/null -w "%{http_code}" $URL/api/health | grep -q 200\n';
              smokeTestScriptContent += 'if [ $? -ne 0 ]; then\n';
              smokeTestScriptContent += '  echo "Error: API no responde correctamente"\n';
              smokeTestScriptContent += '  exit 1\n';
              smokeTestScriptContent += 'fi\n\n';
              smokeTestScriptContent += '# Verificar tiempo de respuesta\n';
              smokeTestScriptContent += 'echo "Verificando tiempo de respuesta..."\n';
              smokeTestScriptContent += 'RESPONSE_TIME=$(curl -s -w "%{time_total}" -o /dev/null $URL)\n';
              smokeTestScriptContent += 'echo "Tiempo de respuesta: ${RESPONSE_TIME}s"\n';
              smokeTestScriptContent += 'if (( $(echo "$RESPONSE_TIME > 2.0" | bc -l) )); then\n';
              smokeTestScriptContent += '  echo "Advertencia: Tiempo de respuesta superior a 2 segundos"\n';
              smokeTestScriptContent += 'fi\n\n';
              smokeTestScriptContent += 'echo "Pruebas de humo completadas exitosamente"\n';

              // Escribir script de pruebas de humo
              fs.writeFileSync(path.join(scriptsDir, 'smoke-test.sh'), smokeTestScriptContent);

              // Crear script de pruebas de humo para Windows
              let smokeTestScriptWindowsContent = '@echo off\n\n';
              smokeTestScriptWindowsContent += 'REM Script de pruebas de humo para Windows\n\n';
              smokeTestScriptWindowsContent += 'setlocal enabledelayedexpansion\n\n';
              smokeTestScriptWindowsContent += 'REM Parámetros\n';
              smokeTestScriptWindowsContent += 'set URL=%1\n\n';
              smokeTestScriptWindowsContent += 'REM Validar parámetros\n';
              smokeTestScriptWindowsContent += 'if "%URL%"=="" (\n';
              smokeTestScriptWindowsContent += '  echo Uso: %0 ^<url^>\n';
              smokeTestScriptWindowsContent += '  echo Ejemplo: %0 https://example.com\n';
              smokeTestScriptWindowsContent += '  exit /b 1\n';
              smokeTestScriptWindowsContent += ')\n\n';
              smokeTestScriptWindowsContent += 'echo Ejecutando pruebas de humo en %URL%...\n\n';
              smokeTestScriptWindowsContent += 'REM Verificar que el servidor responde\n';
              smokeTestScriptWindowsContent += 'echo Verificando conexión...\n';
              smokeTestScriptWindowsContent += 'curl -s -o nul -w "%%{http_code}" %URL% | findstr "200" > nul\n';
              smokeTestScriptWindowsContent += 'if %ERRORLEVEL% NEQ 0 (\n';
              smokeTestScriptWindowsContent += '  echo Error: No se pudo conectar al servidor\n';
              smokeTestScriptWindowsContent += '  exit /b 1\n';
              smokeTestScriptWindowsContent += ')\n\n';
              smokeTestScriptWindowsContent += 'REM Verificar API\n';
              smokeTestScriptWindowsContent += 'echo Verificando API...\n';
              smokeTestScriptWindowsContent += 'curl -s -o nul -w "%%{http_code}" %URL%/api/health | findstr "200" > nul\n';
              smokeTestScriptWindowsContent += 'if %ERRORLEVEL% NEQ 0 (\n';
              smokeTestScriptWindowsContent += '  echo Error: API no responde correctamente\n';
              smokeTestScriptWindowsContent += '  exit /b 1\n';
              smokeTestScriptWindowsContent += ')\n\n';
              smokeTestScriptWindowsContent += 'REM Verificar tiempo de respuesta\n';
              smokeTestScriptWindowsContent += 'echo Verificando tiempo de respuesta...\n';
              smokeTestScriptWindowsContent += 'for /f "tokens=*" %%a in (\'curl -s -w "%%{time_total}" -o nul %URL%\') do set RESPONSE_TIME=%%a\n';
              smokeTestScriptWindowsContent += 'echo Tiempo de respuesta: %RESPONSE_TIME%s\n\n';
              smokeTestScriptWindowsContent += 'echo Pruebas de humo completadas exitosamente\n';

              // Escribir script de pruebas de humo para Windows
              fs.writeFileSync(path.join(scriptsDir, 'smoke-test.bat'), smokeTestScriptWindowsContent);

              // Crear README.md para scripts
              let scriptsReadmeContent = '# Scripts de CI/CD\n\n';
              scriptsReadmeContent += 'Este directorio contiene scripts útiles para la integración continua y el despliegue continuo.\n\n';
              scriptsReadmeContent += '## Scripts\n\n';
              scriptsReadmeContent += '### deploy.sh / deploy.bat\n\n';
              scriptsReadmeContent += 'Script para desplegar la aplicación en diferentes entornos.\n\n';
              scriptsReadmeContent += '```bash\n';
              scriptsReadmeContent += '# Uso en Linux/macOS\n';
              scriptsReadmeContent += './deploy.sh <environment> <version>\n\n';
              scriptsReadmeContent += '# Ejemplo\n';
              scriptsReadmeContent += './deploy.sh staging 1.0.0\n';
              scriptsReadmeContent += '```\n\n';
              scriptsReadmeContent += '```batch\n';
              scriptsReadmeContent += '# Uso en Windows\n';
              scriptsReadmeContent += 'deploy.bat <environment> <version>\n\n';
              scriptsReadmeContent += '# Ejemplo\n';
              scriptsReadmeContent += 'deploy.bat staging 1.0.0\n';
              scriptsReadmeContent += '```\n\n';
              scriptsReadmeContent += '### smoke-test.sh / smoke-test.bat\n\n';
              scriptsReadmeContent += 'Script para ejecutar pruebas de humo después de un despliegue.\n\n';
              scriptsReadmeContent += '```bash\n';
              scriptsReadmeContent += '# Uso en Linux/macOS\n';
              scriptsReadmeContent += './smoke-test.sh <url>\n\n';
              scriptsReadmeContent += '# Ejemplo\n';
              scriptsReadmeContent += './smoke-test.sh https://example.com\n';
              scriptsReadmeContent += '```\n\n';
              scriptsReadmeContent += '```batch\n';
              scriptsReadmeContent += '# Uso en Windows\n';
              scriptsReadmeContent += 'smoke-test.bat <url>\n\n';
              scriptsReadmeContent += '# Ejemplo\n';
              scriptsReadmeContent += 'smoke-test.bat https://example.com\n';
              scriptsReadmeContent += '```\n\n';
              scriptsReadmeContent += '## Integración con CI/CD\n\n';
              scriptsReadmeContent += 'Estos scripts están diseñados para ser utilizados en pipelines de CI/CD. Puedes llamarlos desde GitHub Actions, Jenkins, GitLab CI/CD o Azure DevOps.\n\n';
              scriptsReadmeContent += '### Ejemplo en GitHub Actions\n\n';
              scriptsReadmeContent += '```yaml\n';
              scriptsReadmeContent += 'deploy:\n';
              scriptsReadmeContent += '  runs-on: ubuntu-latest\n';
              scriptsReadmeContent += '  steps:\n';
              scriptsReadmeContent += '  - uses: actions/checkout@v2\n';
              scriptsReadmeContent += '  - name: Deploy to staging\n';
              scriptsReadmeContent += '    run: ./cicd/scripts/deploy.sh staging ${{ github.sha }}\n';
              scriptsReadmeContent += '  - name: Run smoke tests\n';
              scriptsReadmeContent += '    run: ./cicd/scripts/smoke-test.sh https://staging.example.com\n';
              scriptsReadmeContent += '```\n';

              // Escribir README.md para scripts
              fs.writeFileSync(path.join(scriptsDir, 'README.md'), scriptsReadmeContent);

              return cicdDir;
            } catch (error) {
              console.error('Error al crear archivos de CI/CD:', error);
              throw error;
            }
          }

          /**
           * Crea archivos de configuración para monitoreo
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de monitoreo
           */
          async createMonitoringFiles(projectDir, config) {
            try {
              const monitoringDir = path.join(projectDir, 'monitoring');
              if (!fs.existsSync(monitoringDir)) {
                fs.mkdirSync(monitoringDir, { recursive: true });
              }

              // Crear directorio para Prometheus
              const prometheusDir = path.join(monitoringDir, 'prometheus');
              if (!fs.existsSync(prometheusDir)) {
                fs.mkdirSync(prometheusDir, { recursive: true });
              }

              // Crear prometheus.yml
              let prometheusContent = 'global:\n';
              prometheusContent += '  scrape_interval: 15s\n';
              prometheusContent += '  evaluation_interval: 15s\n\n';
              prometheusContent += 'alerting:\n';
              prometheusContent += '  alertmanagers:\n';
              prometheusContent += '  - static_configs:\n';
              prometheusContent += '    - targets: [\'alertmanager:9093\']\n\n';
              prometheusContent += 'rule_files:\n';
              prometheusContent += '  - "alert_rules.yml"\n\n';
              prometheusContent += 'scrape_configs:\n';
              prometheusContent += '  - job_name: \'prometheus\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '    - targets: [\'localhost:9090\']\n\n';
              prometheusContent += '  - job_name: \'node-exporter\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '    - targets: [\'node-exporter:9100\']\n\n';
              prometheusContent += '  - job_name: \'cadvisor\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '    - targets: [\'cadvisor:8080\']\n\n';
              
              // Añadir configuración específica según el tipo de proyecto
              if (config.projectType === 'web' || config.projectType === 'fullstack') {
                prometheusContent += '  - job_name: \'frontend\'\n';
                prometheusContent += '    static_configs:\n';
                prometheusContent += '    - targets: [\'frontend:3000\']\n\n';
              }
              
              if (config.projectType === 'api' || config.projectType === 'fullstack') {
                prometheusContent += '  - job_name: \'backend\'\n';
                prometheusContent += '    static_configs:\n';
                prometheusContent += '    - targets: [\'backend:8080\']\n\n';
              }

              // Escribir prometheus.yml
              fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);

              // Crear alert_rules.yml
              let alertRulesContent = 'groups:\n';
              alertRulesContent += '- name: example\n';
              alertRulesContent += '  rules:\n';
              alertRulesContent += '  - alert: HighCPULoad\n';
              alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High CPU load (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "CPU load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
              
              alertRulesContent += '  - alert: HighMemoryLoad\n';
              alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 > 80\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High memory load (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "Memory load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
              
              alertRulesContent += '  - alert: HighDiskUsage\n';
              alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High disk usage (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "Disk usage is > 85%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n';

              // Escribir alert_rules.yml
              fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);

              // Crear configuración de Alertmanager
              const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
              if (!fs.existsSync(alertmanagerDir)) {
                fs.mkdirSync(alertmanagerDir, { recursive: true });
              }

              // Crear alertmanager.yml
              let alertmanagerContent = 'global:\n';
              alertmanagerContent += '  resolve_timeout: 5m\n';
              alertmanagerContent += '  smtp_smarthost: "smtp.example.com:587"\n';
              alertmanagerContent += '  smtp_from: "alertmanager@example.com"\n';
              alertmanagerContent += '  smtp_auth_username: "alertmanager"\n';
              alertmanagerContent += '  smtp_auth_password: "password"\n\n';
              alertmanagerContent += 'route:\n';
              alertmanagerContent += '  group_by: [\'alertname\', \'instance\']\n';
              alertmanagerContent += '  group_wait: 30s\n';
              alertmanagerContent += '  group_interval: 5m\n';
              alertmanagerContent += '  repeat_interval: 1h\n';
              alertmanagerContent += '  receiver: \'email\'\n\n';
              alertmanagerContent += 'receivers:\n';
              alertmanagerContent += '- name: \'email\'\n';
              alertmanagerContent += '  email_configs:\n';
              alertmanagerContent += '  - to: "alerts@example.com"\n';
              alertmanagerContent += '    send_resolved: true\n\n';
              alertmanagerContent += 'inhibit_rules:\n';
              alertmanagerContent += '  - source_match:\n';
              alertmanagerContent += '      severity: \'critical\'\n';
              alertmanagerContent += '    target_match:\n';
              alertmanagerContent += '      severity: \'warning\'\n';
              alertmanagerContent += '    equal: [\'alertname\', \'instance\']\n';

              // Escribir alertmanager.yml
              fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);

              // Crear configuración de Grafana
              const grafanaDir = path.join(monitoringDir, 'grafana');
              if (!fs.existsSync(grafanaDir)) {
                fs.mkdirSync(grafanaDir, { recursive: true });
              }

              // Crear datasources.yml
              let datasourcesContent = 'apiVersion: 1\n\n';
              datasourcesContent += 'datasources:\n';
              datasourcesContent += '  - name: Prometheus\n';
              datasourcesContent += '    type: prometheus\n';
              datasourcesContent += '    access: proxy\n';
              datasourcesContent += '    url: http://prometheus:9090\n';
              datasourcesContent += '    isDefault: true\n';
              datasourcesContent += '    editable: true\n';

              // Escribir datasources.yml
              fs.writeFileSync(path.join(grafanaDir, 'datasources.yml'), datasourcesContent);

              // Crear directorio para dashboards
              const dashboardsDir = path.join(grafanaDir, 'dashboards');
              if (!fs.existsSync(dashboardsDir)) {
                fs.mkdirSync(dashboardsDir, { recursive: true });
              }

              // Crear dashboard.json básico
              let dashboardContent = JSON.stringify({
                annotations: {
                  list: [
                    {
                      builtIn: 1,
                      datasource: "-- Grafana --",
                      enable: true,
                      hide: true,
                      iconColor: "rgba(0, 211, 255, 1)",
                      name: "Annotations & Alerts",
                      type: "dashboard"
                    }
                  ]
                },
                editable: true,
                gnetId: null,
                graphTooltip: 0,
                id: 1,
                links: [],
                panels: [
                  {
                    alert: {
                      conditions: [
                        {
                          evaluator: {
                            params: [80],
                            type: "gt"
                          },
                          operator: {
                            type: "and"
                          },
                          query: {
                            params: ["A", "5m", "now"]
                          },
                          reducer: {
                            params: [],
                            type: "avg"
                          },
                          type: "query"
                        }
                      ],
                      executionErrorState: "alerting",
                      frequency: "60s",
                      handler: 1,
                      name: "CPU Usage alert",
                      noDataState: "no_data",
                      notifications: []
                    },
                    aliasColors: {},
                    bars: false,
                    dashLength: 10,
                    dashes: false,
                    datasource: "Prometheus",
                    fieldConfig: {
                      defaults: {
                        custom: {}
                      },
                      overrides: []
                    },
                    fill: 1,
                    fillGradient: 0,
                    gridPos: {
                      h: 9,
                      w: 12,
                      x: 0,
                      y: 0
                    },
                    hiddenSeries: false,
                    id: 2,
                    legend: {
                      avg: false,
                      current: false,
                      max: false,
                      min: false,
                      show: true,
                      total: false,
                      values: false
                    },
                    lines: true,
                    linewidth: 1,
                    nullPointMode: "null",
                    options: {
                      alertThreshold: true
                    },
                    percentage: false,
                    pluginVersion: "7.3.7",
                    pointradius: 2,
                    points: false,
                    renderer: "flot",
                    seriesOverrides: [],
                    spaceLength: 10,
                    stack: false,
                    steppedLine: false,
                    targets: [
                      {
                        expr: "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
                        interval: "",
                        legendFormat: "",
                        refId: "A"
                      }
                    ],
                    thresholds: [
                      {
                        colorMode: "critical",
                        fill: true,
                        line: true,
                        op: "gt",
                        value: 80
                      }
                    ],
                    timeFrom: null,
                    timeRegions: [],
                    timeShift: null,
                    title: "CPU Usage",
                    tooltip: {
                      shared: true,
                      sort: 0,
                      value_type: "individual"
                    },
                    type: "graph",
                    xaxis: {
                      buckets: null,
                      mode: "time",
                      name: null,
                      show: true,
                      values: []
                    },
                    yaxes: [
                      {
                        format: "percent",
                        label: null,
                        logBase: 1,
                        max: null,
                        min: null,
                        show: true
                      },
                      {
                        format: "short",
                        label: null,
                        logBase: 1,
                        max: null,
                        min: null,
                        show: true
                      }
                    ],
                    yaxis: {
                      align: false,
                      alignLevel: null
                    }
                  }
                ],
                schemaVersion: 26,
                style: "dark",
                tags: [],
                templating: {
                  list: []
                },
                time: {
                  from: "now-6h",
                  to: "now"
                },
                timepicker: {},
                timezone: "",
                title: "System Monitoring",
                uid: "system-monitoring",
                version: 1
              }, null, 2);

              // Escribir dashboard.json
              fs.writeFileSync(path.join(dashboardsDir, 'dashboard.json'), dashboardContent);

              // Crear dashboard.yml
              let dashboardYamlContent = 'apiVersion: 1\n\n';
              dashboardYamlContent += 'providers:\n';
              dashboardYamlContent += '  - name: \'default\'\n';
              dashboardYamlContent += '    orgId: 1\n';
              dashboardYamlContent += '    folder: \'\'\n';
              dashboardYamlContent += '    type: file\n';
              dashboardYamlContent += '    disableDeletion: false\n';
              dashboardYamlContent += '    editable: true\n';
              dashboardYamlContent += '    options:\n';
              dashboardYamlContent += '      path: /etc/grafana/dashboards\n';

              // Escribir dashboard.yml
              fs.writeFileSync(path.join(grafanaDir, 'dashboard.yml'), dashboardYamlContent);

              // Crear docker-compose.yml para monitoreo
              let dockerComposeContent = 'version: "3.8"\n\n';
              dockerComposeContent += 'services:\n';
              dockerComposeContent += '  prometheus:\n';
              dockerComposeContent += '    image: prom/prometheus:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
              dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
              dockerComposeContent += '      - prometheus_data:/prometheus\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
              dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
              dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
              dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9090:9090"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  alertmanager:\n';
              dockerComposeContent += '    image: prom/alertmanager:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
              dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
              dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9093:9093"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  grafana:\n';
              dockerComposeContent += '    image: grafana/grafana:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
              dockerComposeContent += '      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml\n';
              dockerComposeContent += '      - ./grafana/dashboards:/etc/grafana/dashboards\n';
              dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
              dockerComposeContent += '    environment:\n';
              dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
              dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
              dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "3000:3000"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  node-exporter:\n';
              dockerComposeContent += '    image: prom/node-exporter:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - /proc:/host/proc:ro\n';
              dockerComposeContent += '      - /sys:/host/sys:ro\n';
              dockerComposeContent += '      - /:/rootfs:ro\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
              dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
              dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9100:9100"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  cadvisor:\n';
              dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - /:/rootfs:ro\n';
              dockerComposeContent += '      - /var/run:/var/run:ro\n';
              dockerComposeContent += '      - /sys:/sys:ro\n';
              dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "8080:8080"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += 'networks:\n';
              dockerComposeContent += '  monitoring-network:\n';
              dockerComposeContent += '    driver: bridge\n\n';
              
              dockerComposeContent += 'volumes:\n';
              dockerComposeContent += '  prometheus_data:\n';
              dockerComposeContent += '    driver: local\n';
              dockerComposeContent += '  alertmanager_data:\n';
              dockerComposeContent += '    driver: local\n';
              dockerComposeContent += '  grafana_data:\n';
              dockerComposeContent += '    driver: local\n';

              // Escribir docker-compose.yml
              fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);

              // Crear README.md
              let readmeContent = '# Stack de Monitoreo\n\n';
              readmeContent += 'Este directorio contiene la configuración para un stack de monitoreo completo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
              readmeContent += '## Componentes\n\n';
              readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
              readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
              readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
              readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
              readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
              readmeContent += '## Inicio Rápido\n\n';
              readmeContent += '```bash\n';
              readmeContent += '# Iniciar el stack de monitoreo\n';
              readmeContent += 'docker-compose up -d\n';
              readmeContent += '```\n\n';
              readmeContent += '## Acceso\n\n';
              readmeContent += '- **Prometheus**: http://localhost:9090\n';
              readmeContent += '- **Alertmanager**: http://localhost:9093\n';
              readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
              readmeContent += '- **Node Exporter**: http://localhost:9100\n';
              readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
              readmeContent += '## Personalización\n\n';
              readmeContent += '### Prometheus\n\n';
              readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
              readmeContent += '### Alertmanager\n\n';
              readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
              readmeContent += '### Grafana\n\n';
              readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/dashboard.yml` si es necesario.\n';

              // Escribir README.md
              fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);

              // Crear directorio para ELK stack (opcional)
              if (config.monitoring && config.monitoring.includeELK) {
                const elkDir = path.join(monitoringDir, 'elk');
                if (!fs.existsSync(elkDir)) {
                  fs.mkdirSync(elkDir, { recursive: true });
                }

                // Crear docker-compose.yml para ELK stack
                let elkComposeContent = 'version: "3.8"\n\n';
                elkComposeContent += 'services:\n';
                elkComposeContent += '  elasticsearch:\n';
                elkComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
                elkComposeContent += '    environment:\n';
                elkComposeContent += '      - discovery.type=single-node\n';
                elkComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
                elkComposeContent += '    volumes:\n';
                elkComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
                elkComposeContent += '    ports:\n';
                elkComposeContent += '      - "9200:9200"\n';
                elkComposeContent += '      - "9300:9300"\n';
                elkComposeContent += '    networks:\n';
                elkComposeContent += '      - elk-network\n';
                elkComposeContent += '    restart: unless-stopped\n\n';
                
                elkComposeContent += '  logstash:\n';
                elkComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
                elkComposeContent += '    volumes:\n';
                elkComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
                elkComposeContent += '    ports:\n';
                elkComposeContent += '      - "5000:5000"\n';
                elkComposeContent += '      - "9600:9600"\n';
                elkComposeContent += '    environment:\n';
                elkComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
                elkComposeContent += '    networks:\n';
                elkComposeContent += '      - elk-network\n';
                elkComposeContent += '    depends_on:\n';
                elkComposeContent += '      - elasticsearch\n';
                elkComposeContent += '    restart: unless-stopped\n\n';
                
                elkComposeContent += '  kibana:\n';
                elkComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
                elkComposeContent += '    ports:\n';
                elkComposeContent += '      - "5601:5601"\n';
                elkComposeContent += '    environment:\n';
                elkComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
                elkComposeContent += '    networks:\n';
                elkComposeContent += '      - elk-network\n';
                elkComposeContent += '    depends_on:\n';
                elkComposeContent += '      - elasticsearch\n';
                elkComposeContent += '    restart: unless-stopped\n\n';
                
                elkComposeContent += '  filebeat:\n';
                elkComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
                elkComposeContent += '    user: root\n';
                elkComposeContent += '    volumes:\n';
                elkComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
                elkComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
                elkComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
                elkComposeContent += '    networks:\n';
                elkComposeContent += '      - elk-network\n';
                elkComposeContent += '    depends_on:\n';
                elkComposeContent += '      - elasticsearch\n';
                elkComposeContent += '      - logstash\n';
                elkComposeContent += '    restart: unless-stopped\n\n';
                
                elkComposeContent += 'networks:\n';
                elkComposeContent += '  elk-network:\n';
                elkComposeContent += '    driver: bridge\n\n';
                
                elkComposeContent += 'volumes:\n';
                elkComposeContent += '  elasticsearch_data:\n';
                elkComposeContent += '    driver: local\n';

                // Escribir docker-compose.yml para ELK stack
                fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), elkComposeContent);

                // Crear directorios adicionales para ELK
                const logstashDir = path.join(elkDir, 'logstash');
                if (!fs.existsSync(logstashDir)) {
                  fs.mkdirSync(logstashDir, { recursive: true });
                }

                const pipelineDir = path.join(logstashDir, 'pipeline');
                if (!fs.existsSync(pipelineDir)) {
                  fs.mkdirSync(pipelineDir, { recursive: true });
                }

                // Crear logstash.conf
                let logstashConfContent = 'input {\n';
                logstashConfContent += '  beats {\n';
                logstashConfContent += '    port => 5000\n';
                logstashConfContent += '  }\n';
                logstashConfContent += '}\n\n';
                logstashConfContent += 'filter {\n';
                logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
                logstashConfContent += '    mutate {\n';
                logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
                logstashConfContent += '    }\n';
                logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
                logstashConfContent += '    mutate {\n';
                logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
                logstashConfContent += '    }\n';
                logstashConfContent += '  } else {\n';
                logstashConfContent += '    mutate {\n';
                logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
                logstashConfContent += '    }\n';
                logstashConfContent += '  }\n';
                logstashConfContent += '}\n\n';
                logstashConfContent += 'output {\n';
                logstashConfContent += '  elasticsearch {\n';
                logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
                logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
                logstashConfContent += '    manage_template => false\n';
                logstashConfContent += '  }\n';
                logstashConfContent += '}\n';

                // Escribir logstash.conf
                fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);

                // Crear directorio para Filebeat
                const filebeatDir = path.join(elkDir, 'filebeat');
                if (!fs.existsSync(filebeatDir)) {
                  fs.mkdirSync(filebeatDir, { recursive: true });
                }

                // Crear filebeat.yml
                let filebeatContent = 'filebeat.inputs:\n';
                filebeatContent += '- type: container\n';
                filebeatContent += '  paths:\n';
                filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
                filebeatContent += '  processors:\n';
                filebeatContent += '    - add_docker_metadata: ~\n\n';
                filebeatContent += 'processors:\n';
                filebeatContent += '  - add_host_metadata: ~\n';
                filebeatContent += '  - add_cloud_metadata: ~\n\n';
                filebeatContent += 'output.logstash:\n';
                filebeatContent += '  hosts: ["logstash:5000"]\n';

                // Escribir filebeat.yml
                fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);

                // Crear README.md para ELK
                let elkReadmeContent = '# ELK Stack para Logging\n\n';
                elkReadmeContent += 'Este directorio contiene la configuración para un stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat para la recolección y análisis de logs.\n\n';
                elkReadmeContent += '## Componentes\n\n';
                elkReadmeContent += '- **Elasticsearch**: Motor de búsqueda y análisis\n';
                elkReadmeContent += '- **Logstash**: Procesamiento de datos y logs\n';
                elkReadmeContent += '- **Kibana**: Visualización de datos\n';
                elkReadmeContent += '- **Filebeat**: Recolector de logs\n\n';
                elkReadmeContent += '## Inicio Rápido\n\n';
                elkReadmeContent += '```bash\n';
                elkReadmeContent += '# Iniciar el stack ELK\n';
                elkReadmeContent += 'docker-compose up -d\n';
                elkReadmeContent += '```\n\n';
                elkReadmeContent += '## Acceso\n\n';
                elkReadmeContent += '- **Elasticsearch**: http://localhost:9200\n';
                elkReadmeContent += '- **Kibana**: http://localhost:5601\n';
                elkReadmeContent += '- **Logstash**: http://localhost:9600\n\n';
                elkReadmeContent += '## Personalización\n\n';
                elkReadmeContent += '### Logstash\n\n';
                elkReadmeContent += 'Edita `logstash/pipeline/logstash.conf` para modificar el procesamiento de logs.\n\n';
                elkReadmeContent += '### Filebeat\n\n';
                elkReadmeContent += 'Edita `filebeat/filebeat.yml` para configurar la recolección de logs.\n';

                // Escribir README.md para ELK
                fs.writeFileSync(path.join(elkDir, 'README.md'), elkReadmeContent);
              }

              return monitoringDir;
            } catch (error) {
              console.error('Error al crear archivos de monitoreo:', error);
              throw error;
            }
          }

          /**
           * Crea archivos de configuración para seguridad
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de seguridad
           */
          async createSecurityFiles(projectDir, config) {
            try {
              const securityDir = path.join(projectDir, 'security');
              if (!fs.existsSync(securityDir)) {
                fs.mkdirSync(securityDir, { recursive: true });
              }

              // Crear directorio para análisis de seguridad
              const scanDir = path.join(securityDir, 'scans');
              if (!fs.existsSync(scanDir)) {
                fs.mkdirSync(scanDir, { recursive: true });
              }

              // Crear docker-compose.yml para herramientas de seguridad
              let securityComposeContent = 'version: "3.8"\n\n';
              securityComposeContent += 'services:\n';
              securityComposeContent += '  owasp-zap:\n';
              securityComposeContent += '    image: owasp/zap2docker-stable\n';
              securityComposeContent += '    command: zap-baseline.py -t https://example.com -g gen.conf -r owasp-report.html\n';
              securityComposeContent += '    volumes:\n';
              securityComposeContent += '      - ./scans:/zap/wrk/:rw\n';
              securityComposeContent += '    environment:\n';
              securityComposeContent += '      - ZAP_PORT=8080\n';
              securityComposeContent += '    ports:\n';
              securityComposeContent += '      - "8080:8080"\n\n';
              
              securityComposeContent += '  sonarqube:\n';
              securityComposeContent += '    image: sonarqube:latest\n';
              securityComposeContent += '    ports:\n';
              securityComposeContent += '      - "9000:9000"\n';
              securityComposeContent += '    environment:\n';
              securityComposeContent += '      - SONARQUBE_JDBC_URL=jdbc:postgresql://sonarqube-db:5432/sonar\n';
              securityComposeContent += '      - SONARQUBE_JDBC_USERNAME=sonar\n';
              securityComposeContent += '      - SONARQUBE_JDBC_PASSWORD=sonar\n';
              securityComposeContent += '    volumes:\n';
              securityComposeContent += '      - sonarqube_data:/opt/sonarqube/data\n';
              securityComposeContent += '      - sonarqube_extensions:/opt/sonarqube/extensions\n';
              securityComposeContent += '      - sonarqube_logs:/opt/sonarqube/logs\n';
              securityComposeContent += '    depends_on:\n';
              securityComposeContent += '      - sonarqube-db\n\n';
              
              securityComposeContent += '  sonarqube-db:\n';
              securityComposeContent += '    image: postgres:13\n';
              securityComposeContent += '    environment:\n';
              securityComposeContent += '      - POSTGRES_USER=sonar\n';
              securityComposeContent += '      - POSTGRES_PASSWORD=sonar\n';
              securityComposeContent += '      - POSTGRES_DB=sonar\n';
              securityComposeContent += '    volumes:\n';
              securityComposeContent += '      - sonarqube_db:/var/lib/postgresql/data\n\n';
              
              securityComposeContent += '  trivy:\n';
              securityComposeContent += '    image: aquasec/trivy:latest\n';
              securityComposeContent += '    volumes:\n';
              securityComposeContent += '      - ./scans:/scans\n';
              securityComposeContent += '    command: image --format json --output /scans/trivy-results.json myorg/myapp:latest\n\n';
              
              securityComposeContent += 'volumes:\n';
              securityComposeContent += '  sonarqube_data:\n';
              securityComposeContent += '  sonarqube_extensions:\n';
              securityComposeContent += '  sonarqube_logs:\n';
              securityComposeContent += '  sonarqube_db:\n';

              // Escribir docker-compose.yml
              fs.writeFileSync(path.join(securityDir, 'docker-compose.yml'), securityComposeContent);

              // Crear sonar-project.properties
              let sonarPropertiesContent = '# Información del proyecto\n';
              sonarPropertiesContent += `sonar.projectKey=${config.projectName || 'my-project'}\n`;
              sonarPropertiesContent += `sonar.projectName=${config.projectName || 'My Project'}\n`;
              sonarPropertiesContent += 'sonar.projectVersion=1.0.0\n\n';
              sonarPropertiesContent += '# Ruta al código fuente\n';
              sonarPropertiesContent += 'sonar.sources=src\n\n';
              sonarPropertiesContent += '# Exclusiones\n';
              sonarPropertiesContent += 'sonar.exclusions=**/node_modules/**,**/*.spec.ts,**/*.test.ts,**/dist/**,**/coverage/**\n\n';
              sonarPropertiesContent += '# Cobertura de código\n';
              sonarPropertiesContent += 'sonar.javascript.lcov.reportPaths=coverage/lcov.info\n';

              // Escribir sonar-project.properties
              fs.writeFileSync(path.join(securityDir, 'sonar-project.properties'), sonarPropertiesContent);

              // Crear script de análisis de seguridad
              let securityScanScriptContent = '#!/bin/bash\n\n';
              securityScanScriptContent += '# Script para ejecutar análisis de seguridad\n\n';
              securityScanScriptContent += 'echo "Iniciando análisis de seguridad..."\n\n';
              securityScanScriptContent += '# Ejecutar SonarQube\n';
              securityScanScriptContent += 'echo "Ejecutando análisis con SonarQube..."\n';
              securityScanScriptContent += 'docker-compose -f security/docker-compose.yml up -d sonarqube sonarqube-db\n';
              securityScanScriptContent += 'sleep 30  # Esperar a que SonarQube esté listo\n';
              securityScanScriptContent += 'sonar-scanner -Dsonar.host.url=http://localhost:9000 -Dsonar.login=admin -Dsonar.password=admin\n\n';
              securityScanScriptContent += '# Ejecutar Trivy para escaneo de vulnerabilidades en imágenes\n';
              securityScanScriptContent += 'echo "Escaneando imágenes Docker con Trivy..."\n';
              securityScanScriptContent += 'docker-compose -f security/docker-compose.yml run --rm trivy\n\n';
              securityScanScriptContent += '# Ejecutar OWASP ZAP para análisis de aplicación web\n';
              securityScanScriptContent += 'echo "Ejecutando análisis con OWASP ZAP..."\n';
              securityScanScriptContent += 'docker-compose -f security/docker-compose.yml run --rm owasp-zap\n\n';
              securityScanScriptContent += 'echo "Análisis de seguridad completado. Revisa los resultados en el directorio security/scans"\n';

              // Escribir script de análisis de seguridad
              fs.writeFileSync(path.join(securityDir, 'run-security-scan.sh'), securityScanScriptContent);
              // Hacer ejecutable el script
              fs.chmodSync(path.join(securityDir, 'run-security-scan.sh'), '755');

              // Crear script de análisis de seguridad para Windows
              let securityScanScriptWindowsContent = '@echo off\n\n';
              securityScanScriptWindowsContent += 'REM Script para ejecutar análisis de seguridad en Windows\n\n';
              securityScanScriptWindowsContent += 'echo Iniciando análisis de seguridad...\n\n';
              securityScanScriptWindowsContent += 'REM Ejecutar SonarQube\n';
              securityScanScriptWindowsContent += 'echo Ejecutando análisis con SonarQube...\n';
              securityScanScriptWindowsContent += 'docker-compose -f security\\docker-compose.yml up -d sonarqube sonarqube-db\n';
              securityScanScriptWindowsContent += 'timeout /t 30 /nobreak > nul\n';
              securityScanScriptWindowsContent += 'sonar-scanner -Dsonar.host.url=http://localhost:9000 -Dsonar.login=admin -Dsonar.password=admin\n\n';
              securityScanScriptWindowsContent += 'REM Ejecutar Trivy para escaneo de vulnerabilidades en imágenes\n';
              securityScanScriptWindowsContent += 'echo Escaneando imágenes Docker con Trivy...\n';
              securityScanScriptWindowsContent += 'docker-compose -f security\\docker-compose.yml run --rm trivy\n\n';
              securityScanScriptWindowsContent += 'REM Ejecutar OWASP ZAP para análisis de aplicación web\n';
              securityScanScriptWindowsContent += 'echo Ejecutando análisis con OWASP ZAP...\n';
              securityScanScriptWindowsContent += 'docker-compose -f security\\docker-compose.yml run --rm owasp-zap\n\n';
              securityScanScriptWindowsContent += 'echo Análisis de seguridad completado. Revisa los resultados en el directorio security\\scans\n';

              // Escribir script de análisis de seguridad para Windows
              fs.writeFileSync(path.join(securityDir, 'run-security-scan.bat'), securityScanScriptWindowsContent);

              // Crear guía de seguridad
              let securityGuideContent = '# Guía de Seguridad\n\n';
              securityGuideContent += '## Introducción\n\n';
              securityGuideContent += 'Esta guía proporciona recomendaciones y mejores prácticas para mantener la seguridad del proyecto.\n\n';
              securityGuideContent += '## Análisis de Seguridad\n\n';
              securityGuideContent += '### SonarQube\n\n';
              securityGuideContent += 'SonarQube es una plataforma para el análisis estático de código que detecta bugs, vulnerabilidades y code smells.\n\n';
              securityGuideContent += '1. Inicia SonarQube:\n';
              securityGuideContent += '```bash\n';
              securityGuideContent += 'docker-compose -f security/docker-compose.yml up -d sonarqube sonarqube-db\n';
              securityGuideContent += '```\n\n';
              securityGuideContent += '2. Accede a la interfaz web: http://localhost:9000 (usuario: admin, contraseña: admin)\n\n';
              securityGuideContent += '3. Ejecuta el análisis:\n';
              securityGuideContent += '```bash\n';
              securityGuideContent += 'sonar-scanner\n';
              securityGuideContent += '```\n\n';
              securityGuideContent += '### Trivy\n\n';
              securityGuideContent += 'Trivy es un escáner de vulnerabilidades para imágenes de contenedores.\n\n';
              securityGuideContent += '```bash\n';
              securityGuideContent += 'docker-compose -f security/docker-compose.yml run --rm trivy\n';
              securityGuideContent += '```\n\n';
              securityGuideContent += '### OWASP ZAP\n\n';
              securityGuideContent += 'OWASP ZAP (Zed Attack Proxy) es una herramienta para encontrar vulnerabilidades en aplicaciones web.\n\n';
              securityGuideContent += '```bash\n';
              securityGuideContent += 'docker-compose -f security/docker-compose.yml run --rm owasp-zap\n';
              securityGuideContent += '```\n\n';
              securityGuideContent += '## Mejores Prácticas de Seguridad\n\n';
              securityGuideContent += '### Gestión de Dependencias\n\n';
              securityGuideContent += '- Mantén todas las dependencias actualizadas\n';
              securityGuideContent += '- Utiliza herramientas como npm audit o yarn audit para verificar vulnerabilidades\n';
              securityGuideContent += '- Considera usar Dependabot para actualizaciones automáticas\n\n';
              securityGuideContent += '### Secretos y Credenciales\n\n';
              securityGuideContent += '- Nunca almacenes secretos o credenciales en el código fuente\n';
              securityGuideContent += '- Utiliza variables de entorno o servicios de gestión de secretos\n';
              securityGuideContent += '- Considera usar herramientas como HashiCorp Vault o AWS Secrets Manager\n\n';
              securityGuideContent += '### Seguridad en el Código\n\n';
              securityGuideContent += '- Valida todas las entradas de usuario\n';
              securityGuideContent += '- Implementa protección contra ataques comunes (XSS, CSRF, inyección SQL)\n';
              securityGuideContent += '- Utiliza HTTPS para todas las comunicaciones\n';
              securityGuideContent += '- Implementa autenticación y autorización adecuadas\n\n';
              securityGuideContent += '### Contenedores\n\n';
              securityGuideContent += '- Utiliza imágenes base mínimas (alpine, slim)\n';
              securityGuideContent += '- No ejecutes contenedores como root\n';
              securityGuideContent += '- Escanea regularmente las imágenes en busca de vulnerabilidades\n\n';
              securityGuideContent += '## Recursos Adicionales\n\n';
              securityGuideContent += '- [OWASP Top 10](https://owasp.org/www-project-top-ten/)\n';
              securityGuideContent += '- [SANS Security Checklist](https://www.sans.org/security-resources/)\n';
              securityGuideContent += '- [Mozilla Web Security Guidelines](https://infosec.mozilla.org/guidelines/web_security)\n';

              // Escribir guía de seguridad
              fs.writeFileSync(path.join(securityDir, 'SECURITY_GUIDE.md'), securityGuideContent);

              // Crear README.md
              let readmeContent = '# Seguridad\n\n';
              readmeContent += 'Este directorio contiene herramientas y configuraciones para garantizar la seguridad del proyecto.\n\n';
              readmeContent += '## Contenido\n\n';
              readmeContent += '- `docker-compose.yml`: Configuración para herramientas de seguridad (SonarQube, OWASP ZAP, Trivy)\n';
              readmeContent += '- `sonar-project.properties`: Configuración para análisis con SonarQube\n';
              readmeContent += '- `run-security-scan.sh` / `run-security-scan.bat`: Scripts para ejecutar análisis de seguridad\n';
              readmeContent += '- `SECURITY_GUIDE.md`: Guía con mejores prácticas de seguridad\n';
              readmeContent += '- `scans/`: Directorio donde se almacenan los resultados de los análisis\n\n';
              readmeContent += '## Uso\n\n';
              readmeContent += '### Ejecutar análisis completo\n\n';
              readmeContent += '```bash\n';
              readmeContent += '# En Linux/macOS\n';
              readmeContent += './run-security-scan.sh\n\n';
              readmeContent += '# En Windows\n';
              readmeContent += 'run-security-scan.bat\n';
              readmeContent += '```\n\n';
              readmeContent += '### Ejecutar herramientas individuales\n\n';
              readmeContent += '```bash\n';
              readmeContent += '# SonarQube\n';
              readmeContent += 'docker-compose -f docker-compose.yml up -d sonarqube sonarqube-db\n';
              readmeContent += 'sonar-scanner\n\n';
              readmeContent += '# Trivy\n';
              readmeContent += 'docker-compose -f docker-compose.yml run --rm trivy\n\n';
              readmeContent += '# OWASP ZAP\n';
              readmeContent += 'docker-compose -f docker-compose.yml run --rm owasp-zap\n';
              readmeContent += '```\n\n';
              readmeContent += '## Integración con CI/CD\n\n';
              readmeContent += 'Para integrar estos análisis en tu pipeline de CI/CD, puedes ejecutar los scripts en las etapas correspondientes.\n\n';
              readmeContent += '### Ejemplo en GitHub Actions\n\n';
              readmeContent += '```yaml\n';
              readmeContent += 'security-scan:\n';
              readmeContent += '  runs-on: ubuntu-latest\n';
              readmeContent += '  steps:\n';
              readmeContent += '  - uses: actions/checkout@v2\n';
              readmeContent += '  - name: Run security scan\n';
              readmeContent += '    run: ./security/run-security-scan.sh\n';
              readmeContent += '```\n';

              // Escribir README.md
              fs.writeFileSync(path.join(securityDir, 'README.md'), readmeContent);

              return securityDir;
            } catch (error) {
              console.error('Error al crear archivos de seguridad:', error);
              throw error;
            }
          }

          /**
           * Crea archivos de configuración para documentación
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de documentación
           */
          async createDocumentationFiles(projectDir, config) {
            try {
              const docsDir = path.join(projectDir, 'docs');
              if (!fs.existsSync(docsDir)) {
                fs.mkdirSync(docsDir, { recursive: true });
              }

              // Crear estructura de directorios para la documentación
              const architectureDir = path.join(docsDir, 'architecture');
              if (!fs.existsSync(architectureDir)) {
                fs.mkdirSync(architectureDir, { recursive: true });
              }

              const apiDir = path.join(docsDir, 'api');
              if (!fs.existsSync(apiDir)) {
                fs.mkdirSync(apiDir, { recursive: true });
              }

              const userGuideDir = path.join(docsDir, 'user-guide');
              if (!fs.existsSync(userGuideDir)) {
                fs.mkdirSync(userGuideDir, { recursive: true });
              }

              const devGuideDir = path.join(docsDir, 'dev-guide');
              if (!fs.existsSync(devGuideDir)) {
                fs.mkdirSync(devGuideDir, { recursive: true });
              }

              // Crear README.md principal
              let mainReadmeContent = `# Documentación de ${config.projectName || 'Mi Proyecto'}\n\n`;
              mainReadmeContent += 'Esta carpeta contiene toda la documentación del proyecto.\n\n';
              mainReadmeContent += '## Estructura\n\n';
              mainReadmeContent += '- `architecture/`: Documentación de la arquitectura del sistema\n';
              mainReadmeContent += '- `api/`: Documentación de la API\n';
              mainReadmeContent += '- `user-guide/`: Guía de usuario\n';
              mainReadmeContent += '- `dev-guide/`: Guía para desarrolladores\n\n';
              mainReadmeContent += '## Generación de Documentación\n\n';
              mainReadmeContent += 'Para generar la documentación, ejecuta:\n\n';
              mainReadmeContent += '```bash\n';
              mainReadmeContent += 'npm run docs\n';
              mainReadmeContent += '```\n\n';
              mainReadmeContent += 'La documentación generada estará disponible en `docs/build/`.\n';

              // Escribir README.md principal
              fs.writeFileSync(path.join(docsDir, 'README.md'), mainReadmeContent);

              // Crear documentación de arquitectura
              let architectureContent = '# Arquitectura del Sistema\n\n';
              architectureContent += '## Visión General\n\n';
              architectureContent += 'Este documento describe la arquitectura general del sistema, incluyendo componentes, interacciones y decisiones de diseño.\n\n';
              architectureContent += '## Componentes Principales\n\n';
              
              if (config.projectType === 'fullstack' || config.projectType === 'web') {
                architectureContent += '### Frontend\n\n';
                architectureContent += '- **Tecnología**: React/Vue/Angular\n';
                architectureContent += '- **Responsabilidad**: Interfaz de usuario y experiencia de usuario\n';
                architectureContent += '- **Estructura**:\n';
                architectureContent += '  - `components/`: Componentes reutilizables\n';
                architectureContent += '  - `pages/`: Páginas de la aplicación\n';
                architectureContent += '  - `services/`: Servicios para comunicación con el backend\n';
                architectureContent += '  - `store/`: Gestión del estado (Redux/Vuex/NgRx)\n\n';
              }
              
              if (config.projectType === 'fullstack' || config.projectType === 'api') {
                architectureContent += '### Backend\n\n';
                architectureContent += '- **Tecnología**: Node.js/Express/NestJS\n';
                architectureContent += '- **Responsabilidad**: Lógica de negocio y acceso a datos\n';
                architectureContent += '- **Estructura**:\n';
                architectureContent += '  - `controllers/`: Manejo de peticiones HTTP\n';
                architectureContent += '  - `services/`: Lógica de negocio\n';
                architectureContent += '  - `models/`: Definición de modelos de datos\n';
                architectureContent += '  - `repositories/`: Acceso a la base de datos\n';
                architectureContent += '  - `middlewares/`: Funciones intermedias para procesamiento de peticiones\n\n';
              }
              
              architectureContent += '### Base de Datos\n\n';
              architectureContent += '- **Tecnología**: PostgreSQL/MongoDB/MySQL\n';
              architectureContent += '- **Responsabilidad**: Almacenamiento persistente de datos\n';
              architectureContent += '- **Esquema**: [Descripción del esquema de la base de datos]\n\n';
              
              architectureContent += '## Diagrama de Arquitectura\n\n';
              architectureContent += '```\n';
              architectureContent += '┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n';
              architectureContent += '│             │     │             │     │             │\n';
              architectureContent += '│   Cliente   │────▶│   Backend   │────▶│ Base de Datos │\n';
              architectureContent += '│             │     │             │     │             │\n';
              architectureContent += '└─────────────┘     └─────────────┘     └─────────────┘\n';
              architectureContent += '```\n\n';
              
              architectureContent += '## Flujo de Datos\n\n';
              architectureContent += '1. El cliente realiza una petición HTTP al backend\n';
              architectureContent += '2. El backend procesa la petición a través de middlewares\n';
              architectureContent += '3. El controlador correspondiente recibe la petición\n';
              architectureContent += '4. El servicio ejecuta la lógica de negocio\n';
              architectureContent += '5. El repositorio interactúa con la base de datos\n';
              architectureContent += '6. La respuesta sigue el camino inverso hasta el cliente\n\n';
              
              architectureContent += '## Decisiones de Arquitectura\n\n';
              architectureContent += '### Patrón de Arquitectura\n\n';
              architectureContent += 'Se ha elegido una arquitectura en capas para separar claramente las responsabilidades:\n\n';
              architectureContent += '- **Capa de Presentación**: Interfaz de usuario\n';
              architectureContent += '- **Capa de Aplicación**: Lógica de negocio\n';
              architectureContent += '- **Capa de Datos**: Acceso y persistencia de datos\n\n';
              
              architectureContent += '### Comunicación entre Componentes\n\n';
              architectureContent += 'La comunicación entre el frontend y el backend se realiza mediante una API RESTful.\n\n';
              
              architectureContent += '### Escalabilidad\n\n';
              architectureContent += 'La arquitectura está diseñada para escalar horizontalmente mediante la adición de más instancias de los servicios.\n\n';
              
              architectureContent += '## Consideraciones de Seguridad\n\n';
              architectureContent += '- Autenticación mediante JWT\n';
              architectureContent += '- Autorización basada en roles\n';
              architectureContent += '- Validación de entradas\n';
              architectureContent += '- Protección contra ataques comunes (XSS, CSRF, inyección SQL)\n';

              // Escribir documentación de arquitectura
              fs.writeFileSync(path.join(architectureDir, 'overview.md'), architectureContent);

              // Crear documentación de API
              let apiDocContent = '# Documentación de la API\n\n';
              apiDocContent += '## Introducción\n\n';
              apiDocContent += 'Esta documentación describe los endpoints disponibles en la API, sus parámetros y respuestas.\n\n';
              apiDocContent += '## Base URL\n\n';
              apiDocContent += '```\n';
              apiDocContent += 'https://api.example.com/v1\n';
              apiDocContent += '```\n\n';
              apiDocContent += '## Autenticación\n\n';
              apiDocContent += 'La API utiliza autenticación mediante tokens JWT. Para autenticarte, incluye el token en el encabezado de la petición:\n\n';
              apiDocContent += '```\n';
              apiDocContent += 'Authorization: Bearer <token>\n';
              apiDocContent += '```\n\n';
              apiDocContent += '## Endpoints\n\n';
              apiDocContent += '### Usuarios\n\n';
              apiDocContent += '#### Obtener todos los usuarios\n\n';
              apiDocContent += '```\n';
              apiDocContent += 'GET /users\n';
              apiDocContent += '```\n\n';
              apiDocContent += 'Parámetros de consulta:\n\n';
              apiDocContent += '| Parámetro | Tipo | Descripción |\n';
              apiDocContent += '|-----------|------|-------------|\n';
              apiDocContent += '| page | number | Número de página |\n';
              apiDocContent += '| limit | number | Elementos por página |\n\n';
              apiDocContent += 'Respuesta:\n\n';
              apiDocContent += '```json\n';
              apiDocContent += '{\n';
              apiDocContent += '  "data": [\n';
              apiDocContent += '    {\n';
              apiDocContent += '      "id": 1,\n';
              apiDocContent += '      "name": "John Doe",\n';
              apiDocContent += '      "email": "john@example.com",\n';
              apiDocContent += '      "createdAt": "2023-01-01T00:00:00Z"\n';
              apiDocContent += '    },\n';
              apiDocContent += '    // ...\n';
              apiDocContent += '  ],\n';
              apiDocContent += '  "meta": {\n';
              apiDocContent += '    "total": 100,\n';
              apiDocContent += '    "page": 1,\n';
              apiDocContent += '    "limit": 10,\n';
              apiDocContent += '    "pages": 10\n';
              apiDocContent += '  }\n';
              apiDocContent += '}\n';
              apiDocContent += '```\n\n';
              apiDocContent += '#### Obtener un usuario por ID\n\n';
              apiDocContent += '```\n';
              apiDocContent += 'GET /users/:id\n';
              apiDocContent += '```\n\n';
              apiDocContent += 'Parámetros de ruta:\n\n';
              apiDocContent += '| Parámetro | Tipo | Descripción |\n';
              apiDocContent += '|-----------|------|-------------|\n';
              apiDocContent += '| id | number | ID del usuario |\n\n';
              apiDocContent += 'Respuesta:\n\n';
              apiDocContent += '```json\n';
              apiDocContent += '{\n';
              apiDocContent += '  "id": 1,\n';
              apiDocContent += '  "name": "John Doe",\n';
              apiDocContent += '  "email": "john@example.com",\n';
              apiDocContent += '  "createdAt": "2023-01-01T00:00:00Z"\n';
              apiDocContent += '}\n';
              apiDocContent += '```\n\n';
              apiDocContent += '#### Crear un usuario\n\n';
              apiDocContent += '```\n';
              apiDocContent += 'POST /users\n';
              apiDocContent += '```\n\n';
              apiDocContent += 'Cuerpo de la petición:\n\n';
              apiDocContent += '```json\n';
              apiDocContent += '{\n';
              apiDocContent += '  "name": "Jane Doe",\n';
              apiDocContent += '  "email": "jane@example.com",\n';
              apiDocContent += '  "password": "securepassword"\n';
              apiDocContent += '}\n';
              apiDocContent += '```\n\n';
              apiDocContent += 'Respuesta:\n\n';
              apiDocContent += '```json\n';
              apiDocContent += '{\n';
              apiDocContent += '  "id": 2,\n';
              apiDocContent += '  "name": "Jane Doe",\n';
              apiDocContent += '  "email": "jane@example.com",\n';
              apiDocContent += '  "createdAt": "2023-01-02T00:00:00Z"\n';
              apiDocContent += '}\n';
              apiDocContent += '```\n\n';
              apiDocContent += '### Productos\n\n';
              apiDocContent += '#### Obtener todos los productos\n\n';
              apiDocContent += '```\n';
              apiDocContent += 'GET /products\n';
              apiDocContent += '```\n\n';
              apiDocContent += 'Parámetros de consulta:\n\n';
              apiDocContent += '| Parámetro | Tipo | Descripción |\n';
              apiDocContent += '|-----------|------|-------------|\n';
              apiDocContent += '| page | number | Número de página |\n';
              apiDocContent += '| limit | number | Elementos por página |\n';
              apiDocContent += '| category | string | Filtrar por categoría |\n\n';
              apiDocContent += 'Respuesta:\n\n';
              apiDocContent += '```json\n';
              apiDocContent += '{\n';
              apiDocContent += '  "data": [\n';
              apiDocContent += '    {\n';
              apiDocContent += '      "id": 1,\n';
              apiDocContent += '      "name": "Producto 1",\n';
              apiDocContent += '      "price": 19.99,\n';
              apiDocContent += '      "category": "electronics",\n';
              apiDocContent += '      "createdAt": "2023-01-01T00:00:00Z"\n';
              apiDocContent += '    },\n';
              apiDocContent += '    // ...\n';
              apiDocContent += '  ],\n';
              apiDocContent += '  "meta": {\n';
              apiDocContent += '    "total": 50,\n';
              apiDocContent += '    "page": 1,\n';
              apiDocContent += '    "limit": 10,\n';
              apiDocContent += '    "pages": 5\n';
              apiDocContent += '  }\n';
              apiDocContent += '}\n';
              apiDocContent += '```\n\n';
              apiDocContent += '## Códigos de Estado\n\n';
              apiDocContent += '| Código | Descripción |\n';
              apiDocContent += '|--------|-------------|\n';
              apiDocContent += '| 200 | OK - La petición se ha completado correctamente |\n';
              apiDocContent += '| 201 | Created - Se ha creado un nuevo recurso |\n';
              apiDocContent += '| 400 | Bad Request - La petición es inválida |\n';
              apiDocContent += '| 401 | Unauthorized - No autenticado |\n';
              apiDocContent += '| 403 | Forbidden - No autorizado |\n';
              apiDocContent += '| 404 | Not Found - Recurso no encontrado |\n';
              apiDocContent += '| 500 | Internal Server Error - Error del servidor |\n\n';
              apiDocContent += '## Manejo de Errores\n\n';
              apiDocContent += 'Los errores se devuelven en el siguiente formato:\n\n';
              apiDocContent += '```json\n';
              apiDocContent += '{\n';
              apiDocContent += '  "error": {\n';
              apiDocContent += '    "code": "ERROR_CODE",\n';
              apiDocContent += '    "message": "Descripción del error",\n';
              apiDocContent += '    "details": {}\n';
              apiDocContent += '  }\n';
              apiDocContent += '}\n';
              apiDocContent += '```\n\n';
              apiDocContent += '## Limitación de Tasa\n\n';
              apiDocContent += 'La API tiene un límite de 100 peticiones por minuto por IP. Si excedes este límite, recibirás un código de estado 429 (Too Many Requests).\n\n';
              apiDocContent += '## Versionado\n\n';
              apiDocContent += 'La API está versionada en la URL. La versión actual es v1.\n';

              // Escribir documentación de API
              fs.writeFileSync(path.join(apiDir, 'api-reference.md'), apiDocContent);

              // Crear guía de usuario
              let userGuideContent = '# Guía de Usuario\n\n';
              userGuideContent += '## Introducción\n\n';
              userGuideContent += `Bienvenido a la guía de usuario de ${config.projectName || 'Mi Proyecto'}. Esta guía te ayudará a entender cómo utilizar la aplicación.\n\n`;
              userGuideContent += '## Requisitos del Sistema\n\n';
              userGuideContent += '- Navegador web moderno (Chrome, Firefox, Safari, Edge)\n';
              userGuideContent += '- Conexión a Internet\n';
              userGuideContent += '- Resolución mínima de pantalla: 1280x720\n\n';
              userGuideContent += '## Instalación\n\n';
              userGuideContent += '### Aplicación Web\n\n';
              userGuideContent += 'No se requiere instalación. Simplemente accede a la aplicación a través de la URL proporcionada.\n\n';
              userGuideContent += '### Aplicación Móvil\n\n';
              userGuideContent += '1. Descarga la aplicación desde la App Store (iOS) o Google Play Store (Android)\n';
              userGuideContent += '2. Instala la aplicación siguiendo las instrucciones en pantalla\n';
              userGuideContent += '3. Abre la aplicación una vez instalada\n\n';
              userGuideContent += '## Primeros Pasos\n\n';
              userGuideContent += '### Registro\n\n';
              userGuideContent += '1. Accede a la página de registro\n';
              userGuideContent += '2. Completa el formulario con tu información personal\n';
              userGuideContent += '3. Haz clic en "Registrarse"\n';
              userGuideContent += '4. Verifica tu correo electrónico haciendo clic en el enlace enviado\n\n';
              userGuideContent += '### Inicio de Sesión\n\n';
              userGuideContent += '1. Accede a la página de inicio de sesión\n';
              userGuideContent += '2. Ingresa tu correo electrónico y contraseña\n';
              userGuideContent += '3. Haz clic en "Iniciar Sesión"\n\n';
              userGuideContent += '## Funcionalidades Principales\n\n';
              userGuideContent += '### Navegación\n\n';
              userGuideContent += 'La aplicación está organizada en las siguientes secciones principales:\n\n';
              userGuideContent += '- **Inicio**: Resumen de la actividad reciente\n';
              userGuideContent += '- **Perfil**: Gestión de tu información personal\n';
              userGuideContent += '- **Productos**: Exploración y gestión de productos\n';
              userGuideContent += '- **Configuración**: Ajustes de la aplicación\n\n';
              userGuideContent += '### Gestión de Perfil\n\n';
              userGuideContent += '1. Accede a la sección "Perfil"\n';
              userGuideContent += '2. Haz clic en "Editar Perfil" para modificar tu información\n';
              userGuideContent += '3. Actualiza los campos necesarios\n';
              userGuideContent += '4. Haz clic en "Guardar Cambios"\n\n';
              userGuideContent += '### Gestión de Productos\n\n';
              userGuideContent += '#### Crear un Producto\n\n';
              userGuideContent += '1. Accede a la sección "Productos"\n';
              userGuideContent += '2. Haz clic en "Nuevo Producto"\n';
              userGuideContent += '3. Completa el formulario con la información del producto\n';
              userGuideContent += '4. Haz clic en "Crear Producto"\n\n';
              userGuideContent += '#### Editar un Producto\n\n';
              userGuideContent += '1. Accede a la sección "Productos"\n';
              userGuideContent += '2. Encuentra el producto que deseas editar\n';
              userGuideContent += '3. Haz clic en el icono de edición\n';
              userGuideContent += '4. Actualiza la información necesaria\n';
              userGuideContent += '5. Haz clic en "Guardar Cambios"\n\n';
              userGuideContent += '## Solución de Problemas\n\n';
              userGuideContent += '### Problemas Comunes\n\n';
              userGuideContent += '#### No puedo iniciar sesión\n\n';
              userGuideContent += '- Verifica que estás utilizando el correo electrónico y contraseña correctos\n';
              userGuideContent += '- Asegúrate de que tu cuenta ha sido verificada\n';
              userGuideContent += '- Intenta restablecer tu contraseña\n\n';
              userGuideContent += '#### La aplicación está lenta\n\n';
              userGuideContent += '- Verifica tu conexión a Internet\n';
              userGuideContent += '- Cierra otras aplicaciones o pestañas del navegador\n';
              userGuideContent += '- Borra la caché del navegador\n\n';
              userGuideContent += '### Contacto de Soporte\n\n';
              userGuideContent += 'Si necesitas ayuda adicional, puedes contactar a nuestro equipo de soporte:\n\n';
              userGuideContent += '- Correo electrónico: support@example.com\n';
              userGuideContent += '- Teléfono: +1 (123) 456-7890\n';
              userGuideContent += '- Horario de atención: Lunes a Viernes, 9:00 AM - 5:00 PM (UTC)\n';

              // Escribir guía de usuario
              fs.writeFileSync(path.join(userGuideDir, 'getting-started.md'), userGuideContent);

              // Crear guía para desarrolladores
              let devGuideContent = '# Guía para Desarrolladores\n\n';
              devGuideContent += '## Introducción\n\n';
              devGuideContent += `Esta guía está diseñada para ayudar a los desarrolladores a entender la estructura del proyecto ${config.projectName || 'Mi Proyecto'} y cómo contribuir al mismo.\n\n`;
              devGuideContent += '## Configuración del Entorno de Desarrollo\n\n';
              devGuideContent += '### Requisitos Previos\n\n';
              devGuideContent += '- Node.js (v14 o superior)\n';
              devGuideContent += '- npm (v6 o superior) o yarn (v1.22 o superior)\n';
              devGuideContent += '- Git\n';
              devGuideContent += '- Docker y Docker Compose (opcional, para desarrollo con contenedores)\n\n';
              devGuideContent += '### Clonar el Repositorio\n\n';
              devGuideContent += '```bash\n';
              devGuideContent += 'git clone https://github.com/example/my-project.git\n';
              devGuideContent += 'cd my-project\n';
              devGuideContent += '```\n\n';
              devGuideContent += '### Instalar Dependencias\n\n';
              devGuideContent += '```bash\n';
              devGuideContent += 'npm install\n';
              devGuideContent += '# o\n';
              devGuideContent += 'yarn install\n';
              devGuideContent += '```\n\n';
              devGuideContent += '### Configuración de Variables de Entorno\n\n';
              devGuideContent += '1. Copia el archivo `.env.example` a `.env`\n';
              devGuideContent += '```bash\n';
              devGuideContent += 'cp .env.example .env\n';
              devGuideContent += '```\n\n';
              devGuideContent += '2. Edita el archivo `.env` con tus configuraciones locales\n\n';
              devGuideContent += '### Iniciar el Servidor de Desarrollo\n\n';
              devGuideContent += '```bash\n';
              devGuideContent += 'npm run dev\n';
              devGuideContent += '# o\n';
              devGuideContent += 'yarn dev\n';
              devGuideContent += '```\n\n';
              devGuideContent += 'La aplicación estará disponible en `http://localhost:3000`.\n\n';
              devGuideContent += '## Estructura del Proyecto\n\n';
              
              if (config.projectType === 'fullstack') {
                devGuideContent += '```\n';
                devGuideContent += 'my-project/\n';
                devGuideContent += '├── frontend/           # Código del frontend\n';
                devGuideContent += '│   ├── public/         # Archivos estáticos\n';
                devGuideContent += '│   ├── src/            # Código fuente\n';
                devGuideContent += '│   │   ├── components/ # Componentes reutilizables\n';
                devGuideContent += '│   │   ├── pages/      # Páginas de la aplicación\n';
                devGuideContent += '│   │   ├── services/   # Servicios para comunicación con el backend\n';
                devGuideContent += '│   │   └── store/      # Gestión del estado\n';
                devGuideContent += '│   ├── package.json    # Dependencias del frontend\n';
                devGuideContent += '│   └── README.md       # Documentación del frontend\n';
                devGuideContent += '├── backend/            # Código del backend\n';
                devGuideContent += '│   ├── src/            # Código fuente\n';
                devGuideContent += '│   │   ├── controllers/ # Controladores\n';
                devGuideContent += '│   │   ├── services/   # Servicios\n';
                devGuideContent += '│   │   ├── models/     # Modelos de datos\n';
                devGuideContent += '│   │   ├── routes/     # Definición de rutas\n';
                devGuideContent += '│   │   └── middlewares/ # Middlewares\n';
                devGuideContent += '│   ├── package.json    # Dependencias del backend\n';
                devGuideContent += '│   └── README.md       # Documentación del backend\n';
                devGuideContent += '├── docs/               # Documentación\n';
                devGuideContent += '├── .github/            # Configuración de GitHub\n';
                devGuideContent += '├── docker-compose.yml  # Configuración de Docker Compose\n';
                devGuideContent += '├── .env.example        # Ejemplo de variables de entorno\n';
                devGuideContent += '└── README.md           # Documentación principal\n';
                devGuideContent += '```\n\n';
              } else if (config.projectType === 'web') {
                devGuideContent += '```\n';
                devGuideContent += 'my-project/\n';
                devGuideContent += '├── public/             # Archivos estáticos\n';
                devGuideContent += '├── src/                # Código fuente\n';
                devGuideContent += '│   ├── components/     # Componentes reutilizables\n';
                devGuideContent += '│   ├── pages/          # Páginas de la aplicación\n';
                devGuideContent += '│   ├── services/       # Servicios para comunicación con APIs\n';
                devGuideContent += '│   └── store/          # Gestión del estado\n';
                devGuideContent += '├── docs/               # Documentación\n';
                devGuideContent += '├── .github/            # Configuración de GitHub\n';
                devGuideContent += '├── .env.example        # Ejemplo de variables de entorno\n';
                devGuideContent += '└── README.md           # Documentación principal\n';
                devGuideContent += '```\n\n';
              } else if (config.projectType === 'api') {
                devGuideContent += '```\n';
                devGuideContent += 'my-project/\n';
                devGuideContent += '├── src/                # Código fuente\n';
                devGuideContent += '│   ├── controllers/    # Controladores\n';
                devGuideContent += '│   ├── services/       # Servicios\n';
                devGuideContent += '│   ├── models/         # Modelos de datos\n';
                devGuideContent += '│   ├── routes/         # Definición de rutas\n';
                devGuideContent += '│   └── middlewares/    # Middlewares\n';
                devGuideContent += '├── docs/               # Documentación\n';
                devGuideContent += '├── .github/            # Configuración de GitHub\n';
                devGuideContent += '├── docker-compose.yml  # Configuración de Docker Compose\n';
                devGuideContent += '├── .env.example        # Ejemplo de variables de entorno\n';
                devGuideContent += '└── README.md           # Documentación principal\n';
                devGuideContent += '```\n\n';
              }
              
              devGuideContent += '## Flujo de Trabajo de Desarrollo\n\n';
              devGuideContent += '### Ramas\n\n';
              devGuideContent += 'Utilizamos el siguiente esquema de ramas:\n\n';
              devGuideContent += '- `main`: Código en producción\n';
              devGuideContent += '- `develop`: Código en desarrollo\n';
              devGuideContent += '- `feature/*`: Nuevas funcionalidades\n';
              devGuideContent += '- `bugfix/*`: Corrección de errores\n';
              devGuideContent += '- `release/*`: Preparación para lanzamiento\n\n';
              devGuideContent += '### Proceso de Desarrollo\n\n';
              devGuideContent += '1. Crea una nueva rama desde `develop`\n';
              devGuideContent += '```bash\n';
              devGuideContent += 'git checkout develop\n';
              devGuideContent += 'git pull\n';
              devGuideContent += 'git checkout -b feature/nueva-funcionalidad\n';
              devGuideContent += '```\n\n';
              devGuideContent += '2. Desarrolla la funcionalidad\n\n';
              devGuideContent += '3. Realiza commits con mensajes descriptivos\n';
              devGuideContent += '```bash\n';
              devGuideContent += 'git add .\n';
              devGuideContent += 'git commit -m "feat: añadir nueva funcionalidad"\n';
              devGuideContent += '```\n\n';
              devGuideContent += '4. Sube la rama al repositorio remoto\n';
              devGuideContent += '```bash\n';
              devGuideContent += 'git push origin feature/nueva-funcionalidad\n';
              devGuideContent += '```\n\n';
              devGuideContent += '5. Crea un Pull Request a `develop`\n\n';
              devGuideContent += '### Convenciones de Código\n\n';
              devGuideContent += '#### Estilo de Código\n\n';
              devGuideContent += 'Utilizamos ESLint y Prettier para mantener un estilo de código consistente.\n\n';
              devGuideContent += '```bash\n';
              devGuideContent += '# Verificar estilo de código\n';
              devGuideContent += 'npm run lint\n\n';
              devGuideContent += '# Corregir automáticamente problemas de estilo\n';
              devGuideContent += 'npm run lint:fix\n';
              devGuideContent += '```\n\n';
              devGuideContent += '#### Convenciones de Commit\n\n';
              devGuideContent += 'Seguimos las convenciones de Conventional Commits:\n\n';
              devGuideContent += '- `feat`: Nueva funcionalidad\n';
              devGuideContent += '- `fix`: Corrección de errores\n';
              devGuideContent += '- `docs`: Cambios en la documentación\n';
              devGuideContent += '- `style`: Cambios de estilo (formato, espacios, etc.)\n';
              devGuideContent += '- `refactor`: Refactorización de código\n';
              devGuideContent += '- `test`: Adición o corrección de pruebas\n';
              devGuideContent += '- `chore`: Cambios en el proceso de construcción o herramientas auxiliares\n\n';
              devGuideContent += '## Pruebas\n\n';
              devGuideContent += '### Ejecutar Pruebas\n\n';
              devGuideContent += '```bash\n';
              devGuideContent += '# Ejecutar todas las pruebas\n';
              devGuideContent += 'npm test\n\n';
              devGuideContent += '# Ejecutar pruebas con cobertura\n';
              devGuideContent += 'npm run test:coverage\n';
              devGuideContent += '```\n\n';
              devGuideContent += '### Escribir Pruebas\n\n';
              devGuideContent += 'Utilizamos Jest para pruebas unitarias y de integración. Cada archivo de prueba debe estar ubicado junto al archivo que prueba con la extensión `.test.js` o `.spec.js`.\n\n';
              devGuideContent += '```javascript\n';
              devGuideContent += '// ejemplo.test.js\n';
              devGuideContent += 'import { miFuncion } from \'./ejemplo\';\n\n';
              devGuideContent += 'describe(\'miFuncion\', () => {\n';
              devGuideContent += '  it(\'debería devolver el resultado esperado\', () => {\n';
              devGuideContent += '    expect(miFuncion(1, 2)).toBe(3);\n';
              devGuideContent += '  });\n';
              devGuideContent += '});\n';
              devGuideContent += '```\n\n';
              devGuideContent += '## Despliegue\n\n';
              devGuideContent += '### Construcción para Producción\n\n';
              devGuideContent += '```bash\n';
              devGuideContent += 'npm run build\n';
              devGuideContent += '```\n\n';
              devGuideContent += '### Despliegue Manual\n\n';
              devGuideContent += '1. Construye la aplicación para producción\n';
              devGuideContent += '2. Copia los archivos generados al servidor\n';
              devGuideContent += '3. Configura el servidor web (Nginx, Apache, etc.)\n\n';
              devGuideContent += '### Despliegue Automático\n\n';
              devGuideContent += 'Utilizamos GitHub Actions para el despliegue automático. Cada vez que se hace un push a la rama `main`, se ejecuta el flujo de trabajo de despliegue.\n\n';
              devGuideContent += '## Recursos Adicionales\n\n';
              devGuideContent += '- [Documentación de la API](../api/api-reference.md)\n';
              devGuideContent += '- [Arquitectura del Sistema](../architecture/overview.md)\n';
              devGuideContent += '- [Guía de Usuario](../user-guide/getting-started.md)\n';

              // Escribir guía para desarrolladores
              fs.writeFileSync(path.join(devGuideDir, 'development-guide.md'), devGuideContent);

              // Crear archivo de configuración para MkDocs
              let mkdocsContent = 'site_name: ' + (config.projectName || 'Mi Proyecto') + ' Documentación\n';
              mkdocsContent += 'site_description: Documentación completa para ' + (config.projectName || 'Mi Proyecto') + '\n';
              mkdocsContent += 'site_author: Equipo de Desarrollo\n';
              mkdocsContent += 'repo_url: https://github.com/example/my-project\n';
              mkdocsContent += 'theme: readthedocs\n\n';
              mkdocsContent += 'nav:\n';
              mkdocsContent += '  - Inicio: index.md\n';
              mkdocsContent += '  - Arquitectura:\n';
              mkdocsContent += '    - Visión General: architecture/overview.md\n';
              mkdocsContent += '  - API:\n';
              mkdocsContent += '    - Referencia de la API: api/api-reference.md\n';
              mkdocsContent += '  - Guía de Usuario:\n';
              mkdocsContent += '    - Primeros Pasos: user-guide/getting-started.md\n';
              mkdocsContent += '  - Guía para Desarrolladores:\n';
              mkdocsContent += '    - Guía de Desarrollo: dev-guide/development-guide.md\n\n';
              mkdocsContent += 'markdown_extensions:\n';
              mkdocsContent += '  - admonition\n';
              mkdocsContent += '  - codehilite\n';
              mkdocsContent += '  - toc:\n';
              mkdocsContent += '      permalink: true\n';

              // Escribir archivo de configuración para MkDocs
              fs.writeFileSync(path.join(docsDir, 'mkdocs.yml'), mkdocsContent);

              // Crear archivo index.md para MkDocs
              let indexContent = '# ' + (config.projectName || 'Mi Proyecto') + ' Documentación\n\n';
              indexContent += '## Bienvenido\n\n';
              indexContent += `Bienvenido a la documentación oficial de ${config.projectName || 'Mi Proyecto'}. Aquí encontrarás toda la información necesaria para entender, utilizar y contribuir al proyecto.\n\n`;
              indexContent += '## Contenido\n\n';
              indexContent += '- **[Arquitectura](architecture/overview.md)**: Descripción de la arquitectura del sistema\n';
              indexContent += '- **[API](api/api-reference.md)**: Documentación detallada de la API\n';
              indexContent += '- **[Guía de Usuario](user-guide/getting-started.md)**: Guía para usuarios finales\n';
              indexContent += '- **[Guía para Desarrolladores](dev-guide/development-guide.md)**: Guía para desarrolladores\n\n';
              indexContent += '## Inicio Rápido\n\n';
              indexContent += '### Instalación\n\n';
              indexContent += '```bash\n';
              indexContent += 'git clone https://github.com/example/my-project.git\n';
              indexContent += 'cd my-project\n';
              indexContent += 'npm install\n';
              indexContent += '```\n\n';
              indexContent += '### Ejecución\n\n';
              indexContent += '```bash\n';
              indexContent += 'npm run dev\n';
              indexContent += '```\n\n';
              indexContent += '## Soporte\n\n';
              indexContent += 'Si necesitas ayuda, puedes:\n\n';
              indexContent += '- Abrir un issue en GitHub\n';
              indexContent += '- Contactar al equipo de soporte en support@example.com\n';
              indexContent += '- Unirte a nuestro canal de Slack\n\n';
              indexContent += '## Contribuir\n\n';
              indexContent += 'Nos encantaría recibir tu contribución. Por favor, lee nuestra [Guía para Desarrolladores](dev-guide/development-guide.md) para obtener más información sobre cómo contribuir al proyecto.\n';

              // Escribir archivo index.md
              fs.writeFileSync(path.join(docsDir, 'index.md'), indexContent);

              // Crear script para generar documentación
              let generateDocsScript = '#!/bin/bash\n\n';
              generateDocsScript += '# Script para generar la documentación\n\n';
              generateDocsScript += 'cd docs\n';
              generateDocsScript += 'mkdocs build\n';
              generateDocsScript += 'echo "Documentación generada en docs/site/"\n';

              // Escribir script para generar documentación (Linux/macOS)
              fs.writeFileSync(path.join(docsDir, 'generate-docs.sh'), generateDocsScript);
              fs.chmodSync(path.join(docsDir, 'generate-docs.sh'), '755');

              // Crear script para Windows
              let generateDocsScriptWin = '@echo off\n\n';
              generateDocsScriptWin += 'REM Script para generar la documentación\n\n';
              generateDocsScriptWin += 'cd docs\n';
              generateDocsScriptWin += 'mkdocs build\n';
              generateDocsScriptWin += 'echo Documentación generada en docs\\site\\\n';

              // Escribir script para generar documentación (Windows)
              fs.writeFileSync(path.join(docsDir, 'generate-docs.bat'), generateDocsScriptWin);

              return docsDir;
            } catch (error) {
              console.error('Error al crear archivos de documentación:', error);
              throw error;
            }
          }

          /**
           * Crea archivos de configuración para monitoreo
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de monitoreo
           */
          async createMonitoringFiles(projectDir, config) {
            try {
              const monitoringDir = path.join(projectDir, 'monitoring');
              if (!fs.existsSync(monitoringDir)) {
                fs.mkdirSync(monitoringDir, { recursive: true });
              }

              // Crear directorio para Prometheus
              const prometheusDir = path.join(monitoringDir, 'prometheus');
              if (!fs.existsSync(prometheusDir)) {
                fs.mkdirSync(prometheusDir, { recursive: true });
              }

              // Crear prometheus.yml
              let prometheusContent = 'global:\n';
              prometheusContent += '  scrape_interval: 15s\n';
              prometheusContent += '  evaluation_interval: 15s\n\n';
              prometheusContent += 'alerting:\n';
              prometheusContent += '  alertmanagers:\n';
              prometheusContent += '    - static_configs:\n';
              prometheusContent += '        - targets: [\'alertmanager:9093\']\n\n';
              prometheusContent += 'rule_files:\n';
              prometheusContent += '  - "alert_rules.yml"\n\n';
              prometheusContent += 'scrape_configs:\n';
              prometheusContent += '  - job_name: \'prometheus\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '      - targets: [\'localhost:9090\']\n\n';
              prometheusContent += '  - job_name: \'node-exporter\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '      - targets: [\'node-exporter:9100\']\n\n';
              prometheusContent += '  - job_name: \'cadvisor\'\n';
              prometheusContent += '    static_configs:\n';
              prometheusContent += '      - targets: [\'cadvisor:8080\']\n';

              // Añadir configuración específica según el tipo de proyecto
              if (config.projectType === 'fullstack' || config.projectType === 'api') {
                prometheusContent += '\n  - job_name: \'backend\'\n';
                prometheusContent += '    static_configs:\n';
                prometheusContent += '      - targets: [\'backend:3000\']\n';
              }

              if (config.projectType === 'fullstack' || config.projectType === 'web') {
                prometheusContent += '\n  - job_name: \'frontend\'\n';
                prometheusContent += '    static_configs:\n';
                prometheusContent += '      - targets: [\'frontend:80\']\n';
              }

              // Escribir prometheus.yml
              fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);

              // Crear alert_rules.yml
              let alertRulesContent = 'groups:\n';
              alertRulesContent += '- name: example\n';
              alertRulesContent += '  rules:\n';
              alertRulesContent += '  - alert: HighCPULoad\n';
              alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High CPU load (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "CPU load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
              
              alertRulesContent += '  - alert: HighMemoryLoad\n';
              alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 > 80\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High memory load (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "Memory load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
              
              alertRulesContent += '  - alert: HighDiskUsage\n';
              alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85\n';
              alertRulesContent += '    for: 5m\n';
              alertRulesContent += '    labels:\n';
              alertRulesContent += '      severity: warning\n';
              alertRulesContent += '    annotations:\n';
              alertRulesContent += '      summary: "High disk usage (instance {{ $labels.instance }})"\n';
              alertRulesContent += '      description: "Disk usage is > 85%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n';

              // Escribir alert_rules.yml
              fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);

              // Crear configuración de Alertmanager
              const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
              if (!fs.existsSync(alertmanagerDir)) {
                fs.mkdirSync(alertmanagerDir, { recursive: true });
              }

              // Crear alertmanager.yml
              let alertmanagerContent = 'global:\n';
              alertmanagerContent += '  resolve_timeout: 5m\n';
              alertmanagerContent += '  smtp_smarthost: "smtp.example.com:587"\n';
              alertmanagerContent += '  smtp_from: "alertmanager@example.com"\n';
              alertmanagerContent += '  smtp_auth_username: "alertmanager"\n';
              alertmanagerContent += '  smtp_auth_password: "password"\n\n';
              alertmanagerContent += 'route:\n';
              alertmanagerContent += '  group_by: [\'alertname\', \'instance\']\n';
              alertmanagerContent += '  group_wait: 30s\n';
              alertmanagerContent += '  group_interval: 5m\n';
              alertmanagerContent += '  repeat_interval: 1h\n';
              alertmanagerContent += '  receiver: \'email\'\n\n';
              alertmanagerContent += 'receivers:\n';
              alertmanagerContent += '- name: \'email\'\n';
              alertmanagerContent += '  email_configs:\n';
              alertmanagerContent += '  - to: "alerts@example.com"\n';
              alertmanagerContent += '    send_resolved: true\n\n';
              alertmanagerContent += 'inhibit_rules:\n';
              alertmanagerContent += '  - source_match:\n';
              alertmanagerContent += '      severity: \'critical\'\n';
              alertmanagerContent += '    target_match:\n';
              alertmanagerContent += '      severity: \'warning\'\n';
              alertmanagerContent += '    equal: [\'alertname\', \'instance\']\n';

              // Escribir alertmanager.yml
              fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);

              // Crear configuración de Grafana
              const grafanaDir = path.join(monitoringDir, 'grafana');
              if (!fs.existsSync(grafanaDir)) {
                fs.mkdirSync(grafanaDir, { recursive: true });
              }

              // Crear datasources.yml
              let datasourcesContent = 'apiVersion: 1\n\n';
              datasourcesContent += 'datasources:\n';
              datasourcesContent += '  - name: Prometheus\n';
              datasourcesContent += '    type: prometheus\n';
              datasourcesContent += '    access: proxy\n';
              datasourcesContent += '    url: http://prometheus:9090\n';
              datasourcesContent += '    isDefault: true\n';
              datasourcesContent += '    editable: true\n';

              // Escribir datasources.yml
              fs.writeFileSync(path.join(grafanaDir, 'datasources.yml'), datasourcesContent);

              // Crear directorio para dashboards
              const dashboardsDir = path.join(grafanaDir, 'dashboards');
              if (!fs.existsSync(dashboardsDir)) {
                fs.mkdirSync(dashboardsDir, { recursive: true });
              }

              // Crear dashboard.json (versión simplificada para no extender demasiado el código)
              let dashboardContent = '{\n';
              dashboardContent += '  "annotations": {\n';
              dashboardContent += '    "list": [\n';
              dashboardContent += '      {\n';
              dashboardContent += '        "builtIn": 1,\n';
              dashboardContent += '        "datasource": "-- Grafana --",\n';
              dashboardContent += '        "enable": true,\n';
              dashboardContent += '        "hide": true,\n';
              dashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
              dashboardContent += '        "name": "Annotations & Alerts",\n';
              dashboardContent += '        "type": "dashboard"\n';
              dashboardContent += '      }\n';
              dashboardContent += '    ]\n';
              dashboardContent += '  },\n';
              dashboardContent += '  "editable": true,\n';
              dashboardContent += '  "gnetId": null,\n';
              dashboardContent += '  "graphTooltip": 0,\n';
              dashboardContent += '  "id": 1,\n';
              dashboardContent += '  "links": [],\n';
              dashboardContent += '  "panels": [],\n';
              dashboardContent += '  "schemaVersion": 26,\n';
              dashboardContent += '  "style": "dark",\n';
              dashboardContent += '  "tags": [],\n';
              dashboardContent += '  "templating": {\n';
              dashboardContent += '    "list": []\n';
              dashboardContent += '  },\n';
              dashboardContent += '  "time": {\n';
              dashboardContent += '    "from": "now-6h",\n';
              dashboardContent += '    "to": "now"\n';
              dashboardContent += '  },\n';
              dashboardContent += '  "timepicker": {},\n';
              dashboardContent += '  "timezone": "",\n';
              dashboardContent += '  "title": "System Monitoring",\n';
              dashboardContent += '  "uid": "system-monitoring",\n';
              dashboardContent += '  "version": 1\n';
              dashboardContent += '}\n';

              // Escribir dashboard.json
              fs.writeFileSync(path.join(dashboardsDir, 'dashboard.json'), dashboardContent);

              // Crear dashboard.yml
              let dashboardYamlContent = 'apiVersion: 1\n\n';
              dashboardYamlContent += 'providers:\n';
              dashboardYamlContent += '  - name: \'default\'\n';
              dashboardYamlContent += '    orgId: 1\n';
              dashboardYamlContent += '    folder: \'\'\n';
              dashboardYamlContent += '    type: file\n';
              dashboardYamlContent += '    disableDeletion: false\n';
              dashboardYamlContent += '    editable: true\n';
              dashboardYamlContent += '    options:\n';
              dashboardYamlContent += '      path: /etc/grafana/dashboards\n';

              // Escribir dashboard.yml
              fs.writeFileSync(path.join(grafanaDir, 'dashboard.yml'), dashboardYamlContent);

              // Crear docker-compose.yml para monitoreo
              let dockerComposeContent = 'version: "3.8"\n\n';
              dockerComposeContent += 'services:\n';
              dockerComposeContent += '  prometheus:\n';
              dockerComposeContent += '    image: prom/prometheus:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
              dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
              dockerComposeContent += '      - prometheus_data:/prometheus\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
              dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
              dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
              dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9090:9090"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  alertmanager:\n';
              dockerComposeContent += '    image: prom/alertmanager:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
              dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
              dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9093:9093"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  grafana:\n';
              dockerComposeContent += '    image: grafana/grafana:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
              dockerComposeContent += '      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml\n';
              dockerComposeContent += '      - ./grafana/dashboards:/etc/grafana/dashboards\n';
              dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
              dockerComposeContent += '    environment:\n';
              dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
              dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
              dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "3000:3000"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  node-exporter:\n';
              dockerComposeContent += '    image: prom/node-exporter:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - /proc:/host/proc:ro\n';
              dockerComposeContent += '      - /sys:/host/sys:ro\n';
              dockerComposeContent += '      - /:/rootfs:ro\n';
              dockerComposeContent += '    command:\n';
              dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
              dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
              dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "9100:9100"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += '  cadvisor:\n';
              dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
              dockerComposeContent += '    volumes:\n';
              dockerComposeContent += '      - /:/rootfs:ro\n';
              dockerComposeContent += '      - /var/run:/var/run:ro\n';
              dockerComposeContent += '      - /sys:/sys:ro\n';
              dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
              dockerComposeContent += '    ports:\n';
              dockerComposeContent += '      - "8080:8080"\n';
              dockerComposeContent += '    networks:\n';
              dockerComposeContent += '      - monitoring-network\n';
              dockerComposeContent += '    restart: unless-stopped\n\n';
              
              dockerComposeContent += 'networks:\n';
              dockerComposeContent += '  monitoring-network:\n';
              dockerComposeContent += '    driver: bridge\n\n';
              
              dockerComposeContent += 'volumes:\n';
              dockerComposeContent += '  prometheus_data:\n';
              dockerComposeContent += '    driver: local\n';
              dockerComposeContent += '  alertmanager_data:\n';
              dockerComposeContent += '    driver: local\n';
              dockerComposeContent += '  grafana_data:\n';
              dockerComposeContent += '    driver: local\n';

              // Escribir docker-compose.yml
              fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);

              // Crear README.md
              let readmeContent = '# Monitoreo\n\n';
              readmeContent += 'Este directorio contiene la configuración para el stack de monitoreo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
              readmeContent += '## Componentes\n\n';
              readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
              readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
              readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
              readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
              readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
              readmeContent += '## Inicio Rápido\n\n';
              readmeContent += '```bash\n';
              readmeContent += '# Iniciar el stack de monitoreo\n';
              readmeContent += 'docker-compose up -d\n';
              readmeContent += '```\n\n';
              readmeContent += '## Acceso\n\n';
              readmeContent += '- **Prometheus**: http://localhost:9090\n';
              readmeContent += '- **Alertmanager**: http://localhost:9093\n';
              readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
              readmeContent += '- **Node Exporter**: http://localhost:9100\n';
              readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
              readmeContent += '## Personalización\n\n';
              readmeContent += '### Prometheus\n\n';
              readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
              readmeContent += '### Alertmanager\n\n';
              readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
              readmeContent += '### Grafana\n\n';
              readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/dashboard.yml` si es necesario.\n';

              // Escribir README.md
              fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);

              return monitoringDir;
            } catch (error) {
              console.error('Error al crear archivos de monitoreo:', error);
              throw error;
            }
          }

          /**
           * Crea archivos de configuración para logging
           * @param {string} projectDir - Directorio del proyecto
           * @param {Object} config - Configuración del proyecto
           * @returns {string} - Directorio de logging
           */
          async createLoggingFiles(projectDir, config) {
            try {
              const loggingDir = path.join(projectDir, 'logging');
              if (!fs.existsSync(loggingDir)) {
                fs.mkdirSync(loggingDir, { recursive: true });
              }

              // Crear directorio para ELK stack
              const elkDir = path.join(loggingDir, 'elk');
              if (!fs.existsSync(elkDir)) {
                fs.mkdirSync(elkDir, { recursive: true });
              }

              // Crear docker-compose.yml para ELK stack
              let elkComposeContent = 'version: "3.8"\n\n';
              elkComposeContent += 'services:\n';
              elkComposeContent += '  elasticsearch:\n';
              elkComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
              elkComposeContent += '    environment:\n';
              elkComposeContent += '      - discovery.type=single-node\n';
              elkComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
              elkComposeContent += '    volumes:\n';
              elkComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
              elkComposeContent += '    ports:\n';
              elkComposeContent += '      - "9200:9200"\n';
              elkComposeContent += '      - "9300:9300"\n';
              elkComposeContent += '    networks:\n';
              elkComposeContent += '      - elk-network\n';
              elkComposeContent += '    restart: unless-stopped\n\n';
              
              elkComposeContent += '  logstash:\n';
              elkComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
              elkComposeContent += '    volumes:\n';
              elkComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
              elkComposeContent += '    ports:\n';
              elkComposeContent += '      - "5000:5000"\n';
              elkComposeContent += '      - "9600:9600"\n';
              elkComposeContent += '    environment:\n';
              elkComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
              elkComposeContent += '    networks:\n';
              elkComposeContent += '      - elk-network\n';
              elkComposeContent += '    depends_on:\n';
              elkComposeContent += '      - elasticsearch\n';
              elkComposeContent += '    restart: unless-stopped\n\n';
              
              elkComposeContent += '  kibana:\n';
              elkComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
              elkComposeContent += '    ports:\n';
              elkComposeContent += '      - "5601:5601"\n';
              elkComposeContent += '    environment:\n';
              elkComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
              elkComposeContent += '    networks:\n';
              elkComposeContent += '      - elk-network\n';
              elkComposeContent += '    depends_on:\n';
              elkComposeContent += '      - elasticsearch\n';
              elkComposeContent += '    restart: unless-stopped\n\n';
              
              elkComposeContent += '  filebeat:\n';
              elkComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
              elkComposeContent += '    user: root\n';
              elkComposeContent += '    volumes:\n';
              elkComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
              elkComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
              elkComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
              elkComposeContent += '    networks:\n';
              elkComposeContent += '      - elk-network\n';
              elkComposeContent += '    depends_on:\n';
              elkComposeContent += '      - elasticsearch\n';
              elkComposeContent += '      - logstash\n';
              elkComposeContent += '    restart: unless-stopped\n\n';
              
              elkComposeContent += 'networks:\n';
              elkComposeContent += '  elk-network:\n';
              elkComposeContent += '    driver: bridge\n\n';
              
              elkComposeContent += 'volumes:\n';
              elkComposeContent += '  elasticsearch_data:\n';
              elkComposeContent += '    driver: local\n';

              // Escribir docker-compose.yml para ELK stack
              fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), elkComposeContent);

                            // Crear directorio para Logstash pipeline
                            const logstashDir = path.join(elkDir, 'logstash');
                            if (!fs.existsSync(logstashDir)) {
                              fs.mkdirSync(logstashDir, { recursive: true });
                            }
              
                            const pipelineDir = path.join(logstashDir, 'pipeline');
                            if (!fs.existsSync(pipelineDir)) {
                              fs.mkdirSync(pipelineDir, { recursive: true });
                            }
              
                            // Crear logstash.conf
                            let logstashConfContent = 'input {\n';
                            logstashConfContent += '  beats {\n';
                            logstashConfContent += '    port => 5000\n';
                            logstashConfContent += '  }\n';
                            logstashConfContent += '}\n\n';
                            logstashConfContent += 'filter {\n';
                            logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
                            logstashConfContent += '    mutate {\n';
                            logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
                            logstashConfContent += '    }\n';
                            logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
                            logstashConfContent += '    mutate {\n';
                            logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
                            logstashConfContent += '    }\n';
                            logstashConfContent += '  } else {\n';
                            logstashConfContent += '    mutate {\n';
                            logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
                            logstashConfContent += '    }\n';
                            logstashConfContent += '  }\n';
                            logstashConfContent += '}\n\n';
                            logstashConfContent += 'output {\n';
                            logstashConfContent += '  elasticsearch {\n';
                            logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
                            logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
                            logstashConfContent += '  }\n';
                            logstashConfContent += '}\n';
              
                            // Escribir logstash.conf
                            fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);
              
                            // Crear directorio para Filebeat
                            const filebeatDir = path.join(elkDir, 'filebeat');
                            if (!fs.existsSync(filebeatDir)) {
                              fs.mkdirSync(filebeatDir, { recursive: true });
                            }
              
                            // Crear filebeat.yml
                            let filebeatContent = 'filebeat.inputs:\n';
                            filebeatContent += '- type: container\n';
                            filebeatContent += '  paths:\n';
                            filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
                            filebeatContent += '  processors:\n';
                            filebeatContent += '    - add_docker_metadata:\n';
                            filebeatContent += '        host: "unix:///var/run/docker.sock"\n\n';
                            filebeatContent += 'processors:\n';
                            filebeatContent += '  - add_host_metadata:\n';
                            filebeatContent += '      when.not.contains.tags: forwarded\n';
                            filebeatContent += '  - add_cloud_metadata: ~\n';
                            filebeatContent += '  - add_docker_metadata: ~\n';
                            filebeatContent += '  - add_kubernetes_metadata: ~\n\n';
                            filebeatContent += 'output.logstash:\n';
                            filebeatContent += '  hosts: ["logstash:5000"]\n';
              
                            // Escribir filebeat.yml
                            fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);
              
                            // Crear README.md para ELK stack
                            let elkReadmeContent = '# ELK Stack para Logging\n\n';
                            elkReadmeContent += 'Este directorio contiene la configuración para un stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat para la recolección y análisis de logs.\n\n';
                            elkReadmeContent += '## Componentes\n\n';
                            elkReadmeContent += '- **Elasticsearch**: Motor de búsqueda y análisis\n';
                            elkReadmeContent += '- **Logstash**: Procesamiento de datos y logs\n';
                            elkReadmeContent += '- **Kibana**: Visualización de datos\n';
                            elkReadmeContent += '- **Filebeat**: Recolector de logs\n\n';
                            elkReadmeContent += '## Inicio Rápido\n\n';
                            elkReadmeContent += '```bash\n';
                            elkReadmeContent += '# Iniciar el stack ELK\n';
                            elkReadmeContent += 'docker-compose up -d\n';
                            elkReadmeContent += '```\n\n';
                            elkReadmeContent += '## Acceso\n\n';
                            elkReadmeContent += '- **Elasticsearch**: http://localhost:9200\n';
                            elkReadmeContent += '- **Kibana**: http://localhost:5601\n';
                            elkReadmeContent += '- **Logstash**: http://localhost:9600\n\n';
                            elkReadmeContent += '## Personalización\n\n';
                            elkReadmeContent += '### Logstash\n\n';
                            elkReadmeContent += 'Edita `logstash/pipeline/logstash.conf` para modificar el procesamiento de logs.\n\n';
                            elkReadmeContent += '### Filebeat\n\n';
                            elkReadmeContent += 'Edita `filebeat/filebeat.yml` para cambiar la configuración de recolección de logs.\n';
              
                            // Escribir README.md para ELK stack
                            fs.writeFileSync(path.join(elkDir, 'README.md'), elkReadmeContent);
              
                            // Crear directorio para Fluentd
                            const fluentdDir = path.join(loggingDir, 'fluentd');
                            if (!fs.existsSync(fluentdDir)) {
                              fs.mkdirSync(fluentdDir, { recursive: true });
                            }
              
                            // Crear docker-compose.yml para Fluentd
                            let fluentdComposeContent = 'version: "3.8"\n\n';
                            fluentdComposeContent += 'services:\n';
                            fluentdComposeContent += '  fluentd:\n';
                            fluentdComposeContent += '    image: fluent/fluentd:v1.12\n';
                            fluentdComposeContent += '    volumes:\n';
                            fluentdComposeContent += '      - ./fluent.conf:/fluentd/etc/fluent.conf\n';
                            fluentdComposeContent += '      - ./logs:/fluentd/log\n';
                            fluentdComposeContent += '    ports:\n';
                            fluentdComposeContent += '      - "24224:24224"\n';
                            fluentdComposeContent += '      - "24224:24224/udp"\n';
                            fluentdComposeContent += '    networks:\n';
                            fluentdComposeContent += '      - fluentd-network\n';
                            fluentdComposeContent += '    restart: unless-stopped\n\n';
                            
                            fluentdComposeContent += 'networks:\n';
                            fluentdComposeContent += '  fluentd-network:\n';
                            fluentdComposeContent += '    driver: bridge\n';
              
                            // Escribir docker-compose.yml para Fluentd
                            fs.writeFileSync(path.join(fluentdDir, 'docker-compose.yml'), fluentdComposeContent);
              
                            // Crear fluent.conf
                            let fluentConfContent = '<source>\n';
                            fluentConfContent += '  @type forward\n';
                            fluentConfContent += '  port 24224\n';
                            fluentConfContent += '  bind 0.0.0.0\n';
                            fluentConfContent += '</source>\n\n';
                            fluentConfContent += '<filter **>\n';
                            fluentConfContent += '  @type record_transformer\n';
                            fluentConfContent += '  <record>\n';
                            fluentConfContent += '    hostname "#{Socket.gethostname}"\n';
                            fluentConfContent += '    tag ${tag}\n';
                            fluentConfContent += '  </record>\n';
                            fluentConfContent += '</filter>\n\n';
                            fluentConfContent += '<match **>\n';
                            fluentConfContent += '  @type file\n';
                            fluentConfContent += '  path /fluentd/log/${tag}/%Y/%m/%d.%H.%M\n';
                            fluentConfContent += '  append true\n';
                            fluentConfContent += '  <buffer tag,time>\n';
                            fluentConfContent += '    @type file\n';
                            fluentConfContent += '    timekey 1h\n';
                            fluentConfContent += '    timekey_wait 10m\n';
                            fluentConfContent += '    timekey_use_utc true\n';
                            fluentConfContent += '    flush_mode interval\n';
                            fluentConfContent += '    flush_interval 10s\n';
                            fluentConfContent += '  </buffer>\n';
                            fluentConfContent += '</match>\n';
              
                            // Escribir fluent.conf
                            fs.writeFileSync(path.join(fluentdDir, 'fluent.conf'), fluentConfContent);
              
                            // Crear directorio para logs
                            const fluentdLogsDir = path.join(fluentdDir, 'logs');
                            if (!fs.existsSync(fluentdLogsDir)) {
                              fs.mkdirSync(fluentdLogsDir, { recursive: true });
                            }
              
                            // Crear README.md para Fluentd
                            let fluentdReadmeContent = '# Fluentd para Logging\n\n';
                            fluentdReadmeContent += 'Este directorio contiene la configuración para Fluentd, un recolector de datos unificado.\n\n';
                            fluentdReadmeContent += '## Inicio Rápido\n\n';
                            fluentdReadmeContent += '```bash\n';
                            fluentdReadmeContent += '# Iniciar Fluentd\n';
                            fluentdReadmeContent += 'docker-compose up -d\n';
                            fluentdReadmeContent += '```\n\n';
                            fluentdReadmeContent += '## Configuración\n\n';
                            fluentdReadmeContent += 'Edita `fluent.conf` para modificar la configuración de Fluentd.\n\n';
                            fluentdReadmeContent += '## Uso con Docker\n\n';
                            fluentdReadmeContent += 'Para enviar logs de un contenedor a Fluentd, usa el siguiente driver de logging:\n\n';
                            fluentdReadmeContent += '```yaml\n';
                            fluentdReadmeContent += 'services:\n';
                            fluentdReadmeContent += '  app:\n';
                            fluentdReadmeContent += '    image: your-app-image\n';
                            fluentdReadmeContent += '    logging:\n';
                            fluentdReadmeContent += '      driver: fluentd\n';
                            fluentdReadmeContent += '      options:\n';
                            fluentdReadmeContent += '        fluentd-address: localhost:24224\n';
                            fluentdReadmeContent += '        tag: app.logs\n';
                            fluentdReadmeContent += '```\n';
              
                            // Escribir README.md para Fluentd
                            fs.writeFileSync(path.join(fluentdDir, 'README.md'), fluentdReadmeContent);
              
                            // Crear README.md principal para logging
                            let loggingReadmeContent = '# Logging\n\n';
                            loggingReadmeContent += 'Este directorio contiene diferentes opciones para la gestión de logs en el proyecto.\n\n';
                            loggingReadmeContent += '## Opciones Disponibles\n\n';
                            loggingReadmeContent += '### ELK Stack\n\n';
                            loggingReadmeContent += 'El stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat proporciona una solución completa para la recolección, procesamiento, almacenamiento y visualización de logs.\n\n';
                            loggingReadmeContent += '[Ver documentación del ELK Stack](./elk/README.md)\n\n';
                            loggingReadmeContent += '### Fluentd\n\n';
                            loggingReadmeContent += 'Fluentd es un recolector de datos unificado que permite recopilar, procesar y reenviar logs a diferentes destinos.\n\n';
                            loggingReadmeContent += '[Ver documentación de Fluentd](./fluentd/README.md)\n\n';
                            loggingReadmeContent += '## Recomendaciones\n\n';
                            loggingReadmeContent += '- **Aplicaciones pequeñas**: Utiliza Fluentd para una solución ligera y flexible.\n';
                            loggingReadmeContent += '- **Aplicaciones medianas a grandes**: Utiliza el stack ELK para una solución más completa con capacidades avanzadas de búsqueda y visualización.\n\n';
                            loggingReadmeContent += '## Integración con Aplicaciones\n\n';
                            loggingReadmeContent += '### Node.js\n\n';
                            loggingReadmeContent += '```javascript\n';
                            loggingReadmeContent += 'const winston = require(\'winston\');\n';
                            loggingReadmeContent += 'const { createLogger, format, transports } = winston;\n\n';
                            loggingReadmeContent += 'const logger = createLogger({\n';
                            loggingReadmeContent += '  level: \'info\',\n';
                            loggingReadmeContent += '  format: format.combine(\n';
                            loggingReadmeContent += '    format.timestamp(),\n';
                            loggingReadmeContent += '    format.json()\n';
                            loggingReadmeContent += '  ),\n';
                            loggingReadmeContent += '  defaultMeta: { service: \'user-service\' },\n';
                            loggingReadmeContent += '  transports: [\n';
                            loggingReadmeContent += '    new transports.File({ filename: \'error.log\', level: \'error\' }),\n';
                            loggingReadmeContent += '    new transports.File({ filename: \'combined.log\' })\n';
                            loggingReadmeContent += '  ]\n';
                            loggingReadmeContent += '});\n\n';
                            loggingReadmeContent += 'if (process.env.NODE_ENV !== \'production\') {\n';
                            loggingReadmeContent += '  logger.add(new transports.Console({\n';
                            loggingReadmeContent += '    format: format.combine(\n';
                            loggingReadmeContent += '      format.colorize(),\n';
                            loggingReadmeContent += '      format.simple()\n';
                            loggingReadmeContent += '    )\n';
                            loggingReadmeContent += '  }));\n';
                            loggingReadmeContent += '}\n';
                            loggingReadmeContent += '```\n\n';
                            loggingReadmeContent += '### Python\n\n';
                            loggingReadmeContent += '```python\n';
                            loggingReadmeContent += 'import logging\n';
                            loggingReadmeContent += 'import json\n';
                            loggingReadmeContent += 'from datetime import datetime\n\n';
                            loggingReadmeContent += 'class JsonFormatter(logging.Formatter):\n';
                            loggingReadmeContent += '    def format(self, record):\n';
                            loggingReadmeContent += '        log_record = {\n';
                            loggingReadmeContent += '            "timestamp": datetime.utcnow().isoformat(),\n';
                            loggingReadmeContent += '            "level": record.levelname,\n';
                            loggingReadmeContent += '            "message": record.getMessage(),\n';
                            loggingReadmeContent += '            "module": record.module,\n';
                            loggingReadmeContent += '            "function": record.funcName,\n';
                            loggingReadmeContent += '            "line": record.lineno\n';
                            loggingReadmeContent += '        }\n';
                            loggingReadmeContent += '        return json.dumps(log_record)\n\n';
                            loggingReadmeContent += 'logger = logging.getLogger("app")\n';
                            loggingReadmeContent += 'handler = logging.StreamHandler()\n';
                            loggingReadmeContent += 'handler.setFormatter(JsonFormatter())\n';
                            loggingReadmeContent += 'logger.addHandler(handler)\n';
                            loggingReadmeContent += 'logger.setLevel(logging.INFO)\n';
                            loggingReadmeContent += '```\n';
              
                            // Escribir README.md principal para logging
                            fs.writeFileSync(path.join(loggingDir, 'README.md'), loggingReadmeContent);
              
                            return loggingDir;
                          } catch (error) {
                            console.error('Error al crear archivos de logging:', error);
                            throw error;
                          }
                        }
              
                        /**
                         * Crea archivos de configuración para CI/CD
                         * @param {string} projectDir - Directorio del proyecto
                         * @param {Object} config - Configuración del proyecto
                         * @returns {string} - Directorio de CI/CD
                         */
                        async createCICDFiles(projectDir, config) {
                          try {
                            // Crear directorio .github
                            const githubDir = path.join(projectDir, '.github');
                            if (!fs.existsSync(githubDir)) {
                              fs.mkdirSync(githubDir, { recursive: true });
                            }
              
                            // Crear directorio workflows
                            const workflowsDir = path.join(githubDir, 'workflows');
                            if (!fs.existsSync(workflowsDir)) {
                              fs.mkdirSync(workflowsDir, { recursive: true });
                            }
              
                            // Crear CI workflow
                            let ciWorkflowContent = 'name: CI\n\n';
                            ciWorkflowContent += 'on:\n';
                            ciWorkflowContent += '  push:\n';
                            ciWorkflowContent += '    branches: [ main, develop ]\n';
                            ciWorkflowContent += '  pull_request:\n';
                            ciWorkflowContent += '    branches: [ main, develop ]\n\n';
                            ciWorkflowContent += 'jobs:\n';
                            ciWorkflowContent += '  build-and-test:\n';
                            ciWorkflowContent += '    runs-on: ubuntu-latest\n\n';
                            ciWorkflowContent += '    strategy:\n';
                            ciWorkflowContent += '      matrix:\n';
                            ciWorkflowContent += '        node-version: [14.x, 16.x, 18.x]\n\n';
                            ciWorkflowContent += '    steps:\n';
                            ciWorkflowContent += '    - uses: actions/checkout@v3\n';
                            ciWorkflowContent += '    - name: Use Node.js ${{ matrix.node-version }}\n';
                            ciWorkflowContent += '      uses: actions/setup-node@v3\n';
                            ciWorkflowContent += '      with:\n';
                            ciWorkflowContent += '        node-version: ${{ matrix.node-version }}\n';
                            ciWorkflowContent += '        cache: \'npm\'\n';
                            ciWorkflowContent += '    - run: npm ci\n';
                            ciWorkflowContent += '    - run: npm run build --if-present\n';
                            ciWorkflowContent += '    - run: npm test\n';
                            ciWorkflowContent += '    - name: Upload coverage to Codecov\n';
                            ciWorkflowContent += '      uses: codecov/codecov-action@v3\n';
                            ciWorkflowContent += '      with:\n';
                            ciWorkflowContent += '        token: ${{ secrets.CODECOV_TOKEN }}\n';
                            ciWorkflowContent += '        directory: ./coverage/\n';
                            ciWorkflowContent += '        flags: unittests\n';
                            ciWorkflowContent += '        name: codecov-umbrella\n';
                            ciWorkflowContent += '        fail_ci_if_error: true\n';
                            ciWorkflowContent += '        verbose: true\n';
              
                            // Escribir CI workflow
                            fs.writeFileSync(path.join(workflowsDir, 'ci.yml'), ciWorkflowContent);
              
                            // Crear CD workflow
                            let cdWorkflowContent = 'name: CD\n\n';
                            cdWorkflowContent += 'on:\n';
                            cdWorkflowContent += '  push:\n';
                            cdWorkflowContent += '    branches: [ main ]\n\n';
                            cdWorkflowContent += 'jobs:\n';
                            cdWorkflowContent += '  deploy:\n';
                            cdWorkflowContent += '    runs-on: ubuntu-latest\n\n';
                            cdWorkflowContent += '    steps:\n';
                            cdWorkflowContent += '    - uses: actions/checkout@v3\n';
                            cdWorkflowContent += '    - name: Use Node.js 16.x\n';
                            cdWorkflowContent += '      uses: actions/setup-node@v3\n';
                            cdWorkflowContent += '      with:\n';
                            cdWorkflowContent += '        node-version: 16.x\n';
                            cdWorkflowContent += '        cache: \'npm\'\n';
                            cdWorkflowContent += '    - run: npm ci\n';
                            cdWorkflowContent += '    - run: npm run build --if-present\n';
                            cdWorkflowContent += '    - name: Deploy to Production\n';
                            cdWorkflowContent += '      uses: appleboy/ssh-action@master\n';
                            cdWorkflowContent += '      with:\n';
                            cdWorkflowContent += '        host: ${{ secrets.HOST }}\n';
                            cdWorkflowContent += '        username: ${{ secrets.USERNAME }}\n';
                            cdWorkflowContent += '        key: ${{ secrets.SSH_KEY }}\n';
                            cdWorkflowContent += '        script: |\n';
                            cdWorkflowContent += '          cd /path/to/project\n';
                            cdWorkflowContent += '          git pull\n';
                            cdWorkflowContent += '          npm ci\n';
                            cdWorkflowContent += '          npm run build\n';
                            cdWorkflowContent += '          pm2 restart app\n';
              
                            // Escribir CD workflow
                            fs.writeFileSync(path.join(workflowsDir, 'cd.yml'), cdWorkflowContent);
              
                            // Crear Docker workflow
                            let dockerWorkflowContent = 'name: Docker\n\n';
                            dockerWorkflowContent += 'on:\n';
                            dockerWorkflowContent += '  push:\n';
                            dockerWorkflowContent += '    branches: [ main ]\n';
                            dockerWorkflowContent += '    tags: [ \'v*\' ]\n\n';
                            dockerWorkflowContent += 'jobs:\n';
                            dockerWorkflowContent += '  build-and-push:\n';
                            dockerWorkflowContent += '    runs-on: ubuntu-latest\n\n';
                            dockerWorkflowContent += '    steps:\n';
                            dockerWorkflowContent += '    - uses: actions/checkout@v3\n';
                            dockerWorkflowContent += '    - name: Set up Docker Buildx\n';
                            dockerWorkflowContent += '      uses: docker/setup-buildx-action@v2\n';
                            dockerWorkflowContent += '    - name: Login to DockerHub\n';
                            dockerWorkflowContent += '      uses: docker/login-action@v2\n';
                            dockerWorkflowContent += '      with:\n';
                            dockerWorkflowContent += '        username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
                            dockerWorkflowContent += '        password: ${{ secrets.DOCKERHUB_TOKEN }}\n';
                            dockerWorkflowContent += '    - name: Extract metadata\n';
                            dockerWorkflowContent += '      id: meta\n';
                            dockerWorkflowContent += '      uses: docker/metadata-action@v4\n';
                            dockerWorkflowContent += '      with:\n';
                            dockerWorkflowContent += '        images: username/app\n';
                            dockerWorkflowContent += '        tags: |\n';
                            dockerWorkflowContent += '          type=semver,pattern={{version}}\n';
                            dockerWorkflowContent += '          type=semver,pattern={{major}}.{{minor}}\n';
                            dockerWorkflowContent += '          type=ref,event=branch\n';
                            dockerWorkflowContent += '    - name: Build and push\n';
                            dockerWorkflowContent += '      uses: docker/build-push-action@v4\n';
                            dockerWorkflowContent += '      with:\n';
                            dockerWorkflowContent += '        context: .\n';
                            dockerWorkflowContent += '        push: true\n';
                            dockerWorkflowContent += '        tags: ${{ steps.meta.outputs.tags }}\n';
                            dockerWorkflowContent += '        labels: ${{ steps.meta.outputs.labels }}\n';
                            dockerWorkflowContent += '        cache-from: type=registry,ref=username/app:buildcache\n';
                            dockerWorkflowContent += '        cache-to: type=registry,ref=username/app:buildcache,mode=max\n';
              
                            // Escribir Docker workflow
                            fs.writeFileSync(path.join(workflowsDir, 'docker.yml'), dockerWorkflowContent);
              
                            // Crear directorio para GitLab CI
                            const gitlabDir = path.join(projectDir, '.gitlab');
                            if (!fs.existsSync(gitlabDir)) {
                              fs.mkdirSync(gitlabDir, { recursive: true });
                            }
              
                            // Crear .gitlab-ci.yml
                            let gitlabCIContent = 'stages:\n';
                            gitlabCIContent += '  - build\n';
                            gitlabCIContent += '  - test\n';
                            gitlabCIContent += '  - deploy\n\n';
                            gitlabCIContent += 'variables:\n';
                            gitlabCIContent += '  NODE_ENV: development\n\n';
                            gitlabCIContent += 'cache:\n';
                            gitlabCIContent += '  paths:\n';
                            gitlabCIContent += '    - node_modules/\n\n';
                            gitlabCIContent += 'build:\n';
                            gitlabCIContent += '  stage: build\n';
                            gitlabCIContent += '  image: node:16\n';
                            gitlabCIContent += '  script:\n';
                            gitlabCIContent += '    - npm ci\n';
                            gitlabCIContent += '    - npm run build\n';
                            gitlabCIContent += '  artifacts:\n';
                            gitlabCIContent += '    paths:\n';
                            gitlabCIContent += '      - dist/\n';
                            gitlabCIContent += '      - build/\n';
                            gitlabCIContent += '    expire_in: 1 week\n\n';
                            gitlabCIContent += 'test:\n';
                            gitlabCIContent += '  stage: test\n';
                            gitlabCIContent += '  image: node:16\n';
                            gitlabCIContent += '  script:\n';
                            gitlabCIContent += '    - npm ci\n';
                            gitlabCIContent += '    - npm test\n';
                            gitlabCIContent += '  coverage: /All files[^|]*\\|[^|]*\\s+([\\d\\.]+)/\n\n';
                            gitlabCIContent += 'lint:\n';
                            gitlabCIContent += '  stage: test\n';
                            gitlabCIContent += '  image: node:16\n';
                            gitlabCIContent += '  script:\n';
                            gitlabCIContent += '    - npm ci\n';
                            gitlabCIContent += '    - npm run lint\n\n';
                            gitlabCIContent += 'deploy_staging:\n';
                            gitlabCIContent += '  stage: deploy\n';
                            gitlabCIContent += '  image: alpine:latest\n';
                            gitlabCIContent += '  before_script:\n';
                            gitlabCIContent += '    - apk add --no-cache openssh-client\n';
                            gitlabCIContent += '    - eval $(ssh-agent -s)\n';
                            gitlabCIContent += '    - echo "$SSH_PRIVATE_KEY" | tr -d \'\\r\' | ssh-add -\n';
                            gitlabCIContent += '    - mkdir -p ~/.ssh\n';
                            gitlabCIContent += '    - chmod 700 ~/.ssh\n';
                            gitlabCIContent += '  script:\n';
                            gitlabCIContent += '    - ssh -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_HOST "cd /path/to/app && git pull && npm ci && npm run build && pm2 restart app"\n';
                            gitlabCIContent += '  environment:\n';
                            gitlabCIContent += '    name: staging\n';
                            gitlabCIContent += '    url: https://staging.example.com\n';
                            gitlabCIContent += '  only:\n';
                            gitlabCIContent += '    - develop\n\n';
                            gitlabCIContent += 'deploy_production:\n';
                            gitlabCIContent += '  stage: deploy\n';
                            gitlabCIContent += '  image: alpine:latest\n';
                            gitlabCIContent += '  before_script:\n';
                            gitlabCIContent += '    - apk add --no-cache openssh-client\n';
                            gitlabCIContent += '    - eval $(ssh-agent -s)\n';
                            gitlabCIContent += '    - echo "$SSH_PRIVATE_KEY" | tr -d \'\\r\' | ssh-add -\n';
                            gitlabCIContent += '    - mkdir -p ~/.ssh\n';
                            gitlabCIContent += '    - chmod 700 ~/.ssh\n';
                            gitlabCIContent += '  script:\n';
                            gitlabCIContent += '    - ssh -o StrictHostKeyChecking=no $PROD_SERVER_USER@$PROD_SERVER_HOST "cd /path/to/app && git pull && npm ci && npm run build && pm2 restart app"\n';
                            gitlabCIContent += '  environment:\n';
                            gitlabCIContent += '    name: production\n';
                            gitlabCIContent += '    url: https://example.com\n';
                            gitlabCIContent += '  only:\n';
                            gitlabCIContent += '    - main\n';
                            gitlabCIContent += '  when: manual\n';

                            // Escribir .gitlab-ci.yml
                            fs.writeFileSync(path.join(projectDir, '.gitlab-ci.yml'), gitlabCIContent);

                            // Crear directorio para Jenkins
                            const jenkinsDir = path.join(projectDir, 'jenkins');
                            if (!fs.existsSync(jenkinsDir)) {
                              fs.mkdirSync(jenkinsDir, { recursive: true });
                            }

                            // Crear Jenkinsfile
                            let jenkinsfileContent = 'pipeline {\n';
                            jenkinsfileContent += '  agent {\n';
                            jenkinsfileContent += '    docker {\n';
                            jenkinsfileContent += '      image \'node:16-alpine\'\n';
                            jenkinsfileContent += '    }\n';
                            jenkinsfileContent += '  }\n\n';
                            jenkinsfileContent += '  stages {\n';
                            jenkinsfileContent += '    stage(\'Install dependencies\') {\n';
                            jenkinsfileContent += '      steps {\n';
                            jenkinsfileContent += '        sh \'npm ci\'\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '    }\n\n';
                            jenkinsfileContent += '    stage(\'Lint\') {\n';
                            jenkinsfileContent += '      steps {\n';
                            jenkinsfileContent += '        sh \'npm run lint\'\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '    }\n\n';
                            jenkinsfileContent += '    stage(\'Test\') {\n';
                            jenkinsfileContent += '      steps {\n';
                            jenkinsfileContent += '        sh \'npm test\'\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '      post {\n';
                            jenkinsfileContent += '        always {\n';
                            jenkinsfileContent += '          junit \'**/junit.xml\'\n';
                            jenkinsfileContent += '          publishHTML(target: [\n';
                            jenkinsfileContent += '            allowMissing: false,\n';
                            jenkinsfileContent += '            alwaysLinkToLastBuild: false,\n';
                            jenkinsfileContent += '            keepAll: true,\n';
                            jenkinsfileContent += '            reportDir: \'coverage\',\n';
                            jenkinsfileContent += '            reportFiles: \'index.html\',\n';
                            jenkinsfileContent += '            reportName: \'Coverage Report\'\n';
                            jenkinsfileContent += '          ])\n';
                            jenkinsfileContent += '        }\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '    }\n\n';
                            jenkinsfileContent += '    stage(\'Build\') {\n';
                            jenkinsfileContent += '      steps {\n';
                            jenkinsfileContent += '        sh \'npm run build\'\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '    }\n\n';
                            jenkinsfileContent += '    stage(\'Deploy to Staging\') {\n';
                            jenkinsfileContent += '      when {\n';
                            jenkinsfileContent += '        branch \'develop\'\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '      steps {\n';
                            jenkinsfileContent += '        withCredentials([sshUserPrivateKey(credentialsId: \'ssh-key\', keyFileVariable: \'SSH_KEY\')]) {\n';
                            jenkinsfileContent += '          sh \'ssh -i $SSH_KEY -o StrictHostKeyChecking=no user@staging-server "cd /path/to/app && git pull && npm ci && npm run build && pm2 restart app"\'\n';
                            jenkinsfileContent += '        }\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '    }\n\n';
                            jenkinsfileContent += '    stage(\'Deploy to Production\') {\n';
                            jenkinsfileContent += '      when {\n';
                            jenkinsfileContent += '        branch \'main\'\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '      steps {\n';
                            jenkinsfileContent += '        input message: \'Deploy to production?\'\n';
                            jenkinsfileContent += '        withCredentials([sshUserPrivateKey(credentialsId: \'ssh-key\', keyFileVariable: \'SSH_KEY\')]) {\n';
                            jenkinsfileContent += '          sh \'ssh -i $SSH_KEY -o StrictHostKeyChecking=no user@production-server "cd /path/to/app && git pull && npm ci && npm run build && pm2 restart app"\'\n';
                            jenkinsfileContent += '        }\n';
                            jenkinsfileContent += '      }\n';
                            jenkinsfileContent += '    }\n';
                            jenkinsfileContent += '  }\n\n';
                            jenkinsfileContent += '  post {\n';
                            jenkinsfileContent += '    always {\n';
                            jenkinsfileContent += '      cleanWs()\n';
                            jenkinsfileContent += '    }\n';
                            jenkinsfileContent += '    success {\n';
                            jenkinsfileContent += '      slackSend(color: \'#36a64f\', message: "Build Succeeded: ${env.JOB_NAME} ${env.BUILD_NUMBER}")\n';
                            jenkinsfileContent += '    }\n';
                            jenkinsfileContent += '    failure {\n';
                            jenkinsfileContent += '      slackSend(color: \'#ff0000\', message: "Build Failed: ${env.JOB_NAME} ${env.BUILD_NUMBER}")\n';
                            jenkinsfileContent += '    }\n';
                            jenkinsfileContent += '  }\n';
                            jenkinsfileContent += '}\n';

                            // Escribir Jenkinsfile
                            fs.writeFileSync(path.join(projectDir, 'Jenkinsfile'), jenkinsfileContent);

                            // Crear README.md para CI/CD
                            let cicdReadmeContent = '# CI/CD\n\n';
                            cicdReadmeContent += 'Este proyecto incluye configuraciones para diferentes sistemas de CI/CD:\n\n';
                            cicdReadmeContent += '## GitHub Actions\n\n';
                            cicdReadmeContent += 'Los workflows de GitHub Actions se encuentran en el directorio `.github/workflows/`:\n\n';
                            cicdReadmeContent += '- **ci.yml**: Ejecuta pruebas y análisis en cada push y pull request.\n';
                            cicdReadmeContent += '- **cd.yml**: Despliega la aplicación en producción cuando se hace push a la rama main.\n';
                            cicdReadmeContent += '- **docker.yml**: Construye y publica imágenes Docker cuando se hace push a la rama main o se crea un tag.\n\n';
                            cicdReadmeContent += '## GitLab CI\n\n';
                            cicdReadmeContent += 'La configuración de GitLab CI se encuentra en el archivo `.gitlab-ci.yml` en la raíz del proyecto.\n\n';
                            cicdReadmeContent += '## Jenkins\n\n';
                            cicdReadmeContent += 'La configuración de Jenkins se encuentra en el archivo `Jenkinsfile` en la raíz del proyecto.\n\n';
                            cicdReadmeContent += '## Configuración de Secretos\n\n';
                            cicdReadmeContent += '### GitHub Actions\n\n';
                            cicdReadmeContent += 'Para GitHub Actions, debes configurar los siguientes secretos en la configuración del repositorio:\n\n';
                            cicdReadmeContent += '- `SSH_KEY`: Clave SSH privada para el despliegue.\n';
                            cicdReadmeContent += '- `HOST`: Host del servidor de producción.\n';
                            cicdReadmeContent += '- `USERNAME`: Nombre de usuario para SSH.\n';
                            cicdReadmeContent += '- `DOCKERHUB_USERNAME`: Nombre de usuario de DockerHub.\n';
                            cicdReadmeContent += '- `DOCKERHUB_TOKEN`: Token de acceso de DockerHub.\n\n';
                            cicdReadmeContent += '### GitLab CI\n\n';
                            cicdReadmeContent += 'Para GitLab CI, debes configurar las siguientes variables en la configuración del proyecto:\n\n';
                            cicdReadmeContent += '- `SSH_PRIVATE_KEY`: Clave SSH privada para el despliegue.\n';
                            cicdReadmeContent += '- `SERVER_USER`: Nombre de usuario para SSH en el servidor de staging.\n';
                            cicdReadmeContent += '- `SERVER_HOST`: Host del servidor de staging.\n';
                            cicdReadmeContent += '- `PROD_SERVER_USER`: Nombre de usuario para SSH en el servidor de producción.\n';
                            cicdReadmeContent += '- `PROD_SERVER_HOST`: Host del servidor de producción.\n\n';
                            cicdReadmeContent += '### Jenkins\n\n';
                            cicdReadmeContent += 'Para Jenkins, debes configurar las siguientes credenciales:\n\n';
                            cicdReadmeContent += '- `ssh-key`: Credencial de tipo SSH con clave privada para el despliegue.\n';

                            // Escribir README.md para CI/CD
                            fs.writeFileSync(path.join(githubDir, 'README.md'), cicdReadmeContent);

                            return githubDir;
                          } catch (error) {
                            console.error('Error al crear archivos de CI/CD:', error);
                            throw error;
                          }
                        }

                        /**
                         * Crea archivos de configuración para seguridad
                         * @param {string} projectDir - Directorio del proyecto
                         * @param {Object} config - Configuración del proyecto
                         * @returns {string} - Directorio de seguridad
                         */
                        async createSecurityFiles(projectDir, config) {
                          try {
                            const securityDir = path.join(projectDir, 'security');
                            if (!fs.existsSync(securityDir)) {
                              fs.mkdirSync(securityDir, { recursive: true });
                            }

                            // Crear .env.example
                            let envExampleContent = '# Variables de entorno de ejemplo\n\n';
                            envExampleContent += '# Configuración de la aplicación\n';
                            envExampleContent += 'NODE_ENV=development\n';
                            envExampleContent += 'PORT=3000\n\n';
                            envExampleContent += '# Configuración de la base de datos\n';
                            envExampleContent += 'DB_HOST=localhost\n';
                            envExampleContent += 'DB_PORT=5432\n';
                            envExampleContent += 'DB_NAME=mydatabase\n';
                            envExampleContent += 'DB_USER=myuser\n';
                            envExampleContent += 'DB_PASSWORD=mypassword\n\n';
                            envExampleContent += '# Configuración de JWT\n';
                            envExampleContent += 'JWT_SECRET=your_jwt_secret_key\n';
                            envExampleContent += 'JWT_EXPIRATION=1h\n\n';
                            envExampleContent += '# Configuración de API externa\n';
                            envExampleContent += 'API_KEY=your_api_key\n';
                            envExampleContent += 'API_URL=https://api.example.com\n\n';
                            envExampleContent += '# Configuración de correo electrónico\n';
                            envExampleContent += 'SMTP_HOST=smtp.example.com\n';
                            envExampleContent += 'SMTP_PORT=587\n';
                            envExampleContent += 'SMTP_USER=user@example.com\n';
                            envExampleContent += 'SMTP_PASSWORD=your_smtp_password\n';
                            envExampleContent += 'EMAIL_FROM=noreply@example.com\n';

                            // Escribir .env.example
                            fs.writeFileSync(path.join(projectDir, '.env.example'), envExampleContent);

                            // Crear .gitignore si no existe
                            if (!fs.existsSync(path.join(projectDir, '.gitignore'))) {
                              let gitignoreContent = '# Dependencias\n';
                              gitignoreContent += 'node_modules/\n';
                              gitignoreContent += 'npm-debug.log\n';
                              gitignoreContent += 'yarn-error.log\n\n';
                              gitignoreContent += '# Entorno\n';
                              gitignoreContent += '.env\n';
                              gitignoreContent += '.env.local\n';
                              gitignoreContent += '.env.development.local\n';
                              gitignoreContent += '.env.test.local\n';
                              gitignoreContent += '.env.production.local\n\n';
                              gitignoreContent += '# Compilados\n';
                              gitignoreContent += 'dist/\n';
                              gitignoreContent += 'build/\n';
                              gitignoreContent += 'out/\n';
                              gitignoreContent += '.next/\n\n';
                              gitignoreContent += '# Cobertura\n';
                              gitignoreContent += 'coverage/\n\n';
                              gitignoreContent += '# Logs\n';
                              gitignoreContent += 'logs/\n';
                              gitignoreContent += '*.log\n\n';
                              gitignoreContent += '# Sistema operativo\n';
                              gitignoreContent += '.DS_Store\n';
                              gitignoreContent += 'Thumbs.db\n\n';
                              gitignoreContent += '# IDE\n';
                              gitignoreContent += '.idea/\n';
                              gitignoreContent += '.vscode/\n';
                              gitignoreContent += '*.sublime-project\n';
                              gitignoreContent += '*.sublime-workspace\n\n';
                              gitignoreContent += '# Certificados\n';
                              gitignoreContent += '*.pem\n';
                              gitignoreContent += '*.key\n';
                              gitignoreContent += '*.crt\n';

                              // Escribir .gitignore
                              fs.writeFileSync(path.join(projectDir, '.gitignore'), gitignoreContent);
                            }

                            // Crear SECURITY.md
                            let securityMdContent = '# Política de Seguridad\n\n';
                            securityMdContent += '## Versiones Soportadas\n\n';
                            securityMdContent += 'Actualmente estamos proporcionando actualizaciones de seguridad para las siguientes versiones:\n\n';
                            securityMdContent += '| Versión | Soportada          |\n';
                            securityMdContent += '| ------- | ------------------ |\n';
                            securityMdContent += '| 1.0.x   | :white_check_mark: |\n';
                            securityMdContent += '| < 1.0   | :x:                |\n\n';
                            securityMdContent += '## Reportar una Vulnerabilidad\n\n';
                            securityMdContent += 'Para reportar una vulnerabilidad, por favor envía un correo electrónico a security@example.com con los siguientes detalles:\n\n';
                            securityMdContent += '- Descripción de la vulnerabilidad\n';
                            securityMdContent += '- Pasos para reproducir la vulnerabilidad\n';
                            securityMdContent += '- Posible impacto\n';
                            securityMdContent += '- Si es posible, sugerencias para mitigar o solucionar la vulnerabilidad\n\n';
                            securityMdContent += 'Nuestro equipo de seguridad revisará el reporte y te responderá lo antes posible, generalmente dentro de 48 horas. Una vez que la vulnerabilidad sea confirmada, trabajaremos en una solución y te mantendremos informado sobre el progreso.\n\n';
                            securityMdContent += '## Proceso de Divulgación\n\n';
                            securityMdContent += 'Seguimos un proceso de divulgación coordinada:\n\n';
                            securityMdContent += '1. Recibimos y confirmamos la vulnerabilidad\n';
                            securityMdContent += '2. Desarrollamos y probamos una solución\n';
                            securityMdContent += '3. Preparamos un calendario para el lanzamiento de la solución\n';
                            securityMdContent += '4. Notificamos a los usuarios sobre la vulnerabilidad y la disponibilidad de la actualización\n';
                            securityMdContent += '5. Publicamos detalles técnicos sobre la vulnerabilidad después de que los usuarios hayan tenido tiempo suficiente para actualizar\n\n';
                            securityMdContent += 'Agradecemos tu ayuda para mantener nuestro proyecto seguro.\n';

                            // Escribir SECURITY.md
                            fs.writeFileSync(path.join(projectDir, 'SECURITY.md'), securityMdContent);

                            // Crear directorio para OWASP ZAP
                            const zapDir = path.join(securityDir, 'zap');
                            if (!fs.existsSync(zapDir)) {
                              fs.mkdirSync(zapDir, { recursive: true });
                            }

                            // Crear zap-scan.sh
                            let zapScanContent = '#!/bin/bash\n\n';
                            zapScanContent += '# Script para ejecutar escaneos de seguridad con OWASP ZAP\n\n';
                            zapScanContent += '# Configuración\n';
                            zapScanContent += 'TARGET_URL=${1:-"http://localhost:3000"}\n';
                            zapScanContent += 'ZAP_API_KEY=${2:-"zap-api-key"}\n';
                            zapScanContent += 'REPORT_DIR=${3:-"./reports"}\n';
                            zapScanContent += 'DATE=$(date +"%Y-%m-%d")\n\n';
                            zapScanContent += '# Crear directorio para reportes si no existe\n';
                            zapScanContent += 'mkdir -p "$REPORT_DIR"\n\n';
                            zapScanContent += '# Iniciar ZAP en modo daemon\n';
                            zapScanContent += 'echo "Iniciando ZAP..."\n';
                            zapScanContent += 'docker run -d --name zap-weekly -p 8080:8080 -p 8090:8090 -i owasp/zap2docker-weekly zap-x.sh -daemon -host 0.0.0.0 -port 8080 -config api.key=$ZAP_API_KEY -config api.addrs.addr.regex=.* -config connection.timeoutInSecs=60\n\n';
                            zapScanContent += '# Esperar a que ZAP esté listo\n';
                            zapScanContent += 'echo "Esperando a que ZAP esté listo..."\n';
                            zapScanContent += 'sleep 30\n\n';
                            zapScanContent += '# Ejecutar escaneo activo\n';
                            zapScanContent += 'echo "Iniciando escaneo activo en $TARGET_URL..."\n';
                            zapScanContent += 'docker exec zap-weekly zap-cli -p 8080 -a scan -r "$TARGET_URL" -J "$REPORT_DIR/zap-scan-$DATE.json" -x "$REPORT_DIR/zap-scan-$DATE.xml" -I -s -z "-config scanner.attackOnStart=true -config view.mode=attack -config connection.dnsTtlSuccessfulQueries=-1"\n\n';
                            zapScanContent += '# Generar reporte HTML\n';
                            zapScanContent += 'echo "Generando reporte HTML..."\n';
                            zapScanContent += 'docker exec zap-weekly zap-cli -p 8080 report -o "$REPORT_DIR/zap-scan-$DATE.html" -f html\n\n';
                            zapScanContent += '# Detener y eliminar contenedor ZAP\n';
                            zapScanContent += 'echo "Deteniendo ZAP..."\n';
                            zapScanContent += 'docker stop zap-weekly\n';
                            zapScanContent += 'docker rm zap-weekly\n\n';
                            zapScanContent += 'echo "Escaneo completado. Reportes disponibles en $REPORT_DIR"\n';

                            // Escribir zap-scan.sh
                            fs.writeFileSync(path.join(zapDir, 'zap-scan.sh'), zapScanContent);

                            // Crear zap-scan.bat para Windows
                            let zapScanBatContent = '@echo off\n\n';
                            zapScanBatContent += 'REM Script para ejecutar escaneos de seguridad con OWASP ZAP en Windows\n\n';
                            zapScanBatContent += 'REM Configuración\n';
                            zapScanBatContent += 'set TARGET_URL=%1\n';
                            zapScanBatContent += 'if "%TARGET_URL%"=="" set TARGET_URL=http://localhost:3000\n\n';
                            zapScanBatContent += 'set ZAP_API_KEY=%2\n';
                            zapScanBatContent += 'if "%ZAP_API_KEY%"=="" set ZAP_API_KEY=zap-api-key\n\n';
                            zapScanBatContent += 'set REPORT_DIR=%3\n';
                            zapScanBatContent += 'if "%REPORT_DIR%"=="" set REPORT_DIR=.\\reports\n\n';
                            zapScanBatContent += 'for /f "tokens=2 delims==" %%a in (\'wmic OS Get localdatetime /value\') do set "dt=%%a"\n';
                            zapScanBatContent += 'set "DATE=%dt:~0,4%-%dt:~4,2%-%dt:~6,2%"\n\n';
                            zapScanBatContent += 'REM Crear directorio para reportes si no existe\n';
                            zapScanBatContent += 'if not exist "%REPORT_DIR%" mkdir "%REPORT_DIR%"\n\n';
                            zapScanBatContent += 'REM Iniciar ZAP en modo daemon\n';
                            zapScanBatContent += 'echo Iniciando ZAP...\n';
                            zapScanBatContent += 'docker run -d --name zap-weekly -p 8080:8080 -p 8090:8090 -i owasp/zap2docker-weekly zap-x.sh -daemon -host 0.0.0.0 -port 8080 -config api.key=%ZAP_API_KEY% -config api.addrs.addr.regex=.* -config connection.timeoutInSecs=60\n\n';
                            zapScanBatContent += 'REM Esperar a que ZAP esté listo\n';
                            zapScanBatContent += 'echo Esperando a que ZAP esté listo...\n';
                            zapScanBatContent += 'timeout /t 30 /nobreak\n\n';
                            zapScanBatContent += 'REM Ejecutar escaneo activo\n';
                            zapScanBatContent += 'echo Iniciando escaneo activo en %TARGET_URL%...\n';
                            zapScanBatContent += 'docker exec zap-weekly zap-cli -p 8080 -a scan -r "%TARGET_URL%" -J "%REPORT_DIR%\\zap-scan-%DATE%.json" -x "%REPORT_DIR%\\zap-scan-%DATE%.xml" -I -s -z "-config scanner.attackOnStart=true -config view.mode=attack -config connection.dnsTtlSuccessfulQueries=-1"\n\n';
                            zapScanBatContent += 'REM Generar reporte HTML\n';
                            zapScanBatContent += 'echo Generando reporte HTML...\n';
                            zapScanBatContent += 'docker exec zap-weekly zap-cli -p 8080 report -o "%REPORT_DIR%\\zap-scan-%DATE%.html" -f html\n\n';
                            zapScanBatContent += 'REM Detener y eliminar contenedor ZAP\n';
                            zapScanBatContent += 'echo Deteniendo ZAP...\n';
                            zapScanBatContent += 'docker stop zap-weekly\n';
                            zapScanBatContent += 'docker rm zap-weekly\n\n';
                            zapScanBatContent += 'echo Escaneo completado. Reportes disponibles en %REPORT_DIR%\n';

                            // Escribir zap-scan.bat
                            fs.writeFileSync(path.join(zapDir, 'zap-scan.bat'), zapScanBatContent);

                            // Crear directorio para SAST
                            const sastDir = path.join(securityDir, 'sast');
                            if (!fs.existsSync(sastDir)) {
                              fs.mkdirSync(sastDir, { recursive: true });
                            }

                            // Crear sonarqube.properties
                            let sonarqubeContent = '# Configuración de SonarQube\n\n';
                            sonarqubeContent += '# Información del proyecto\n';
                            sonarqubeContent += 'sonar.projectKey=my-project\n';
                            sonarqubeContent += 'sonar.projectName=My Project\n';
                            sonarqubeContent += 'sonar.projectVersion=1.0.0\n\n';
                            sonarqubeContent += '# Ruta al código fuente\n';
                            sonarqubeContent += 'sonar.sources=src\n';
                            sonarqubeContent += 'sonar.tests=test,tests,__tests__\n\n';
                            sonarqubeContent += '# Exclusiones\n';
                            sonarqubeContent += 'sonar.exclusions=node_modules/**,dist/**,coverage/**,build/**\n';
                            sonarqubeContent += 'sonar.test.exclusions=node_modules/**,dist/**,coverage/**,build/**\n\n';
                            sonarqubeContent += '# Cobertura de código\n';
                            sonarqubeContent += 'sonar.javascript.lcov.reportPaths=coverage/lcov.info\n';
                            sonarqubeContent += 'sonar.testExecutionReportPaths=test-report.xml\n\n';
                            sonarqubeContent += '# Codificación\n';
                            sonarqubeContent += 'sonar.sourceEncoding=UTF-8\n';

                            // Escribir sonarqube.properties
                            fs.writeFileSync(path.join(sastDir, 'sonarqube.properties'), sonarqubeContent);

                            // Crear run-sonarqube.sh
                            let runSonarqubeContent = '#!/bin/bash\n\n';
                            runSonarqubeContent += '# Script para ejecutar análisis de SonarQube\n\n';
                            runSonarqubeContent += '# Configuración\n';
                            runSonarqubeContent += 'SONAR_HOST_URL=${1:-"http://localhost:9000"}\n';
                            runSonarqubeContent += 'SONAR_TOKEN=${2:-"your-sonar-token"}\n';
                            runSonarqubeContent += 'SONAR_PROJECT_KEY=${3:-"my-project"}\n\n';
                            runSonarqubeContent += '# Ejecutar análisis\n';
                            runSonarqubeContent += 'echo "Ejecutando análisis de SonarQube..."\n';
                            runSonarqubeContent += 'docker run --rm \\\n';
                            runSonarqubeContent += '  -e SONAR_HOST_URL="$SONAR_HOST_URL" \\\n';
                            runSonarqubeContent += '  -e SONAR_LOGIN="$SONAR_TOKEN" \\\n';
                            runSonarqubeContent += '  -v "$(pwd):/usr/src" \\\n';
                            runSonarqubeContent += '  sonarsource/sonar-scanner-cli:latest \\\n';
                            runSonarqubeContent += '  -Dsonar.projectKey="$SONAR_PROJECT_KEY"\n\n';
                            runSonarqubeContent += 'echo "Análisis completado. Revisa los resultados en $SONAR_HOST_URL/dashboard?id=$SONAR_PROJECT_KEY"\n';

                            // Escribir run-sonarqube.sh
                            fs.writeFileSync(path.join(sastDir, 'run-sonarqube.sh'), runSonarqubeContent);

                            // Crear run-sonarqube.bat para Windows
                            let runSonarqubeBatContent = '@echo off\n\n';
                            runSonarqubeBatContent += 'REM Script para ejecutar análisis de SonarQube en Windows\n\n';
                            runSonarqubeBatContent += 'REM Configuración\n';
                            runSonarqubeBatContent += 'set SONAR_HOST_URL=%1\n';
                            runSonarqubeBatContent += 'if "%SONAR_HOST_URL%"=="" set SONAR_HOST_URL=http://localhost:9000\n\n';
                            runSonarqubeBatContent += 'set SONAR_TOKEN=%2\n';
                            runSonarqubeBatContent += 'if "%SONAR_TOKEN%"=="" set SONAR_TOKEN=your-sonar-token\n\n';
                            runSonarqubeBatContent += 'set SONAR_PROJECT_KEY=%3\n';
                            runSonarqubeBatContent += 'if "%SONAR_PROJECT_KEY%"=="" set SONAR_PROJECT_KEY=my-project\n\n';
                            runSonarqubeBatContent += 'REM Ejecutar análisis\n';
                            runSonarqubeBatContent += 'echo Ejecutando análisis de SonarQube...\n';
                            runSonarqubeBatContent += 'docker run --rm ^\n';
                            runSonarqubeBatContent += '  -e SONAR_HOST_URL="%SONAR_HOST_URL%" ^\n';
                            runSonarqubeBatContent += '  -e SONAR_LOGIN="%SONAR_TOKEN%" ^\n';
                            runSonarqubeBatContent += '  -v "%cd%:/usr/src" ^\n';
                            runSonarqubeBatContent += '  sonarsource/sonar-scanner-cli:latest ^\n';
                            runSonarqubeBatContent += '  -Dsonar.projectKey="%SONAR_PROJECT_KEY%"\n\n';
                            runSonarqubeBatContent += 'echo Análisis completado. Revisa los resultados en %SONAR_HOST_URL%/dashboard?id=%SONAR_PROJECT_KEY%\n';

                            // Escribir run-sonarqube.bat
                            fs.writeFileSync(path.join(sastDir, 'run-sonarqube.bat'), runSonarqubeBatContent);

                            // Crear directorio para dependencias
                            const depsDir = path.join(securityDir, 'dependencies');
                            if (!fs.existsSync(depsDir)) {
                              fs.mkdirSync(depsDir, { recursive: true });
                            }

                            // Crear run-dependency-check.sh
                            let depCheckContent = '#!/bin/bash\n\n';
                            depCheckContent += '# Script para ejecutar OWASP Dependency Check\n\n';
                            depCheckContent += '# Configuración\n';
                            depCheckContent += 'PROJECT_NAME=${1:-"my-project"}\n';
                            depCheckContent += 'REPORT_DIR=${2:-"./reports"}\n';
                            depCheckContent += 'DATE=$(date +"%Y-%m-%d")\n\n';
                            depCheckContent += '# Crear directorio para reportes si no existe\n';
                            depCheckContent += 'mkdir -p "$REPORT_DIR"\n\n';
                            depCheckContent += '# Ejecutar Dependency Check\n';
                            depCheckContent += 'echo "Ejecutando OWASP Dependency Check..."\n';
                            depCheckContent += 'docker run --rm \\\n';
                            depCheckContent += '  -e user=$USER \\\n';
                            depCheckContent += '  -u $(id -u ${USER}):$(id -g ${USER}) \\\n';
                            depCheckContent += '  -v "$(pwd):/src" \\\n';
                            depCheckContent += '  -v "$REPORT_DIR:/report" \\\n';
                            depCheckContent += '  owasp/dependency-check:latest \\\n';
                            depCheckContent += '  --scan /src \\\n';
                            depCheckContent += '  --format "ALL" \\\n';
                            depCheckContent += '  --project "$PROJECT_NAME" \\\n';
                            depCheckContent += '  --out /report \\\n';
                            depCheckContent += '  --suppression /src/security/dependencies/suppressions.xml\n\n';
                            depCheckContent += 'echo "Análisis completado. Reportes disponibles en $REPORT_DIR"\n';

                            // Escribir run-dependency-check.sh
                            fs.writeFileSync(path.join(depsDir, 'run-dependency-check.sh'), depCheckContent);

                            // Crear run-dependency-check.bat para Windows
                            let depCheckBatContent = '@echo off\n\n';
                            depCheckBatContent += 'REM Script para ejecutar OWASP Dependency Check en Windows\n\n';
                            depCheckBatContent += 'REM Configuración\n';
                            depCheckBatContent += 'set PROJECT_NAME=%1\n';
                            depCheckBatContent += 'if "%PROJECT_NAME%"=="" set PROJECT_NAME=my-project\n\n';
                            depCheckBatContent += 'set REPORT_DIR=%2\n';
                            depCheckBatContent += 'if "%REPORT_DIR%"=="" set REPORT_DIR=.\\reports\n\n';
                            depCheckBatContent += 'for /f "tokens=2 delims==" %%a in (\'wmic OS Get localdatetime /value\') do set "dt=%%a"\n';
                            depCheckBatContent += 'set "DATE=%dt:~0,4%-%dt:~4,2%-%dt:~6,2%"\n\n';
                            depCheckBatContent += 'REM Crear directorio para reportes si no existe\n';
                            depCheckBatContent += 'if not exist "%REPORT_DIR%" mkdir "%REPORT_DIR%"\n\n';
                            depCheckBatContent += 'REM Ejecutar Dependency Check\n';
                            depCheckBatContent += 'echo Ejecutando OWASP Dependency Check...\n';
                            depCheckBatContent += 'docker run --rm ^\n';
                            depCheckBatContent += '  -v "%cd%:/src" ^\n';
                            depCheckBatContent += '  -v "%cd%\\%REPORT_DIR%:/report" ^\n';
                            depCheckBatContent += '  owasp/dependency-check:latest ^\n';
                            depCheckBatContent += '  --scan /src ^\n';
                            depCheckBatContent += '  --format "ALL" ^\n';
                            depCheckBatContent += '  --project "%PROJECT_NAME%" ^\n';
                            depCheckBatContent += '  --out /report ^\n';
                            depCheckBatContent += '  --suppression /src/security/dependencies/suppressions.xml\n\n';
                            depCheckBatContent += 'echo Análisis completado. Reportes disponibles en %REPORT_DIR%\n';

                            // Escribir run-dependency-check.bat
                            fs.writeFileSync(path.join(depsDir, 'run-dependency-check.bat'), depCheckBatContent);

                            // Crear suppressions.xml
                            let suppressionsContent = '<?xml version="1.0" encoding="UTF-8"?>\n';
                            suppressionsContent += '<suppressions xmlns="https://jeremylong.github.io/DependencyCheck/dependency-suppression.1.3.xsd">\n';
                            suppressionsContent += '   <!-- Ejemplo de supresión -->\n';
                            suppressionsContent += '   <!--\n';
                            suppressionsContent += '   <suppress>\n';
                            suppressionsContent += '      <notes>Falso positivo para CVE-2020-XXXX</notes>\n';
                            suppressionsContent += '      <cve>CVE-2020-XXXX</cve>\n';
                            suppressionsContent += '   </suppress>\n';
                            suppressionsContent += '   -->\n';
                            suppressionsContent += '</suppressions>\n';

                            // Escribir suppressions.xml
                            fs.writeFileSync(path.join(depsDir, 'suppressions.xml'), suppressionsContent);

                            // Crear directorio para secretos
                            const secretsDir = path.join(securityDir, 'secrets');
                            if (!fs.existsSync(secretsDir)) {
                              fs.mkdirSync(secretsDir, { recursive: true });
                            }

                            // Crear run-gitleaks.sh
                            let gitleaksContent = '#!/bin/bash\n\n';
                            gitleaksContent += '# Script para ejecutar Gitleaks para detectar secretos en el código\n\n';
                            gitleaksContent += '# Configuración\n';
                            gitleaksContent += 'REPORT_DIR=${1:-"./reports"}\n';
                            gitleaksContent += 'DATE=$(date +"%Y-%m-%d")\n\n';
                            gitleaksContent += '# Crear directorio para reportes si no existe\n';
                            gitleaksContent += 'mkdir -p "$REPORT_DIR"\n\n';
                            gitleaksContent += '# Ejecutar Gitleaks\n';
                            gitleaksContent += 'echo "Ejecutando Gitleaks..."\n';
                            gitleaksContent += 'docker run --rm \\\n';
                            gitleaksContent += '  -v "$(pwd):/src" \\\n';
                            gitleaksContent += '  -v "$REPORT_DIR:/report" \\\n';
                            gitleaksContent += '  zricethezav/gitleaks:latest \\\n';
                            gitleaksContent += '  detect \\\n';
                            gitleaksContent += '  --source="/src" \\\n';
                            gitleaksContent += '  --report-path="/report/gitleaks-report-$DATE.json" \\\n';
                            gitleaksContent += '  --report-format="json"\n\n';
                            gitleaksContent += 'echo "Análisis completado. Reportes disponibles en $REPORT_DIR"\n';

                            // Escribir run-gitleaks.sh
                            fs.writeFileSync(path.join(secretsDir, 'run-gitleaks.sh'), gitleaksContent);

                            // Crear run-gitleaks.bat para Windows
                            let gitleaksBatContent = '@echo off\n\n';
                            gitleaksBatContent += 'REM Script para ejecutar Gitleaks para detectar secretos en el código en Windows\n\n';
                            gitleaksBatContent += 'REM Configuración\n';
                            gitleaksBatContent += 'set REPORT_DIR=%1\n';
                            gitleaksBatContent += 'if "%REPORT_DIR%"=="" set REPORT_DIR=.\\reports\n\n';
                            gitleaksBatContent += 'for /f "tokens=2 delims==" %%a in (\'wmic OS Get localdatetime /value\') do set "dt=%%a"\n';
                            gitleaksBatContent += 'set "DATE=%dt:~0,4%-%dt:~4,2%-%dt:~6,2%"\n\n';
                            gitleaksBatContent += 'REM Crear directorio para reportes si no existe\n';
                            gitleaksBatContent += 'if not exist "%REPORT_DIR%" mkdir "%REPORT_DIR%"\n\n';
                            gitleaksBatContent += 'REM Ejecutar Gitleaks\n';
                            gitleaksBatContent += 'echo Ejecutando Gitleaks...\n';
                            gitleaksBatContent += 'docker run --rm ^\n';
                            gitleaksBatContent += '  -v "%cd%:/src" ^\n';
                            gitleaksBatContent += '  -v "%cd%\\%REPORT_DIR%:/report" ^\n';
                            gitleaksBatContent += '  zricethezav/gitleaks:latest ^\n';
                            gitleaksBatContent += '  detect ^\n';
                            gitleaksBatContent += '  --source="/src" ^\n';
                            gitleaksBatContent += '  --report-path="/report/gitleaks-report-%DATE%.json" ^\n';
                            gitleaksBatContent += '  --report-format="json"\n\n';
                            gitleaksBatContent += 'echo Análisis completado. Reportes disponibles en %REPORT_DIR%\n';

                            // Escribir run-gitleaks.bat
                            fs.writeFileSync(path.join(secretsDir, 'run-gitleaks.bat'), gitleaksBatContent);

                            // Crear .gitleaks.toml
                            let gitleaksTomlContent = '# Configuración de Gitleaks\n\n';
                            gitleaksTomlContent += '[allowlist]\n';
                            gitleaksTomlContent += '  description = "Allowlisted files"\n';
                            gitleaksTomlContent += '  paths = [\n';
                            gitleaksTomlContent += '    "security/secrets/run-gitleaks.sh",\n';
                            gitleaksTomlContent += '    "security/secrets/run-gitleaks.bat",\n';
                            gitleaksTomlContent += '    ".gitleaks.toml"\n';
                            gitleaksTomlContent += '  ]\n';

                            // Escribir .gitleaks.toml
                            fs.writeFileSync(path.join(projectDir, '.gitleaks.toml'), gitleaksTomlContent);

                            // Crear directorio para hardening
                            const hardeningDir = path.join(securityDir, 'hardening');
                            if (!fs.existsSync(hardeningDir)) {
                              fs.mkdirSync(hardeningDir, { recursive: true });
                            }

                            // Crear security-headers.js
                            let securityHeadersContent = '/**\n';
                            securityHeadersContent += ' * Configuración de cabeceras de seguridad para Express.js\n';
                            securityHeadersContent += ' * \n';
                            securityHeadersContent += ' * Uso:\n';
                            securityHeadersContent += ' * const securityHeaders = require(\'./security/hardening/security-headers\');\n';
                            securityHeadersContent += ' * app.use(securityHeaders);\n';
                            securityHeadersContent += ' */\n\n';
                            securityHeadersContent += 'const helmet = require(\'helmet\');\n\n';
                            securityHeadersContent += 'const securityHeaders = helmet({\n';
                            securityHeadersContent += '  contentSecurityPolicy: {\n';
                            securityHeadersContent += '    directives: {\n';
                            securityHeadersContent += '      defaultSrc: ["\'self\'"],\n';
                            securityHeadersContent += '      scriptSrc: ["\'self\'", "\'unsafe-inline\'", "\'unsafe-eval\'"],\n';
                            securityHeadersContent += '      styleSrc: ["\'self\'", "\'unsafe-inline\'"],\n';
                            securityHeadersContent += '      imgSrc: ["\'self\'", "data:"],\n';
                            securityHeadersContent += '      connectSrc: ["\'self\'"],\n';
                            securityHeadersContent += '      fontSrc: ["\'self\'"],\n';
                            securityHeadersContent += '      objectSrc: ["\'none\'"],\n';
                            securityHeadersContent += '      mediaSrc: ["\'self\'"],\n';
                            securityHeadersContent += '      frameSrc: ["\'none\'"],\n';
                            securityHeadersContent += '    },\n';
                            securityHeadersContent += '  },\n';
                            securityHeadersContent += '  xssFilter: true,\n';
                            securityHeadersContent += '  hsts: {\n';
                            securityHeadersContent += '    maxAge: 31536000,\n';
                            securityHeadersContent += '    includeSubDomains: true,\n';
                            securityHeadersContent += '    preload: true,\n';
                            securityHeadersContent += '  },\n';
                            securityHeadersContent += '  noSniff: true,\n';
                            securityHeadersContent += '  referrerPolicy: { policy: "same-origin" },\n';
                            securityHeadersContent += '});\n\n';
                            securityHeadersContent += 'module.exports = securityHeaders;\n';

                            // Escribir security-headers.js
                            fs.writeFileSync(path.join(hardeningDir, 'security-headers.js'), securityHeadersContent);

                            // Crear rate-limiter.js
                            let rateLimiterContent = '/**\n';
                            rateLimiterContent += ' * Configuración de limitador de tasa para Express.js\n';
                            rateLimiterContent += ' * \n';
                            rateLimiterContent += ' * Uso:\n';
                            rateLimiterContent += ' * const rateLimiter = require(\'./security/hardening/rate-limiter\');\n';
                            rateLimiterContent += ' * app.use(rateLimiter);\n';
                            rateLimiterContent += ' */\n\n';
                            rateLimiterContent += 'const rateLimit = require(\'express-rate-limit\');\n\n';
                            rateLimiterContent += 'const rateLimiter = rateLimit({\n';
                            rateLimiterContent += '  windowMs: 15 * 60 * 1000, // 15 minutos\n';
                            rateLimiterContent += '  max: 100, // Límite de 100 solicitudes por ventana por IP\n';
                            rateLimiterContent += '  standardHeaders: true, // Devuelve info de límite en los headers `RateLimit-*`\n';
                            rateLimiterContent += '  legacyHeaders: false, // Deshabilita los headers `X-RateLimit-*`\n';
                            rateLimiterContent += '  message: {\n';
                            rateLimiterContent += '    status: 429,\n';
                            rateLimiterContent += '    message: "Demasiadas solicitudes, por favor intenta de nuevo más tarde."\n';
                            rateLimiterContent += '  },\n';
                            rateLimiterContent += '  skip: (req) => {\n';
                            rateLimiterContent += '    // Opcional: Excluir ciertas rutas o IPs\n';
                            rateLimiterContent += '    return false;\n';
                            rateLimiterContent += '  }\n';
                            rateLimiterContent += '});\n\n';
                            rateLimiterContent += 'module.exports = rateLimiter;\n';

                            // Escribir rate-limiter.js
                            fs.writeFileSync(path.join(hardeningDir, 'rate-limiter.js'), rateLimiterContent);

                            // Crear README.md para seguridad
                            let securityReadmeContent = '# Seguridad\n\n';
                            securityReadmeContent += 'Este directorio contiene herramientas y configuraciones para mejorar la seguridad del proyecto.\n\n';
                            securityReadmeContent += '## Estructura\n\n';
                            securityReadmeContent += '- **zap/**: Scripts para ejecutar escaneos de seguridad con OWASP ZAP.\n';
                            securityReadmeContent += '- **sast/**: Configuración para análisis estático de código con SonarQube.\n';
                            securityReadmeContent += '- **dependencies/**: Scripts para verificar vulnerabilidades en dependencias.\n';
                            securityReadmeContent += '- **secrets/**: Herramientas para detectar secretos en el código.\n';
                            securityReadmeContent += '- **hardening/**: Configuraciones para fortalecer la seguridad de la aplicación.\n\n';
                            securityReadmeContent += '## Uso\n\n';
                            securityReadmeContent += '### Escaneo de Seguridad con OWASP ZAP\n\n';
                            securityReadmeContent += '```bash\n';
                            securityReadmeContent += '# En Linux/Mac\n';
                            securityReadmeContent += './security/zap/zap-scan.sh http://localhost:3000\n\n';
                            securityReadmeContent += '# En Windows\n';
                            securityReadmeContent += '.\\security\\zap\\zap-scan.bat http://localhost:3000\n';
                            securityReadmeContent += '```\n\n';
                            securityReadmeContent += '### Análisis Estático con SonarQube\n\n';
                            securityReadmeContent += '```bash\n';
                            securityReadmeContent += '# En Linux/Mac\n';
                            securityReadmeContent += './security/sast/run-sonarqube.sh http://localhost:9000 your-sonar-token\n\n';
                            securityReadmeContent += '# En Windows\n';
                            securityReadmeContent += '.\\security\\sast\\run-sonarqube.bat http://localhost:9000 your-sonar-token\n';
                            securityReadmeContent += '```\n\n';
                            securityReadmeContent += '### Verificación de Dependencias\n\n';
                            securityReadmeContent += '```bash\n';
                            securityReadmeContent += '# En Linux/Mac\n';
                            securityReadmeContent += './security/dependencies/run-dependency-check.sh my-project ./reports\n\n';
                            securityReadmeContent += '# En Windows\n';
                            securityReadmeContent += '.\\security\\dependencies\\run-dependency-check.bat my-project .\\reports\n';
                            securityReadmeContent += '```\n\n';
                            securityReadmeContent += '### Detección de Secretos\n\n';
                            securityReadmeContent += '```bash\n';
                            securityReadmeContent += '# En Linux/Mac\n';
                            securityReadmeContent += './security/secrets/run-gitleaks.sh ./reports\n\n';
                            securityReadmeContent += '# En Windows\n';
                            securityReadmeContent += '.\\security\\secrets\\run-gitleaks.bat .\\reports\n';
                            securityReadmeContent += '```\n\n';
                            securityReadmeContent += '### Hardening de la Aplicación\n\n';
                            securityReadmeContent += 'Para implementar las cabeceras de seguridad y el limitador de tasa en una aplicación Express.js:\n\n';
                            securityReadmeContent += '```javascript\n';
                            securityReadmeContent += 'const express = require(\'express\');\n';
                            securityReadmeContent += 'const securityHeaders = require(\'./security/hardening/security-headers\');\n';
                            securityReadmeContent += 'const rateLimiter = require(\'./security/hardening/rate-limiter\');\n\n';
                            securityReadmeContent += 'const app = express();\n\n';
                            securityReadmeContent += '// Aplicar cabeceras de seguridad\n';
                            securityReadmeContent += 'app.use(securityHeaders);\n\n';
                            securityReadmeContent += '// Aplicar limitador de tasa\n';
                            securityReadmeContent += 'app.use(rateLimiter);\n';
                            securityReadmeContent += '```\n\n';
                            securityReadmeContent += '## Mejores Prácticas\n\n';
                            securityReadmeContent += '1. **Mantén las dependencias actualizadas**: Ejecuta regularmente `npm audit` y actualiza las dependencias vulnerables.\n';
                            securityReadmeContent += '2. **Implementa autenticación segura**: Utiliza métodos modernos como OAuth 2.0 o JWT con tiempos de expiración adecuados.\n';
                            securityReadmeContent += '3. **Valida todas las entradas**: Implementa validación tanto en el cliente como en el servidor.\n';
                            securityReadmeContent += '4. **Usa HTTPS**: Configura correctamente TLS/SSL para todas las comunicaciones.\n';
                            securityReadmeContent += '5. **Implementa logging y monitoreo**: Registra eventos de seguridad y configura alertas para actividades sospechosas.\n';
                            securityReadmeContent += '6. **Sigue el principio de menor privilegio**: Limita los permisos a lo mínimo necesario.\n';
                            securityReadmeContent += '7. **Realiza pruebas de seguridad regularmente**: Incluye pruebas de seguridad en tu pipeline de CI/CD.\n';

                            // Escribir README.md para seguridad
                            fs.writeFileSync(path.join(securityDir, 'README.md'), securityReadmeContent);

                            return securityDir;
                          } catch (error) {
                            console.error('Error al crear archivos de seguridad:', error);
                            throw error;
                          }
                        }

                        /**
                         * Crea archivos de configuración para monitoreo
                         * @param {string} projectDir - Directorio del proyecto
                         * @param {Object} config - Configuración del proyecto
                         * @returns {string} - Directorio de monitoreo
                         */
                        async createMonitoringFiles(projectDir, config) {
                          try {
                            const monitoringDir = path.join(projectDir, 'monitoring');
                            if (!fs.existsSync(monitoringDir)) {
                              fs.mkdirSync(monitoringDir, { recursive: true });
                            }

                            // Crear directorio para Prometheus
                            const prometheusDir = path.join(monitoringDir, 'prometheus');
                            if (!fs.existsSync(prometheusDir)) {
                              fs.mkdirSync(prometheusDir, { recursive: true });
                            }

                            // Crear prometheus.yml
                            let prometheusContent = 'global:\n';
                            prometheusContent += '  scrape_interval: 15s\n';
                            prometheusContent += '  evaluation_interval: 15s\n\n';
                            prometheusContent += 'alerting:\n';
                            prometheusContent += '  alertmanagers:\n';
                            prometheusContent += '    - static_configs:\n';
                            prometheusContent += '        - targets: [\'alertmanager:9093\']\n\n';
                            prometheusContent += 'rule_files:\n';
                            prometheusContent += '  - "alert_rules.yml"\n\n';
                            prometheusContent += 'scrape_configs:\n';
                            prometheusContent += '  - job_name: \'prometheus\'\n';
                            prometheusContent += '    static_configs:\n';
                            prometheusContent += '      - targets: [\'localhost:9090\']\n\n';
                            prometheusContent += '  - job_name: \'node-exporter\'\n';
                            prometheusContent += '    static_configs:\n';
                            prometheusContent += '      - targets: [\'node-exporter:9100\']\n\n';
                            prometheusContent += '  - job_name: \'cadvisor\'\n';
                            prometheusContent += '    static_configs:\n';
                            prometheusContent += '      - targets: [\'cadvisor:8080\']\n\n';
                            prometheusContent += '  - job_name: \'app\'\n';
                            prometheusContent += '    static_configs:\n';
                            prometheusContent += '      - targets: [\'app:3000\']\n';

                            // Escribir prometheus.yml
                            fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);

                            // Crear alert_rules.yml
                            let alertRulesContent = 'groups:\n';
                            alertRulesContent += '- name: example\n';
                            alertRulesContent += '  rules:\n';
                            alertRulesContent += '  - alert: HighCPULoad\n';
                            alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n';
                            alertRulesContent += '    for: 5m\n';
                            alertRulesContent += '    labels:\n';
                            alertRulesContent += '      severity: warning\n';
                            alertRulesContent += '    annotations:\n';
                            alertRulesContent += '      summary: "High CPU load (instance {{ $labels.instance }})"\n';
                            alertRulesContent += '      description: "CPU load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
                            alertRulesContent += '  - alert: HighMemoryLoad\n';
                            alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80\n';
                            alertRulesContent += '    for: 5m\n';
                            alertRulesContent += '    labels:\n';
                            alertRulesContent += '      severity: warning\n';
                            alertRulesContent += '    annotations:\n';
                            alertRulesContent += '      summary: "High memory load (instance {{ $labels.instance }})"\n';
                            alertRulesContent += '      description: "Memory load is > 80%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n\n';
                            alertRulesContent += '  - alert: HighDiskUsage\n';
                            alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85\n';
                            alertRulesContent += '    for: 5m\n';
                            alertRulesContent += '    labels:\n';
                            alertRulesContent += '      severity: warning\n';
                            alertRulesContent += '    annotations:\n';
                            alertRulesContent += '      summary: "High disk usage (instance {{ $labels.instance }})"\n';
                            alertRulesContent += '      description: "Disk usage is > 85%\\n  VALUE = {{ $value }}\\n  LABELS: {{ $labels }}"\n';

                            // Escribir alert_rules.yml
                            fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);

                            // Crear Alertmanager configuration
                            const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
                            if (!fs.existsSync(alertmanagerDir)) {
                              fs.mkdirSync(alertmanagerDir, { recursive: true });
                            }

                            // Crear alertmanager.yml
                            let alertmanagerContent = 'global:\n';
                            alertmanagerContent += '  resolve_timeout: 5m\n';
                            alertmanagerContent += '  smtp_smarthost: "smtp.example.com:587"\n';
                            alertmanagerContent += '  smtp_from: "alertmanager@example.com"\n';
                            alertmanagerContent += '  smtp_auth_username: "alertmanager"\n';
                            alertmanagerContent += '  smtp_auth_password: "password"\n\n';
                            alertmanagerContent += 'route:\n';
                            alertmanagerContent += '  group_by: [\'alertname\', \'instance\']\n';
                            alertmanagerContent += '  group_wait: 30s\n';
                            alertmanagerContent += '  group_interval: 5m\n';
                            alertmanagerContent += '  repeat_interval: 1h\n';
                            alertmanagerContent += '  receiver: \'email\'\n\n';
                            alertmanagerContent += 'receivers:\n';
                            alertmanagerContent += '- name: \'email\'\n';
                            alertmanagerContent += '  email_configs:\n';
                            alertmanagerContent += '  - to: "alerts@example.com"\n';
                            alertmanagerContent += '    send_resolved: true\n\n';
                            alertmanagerContent += 'inhibit_rules:\n';
                            alertmanagerContent += '  - source_match:\n';
                            alertmanagerContent += '      severity: \'critical\'\n';
                            alertmanagerContent += '    target_match:\n';
                            alertmanagerContent += '      severity: \'warning\'\n';
                            alertmanagerContent += '    equal: [\'alertname\', \'instance\']\n';

                            // Escribir alertmanager.yml
                            fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);

                            // Crear Grafana configuration
                            const grafanaDir = path.join(monitoringDir, 'grafana');
                            if (!fs.existsSync(grafanaDir)) {
                              fs.mkdirSync(grafanaDir, { recursive: true });
                            }

                            // Crear datasources.yml
                            let datasourcesContent = 'apiVersion: 1\n\n';
                            datasourcesContent += 'datasources:\n';
                            datasourcesContent += '  - name: Prometheus\n';
                            datasourcesContent += '    type: prometheus\n';
                            datasourcesContent += '    access: proxy\n';
                            datasourcesContent += '    url: http://prometheus:9090\n';
                            datasourcesContent += '    isDefault: true\n';
                            datasourcesContent += '    editable: true\n';

                            // Escribir datasources.yml
                            fs.writeFileSync(path.join(grafanaDir, 'datasources.yml'), datasourcesContent);

                            // Crear dashboard.json para Grafana
                            let dashboardContent = '{\n';
                            dashboardContent += '  "annotations": {\n';
                            dashboardContent += '    "list": [\n';
                            dashboardContent += '      {\n';
                            dashboardContent += '        "builtIn": 1,\n';
                            dashboardContent += '        "datasource": "-- Grafana --",\n';
                            dashboardContent += '        "enable": true,\n';
                            dashboardContent += '        "hide": true,\n';
                            dashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
                            dashboardContent += '        "name": "Annotations & Alerts",\n';
                            dashboardContent += '        "type": "dashboard"\n';
                            dashboardContent += '      }\n';
                            dashboardContent += '    ]\n';
                            dashboardContent += '  },\n';
                            dashboardContent += '  "editable": true,\n';
                            dashboardContent += '  "gnetId": null,\n';
                            dashboardContent += '  "graphTooltip": 0,\n';
                            dashboardContent += '  "id": 1,\n';
                            dashboardContent += '  "links": [],\n';
                            dashboardContent += '  "panels": [\n';
                            dashboardContent += '    {\n';
                            dashboardContent += '      "alert": {\n';
                            dashboardContent += '        "conditions": [\n';
                            dashboardContent += '          {\n';
                            dashboardContent += '            "evaluator": {\n';
                            dashboardContent += '              "params": [\n';
                            dashboardContent += '                80\n';
                            dashboardContent += '              ],\n';
                            dashboardContent += '              "type": "gt"\n';
                            dashboardContent += '            },\n';
                            dashboardContent += '            "operator": {\n';
                            dashboardContent += '              "type": "and"\n';
                            dashboardContent += '            },\n';
                            dashboardContent += '            "query": {\n';
                            dashboardContent += '              "params": [\n';
                            dashboardContent += '                "A",\n';
                            dashboardContent += '                "5m",\n';
                            dashboardContent += '                "now"\n';
                            dashboardContent += '              ]\n';
                            dashboardContent += '            },\n';
                            dashboardContent += '            "reducer": {\n';
                            dashboardContent += '              "params": [],\n';
                            dashboardContent += '              "type": "avg"\n';
                            dashboardContent += '            },\n';
                            dashboardContent += '            "type": "query"\n';
                            dashboardContent += '          }\n';
                            dashboardContent += '        ],\n';
                            dashboardContent += '        "executionErrorState": "alerting",\n';
                            dashboardContent += '        "frequency": "60s",\n';
                            dashboardContent += '        "handler": 1,\n';
                            dashboardContent += '        "name": "CPU Usage alert",\n';
                            dashboardContent += '        "noDataState": "no_data",\n';
                            dashboardContent += '        "notifications": []\n';
                            dashboardContent += '      },\n';
                            dashboardContent += '      "aliasColors": {},\n';
                            dashboardContent += '      "bars": false,\n';
                            dashboardContent += '      "dashLength": 10,\n';
                            dashboardContent += '      "dashes": false,\n';
                            dashboardContent += '      "datasource": "Prometheus",\n';
                            dashboardContent += '      "fieldConfig": {\n';
                            dashboardContent += '        "defaults": {\n';
                            dashboardContent += '          "custom": {}\n';
                            dashboardContent += '        },\n';
                            dashboardContent += '        "overrides": []\n';
                            dashboardContent += '      },\n';
                            dashboardContent += '      "fill": 1,\n';
                            dashboardContent += '      "fillGradient": 0,\n';
                            dashboardContent += '      "gridPos": {\n';
                            dashboardContent += '        "h": 9,\n';
                            dashboardContent += '        "w": 12,\n';
                            dashboardContent += '        "x": 0,\n';
                            dashboardContent += '        "y": 0\n';
                            dashboardContent += '      },\n';
                            dashboardContent += '      "hiddenSeries": false,\n';
                            dashboardContent += '      "id": 2,\n';
                            dashboardContent += '      "legend": {\n';
                            dashboardContent += '        "avg": false,\n';
                            dashboardContent += '        "current": false,\n';
                            dashboardContent += '        "max": false,\n';
                            dashboardContent += '        "min": false,\n';
                            dashboardContent += '        "show": true,\n';
                            dashboardContent += '        "total": false,\n';
                            dashboardContent += '        "values": false\n';
                            dashboardContent += '      },\n';
                            dashboardContent += '      "lines": true,\n';
                            dashboardContent += '      "linewidth": 1,\n';
                            dashboardContent += '      "nullPointMode": "null",\n';
                            dashboardContent += '      "options": {\n';
                            dashboardContent += '        "alertThreshold": true\n';
                            dashboardContent += '      },\n';
                            dashboardContent += '      "percentage": false,\n';
                            dashboardContent += '      "pluginVersion": "7.3.7",\n';
                            dashboardContent += '      "pointradius": 2,\n';
                            dashboardContent += '      "points": false,\n';
                            dashboardContent += '      "renderer": "flot",\n';
                            dashboardContent += '      "seriesOverrides": [],\n';
                            dashboardContent += '      "spaceLength": 10,\n';
                            dashboardContent += '      "stack": false,\n';
                            dashboardContent += '      "steppedLine": false,\n';
                            dashboardContent += '      "targets": [\n';
                            dashboardContent += '        {\n';
                            dashboardContent += '          "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\\"idle\\"}[5m])) * 100)",\n';
                            dashboardContent += '          "interval": "",\n';
                            dashboardContent += '          "legendFormat": "",\n';
                            dashboardContent += '          "refId": "A"\n';
                            dashboardContent += '        }\n';
                            dashboardContent += '      ],\n';
                            dashboardContent += '      "thresholds": [\n';
                            dashboardContent += '        {\n';
                            dashboardContent += '          "colorMode": "critical",\n';
                            dashboardContent += '          "fill": true,\n';
                            dashboardContent += '          "line": true,\n';
                            dashboardContent += '          "op": "gt",\n';
                            dashboardContent += '          "value": 80\n';
                            dashboardContent += '        }\n';
                            dashboardContent += '      ],\n';
                            dashboardContent += '      "timeFrom": null,\n';
                            dashboardContent += '      "timeRegions": [],\n';
                            dashboardContent += '      "timeShift": null,\n';
                            dashboardContent += '      "title": "CPU Usage",\n';
                            dashboardContent += '      "tooltip": {\n';
                            dashboardContent += '        "shared": true,\n';
                            dashboardContent += '        "sort": 0,\n';
                            dashboardContent += '        "value_type": "individual"\n';
                            dashboardContent += '      },\n';
                            dashboardContent += '      "type": "graph",\n';
                            dashboardContent += '      "xaxis": {\n';
                            dashboardContent += '        "buckets": null,\n';
                            dashboardContent += '        "mode": "time",\n';
                            dashboardContent += '        "name": null,\n';
                            dashboardContent += '        "show": true,\n';
                            dashboardContent += '        "values": []\n';
                            dashboardContent += '      },\n';
                            dashboardContent += '      "yaxes": [\n';
                            dashboardContent += '        {\n';
                            dashboardContent += '          "format": "percent",\n';
                            dashboardContent += '          "label": null,\n';
                            dashboardContent += '          "logBase": 1,\n';
                            dashboardContent += '          "max": null,\n';
                            dashboardContent += '          "min": null,\n';
                            dashboardContent += '          "show": true\n';
                            dashboardContent += '        },\n';
                            dashboardContent += '        {\n';
                            dashboardContent += '          "format": "short",\n';
                            dashboardContent += '          "label": null,\n';
                            dashboardContent += '          "logBase": 1,\n';
                            dashboardContent += '          "max": null,\n';
                            dashboardContent += '          "min": null,\n';
                            dashboardContent += '          "show": true\n';
                            dashboardContent += '        }\n';
                            dashboardContent += '      ],\n';
                            dashboardContent += '      "yaxis": {\n';
                            dashboardContent += '        "align": false,\n';
                            dashboardContent += '        "alignLevel": null\n';
                            dashboardContent += '      }\n';
                            dashboardContent += '    }\n';
                            dashboardContent += '  ],\n';
                            dashboardContent += '  "schemaVersion": 26,\n';
                            dashboardContent += '  "style": "dark",\n';
                            dashboardContent += '  "tags": [],\n';
                            dashboardContent += '  "templating": {\n';
                            dashboardContent += '    "list": []\n';
                            dashboardContent += '  },\n';
                            dashboardContent += '  "time": {\n';
                            dashboardContent += '    "from": "now-6h",\n';
                            dashboardContent += '    "to": "now"\n';
                            dashboardContent += '  },\n';
                            dashboardContent += '  "timepicker": {},\n';
                            dashboardContent += '  "timezone": "",\n';
                            dashboardContent += '  "title": "System Monitoring",\n';
                            dashboardContent += '  "uid": "system-monitoring",\n';
                            dashboardContent += '  "version": 1\n';
                            dashboardContent += '}\n';

                            // Crear directorio para dashboards
                            const dashboardsDir = path.join(grafanaDir, 'dashboards');
                            if (!fs.existsSync(dashboardsDir)) {
                              fs.mkdirSync(dashboardsDir, { recursive: true });
                            }

                            // Escribir dashboard.json
                            fs.writeFileSync(path.join(dashboardsDir, 'dashboard.json'), dashboardContent);

                            // Crear dashboard.yml para provisioning
                            let dashboardYamlContent = 'apiVersion: 1\n\n';
                            dashboardYamlContent += 'providers:\n';
                            dashboardYamlContent += '  - name: \'default\'\n';
                            dashboardYamlContent += '    orgId: 1\n';
                            dashboardYamlContent += '    folder: \'\'\n';
                            dashboardYamlContent += '    type: file\n';
                            dashboardYamlContent += '    disableDeletion: false\n';
                            dashboardYamlContent += '    editable: true\n';
                            dashboardYamlContent += '    options:\n';
                            dashboardYamlContent += '      path: /etc/grafana/dashboards\n';

                            // Escribir dashboard.yml
                            fs.writeFileSync(path.join(grafanaDir, 'dashboard.yml'), dashboardYamlContent);

                            // Crear docker-compose.yml para monitoreo
                            let dockerComposeContent = 'version: "3.8"\n\n';
                            dockerComposeContent += 'services:\n';
                            dockerComposeContent += '  prometheus:\n';
                            dockerComposeContent += '    image: prom/prometheus:latest\n';
                            dockerComposeContent += '    volumes:\n';
                            dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
                            dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
                            dockerComposeContent += '      - prometheus_data:/prometheus\n';
                            dockerComposeContent += '    command:\n';
                            dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
                            dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
                            dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
                            dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
                            dockerComposeContent += '    ports:\n';
                            dockerComposeContent += '      - "9090:9090"\n';
                            dockerComposeContent += '    networks:\n';
                            dockerComposeContent += '      - monitoring-network\n';
                            dockerComposeContent += '    restart: unless-stopped\n\n';
                            
                            dockerComposeContent += '  alertmanager:\n';
                            dockerComposeContent += '    image: prom/alertmanager:latest\n';
                            dockerComposeContent += '    volumes:\n';
                            dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
                            dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
                            dockerComposeContent += '    command:\n';
                            dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
                            dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
                            dockerComposeContent += '    ports:\n';
                            dockerComposeContent += '      - "9093:9093"\n';
                            dockerComposeContent += '    networks:\n';
                            dockerComposeContent += '      - monitoring-network\n';
                            dockerComposeContent += '    restart: unless-stopped\n\n';
                            
                            dockerComposeContent += '  grafana:\n';
                            dockerComposeContent += '    image: grafana/grafana:latest\n';
                            dockerComposeContent += '    volumes:\n';
                            dockerComposeContent += '      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
                            dockerComposeContent += '      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml\n';
                            dockerComposeContent += '      - ./grafana/dashboards:/etc/grafana/dashboards\n';
                            dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
                            dockerComposeContent += '    environment:\n';
                            dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
                            dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
                            dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
                            dockerComposeContent += '    ports:\n';
                            dockerComposeContent += '      - "3000:3000"\n';
                            dockerComposeContent += '    networks:\n';
                            dockerComposeContent += '      - monitoring-network\n';
                            dockerComposeContent += '    restart: unless-stopped\n\n';
                            
                            dockerComposeContent += '  node-exporter:\n';
                            dockerComposeContent += '    image: prom/node-exporter:latest\n';
                            dockerComposeContent += '    volumes:\n';
                            dockerComposeContent += '      - /proc:/host/proc:ro\n';
                            dockerComposeContent += '      - /sys:/host/sys:ro\n';
                            dockerComposeContent += '      - /:/rootfs:ro\n';
                            dockerComposeContent += '    command:\n';
                            dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
                            dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
                            dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
                            dockerComposeContent += '    ports:\n';
                            dockerComposeContent += '      - "9100:9100"\n';
                            dockerComposeContent += '    networks:\n';
                            dockerComposeContent += '      - monitoring-network\n';
                            dockerComposeContent += '    restart: unless-stopped\n\n';
                            
                            dockerComposeContent += '  cadvisor:\n';
                            dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
                            dockerComposeContent += '    volumes:\n';
                            dockerComposeContent += '      - /:/rootfs:ro\n';
                            dockerComposeContent += '      - /var/run:/var/run:ro\n';
                            dockerComposeContent += '      - /sys:/sys:ro\n';
                            dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
                            dockerComposeContent += '    ports:\n';
                            dockerComposeContent += '      - "8080:8080"\n';
                            dockerComposeContent += '    networks:\n';
                            dockerComposeContent += '      - monitoring-network\n';
                            dockerComposeContent += '    restart: unless-stopped\n\n';
                            
                            dockerComposeContent += 'networks:\n';
                            dockerComposeContent += '  monitoring-network:\n';
                            dockerComposeContent += '    driver: bridge\n\n';
                            
                            dockerComposeContent += 'volumes:\n';
                            dockerComposeContent += '  prometheus_data:\n';
                            dockerComposeContent += '    driver: local\n';
                            dockerComposeContent += '  alertmanager_data:\n';
                            dockerComposeContent += '    driver: local\n';
                            dockerComposeContent += '  grafana_data:\n';
                            dockerComposeContent += '    driver: local\n';

                            // Escribir docker-compose.yml
                            fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);

                            // Crear README.md para monitoreo
                            let readmeContent = '# Stack de Monitoreo\n\n';
                            readmeContent += 'Este directorio contiene la configuración para un stack de monitoreo completo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
                            readmeContent += '## Componentes\n\n';
                            readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
                            readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
                            readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
                            readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
                            readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
                            readmeContent += '## Inicio Rápido\n\n';
                            readmeContent += '```bash\n';
                            readmeContent += '# Iniciar el stack de monitoreo\n';
                            readmeContent += 'docker-compose up -d\n';
                            readmeContent += '```\n\n';
                            readmeContent += '## Acceso\n\n';
                            readmeContent += '- **Prometheus**: http://localhost:9090\n';
                            readmeContent += '- **Alertmanager**: http://localhost:9093\n';
                            readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
                            readmeContent += '- **Node Exporter**: http://localhost:9100\n';
                            readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
                            readmeContent += '## Personalización\n\n';
                            readmeContent += '### Prometheus\n\n';
                            readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
                            readmeContent += '### Alertmanager\n\n';
                            readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
                            readmeContent += '### Grafana\n\n';
                            readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/dashboard.yml` si es necesario.\n';

                            // Escribir README.md
                            fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);

                            // Crear directorio para ELK stack
                            const elkDir = path.join(monitoringDir, 'elk');
                            if (!fs.existsSync(elkDir)) {
                              fs.mkdirSync(elkDir, { recursive: true });
                            }

                            // Crear docker-compose.yml para ELK stack
                            let elkComposeContent = 'version: "3.8"\n\n';
                            elkComposeContent += 'services:\n';
                            elkComposeContent += '  elasticsearch:\n';
                            elkComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
                            elkComposeContent += '    environment:\n';
                            elkComposeContent += '      - discovery.type=single-node\n';
                            elkComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
                            elkComposeContent += '    volumes:\n';
                            elkComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
                            elkComposeContent += '    ports:\n';
                            elkComposeContent += '      - "9200:9200"\n';
                            elkComposeContent += '      - "9300:9300"\n';
                            elkComposeContent += '    networks:\n';
                            elkComposeContent += '      - elk-network\n';
                            elkComposeContent += '    restart: unless-stopped\n\n';
                            
                            elkComposeContent += '  logstash:\n';
                            elkComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
                            elkComposeContent += '    volumes:\n';
                            elkComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
                            elkComposeContent += '    ports:\n';
                            elkComposeContent += '      - "5000:5000"\n';
                            elkComposeContent += '      - "9600:9600"\n';
                            elkComposeContent += '    environment:\n';
                            elkComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
                            elkComposeContent += '    networks:\n';
                            elkComposeContent += '      - elk-network\n';
                            elkComposeContent += '    depends_on:\n';
                            elkComposeContent += '      - elasticsearch\n';
                            elkComposeContent += '    restart: unless-stopped\n\n';
                            
                            elkComposeContent += '  kibana:\n';
                            elkComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
                            elkComposeContent += '    ports:\n';
                            elkComposeContent += '      - "5601:5601"\n';
                            elkComposeContent += '    environment:\n';
                            elkComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
                            elkComposeContent += '    networks:\n';
                            elkComposeContent += '      - elk-network\n';
                            elkComposeContent += '    depends_on:\n';
                            elkComposeContent += '      - elasticsearch\n';
                            elkComposeContent += '    restart: unless-stopped\n\n';
                            
                            elkComposeContent += '  filebeat:\n';
                            elkComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
                            elkComposeContent += '    user: root\n';
                            elkComposeContent += '    volumes:\n';
                            elkComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
                            elkComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
                            elkComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
                            elkComposeContent += '    networks:\n';
                            elkComposeContent += '      - elk-network\n';
                            elkComposeContent += '    depends_on:\n';
                            elkComposeContent += '      - elasticsearch\n';
                            elkComposeContent += '      - logstash\n';
                            elkComposeContent += '    restart: unless-stopped\n\n';
                            
                            elkComposeContent += 'networks:\n';
                            elkComposeContent += '  elk-network:\n';
                            elkComposeContent += '    driver: bridge\n\n';
                            
                            elkComposeContent += 'volumes:\n';
                            elkComposeContent += '  elasticsearch_data:\n';
                            elkComposeContent += '    driver: local\n';

                            // Escribir docker-compose.yml para ELK
                            fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), elkComposeContent);

                            // Crear directorio para Logstash pipeline
                            const logstashDir = path.join(elkDir, 'logstash');
                            if (!fs.existsSync(logstashDir)) {
                              fs.mkdirSync(logstashDir, { recursive: true });
                            }

                            const pipelineDir = path.join(logstashDir, 'pipeline');
                            if (!fs.existsSync(pipelineDir)) {
                              fs.mkdirSync(pipelineDir, { recursive: true });
                            }

                            // Crear logstash.conf
                            let logstashConfContent = 'input {\n';
                            logstashConfContent += '  beats {\n';
                            logstashConfContent += '    port => 5000\n';
                            logstashConfContent += '  }\n';
                            logstashConfContent += '}\n\n';
                            logstashConfContent += 'filter {\n';
                            logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
                            logstashConfContent += '    mutate {\n';
                            logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
                            logstashConfContent += '    }\n';
                            logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
                            logstashConfContent += '    mutate {\n';
                            logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
                            logstashConfContent += '    }\n';
                            logstashConfContent += '  } else {\n';
                            logstashConfContent += '    mutate {\n';
                            logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
                            logstashConfContent += '    }\n';
                            logstashConfContent += '  }\n';
                            logstashConfContent += '}\n\n';
                            logstashConfContent += 'output {\n';
                            logstashConfContent += '  elasticsearch {\n';
                            logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
                            logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
                            logstashConfContent += '  }\n';
                            logstashConfContent += '}\n';

                            // Escribir logstash.conf
                            fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);

                            // Crear directorio para Filebeat
                            const filebeatDir = path.join(elkDir, 'filebeat');
                            if (!fs.existsSync(filebeatDir)) {
                              fs.mkdirSync(filebeatDir, { recursive: true });
                            }

                            // Crear filebeat.yml
                            let filebeatContent = 'filebeat.inputs:\n';
                            filebeatContent += '- type: container\n';
                            filebeatContent += '  paths:\n';
                            filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
                            filebeatContent += '  processors:\n';
                            filebeatContent += '    - add_docker_metadata:\n';
                            filebeatContent += '        host: "unix:///var/run/docker.sock"\n\n';
                            filebeatContent += 'processors:\n';
                            filebeatContent += '  - add_host_metadata:\n';
                            filebeatContent += '      when.not.contains.tags: forwarded\n';
                            filebeatContent += '  - add_cloud_metadata: ~\n';
                            filebeatContent += '  - add_docker_metadata: ~\n';
                            filebeatContent += '  - add_kubernetes_metadata: ~\n\n';
                            filebeatContent += 'output.logstash:\n';
                            filebeatContent += '  hosts: ["logstash:5000"]\n';

                            // Escribir filebeat.yml
                            fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);

                            // Crear README.md para ELK
                            let elkReadmeContent = '# Stack ELK para Logging\n\n';
                            elkReadmeContent += 'Este directorio contiene la configuración para un stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat para la recolección y análisis de logs.\n\n';
                            elkReadmeContent += '## Componentes\n\n';
                            elkReadmeContent += '- **Elasticsearch**: Motor de búsqueda y análisis distribuido\n';
                            elkReadmeContent += '- **Logstash**: Procesador de datos para ingestión y transformación de logs\n';
                            elkReadmeContent += '- **Kibana**: Plataforma de visualización para datos de Elasticsearch\n';
                            elkReadmeContent += '- **Filebeat**: Recolector de logs ligero\n\n';
                            elkReadmeContent += '## Inicio Rápido\n\n';
                            elkReadmeContent += '```bash\n';
                            elkReadmeContent += '# Iniciar el stack ELK\n';
                            elkReadmeContent += 'docker-compose up -d\n';
                            elkReadmeContent += '```\n\n';
                            elkReadmeContent += '## Acceso\n\n';
                            elkReadmeContent += '- **Elasticsearch**: http://localhost:9200\n';
                            elkReadmeContent += '- **Kibana**: http://localhost:5601\n';
                            elkReadmeContent += '- **Logstash**: http://localhost:9600 (API)\n\n';
                            elkReadmeContent += '## Personalización\n\n';
                            elkReadmeContent += '### Logstash\n\n';
                            elkReadmeContent += 'Edita `logstash/pipeline/logstash.conf` para modificar la configuración de procesamiento de logs.\n\n';
                            elkReadmeContent += '### Filebeat\n\n';
                            elkReadmeContent += 'Edita `filebeat/filebeat.yml` para configurar la recolección de logs de diferentes fuentes.\n\n';
                            elkReadmeContent += '### Kibana\n\n';
                            elkReadmeContent += 'Accede a Kibana para crear visualizaciones y dashboards personalizados.\n';

                            // Escribir README.md para ELK
                            fs.writeFileSync(path.join(elkDir, 'README.md'), elkReadmeContent);

                            // Crear directorio para scripts de monitoreo
                            const scriptsDir = path.join(monitoringDir, 'scripts');
                            if (!fs.existsSync(scriptsDir)) {
                              fs.mkdirSync(scriptsDir, { recursive: true });
                            }

                            // Crear script para verificar el estado de los servicios
                            let checkServicesScript = '#!/bin/bash\n\n';
                            checkServicesScript += '# Script para verificar el estado de los servicios de monitoreo\n\n';
                            checkServicesScript += 'echo "Verificando servicios de monitoreo..."\n\n';
                            checkServicesScript += '# Verificar Prometheus\n';
                            checkServicesScript += 'if curl -s http://localhost:9090/-/healthy > /dev/null; then\n';
                            checkServicesScript += '  echo "✅ Prometheus está funcionando correctamente"\n';
                            checkServicesScript += 'else\n';
                            checkServicesScript += '  echo "❌ Prometheus no está disponible"\n';
                            checkServicesScript += 'fi\n\n';
                            checkServicesScript += '# Verificar Alertmanager\n';
                            checkServicesScript += 'if curl -s http://localhost:9093/-/healthy > /dev/null; then\n';
                            checkServicesScript += '  echo "✅ Alertmanager está funcionando correctamente"\n';
                            checkServicesScript += 'else\n';
                            checkServicesScript += '  echo "❌ Alertmanager no está disponible"\n';
                            checkServicesScript += 'fi\n\n';
                            checkServicesScript += '# Verificar Grafana\n';
                            checkServicesScript += 'if curl -s http://localhost:3000/api/health > /dev/null; then\n';
                            checkServicesScript += '  echo "✅ Grafana está funcionando correctamente"\n';
                            checkServicesScript += 'else\n';
                            checkServicesScript += '  echo "❌ Grafana no está disponible"\n';
                            checkServicesScript += 'fi\n\n';
                            checkServicesScript += '# Verificar Elasticsearch\n';
                            checkServicesScript += 'if curl -s http://localhost:9200/_cluster/health > /dev/null; then\n';
                            checkServicesScript += '  echo "✅ Elasticsearch está funcionando correctamente"\n';
                            checkServicesScript += 'else\n';
                            checkServicesScript += '  echo "❌ Elasticsearch no está disponible"\n';
                            checkServicesScript += 'fi\n\n';
                            checkServicesScript += '# Verificar Kibana\n';
                            checkServicesScript += 'if curl -s http://localhost:5601/api/status > /dev/null; then\n';
                            checkServicesScript += '  echo "✅ Kibana está funcionando correctamente"\n';
                            checkServicesScript += 'else\n';
                            checkServicesScript += '  echo "❌ Kibana no está disponible"\n';
                            checkServicesScript += 'fi\n';

                            // Escribir script para Linux/Mac
                            fs.writeFileSync(path.join(scriptsDir, 'check-services.sh'), checkServicesScript);
                            
                            // Crear versión para Windows
                            let checkServicesScriptWindows = '@echo off\n\n';
                            checkServicesScriptWindows += 'echo Verificando servicios de monitoreo...\n\n';
                            checkServicesScriptWindows += ':: Verificar Prometheus\n';
                            checkServicesScriptWindows += 'curl -s http://localhost:9090/-/healthy > nul\n';
                            checkServicesScriptWindows += 'if %ERRORLEVEL% == 0 (\n';
                            checkServicesScriptWindows += '  echo ✅ Prometheus está funcionando correctamente\n';
                            checkServicesScriptWindows += ') else (\n';
                            checkServicesScriptWindows += '  echo ❌ Prometheus no está disponible\n';
                            checkServicesScriptWindows += ')\n\n';
                            checkServicesScriptWindows += ':: Verificar Alertmanager\n';
                            checkServicesScriptWindows += 'curl -s http://localhost:9093/-/healthy > nul\n';
                            checkServicesScriptWindows += 'if %ERRORLEVEL% == 0 (\n';
                            checkServicesScriptWindows += '  echo ✅ Alertmanager está funcionando correctamente\n';
                            checkServicesScriptWindows += ') else (\n';
                            checkServicesScriptWindows += '  echo ❌ Alertmanager no está disponible\n';
                            checkServicesScriptWindows += ')\n\n';
                            checkServicesScriptWindows += ':: Verificar Grafana\n';
                            checkServicesScriptWindows += 'curl -s http://localhost:3000/api/health > nul\n';
                            checkServicesScriptWindows += 'if %ERRORLEVEL% == 0 (\n';
                            checkServicesScriptWindows += '  echo ✅ Grafana está funcionando correctamente\n';
                            checkServicesScriptWindows += ') else (\n';
                            checkServicesScriptWindows += '  echo ❌ Grafana no está disponible\n';
                            checkServicesScriptWindows += ')\n\n';
                            checkServicesScriptWindows += ':: Verificar Elasticsearch\n';
                            checkServicesScriptWindows += 'curl -s http://localhost:9200/_cluster/health > nul\n';
                            checkServicesScriptWindows += 'if %ERRORLEVEL% == 0 (\n';
                            checkServicesScriptWindows += '  echo ✅ Elasticsearch está funcionando correctamente\n';
                            checkServicesScriptWindows += ') else (\n';
                            checkServicesScriptWindows += '  echo ❌ Elasticsearch no está disponible\n';
                            checkServicesScriptWindows += ')\n\n';
                            checkServicesScriptWindows += ':: Verificar Kibana\n';
                            checkServicesScriptWindows += 'curl -s http://localhost:5601/api/status > nul\n';
                            checkServicesScriptWindows += 'if %ERRORLEVEL% == 0 (\n';
                            checkServicesScriptWindows += '  echo ✅ Kibana está funcionando correctamente\n';
                            checkServicesScriptWindows += ') else (\n';
                            checkServicesScriptWindows += '  echo ❌ Kibana no está disponible\n';
                            checkServicesScriptWindows += ')\n';

                            // Escribir script para Windows
                            fs.writeFileSync(path.join(scriptsDir, 'check-services.bat'), checkServicesScriptWindows);

                            // Crear script para exportar dashboards de Grafana
                            let exportDashboardsScript = '#!/bin/bash\n\n';
                            exportDashboardsScript += '# Script para exportar dashboards de Grafana\n\n';
                            exportDashboardsScript += 'GRAFANA_URL="http://localhost:3000"\n';
                            exportDashboardsScript += 'API_KEY="$1" # Pasar API key como primer argumento\n';
                            exportDashboardsScript += 'OUTPUT_DIR="./dashboards-backup"\n\n';
                            exportDashboardsScript += 'if [ -z "$API_KEY" ]; then\n';
                            exportDashboardsScript += '  echo "Error: Se requiere una API key de Grafana"\n';
                            exportDashboardsScript += '  echo "Uso: ./export-dashboards.sh <api_key>"\n';
                            exportDashboardsScript += '  exit 1\n';
                            exportDashboardsScript += 'fi\n\n';
                            exportDashboardsScript += 'mkdir -p "$OUTPUT_DIR"\n\n';
                            exportDashboardsScript += 'echo "Obteniendo lista de dashboards..."\n';
                            exportDashboardsScript += 'DASHBOARDS=$(curl -s -H "Authorization: Bearer $API_KEY" $GRAFANA_URL/api/search?type=dash-db)\n\n';
                            exportDashboardsScript += 'echo "$DASHBOARDS" | jq -r ".[] | .uid" | while read -r uid; do\n';
                            exportDashboardsScript += '  if [ -n "$uid" ]; then\n';
                            exportDashboardsScript += '    echo "Exportando dashboard con UID: $uid"\n';
                            exportDashboardsScript += '    curl -s -H "Authorization: Bearer $API_KEY" $GRAFANA_URL/api/dashboards/uid/$uid > "$OUTPUT_DIR/$uid.json"\n';
                            exportDashboardsScript += '  fi\n';
                            exportDashboardsScript += 'done\n\n';
                            exportDashboardsScript += 'echo "Dashboards exportados a $OUTPUT_DIR"\n';

                            // Escribir script para exportar dashboards (Linux/Mac)
                            fs.writeFileSync(path.join(scriptsDir, 'export-dashboards.sh'), exportDashboardsScript);

                            // Crear versión para Windows
                            let exportDashboardsScriptWindows = '@echo off\n\n';
                            exportDashboardsScriptWindows += ':: Script para exportar dashboards de Grafana\n\n';
                            exportDashboardsScriptWindows += 'set GRAFANA_URL=http://localhost:3000\n';
                            exportDashboardsScriptWindows += 'set API_KEY=%1\n';
                            exportDashboardsScriptWindows += 'set OUTPUT_DIR=.\\dashboards-backup\n\n';
                            exportDashboardsScriptWindows += 'if "%API_KEY%" == "" (\n';
                            exportDashboardsScriptWindows += '  echo Error: Se requiere una API key de Grafana\n';
                            exportDashboardsScriptWindows += '  echo Uso: export-dashboards.bat ^<api_key^>\n';
                            exportDashboardsScriptWindows += '  exit /b 1\n';
                            exportDashboardsScriptWindows += ')\n\n';
                            exportDashboardsScriptWindows += 'if not exist "%OUTPUT_DIR%" mkdir "%OUTPUT_DIR%"\n\n';
                            exportDashboardsScriptWindows += 'echo Obteniendo lista de dashboards...\n';
                            exportDashboardsScriptWindows += 'curl -s -H "Authorization: Bearer %API_KEY%" %GRAFANA_URL%/api/search?type=dash-db > dashboards.json\n\n';
                            exportDashboardsScriptWindows += ':: Requiere jq o similar para Windows\n';
                            exportDashboardsScriptWindows += 'echo Nota: Para procesar completamente este script, instala jq para Windows\n';
                            exportDashboardsScriptWindows += 'echo Puedes descargarlo desde: https://stedolan.github.io/jq/download/\n\n';
                            exportDashboardsScriptWindows += 'echo Dashboards exportados a %OUTPUT_DIR%\n';

                            // Escribir script para exportar dashboards (Windows)
                            fs.writeFileSync(path.join(scriptsDir, 'export-dashboards.bat'), exportDashboardsScriptWindows);

                            // Crear script para configurar alertas en Slack
                            let slackAlertsScript = '#!/bin/bash\n\n';
                            slackAlertsScript += '# Script para configurar alertas de Alertmanager en Slack\n\n';
                            slackAlertsScript += 'WEBHOOK_URL="$1" # Pasar webhook URL como primer argumento\n';
                            slackAlertsScript += 'CHANNEL="$2" # Pasar canal como segundo argumento\n';
                            slackAlertsScript += 'CONFIG_FILE="../alertmanager/alertmanager.yml"\n\n';
                            slackAlertsScript += 'if [ -z "$WEBHOOK_URL" ] || [ -z "$CHANNEL" ]; then\n';
                            slackAlertsScript += '  echo "Error: Se requiere webhook URL y canal de Slack"\n';
                            slackAlertsScript += '  echo "Uso: ./setup-slack-alerts.sh <webhook_url> <channel>"\n';
                            slackAlertsScript += '  exit 1\n';
                            slackAlertsScript += 'fi\n\n';
                            slackAlertsScript += 'cat > "$CONFIG_FILE" << EOF\n';
                            slackAlertsScript += 'global:\n';
                            slackAlertsScript += '  resolve_timeout: 5m\n\n';
                            slackAlertsScript += 'route:\n';
                            slackAlertsScript += '  group_by: [\'alertname\', \'instance\']\n';
                            slackAlertsScript += '  group_wait: 30s\n';
                            slackAlertsScript += '  group_interval: 5m\n';
                            slackAlertsScript += '  repeat_interval: 1h\n';
                            slackAlertsScript += '  receiver: \'slack\'\n\n';
                            slackAlertsScript += 'receivers:\n';
                            slackAlertsScript += '- name: \'slack\'\n';
                            slackAlertsScript += '  slack_configs:\n';
                            slackAlertsScript += '  - api_url: \'$WEBHOOK_URL\'\n';
                            slackAlertsScript += '    channel: \'$CHANNEL\'\n';
                            slackAlertsScript += '    send_resolved: true\n';
                            slackAlertsScript += '    title: \'[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}\'\n';
                            slackAlertsScript += '    text: >-\n';
                            slackAlertsScript += '      {{ range .Alerts }}\n';
                            slackAlertsScript += '        *Alert:* {{ .Annotations.summary }}{{ if .Annotations.description }}\\n*Description:* {{ .Annotations.description }}{{ end }}\\n*Details:*\\n{{ range .Labels.SortedPairs }} • *{{ .Name }}:* {{ .Value }}\\n{{ end }}\\n{{ end }}\n';
                            slackAlertsScript += 'EOF\n\n';
                            slackAlertsScript += 'echo "Configuración de alertas de Slack completada. Reinicia Alertmanager para aplicar los cambios."\n';

                            // Escribir script para configurar alertas en Slack (Linux/Mac)
                            fs.writeFileSync(path.join(scriptsDir, 'setup-slack-alerts.sh'), slackAlertsScript);

                            // Crear versión para Windows
                            let slackAlertsScriptWindows = '@echo off\n\n';
                            slackAlertsScriptWindows += ':: Script para configurar alertas de Alertmanager en Slack\n\n';
                            slackAlertsScriptWindows += 'set WEBHOOK_URL=%1\n';
                            slackAlertsScriptWindows += 'set CHANNEL=%2\n';
                            slackAlertsScriptWindows += 'set CONFIG_FILE=..\\alertmanager\\alertmanager.yml\n\n';
                            slackAlertsScriptWindows += 'if "%WEBHOOK_URL%" == "" (\n';
                            slackAlertsScriptWindows += '  echo Error: Se requiere webhook URL y canal de Slack\n';
                            slackAlertsScriptWindows += '  echo Uso: setup-slack-alerts.bat ^<webhook_url^> ^<channel^>\n';
                            slackAlertsScriptWindows += '  exit /b 1\n';
                            slackAlertsScriptWindows += ')\n\n';
                            slackAlertsScriptWindows += '(echo global:) > "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo   resolve_timeout: 5m) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo.) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo route:) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo   group_by: [\'alertname\', \'instance\']) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo   group_wait: 30s) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo   group_interval: 5m) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo   repeat_interval: 1h) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo   receiver: \'slack\') >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo.) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo receivers:) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo - name: \'slack\') >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo   slack_configs:) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo   - api_url: \'%WEBHOOK_URL%\') >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo     channel: \'%CHANNEL%\') >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo     send_resolved: true) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo     title: \'[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}\') >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo     text: ^>-) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo       {{ range .Alerts }}) >> "%CONFIG_FILE%"\n';
                            slackAlertsScriptWindows += '(echo         *Alert:* {{ .Annotations.summary }}{{ if .Annotations.description }}\\n*Description:* {{ .Annotations.description }}{{ end }}\\n*Details:*\\n{{ range .Labels.SortedPairs }} • *{{ .Name }}:* {{ .Value }}\\n{{ end }}\\n{{ end }}) >> "%CONFIG_FILE%"\n\n';
                            slackAlertsScriptWindows += 'echo Configuración de alertas de Slack completada. Reinicia Alertmanager para aplicar los cambios.\n';

                            // Escribir script para configurar alertas en Slack (Windows)
                            fs.writeFileSync(path.join(scriptsDir, 'setup-slack-alerts.bat'), slackAlertsScriptWindows);

                            // Crear README.md para scripts
                            let scriptsReadmeContent = '# Scripts de Utilidad para Monitoreo\n\n';
                            scriptsReadmeContent += 'Este directorio contiene scripts útiles para gestionar y mantener el stack de monitoreo.\n\n';
                            scriptsReadmeContent += '## Scripts Disponibles\n\n';
                            scriptsReadmeContent += '### check-services.sh / check-services.bat\n\n';
                            scriptsReadmeContent += 'Verifica el estado de todos los servicios de monitoreo (Prometheus, Alertmanager, Grafana, Elasticsearch, Kibana).\n\n';
                            scriptsReadmeContent += '```bash\n';
                            scriptsReadmeContent += '# Linux/Mac\n';
                            scriptsReadmeContent += './check-services.sh\n\n';
                            scriptsReadmeContent += '# Windows\n';
                            scriptsReadmeContent += 'check-services.bat\n';
                            scriptsReadmeContent += '```\n\n';
                            scriptsReadmeContent += '### export-dashboards.sh / export-dashboards.bat\n\n';
                            scriptsReadmeContent += 'Exporta todos los dashboards de Grafana a archivos JSON.\n\n';
                            scriptsReadmeContent += '```bash\n';
                            scriptsReadmeContent += '# Linux/Mac\n';
                            scriptsReadmeContent += './export-dashboards.sh <api_key>\n\n';
                            scriptsReadmeContent += '# Windows\n';
                            scriptsReadmeContent += 'export-dashboards.bat <api_key>\n';
                            scriptsReadmeContent += '```\n\n';
                            scriptsReadmeContent += '### setup-slack-alerts.sh / setup-slack-alerts.bat\n\n';
                            scriptsReadmeContent += 'Configura Alertmanager para enviar alertas a un canal de Slack.\n\n';
                            scriptsReadmeContent += '```bash\n';
                            scriptsReadmeContent += '# Linux/Mac\n';
                            scriptsReadmeContent += './setup-slack-alerts.sh <webhook_url> <channel>\n\n';
                            scriptsReadmeContent += '# Windows\n';
                            scriptsReadmeContent += 'setup-slack-alerts.bat <webhook_url> <channel>\n';
                            scriptsReadmeContent += '```\n';

                            // Escribir README.md para scripts
                            fs.writeFileSync(path.join(scriptsDir, 'README.md'), scriptsReadmeContent);

                            console.log('✅ Archivos de monitoreo creados exitosamente');
                        } catch (error) {
                            console.error('❌ Error al crear archivos de monitoreo:', error);
                        }
                    }

                    /**
                     * Crea archivos de CI/CD para el proyecto
                     */
                    async createCICDFiles() {
                        try {
                            console.log('🔄 Creando archivos de CI/CD...');

                            const projectRoot = this.projectPath;
                            const cicdDir = path.join(projectRoot, '.github', 'workflows');

                            // Crear directorio .github/workflows si no existe
                            if (!fs.existsSync(cicdDir)) {
                                fs.mkdirSync(cicdDir, { recursive: true });
                            }

                            // Crear workflow para CI
                            let ciWorkflowContent = 'name: CI\n\n';
                            ciWorkflowContent += 'on:\n';
                            ciWorkflowContent += '  push:\n';
                            ciWorkflowContent += '    branches: [ main, develop ]\n';
                            ciWorkflowContent += '  pull_request:\n';
                            ciWorkflowContent += '    branches: [ main, develop ]\n\n';
                            ciWorkflowContent += 'jobs:\n';
                            ciWorkflowContent += '  lint:\n';
                            ciWorkflowContent += '    name: Lint\n';
                            ciWorkflowContent += '    runs-on: ubuntu-latest\n';
                            ciWorkflowContent += '    steps:\n';
                            ciWorkflowContent += '      - uses: actions/checkout@v3\n';
                            ciWorkflowContent += '      - name: Set up Node.js\n';
                            ciWorkflowContent += '        uses: actions/setup-node@v3\n';
                            ciWorkflowContent += '        with:\n';
                            ciWorkflowContent += '          node-version: 18\n';
                            ciWorkflowContent += '          cache: \'npm\'\n';
                            ciWorkflowContent += '      - name: Install dependencies\n';
                            ciWorkflowContent += '        run: npm ci\n';
                            ciWorkflowContent += '      - name: Run linting\n';
                            ciWorkflowContent += '        run: npm run lint\n\n';
                            ciWorkflowContent += '  test:\n';
                            ciWorkflowContent += '    name: Test\n';
                            ciWorkflowContent += '    runs-on: ubuntu-latest\n';
                            ciWorkflowContent += '    steps:\n';
                            ciWorkflowContent += '      - uses: actions/checkout@v3\n';
                            ciWorkflowContent += '      - name: Set up Node.js\n';
                            ciWorkflowContent += '        uses: actions/setup-node@v3\n';
                            ciWorkflowContent += '        with:\n';
                            ciWorkflowContent += '          node-version: 18\n';
                            ciWorkflowContent += '          cache: \'npm\'\n';
                            ciWorkflowContent += '      - name: Install dependencies\n';
                            ciWorkflowContent += '        run: npm ci\n';
                            ciWorkflowContent += '      - name: Run tests\n';
                            ciWorkflowContent += '        run: npm test\n\n';
                            ciWorkflowContent += '  build:\n';
                            ciWorkflowContent += '    name: Build\n';
                            ciWorkflowContent += '    runs-on: ubuntu-latest\n';
                            ciWorkflowContent += '    needs: [lint, test]\n';
                            ciWorkflowContent += '    steps:\n';
                            ciWorkflowContent += '      - uses: actions/checkout@v3\n';
                            ciWorkflowContent += '      - name: Set up Node.js\n';
                            ciWorkflowContent += '        uses: actions/setup-node@v3\n';
                            ciWorkflowContent += '        with:\n';
                            ciWorkflowContent += '          node-version: 18\n';
                            ciWorkflowContent += '          cache: \'npm\'\n';
                            ciWorkflowContent += '      - name: Install dependencies\n';
                            ciWorkflowContent += '        run: npm ci\n';
                            ciWorkflowContent += '      - name: Build\n';
                            ciWorkflowContent += '        run: npm run build\n';
                            ciWorkflowContent += '      - name: Upload build artifacts\n';
                            ciWorkflowContent += '        uses: actions/upload-artifact@v3\n';
                            ciWorkflowContent += '        with:\n';
                            ciWorkflowContent += '          name: build-artifacts\n';
                            ciWorkflowContent += '          path: dist/\n';

                            // Escribir workflow de CI
                            fs.writeFileSync(path.join(cicdDir, 'ci.yml'), ciWorkflowContent);

                            // Crear workflow para CD
                            let cdWorkflowContent = 'name: CD\n\n';
                            cdWorkflowContent += 'on:\n';
                            cdWorkflowContent += '  push:\n';
                            cdWorkflowContent += '    branches: [ main ]\n';
                            cdWorkflowContent += '  workflow_dispatch:\n\n';
                            cdWorkflowContent += 'jobs:\n';
                            cdWorkflowContent += '  deploy-staging:\n';
                            cdWorkflowContent += '    name: Deploy to Staging\n';
                            cdWorkflowContent += '    runs-on: ubuntu-latest\n';
                            cdWorkflowContent += '    steps:\n';
                            cdWorkflowContent += '      - uses: actions/checkout@v3\n';
                            cdWorkflowContent += '      - name: Set up Node.js\n';
                            cdWorkflowContent += '        uses: actions/setup-node@v3\n';
                            cdWorkflowContent += '        with:\n';
                            cdWorkflowContent += '          node-version: 18\n';
                            cdWorkflowContent += '          cache: \'npm\'\n';
                            cdWorkflowContent += '      - name: Install dependencies\n';
                            cdWorkflowContent += '        run: npm ci\n';
                            cdWorkflowContent += '      - name: Build\n';
                            cdWorkflowContent += '        run: npm run build\n';
                            cdWorkflowContent += '      - name: Deploy to Staging\n';
                            cdWorkflowContent += '        run: echo "Deploying to staging environment..."\n';
                            cdWorkflowContent += '        # Aquí iría la lógica de despliegue a staging\n';
                            cdWorkflowContent += '        # Por ejemplo, usando SSH, AWS CLI, etc.\n\n';
                            cdWorkflowContent += '  deploy-production:\n';
                            cdWorkflowContent += '    name: Deploy to Production\n';
                            cdWorkflowContent += '    needs: deploy-staging\n';
                            cdWorkflowContent += '    runs-on: ubuntu-latest\n';
                            cdWorkflowContent += '    environment:\n';
                            cdWorkflowContent += '      name: production\n';
                            cdWorkflowContent += '      url: https://example.com\n';
                            cdWorkflowContent += '    steps:\n';
                            cdWorkflowContent += '      - uses: actions/checkout@v3\n';
                            cdWorkflowContent += '      - name: Set up Node.js\n';
                            cdWorkflowContent += '        uses: actions/setup-node@v3\n';
                            cdWorkflowContent += '        with:\n';
                            cdWorkflowContent += '          node-version: 18\n';
                            cdWorkflowContent += '          cache: \'npm\'\n';
                            cdWorkflowContent += '      - name: Install dependencies\n';
                            cdWorkflowContent += '        run: npm ci\n';
                            cdWorkflowContent += '      - name: Build\n';
                            cdWorkflowContent += '        run: npm run build\n';
                            cdWorkflowContent += '      - name: Deploy to Production\n';
                            cdWorkflowContent += '        run: echo "Deploying to production environment..."\n';
                            cdWorkflowContent += '        # Aquí iría la lógica de despliegue a producción\n';

                            // Escribir workflow de CD
                            fs.writeFileSync(path.join(cicdDir, 'cd.yml'), cdWorkflowContent);

                            // Crear workflow para análisis de seguridad
                            let securityWorkflowContent = 'name: Security Scan\n\n';
                            securityWorkflowContent += 'on:\n';
                            securityWorkflowContent += '  push:\n';
                            securityWorkflowContent += '    branches: [ main, develop ]\n';
                            securityWorkflowContent += '  pull_request:\n';
                            securityWorkflowContent += '    branches: [ main ]\n';
                            securityWorkflowContent += '  schedule:\n';
                            securityWorkflowContent += '    - cron: \'0 0 * * 0\' # Ejecutar cada domingo a medianoche\n\n';
                            securityWorkflowContent += 'jobs:\n';
                            securityWorkflowContent += '  codeql-analysis:\n';
                            securityWorkflowContent += '    name: CodeQL Analysis\n';
                            securityWorkflowContent += '    runs-on: ubuntu-latest\n';
                            securityWorkflowContent += '    permissions:\n';
                            securityWorkflowContent += '      security-events: write\n';
                            securityWorkflowContent += '      actions: read\n';
                            securityWorkflowContent += '      contents: read\n';
                            securityWorkflowContent += '    steps:\n';
                            securityWorkflowContent += '      - name: Checkout repository\n';
                            securityWorkflowContent += '        uses: actions/checkout@v3\n\n';
                            securityWorkflowContent += '      - name: Initialize CodeQL\n';
                            securityWorkflowContent += '        uses: github/codeql-action/init@v2\n';
                            securityWorkflowContent += '        with:\n';
                            securityWorkflowContent += '          languages: javascript\n\n';
                            securityWorkflowContent += '      - name: Perform CodeQL Analysis\n';
                            securityWorkflowContent += '        uses: github/codeql-action/analyze@v2\n\n';
                            securityWorkflowContent += '  dependency-check:\n';
                            securityWorkflowContent += '    name: Dependency Check\n';
                            securityWorkflowContent += '    runs-on: ubuntu-latest\n';
                            securityWorkflowContent += '    steps:\n';
                            securityWorkflowContent += '      - uses: actions/checkout@v3\n';
                            securityWorkflowContent += '      - name: Set up Node.js\n';
                            securityWorkflowContent += '        uses: actions/setup-node@v3\n';
                            securityWorkflowContent += '        with:\n';
                            securityWorkflowContent += '          node-version: 18\n';
                            securityWorkflowContent += '          cache: \'npm\'\n';
                            securityWorkflowContent += '      - name: Install dependencies\n';
                            securityWorkflowContent += '        run: npm ci\n';
                            securityWorkflowContent += '      - name: Run npm audit\n';
                            securityWorkflowContent += '        run: npm audit --production\n';

                            // Escribir workflow de seguridad
                            fs.writeFileSync(path.join(cicdDir, 'security.yml'), securityWorkflowContent);

                            // Crear README.md para CI/CD
                            let cicdReadmeContent = '# CI/CD Workflows\n\n';
                            cicdReadmeContent += 'Este directorio contiene los workflows de GitHub Actions para CI/CD.\n\n';
                            cicdReadmeContent += '## Workflows Disponibles\n\n';
                            cicdReadmeContent += '### CI (Integración Continua)\n\n';
                            cicdReadmeContent += 'El workflow de CI se ejecuta en cada push a las ramas `main` y `develop`, así como en pull requests a estas ramas.\n\n';
                            cicdReadmeContent += 'Incluye los siguientes jobs:\n';
                            cicdReadmeContent += '- **Lint**: Verifica el estilo del código\n';
                            cicdReadmeContent += '- **Test**: Ejecuta las pruebas automatizadas\n';
                            cicdReadmeContent += '- **Build**: Compila el proyecto y guarda los artefactos\n\n';
                            cicdReadmeContent += '### CD (Despliegue Continuo)\n\n';
                            cicdReadmeContent += 'El workflow de CD se ejecuta en cada push a la rama `main` o manualmente mediante dispatch.\n\n';
                            cicdReadmeContent += 'Incluye los siguientes jobs:\n';
                            cicdReadmeContent += '- **Deploy to Staging**: Despliega la aplicación en el entorno de staging\n';
                            cicdReadmeContent += '- **Deploy to Production**: Despliega la aplicación en producción después de staging\n\n';
                            cicdReadmeContent += '### Security Scan (Análisis de Seguridad)\n\n';
                            cicdReadmeContent += 'El workflow de seguridad se ejecuta en cada push a las ramas `main` y `develop`, en pull requests a `main`, y semanalmente según un cronograma.\n\n';
                            cicdReadmeContent += 'Incluye los siguientes jobs:\n';
                            cicdReadmeContent += '- **CodeQL Analysis**: Análisis estático de código para detectar vulnerabilidades\n';
                            cicdReadmeContent += '- **Dependency Check**: Verifica vulnerabilidades en las dependencias\n\n';
                            cicdReadmeContent += '## Personalización\n\n';
                            cicdReadmeContent += 'Para personalizar estos workflows, edita los archivos YAML correspondientes:\n';
                            cicdReadmeContent += '- `ci.yml`: Workflow de Integración Continua\n';
                            cicdReadmeContent += '- `cd.yml`: Workflow de Despliegue Continuo\n';
                            cicdReadmeContent += '- `security.yml`: Workflow de Análisis de Seguridad\n';

                            // Escribir README.md para CI/CD
                            fs.writeFileSync(path.join(cicdDir, 'README.md'), cicdReadmeContent);

                            console.log('✅ Archivos de CI/CD creados exitosamente');
                        } catch (error) {
                            console.error('❌ Error al crear archivos de CI/CD:', error);
                        }
                    }

                    /**
                     * Crea archivos de infraestructura como código (IaC)
                     */
                    async createIaCFiles() {
                        try {
                            console.log('🔄 Creando archivos de Infraestructura como Código...');

                            const projectRoot = this.projectPath;
                            const iacDir = path.join(projectRoot, 'infrastructure');

                            // Crear directorio de infraestructura si no existe
                            if (!fs.existsSync(iacDir)) {
                                fs.mkdirSync(iacDir, { recursive: true });
                            }

                            // Crear subdirectorios para diferentes herramientas de IaC
                            const terraformDir = path.join(iacDir, 'terraform');
                            const ansibleDir = path.join(iacDir, 'ansible');
                            const kubernetesDir = path.join(iacDir, 'kubernetes');

                            if (!fs.existsSync(terraformDir)) {
                                fs.mkdirSync(terraformDir, { recursive: true });
                            }
                            if (!fs.existsSync(ansibleDir)) {
                                fs.mkdirSync(ansibleDir, { recursive: true });
                            }
                            if (!fs.existsSync(kubernetesDir)) {
                                fs.mkdirSync(kubernetesDir, { recursive: true });
                            }

                            // Crear archivos de Terraform
                            this.createTerraformFiles(terraformDir);

                            // Crear archivos de Ansible
                            this.createAnsibleFiles(ansibleDir);

                            // Crear archivos de Kubernetes
                            this.createKubernetesFiles(kubernetesDir);

                            // Crear README.md para IaC
                            let iacReadmeContent = '# Infraestructura como Código (IaC)\n\n';
                            iacReadmeContent += 'Este directorio contiene la configuración de infraestructura como código para el proyecto, utilizando varias herramientas:\n\n';
                            iacReadmeContent += '## Terraform\n\n';
                            iacReadmeContent += 'La carpeta `terraform/` contiene la configuración para provisionar la infraestructura en la nube.\n\n';
                            iacReadmeContent += '## Ansible\n\n';
                            iacReadmeContent += 'La carpeta `ansible/` contiene playbooks para la configuración y gestión de servidores.\n\n';
                            iacReadmeContent += '## Kubernetes\n\n';
                            iacReadmeContent += 'La carpeta `kubernetes/` contiene manifiestos para desplegar la aplicación en un clúster de Kubernetes.\n\n';
                            iacReadmeContent += '## Uso\n\n';
                            iacReadmeContent += 'Cada subdirectorio contiene instrucciones específicas sobre cómo utilizar las herramientas correspondientes.\n';

                            // Escribir README.md para IaC
                            fs.writeFileSync(path.join(iacDir, 'README.md'), iacReadmeContent);

                            console.log('✅ Archivos de Infraestructura como Código creados exitosamente');
                        } catch (error) {
                            console.error('❌ Error al crear archivos de Infraestructura como Código:', error);
                        }
                    }

                    /**
                     * Crea archivos de Terraform
                     * @param {string} terraformDir - Directorio para archivos de Terraform
                     */
                    createTerraformFiles(terraformDir) {
                        // Crear subdirectorios para diferentes entornos
                        const envs = ['dev', 'staging', 'prod'];
                        
                        for (const env of envs) {
                            const envDir = path.join(terraformDir, env);
                            if (!fs.existsSync(envDir)) {
                                fs.mkdirSync(envDir, { recursive: true });
                            }

                            // Crear main.tf
                            let mainTfContent = 'provider "aws" {\n';
                            mainTfContent += '  region = var.aws_region\n';
                            mainTfContent += '}\n\n';
                            mainTfContent += 'module "vpc" {\n';
                            mainTfContent += '  source = "../modules/vpc"\n\n';
                            mainTfContent += '  environment = "${var.environment}"\n';
                            mainTfContent += '  vpc_cidr    = var.vpc_cidr\n';
                            mainTfContent += '  azs         = var.azs\n';
                            mainTfContent += '  private_subnets = var.private_subnets\n';
                            mainTfContent += '  public_subnets  = var.public_subnets\n';
                            mainTfContent += '}\n\n';
                            mainTfContent += 'module "ecs" {\n';
                            mainTfContent += '  source = "../modules/ecs"\n\n';
                            mainTfContent += '  environment = "${var.environment}"\n';
                            mainTfContent += '  vpc_id      = module.vpc.vpc_id\n';
                            mainTfContent += '  subnets     = module.vpc.private_subnets\n';
                            mainTfContent += '}\n\n';
                            mainTfContent += 'module "rds" {\n';
                            mainTfContent += '  source = "../modules/rds"\n\n';
                            mainTfContent += '  environment = "${var.environment}"\n';
                            mainTfContent += '  vpc_id      = module.vpc.vpc_id\n';
                            mainTfContent += '  subnets     = module.vpc.private_subnets\n';
                            mainTfContent += '  db_name     = var.db_name\n';
                            mainTfContent += '  db_username = var.db_username\n';
                            mainTfContent += '  db_password = var.db_password\n';
                            mainTfContent += '}\n';

                            // Escribir main.tf
                            fs.writeFileSync(path.join(envDir, 'main.tf'), mainTfContent);

                            // Crear variables.tf
                            let variablesTfContent = 'variable "aws_region" {\n';
                            variablesTfContent += '  description = "AWS region"\n';
                            variablesTfContent += '  default     = "us-west-2"\n';
                            variablesTfContent += '}\n\n';
                            variablesTfContent += 'variable "environment" {\n';
                            variablesTfContent += '  description = "Environment name"\n';
                            variablesTfContent += `  default     = "${env}"\n`;
                            variablesTfContent += '}\n\n';
                            variablesTfContent += 'variable "vpc_cidr" {\n';
                            variablesTfContent += '  description = "CIDR block for VPC"\n';
                            variablesTfContent += '  default     = "10.0.0.0/16"\n';
                            variablesTfContent += '}\n\n';
                            variablesTfContent += 'variable "azs" {\n';
                            variablesTfContent += '  description = "Availability zones"\n';
                            variablesTfContent += '  default     = ["us-west-2a", "us-west-2b", "us-west-2c"]\n';
                            variablesTfContent += '}\n\n';
                            variablesTfContent += 'variable "private_subnets" {\n';
                            variablesTfContent += '  description = "Private subnet CIDR blocks"\n';
                            variablesTfContent += '  default     = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]\n';
                            variablesTfContent += '}\n\n';
                            variablesTfContent += 'variable "public_subnets" {\n';
                            variablesTfContent += '  description = "Public subnet CIDR blocks"\n';
                            variablesTfContent += '  default     = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]\n';
                            variablesTfContent += '}\n\n';
                            variablesTfContent += 'variable "db_name" {\n';
                            variablesTfContent += '  description = "Database name"\n';
                            variablesTfContent += '  default     = "appdb"\n';
                            variablesTfContent += '}\n\n';
                            variablesTfContent += 'variable "db_username" {\n';
                            variablesTfContent += '  description = "Database username"\n';
                            variablesTfContent += '  default     = "admin"\n';
                            variablesTfContent += '}\n\n';
                            variablesTfContent += 'variable "db_password" {\n';
                            variablesTfContent += '  description = "Database password"\n';
                            variablesTfContent += '  sensitive   = true\n';
                            variablesTfContent += '}\n';

                            // Escribir variables.tf
                            fs.writeFileSync(path.join(envDir, 'variables.tf'), variablesTfContent);

                            // Crear outputs.tf
                            let outputsTfContent = 'output "vpc_id" {\n';
                            outputsTfContent += '  description = "ID of the VPC"\n';
                            outputsTfContent += '  value       = module.vpc.vpc_id\n';
                            outputsTfContent += '}\n\n';
                            outputsTfContent += 'output "private_subnets" {\n';
                            outputsTfContent += '  description = "IDs of the private subnets"\n';
                            outputsTfContent += '  value       = module.vpc.private_subnets\n';
                            outputsTfContent += '}\n\n';
                            outputsTfContent += 'output "public_subnets" {\n';
                            outputsTfContent += '  description = "IDs of the public subnets"\n';
                            outputsTfContent += '  value       = module.vpc.public_subnets\n';
                            outputsTfContent += '}\n\n';
                            outputsTfContent += 'output "ecs_cluster_id" {\n';
                            outputsTfContent += '  description = "ID of the ECS cluster"\n';
                            outputsTfContent += '  value       = module.ecs.cluster_id\n';
                            outputsTfContent += '}\n\n';
                            outputsTfContent += 'output "db_instance_endpoint" {\n';
                            outputsTfContent += '  description = "Endpoint of the RDS instance"\n';
                            outputsTfContent += '  value       = module.rds.db_instance_endpoint\n';
                            outputsTfContent += '}\n';

                            // Escribir outputs.tf
                            fs.writeFileSync(path.join(envDir, 'outputs.tf'), outputsTfContent);

                            // Crear terraform.tfvars
                            let tfvarsContent = 'aws_region = "us-west-2"\n';
                            tfvarsContent += `environment = "${env}"\n`;
                            tfvarsContent += 'vpc_cidr = "10.0.0.0/16"\n';
                            tfvarsContent += 'azs = ["us-west-2a", "us-west-2b", "us-west-2c"]\n';
                            tfvarsContent += 'private_subnets = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]\n';
                            tfvarsContent += 'public_subnets = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]\n';
                            tfvarsContent += 'db_name = "appdb"\n';
                            tfvarsContent += 'db_username = "admin"\n';
                            tfvarsContent += '# db_password debe ser configurado de forma segura, no en el control de versiones\n';
                            tfvarsContent += '# db_password = "your-secure-password"\n';

                            // Escribir terraform.tfvars
                            fs.writeFileSync(path.join(envDir, 'terraform.tfvars'), tfvarsContent);
                        }

                        // Crear directorio de módulos
                        const modulesDir = path.join(terraformDir, 'modules');
                        if (!fs.existsSync(modulesDir)) {
                            fs.mkdirSync(modulesDir, { recursive: true });
                        }

                        // Crear módulos: VPC, ECS, RDS
                        this.createTerraformModuleVPC(path.join(modulesDir, 'vpc'));
                        this.createTerraformModuleECS(path.join(modulesDir, 'ecs'));
                        this.createTerraformModuleRDS(path.join(modulesDir, 'rds'));

                        // Crear README.md para Terraform
                        let terraformReadmeContent = '# Terraform Infrastructure\n\n';
                        terraformReadmeContent += 'Este directorio contiene la configuración de Terraform para provisionar la infraestructura en AWS.\n\n';
                        terraformReadmeContent += '## Estructura\n\n';
                        terraformReadmeContent += '- `dev/`: Configuración para el entorno de desarrollo\n';
                        terraformReadmeContent += '- `staging/`: Configuración para el entorno de staging\n';
                        terraformReadmeContent += '- `prod/`: Configuración para el entorno de producción\n';
                        terraformReadmeContent += '- `modules/`: Módulos reutilizables de Terraform\n';
                        terraformReadmeContent += '  - `vpc/`: Módulo para crear una VPC\n';
                        terraformReadmeContent += '  - `ecs/`: Módulo para crear un clúster de ECS\n';
                        terraformReadmeContent += '  - `rds/`: Módulo para crear una instancia de RDS\n\n';
                        terraformReadmeContent += '## Uso\n\n';
                        terraformReadmeContent += '```bash\n';
                        terraformReadmeContent += '# Inicializar Terraform\n';
                        terraformReadmeContent += 'cd dev  # o staging, prod\n';
                        terraformReadmeContent += 'terraform init\n\n';
                        terraformReadmeContent += '# Planificar los cambios\n';
                        terraformReadmeContent += 'terraform plan -var-file=terraform.tfvars\n\n';
                        terraformReadmeContent += '# Aplicar los cambios\n';
                        terraformReadmeContent += 'terraform apply -var-file=terraform.tfvars\n\n';
                        terraformReadmeContent += '# Destruir la infraestructura\n';
                        terraformReadmeContent += 'terraform destroy -var-file=terraform.tfvars\n';
                        terraformReadmeContent += '```\n\n';
                        terraformReadmeContent += '## Variables\n\n';
                        terraformReadmeContent += 'Cada entorno tiene su propio conjunto de variables definidas en `terraform.tfvars`. Algunas variables sensibles como contraseñas deben ser proporcionadas en tiempo de ejecución o a través de variables de entorno.\n\n';
                        terraformReadmeContent += '## Seguridad\n\n';
                        terraformReadmeContent += '- No almacene contraseñas o secretos en archivos de configuración que se suban al control de versiones.\n';
                        terraformReadmeContent += '- Utilice AWS Secrets Manager o HashiCorp Vault para gestionar secretos.\n';
                        terraformReadmeContent += '- Considere usar el backend remoto de Terraform para almacenar el estado de forma segura.\n';

                        // Escribir README.md para Terraform
                        fs.writeFileSync(path.join(terraformDir, 'README.md'), terraformReadmeContent);
                    }

                    /**
                     * Crea el módulo VPC de Terraform
                     * @param {string} vpcDir - Directorio para el módulo VPC
                     */
                    createTerraformModuleVPC(vpcDir) {
                        if (!fs.existsSync(vpcDir)) {
                            fs.mkdirSync(vpcDir, { recursive: true });
                        }

                        // Crear main.tf para el módulo VPC
                        let mainTfContent = 'resource "aws_vpc" "main" {\n';
                        mainTfContent += '  cidr_block           = var.vpc_cidr\n';
                        mainTfContent += '  enable_dns_hostnames = true\n';
                        mainTfContent += '  enable_dns_support   = true\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-vpc"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_subnet" "private" {\n';
                        mainTfContent += '  count = length(var.private_subnets)\n\n';
                        mainTfContent += '  vpc_id            = aws_vpc.main.id\n';
                        mainTfContent += '  cidr_block        = var.private_subnets[count.index]\n';
                        mainTfContent += '  availability_zone = var.azs[count.index]\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-private-subnet-${count.index}"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_subnet" "public" {\n';
                        mainTfContent += '  count = length(var.public_subnets)\n\n';
                        mainTfContent += '  vpc_id                  = aws_vpc.main.id\n';
                        mainTfContent += '  cidr_block              = var.public_subnets[count.index]\n';
                        mainTfContent += '  availability_zone       = var.azs[count.index]\n';
                        mainTfContent += '  map_public_ip_on_launch = true\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-public-subnet-${count.index}"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_internet_gateway" "main" {\n';
                        mainTfContent += '  vpc_id = aws_vpc.main.id\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-igw"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_route_table" "public" {\n';
                        mainTfContent += '  vpc_id = aws_vpc.main.id\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-public-route-table"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_route" "public" {\n';
                        mainTfContent += '  route_table_id         = aws_route_table.public.id\n';
                        mainTfContent += '  destination_cidr_block = "0.0.0.0/0"\n';
                        mainTfContent += '  gateway_id             = aws_internet_gateway.main.id\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_route_table_association" "public" {\n';
                        mainTfContent += '  count = length(var.public_subnets)\n\n';
                        mainTfContent += '  subnet_id      = aws_subnet.public[count.index].id\n';
                        mainTfContent += '  route_table_id = aws_route_table.public.id\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_eip" "nat" {\n';
                        mainTfContent += '  count = length(var.private_subnets) > 0 ? 1 : 0\n\n';
                        mainTfContent += '  vpc = true\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-nat-eip"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_nat_gateway" "main" {\n';
                        mainTfContent += '  count = length(var.private_subnets) > 0 ? 1 : 0\n\n';
                        mainTfContent += '  allocation_id = aws_eip.nat[0].id\n';
                        mainTfContent += '  subnet_id     = aws_subnet.public[0].id\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-nat-gateway"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n\n';
                        mainTfContent += '  depends_on = [aws_internet_gateway.main]\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_route_table" "private" {\n';
                        mainTfContent += '  count = length(var.private_subnets) > 0 ? 1 : 0\n\n';
                        mainTfContent += '  vpc_id = aws_vpc.main.id\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-private-route-table"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_route" "private" {\n';
                        mainTfContent += '  count = length(var.private_subnets) > 0 ? 1 : 0\n\n';
                        mainTfContent += '  route_table_id         = aws_route_table.private[0].id\n';
                        mainTfContent += '  destination_cidr_block = "0.0.0.0/0"\n';
                        mainTfContent += '  nat_gateway_id         = aws_nat_gateway.main[0].id\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_route_table_association" "private" {\n';
                        mainTfContent += '  count = length(var.private_subnets)\n\n';
                        mainTfContent += '  subnet_id      = aws_subnet.private[count.index].id\n';
                        mainTfContent += '  route_table_id = aws_route_table.private[0].id\n';
                        mainTfContent += '}\n';

                        // Escribir main.tf para el módulo VPC
                        fs.writeFileSync(path.join(vpcDir, 'main.tf'), mainTfContent);

                        // Crear variables.tf para el módulo VPC
                        let variablesTfContent = 'variable "environment" {\n';
                        variablesTfContent += '  description = "Environment name"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "vpc_cidr" {\n';
                        variablesTfContent += '  description = "CIDR block for VPC"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "azs" {\n';
                        variablesTfContent += '  description = "Availability zones"\n';
                        variablesTfContent += '  type        = list(string)\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "private_subnets" {\n';
                        variablesTfContent += '  description = "Private subnet CIDR blocks"\n';
                        variablesTfContent += '  type        = list(string)\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "public_subnets" {\n';
                        variablesTfContent += '  description = "Public subnet CIDR blocks"\n';
                        variablesTfContent += '  type        = list(string)\n';
                        variablesTfContent += '}\n';

                        // Escribir variables.tf para el módulo VPC
                        fs.writeFileSync(path.join(vpcDir, 'variables.tf'), variablesTfContent);

                        // Crear outputs.tf para el módulo VPC
                        let outputsTfContent = 'output "vpc_id" {\n';
                        outputsTfContent += '  description = "ID of the VPC"\n';
                        outputsTfContent += '  value       = aws_vpc.main.id\n';
                        outputsTfContent += '}\n\n';
                        outputsTfContent += 'output "private_subnets" {\n';
                        outputsTfContent += '  description = "IDs of the private subnets"\n';
                        outputsTfContent += '  value       = aws_subnet.private[*].id\n';
                        outputsTfContent += '}\n\n';
                        outputsTfContent += 'output "public_subnets" {\n';
                        outputsTfContent += '  description = "IDs of the public subnets"\n';
                        outputsTfContent += '  value       = aws_subnet.public[*].id\n';
                        outputsTfContent += '}\n';

                        // Escribir outputs.tf para el módulo VPC
                        fs.writeFileSync(path.join(vpcDir, 'outputs.tf'), outputsTfContent);
                    }

                    /**
                     * Crea el módulo ECS de Terraform
                     * @param {string} ecsDir - Directorio para el módulo ECS
                     */
                    createTerraformModuleECS(ecsDir) {
                        if (!fs.existsSync(ecsDir)) {
                            fs.mkdirSync(ecsDir, { recursive: true });
                        }

                        // Crear main.tf para el módulo ECS
                        let mainTfContent = 'resource "aws_ecs_cluster" "main" {\n';
                        mainTfContent += '  name = "${var.environment}-cluster"\n\n';
                        mainTfContent += '  setting {\n';
                        mainTfContent += '    name  = "containerInsights"\n';
                        mainTfContent += '    value = "enabled"\n';
                        mainTfContent += '  }\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_security_group" "ecs_tasks" {\n';
                        mainTfContent += '  name        = "${var.environment}-ecs-tasks-sg"\n';
                        mainTfContent += '  description = "Allow inbound traffic for ECS tasks"\n';
                        mainTfContent += '  vpc_id      = var.vpc_id\n\n';
                        mainTfContent += '  ingress {\n';
                        mainTfContent += '    protocol    = "tcp"\n';
                        mainTfContent += '    from_port   = 80\n';
                        mainTfContent += '    to_port     = 80\n';
                        mainTfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                        mainTfContent += '  }\n\n';
                        mainTfContent += '  ingress {\n';
                        mainTfContent += '    protocol    = "tcp"\n';
                        mainTfContent += '    from_port   = 443\n';
                        mainTfContent += '    to_port     = 443\n';
                        mainTfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                        mainTfContent += '  }\n\n';
                        mainTfContent += '  egress {\n';
                        mainTfContent += '    protocol    = "-1"\n';
                        mainTfContent += '    from_port   = 0\n';
                        mainTfContent += '    to_port     = 0\n';
                        mainTfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                        mainTfContent += '  }\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-ecs-tasks-sg"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_iam_role" "ecs_task_execution_role" {\n';
                        mainTfContent += '  name = "${var.environment}-ecs-task-execution-role"\n\n';
                        mainTfContent += '  assume_role_policy = jsonencode({\n';
                        mainTfContent += '    Version = "2012-10-17"\n';
                        mainTfContent += '    Statement = [\n';
                        mainTfContent += '      {\n';
                        mainTfContent += '        Action = "sts:AssumeRole"\n';
                        mainTfContent += '        Effect = "Allow"\n';
                        mainTfContent += '        Principal = {\n';
                        mainTfContent += '          Service = "ecs-tasks.amazonaws.com"\n';
                        mainTfContent += '        }\n';
                        mainTfContent += '      }\n';
                        mainTfContent += '    ]\n';
                        mainTfContent += '  })\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_iam_role_policy_attachment" "ecs_task_execution_role_policy" {\n';
                        mainTfContent += '  role       = aws_iam_role.ecs_task_execution_role.name\n';
                        mainTfContent += '  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"\n';
                        mainTfContent += '}\n';

                        // Escribir main.tf para el módulo ECS
                        fs.writeFileSync(path.join(ecsDir, 'main.tf'), mainTfContent);

                        // Crear variables.tf para el módulo ECS
                        let variablesTfContent = 'variable "environment" {\n';
                        variablesTfContent += '  description = "Environment name"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "vpc_id" {\n';
                        variablesTfContent += '  description = "ID of the VPC"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "subnets" {\n';
                        variablesTfContent += '  description = "Subnet IDs for ECS tasks"\n';
                        variablesTfContent += '  type        = list(string)\n';
                        variablesTfContent += '}\n';

                        // Escribir variables.tf para el módulo ECS
                        fs.writeFileSync(path.join(ecsDir, 'variables.tf'), variablesTfContent);

                        // Crear outputs.tf para el módulo ECS
                        let outputsTfContent = 'output "cluster_id" {\n';
                        outputsTfContent += '  description = "ID of the ECS cluster"\n';
                        outputsTfContent += '  value       = aws_ecs_cluster.main.id\n';
                        outputsTfContent += '}\n\n';
                        outputsTfContent += 'output "cluster_name" {\n';
                        outputsTfContent += '  description = "Name of the ECS cluster"\n';
                        outputsTfContent += '  value       = aws_ecs_cluster.main.name\n';
                        outputsTfContent += '}\n\n';
                        outputsTfContent += 'output "task_execution_role_arn" {\n';
                        outputsTfContent += '  description = "ARN of the ECS task execution role"\n';
                        outputsTfContent += '  value       = aws_iam_role.ecs_task_execution_role.arn\n';
                        outputsTfContent += '}\n\n';
                        outputsTfContent += 'output "security_group_id" {\n';
                        outputsTfContent += '  description = "ID of the security group for ECS tasks"\n';
                        outputsTfContent += '  value       = aws_security_group.ecs_tasks.id\n';
                        outputsTfContent += '}\n';

                        // Escribir outputs.tf para el módulo ECS
                        fs.writeFileSync(path.join(ecsDir, 'outputs.tf'), outputsTfContent);
                    }

                    /**
                     * Crea el módulo RDS de Terraform
                     * @param {string} rdsDir - Directorio para el módulo RDS
                     */
                    createTerraformModuleRDS(rdsDir) {
                        if (!fs.existsSync(rdsDir)) {
                            fs.mkdirSync(rdsDir, { recursive: true });
                        }

                        // Crear main.tf para el módulo RDS
                        let mainTfContent = 'resource "aws_security_group" "rds" {\n';
                        mainTfContent += '  name        = "${var.environment}-rds-sg"\n';
                        mainTfContent += '  description = "Allow inbound traffic for RDS"\n';
                        mainTfContent += '  vpc_id      = var.vpc_id\n\n';
                        mainTfContent += '  ingress {\n';
                        mainTfContent += '    protocol        = "tcp"\n';
                        mainTfContent += '    from_port       = 5432\n';
                        mainTfContent += '    to_port         = 5432\n';
                        mainTfContent += '    security_groups = [var.ecs_security_group_id]\n';
                        mainTfContent += '  }\n\n';
                        mainTfContent += '  egress {\n';
                        mainTfContent += '    protocol    = "-1"\n';
                        mainTfContent += '    from_port   = 0\n';
                        mainTfContent += '    to_port     = 0\n';
                        mainTfContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                        mainTfContent += '  }\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-rds-sg"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_db_subnet_group" "main" {\n';
                        mainTfContent += '  name       = "${var.environment}-db-subnet-group"\n';
                        mainTfContent += '  subnet_ids = var.subnets\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-db-subnet-group"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n\n';
                        mainTfContent += 'resource "aws_db_instance" "main" {\n';
                        mainTfContent += '  identifier             = "${var.environment}-db"\n';
                        mainTfContent += '  engine                 = "postgres"\n';
                        mainTfContent += '  engine_version         = "13.4"\n';
                        mainTfContent += '  instance_class         = "db.t3.micro"\n';
                        mainTfContent += '  allocated_storage      = 20\n';
                        mainTfContent += '  storage_type           = "gp2"\n';
                        mainTfContent += '  db_name                = var.db_name\n';
                        mainTfContent += '  username               = var.db_username\n';
                        mainTfContent += '  password               = var.db_password\n';
                        mainTfContent += '  db_subnet_group_name   = aws_db_subnet_group.main.name\n';
                        mainTfContent += '  vpc_security_group_ids = [aws_security_group.rds.id]\n';
                        mainTfContent += '  skip_final_snapshot    = true\n\n';
                        mainTfContent += '  tags = {\n';
                        mainTfContent += '    Name        = "${var.environment}-db"\n';
                        mainTfContent += '    Environment = var.environment\n';
                        mainTfContent += '  }\n';
                        mainTfContent += '}\n';

                        // Escribir main.tf para el módulo RDS
                        fs.writeFileSync(path.join(rdsDir, 'main.tf'), mainTfContent);

                        // Crear variables.tf para el módulo RDS
                        let variablesTfContent = 'variable "environment" {\n';
                        variablesTfContent += '  description = "Environment name"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "vpc_id" {\n';
                        variablesTfContent += '  description = "ID of the VPC"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "subnets" {\n';
                        variablesTfContent += '  description = "Subnet IDs for RDS"\n';
                        variablesTfContent += '  type        = list(string)\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "ecs_security_group_id" {\n';
                        variablesTfContent += '  description = "ID of the ECS security group"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "db_name" {\n';
                        variablesTfContent += '  description = "Name of the database"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "db_username" {\n';
                        variablesTfContent += '  description = "Username for the database"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '}\n\n';
                        variablesTfContent += 'variable "db_password" {\n';
                        variablesTfContent += '  description = "Password for the database"\n';
                        variablesTfContent += '  type        = string\n';
                        variablesTfContent += '  sensitive   = true\n';
                        variablesTfContent += '}\n';

                        // Escribir variables.tf para el módulo RDS
                        fs.writeFileSync(path.join(rdsDir, 'variables.tf'), variablesTfContent);

                        // Crear outputs.tf para el módulo RDS
                        let outputsTfContent = 'output "db_instance_id" {\n';
                        outputsTfContent += '  description = "ID of the RDS instance"\n';
                        outputsTfContent += '  value       = aws_db_instance.main.id\n';
                        outputsTfContent += '}\n\n';
                        outputsTfContent += 'output "db_instance_endpoint" {\n';
                        outputsTfContent += '  description = "Endpoint of the RDS instance"\n';
                        outputsTfContent += '  value       = aws_db_instance.main.endpoint\n';
                        outputsTfContent += '}\n\n';
                        outputsTfContent += 'output "db_instance_name" {\n';
                        outputsTfContent += '  description = "Name of the database"\n';
                        outputsTfContent += '  value       = aws_db_instance.main.db_name\n';
                        outputsTfContent += '}\n\n';
                        outputsTfContent += 'output "db_instance_username" {\n';
                        outputsTfContent += '  description = "Username for the database"\n';
                        outputsTfContent += '  value       = aws_db_instance.main.username\n';
                        outputsTfContent += '}\n';

                        // Escribir outputs.tf para el módulo RDS
                        fs.writeFileSync(path.join(rdsDir, 'outputs.tf'), outputsTfContent);
                    }

                    /**
                     * Crea archivos de Ansible
                     * @param {string} ansibleDir - Directorio para archivos de Ansible
                     */
                    createAnsibleFiles(ansibleDir) {
                        // Crear estructura de directorios para Ansible
                        const inventoryDir = path.join(ansibleDir, 'inventory');
                        const rolesDir = path.join(ansibleDir, 'roles');
                        const playbooksDir = path.join(ansibleDir, 'playbooks');

                        if (!fs.existsSync(inventoryDir)) {
                            fs.mkdirSync(inventoryDir, { recursive: true });
                        }
                        if (!fs.existsSync(rolesDir)) {
                            fs.mkdirSync(rolesDir, { recursive: true });
                        }
                        if (!fs.existsSync(playbooksDir)) {
                            fs.mkdirSync(playbooksDir, { recursive: true });
                        }

                        // Crear archivos de inventario para diferentes entornos
                        const envs = ['dev', 'staging', 'prod'];
                        
                        for (const env of envs) {
                            let inventoryContent = `[${env}]\n`;
                            inventoryContent += `${env}-app-server-1 ansible_host=10.0.1.10 ansible_user=ubuntu\n`;
                            inventoryContent += `${env}-app-server-2 ansible_host=10.0.1.11 ansible_user=ubuntu\n\n`;
                            inventoryContent += `[${env}_db]\n`;
                            inventoryContent += `${env}-db-server ansible_host=10.0.2.10 ansible_user=ubuntu\n\n`;
                            inventoryContent += `[${env}:children]\n`;
                            inventoryContent += `${env}_db\n`;

                            fs.writeFileSync(path.join(inventoryDir, `${env}.ini`), inventoryContent);
                        }

                        // Crear archivo de configuración de Ansible
                        let ansibleCfgContent = '[defaults]\n';
                        ansibleCfgContent += 'inventory = ./inventory\n';
                        ansibleCfgContent += 'roles_path = ./roles\n';
                        ansibleCfgContent += 'host_key_checking = False\n';
                        ansibleCfgContent += 'retry_files_enabled = False\n';
                        ansibleCfgContent += 'stdout_callback = yaml\n\n';
                        ansibleCfgContent += '[ssh_connection]\n';
                        ansibleCfgContent += 'pipelining = True\n';
                        ansibleCfgContent += 'control_path = /tmp/ansible-ssh-%%h-%%p-%%r\n';

                        fs.writeFileSync(path.join(ansibleDir, 'ansible.cfg'), ansibleCfgContent);

                        // Crear roles comunes
                        const commonRoles = ['common', 'nginx', 'docker', 'node'];
                        
                        for (const role of commonRoles) {
                            this.createAnsibleRole(path.join(rolesDir, role), role);
                        }

                        // Crear playbooks
                        this.createAnsiblePlaybooks(playbooksDir);

                        // Crear README.md para Ansible
                        let ansibleReadmeContent = '# Ansible Configuration\n\n';
                        ansibleReadmeContent += 'Este directorio contiene la configuración de Ansible para la gestión de servidores y despliegue de aplicaciones.\n\n';
                        ansibleReadmeContent += '## Estructura\n\n';
                        ansibleReadmeContent += '- `inventory/`: Archivos de inventario para diferentes entornos\n';
                        ansibleReadmeContent += '- `roles/`: Roles de Ansible reutilizables\n';
                        ansibleReadmeContent += '- `playbooks/`: Playbooks para diferentes tareas\n\n';
                        ansibleReadmeContent += '## Uso\n\n';
                        ansibleReadmeContent += '```bash\n';
                        ansibleReadmeContent += '# Verificar la conectividad con los servidores\n';
                        ansibleReadmeContent += 'ansible all -i inventory/dev.ini -m ping\n\n';
                        ansibleReadmeContent += '# Ejecutar un playbook\n';
                        ansibleReadmeContent += 'ansible-playbook -i inventory/dev.ini playbooks/setup.yml\n\n';
                        ansibleReadmeContent += '# Ejecutar un playbook con variables adicionales\n';
                        ansibleReadmeContent += 'ansible-playbook -i inventory/prod.ini playbooks/deploy.yml -e "version=1.0.0"\n';
                        ansibleReadmeContent += '```\n\n';
                        ansibleReadmeContent += '## Roles\n\n';
                        ansibleReadmeContent += '- `common`: Configuración básica para todos los servidores\n';
                        ansibleReadmeContent += '- `nginx`: Instalación y configuración de Nginx\n';
                        ansibleReadmeContent += '- `docker`: Instalación y configuración de Docker\n';
                        ansibleReadmeContent += '- `node`: Instalación y configuración de Node.js\n\n';
                        ansibleReadmeContent += '## Playbooks\n\n';
                        ansibleReadmeContent += '- `setup.yml`: Configuración inicial de servidores\n';
                        ansibleReadmeContent += '- `deploy.yml`: Despliegue de la aplicación\n';
                        ansibleReadmeContent += '- `update.yml`: Actualización de la aplicación\n';
                        ansibleReadmeContent += '- `rollback.yml`: Rollback a una versión anterior\n';

                        fs.writeFileSync(path.join(ansibleDir, 'README.md'), ansibleReadmeContent);
                    }

                    /**
                     * Crea un rol de Ansible
                     * @param {string} roleDir - Directorio para el rol
                     * @param {string} roleName - Nombre del rol
                     */
                    createAnsibleRole(roleDir, roleName) {
                        if (!fs.existsSync(roleDir)) {
                            fs.mkdirSync(roleDir, { recursive: true });
                        }

                        // Crear estructura de directorios para el rol
                        const dirs = ['tasks', 'handlers', 'templates', 'files', 'vars', 'defaults', 'meta'];
                        
                        for (const dir of dirs) {
                            const dirPath = path.join(roleDir, dir);
                            if (!fs.existsSync(dirPath)) {
                                fs.mkdirSync(dirPath, { recursive: true });
                            }
                        }

                        // Crear main.yml para tasks
                        let tasksContent = '---\n';
                        
                        switch (roleName) {
                            case 'common':
                                tasksContent += '# Tareas comunes para todos los servidores\n';
                                tasksContent += '- name: Actualizar caché de paquetes\n';
                                tasksContent += '  apt:\n';
                                tasksContent += '    update_cache: yes\n';
                                tasksContent += '    cache_valid_time: 3600\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Instalar paquetes básicos\n';
                                tasksContent += '  apt:\n';
                                tasksContent += '    name:\n';
                                tasksContent += '      - vim\n';
                                tasksContent += '      - curl\n';
                                tasksContent += '      - wget\n';
                                tasksContent += '      - git\n';
                                tasksContent += '      - htop\n';
                                tasksContent += '      - net-tools\n';
                                tasksContent += '      - unzip\n';
                                tasksContent += '    state: present\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Configurar zona horaria\n';
                                tasksContent += '  timezone:\n';
                                tasksContent += '    name: UTC\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Configurar hostname\n';
                                tasksContent += '  hostname:\n';
                                tasksContent += '    name: "{{ inventory_hostname }}"\n';
                                tasksContent += '  become: yes\n';
                                break;
                            
                            case 'nginx':
                                tasksContent += '# Tareas para instalar y configurar Nginx\n';
                                tasksContent += '- name: Instalar Nginx\n';
                                tasksContent += '  apt:\n';
                                tasksContent += '    name: nginx\n';
                                tasksContent += '    state: present\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Crear configuración de Nginx\n';
                                tasksContent += '  template:\n';
                                tasksContent += '    src: nginx.conf.j2\n';
                                tasksContent += '    dest: /etc/nginx/nginx.conf\n';
                                tasksContent += '  become: yes\n';
                                tasksContent += '  notify: restart nginx\n\n';
                                tasksContent += '- name: Crear configuración de sitio\n';
                                tasksContent += '  template:\n';
                                tasksContent += '    src: site.conf.j2\n';
                                tasksContent += '    dest: /etc/nginx/sites-available/default\n';
                                tasksContent += '  become: yes\n';
                                tasksContent += '  notify: restart nginx\n\n';
                                tasksContent += '- name: Iniciar y habilitar Nginx\n';
                                tasksContent += '  service:\n';
                                tasksContent += '    name: nginx\n';
                                tasksContent += '    state: started\n';
                                tasksContent += '    enabled: yes\n';
                                tasksContent += '  become: yes\n';
                                break;
                            
                            case 'docker':
                                tasksContent += '# Tareas para instalar y configurar Docker\n';
                                tasksContent += '- name: Instalar dependencias\n';
                                tasksContent += '  apt:\n';
                                tasksContent += '    name:\n';
                                tasksContent += '      - apt-transport-https\n';
                                tasksContent += '      - ca-certificates\n';
                                tasksContent += '      - gnupg-agent\n';
                                tasksContent += '      - software-properties-common\n';
                                tasksContent += '    state: present\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Añadir clave GPG de Docker\n';
                                tasksContent += '  apt_key:\n';
                                tasksContent += '    url: https://download.docker.com/linux/ubuntu/gpg\n';
                                tasksContent += '    state: present\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Añadir repositorio de Docker\n';
                                tasksContent += '  apt_repository:\n';
                                tasksContent += '    repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable\n';
                                tasksContent += '    state: present\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Instalar Docker\n';
                                tasksContent += '  apt:\n';
                                tasksContent += '    name:\n';
                                tasksContent += '      - docker-ce\n';
                                tasksContent += '      - docker-ce-cli\n';
                                tasksContent += '      - containerd.io\n';
                                tasksContent += '    state: present\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Instalar Docker Compose\n';
                                tasksContent += '  get_url:\n';
                                tasksContent += '    url: https://github.com/docker/compose/releases/download/1.29.2/docker-compose-{{ ansible_system }}-{{ ansible_architecture }}\n';
                                tasksContent += '    dest: /usr/local/bin/docker-compose\n';
                                tasksContent += '    mode: "0755"\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Añadir usuario al grupo docker\n';
                                tasksContent += '  user:\n';
                                tasksContent += '    name: "{{ ansible_user }}"\n';
                                tasksContent += '    groups: docker\n';
                                tasksContent += '    append: yes\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Iniciar y habilitar Docker\n';
                                tasksContent += '  service:\n';
                                tasksContent += '    name: docker\n';
                                tasksContent += '    state: started\n';
                                tasksContent += '    enabled: yes\n';
                                tasksContent += '  become: yes\n';
                                break;
                            
                            case 'node':
                                tasksContent += '# Tareas para instalar y configurar Node.js\n';
                                tasksContent += '- name: Instalar Node.js y npm\n';
                                tasksContent += '  apt:\n';
                                tasksContent += '    name:\n';
                                tasksContent += '      - nodejs\n';
                                tasksContent += '      - npm\n';
                                tasksContent += '    state: present\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Instalar n (gestor de versiones de Node.js)\n';
                                tasksContent += '  npm:\n';
                                tasksContent += '    name: n\n';
                                tasksContent += '    global: yes\n';
                                tasksContent += '  become: yes\n\n';
                                tasksContent += '- name: Instalar versión específica de Node.js\n';
                                tasksContent += '  shell: n {{ node_version }}\n';
                                tasksContent += '  become: yes\n';
                                tasksContent += '  vars:\n';
                                tasksContent += '    node_version: "{{ node_version | default(\'14.17.0\') }}"\n\n';
                                tasksContent += '- name: Instalar paquetes npm globales\n';
                                tasksContent += '  npm:\n';
                                tasksContent += '    name: "{{ item }}"\n';
                                tasksContent += '    global: yes\n';
                                tasksContent += '  loop:\n';
                                tasksContent += '    - pm2\n';
                                tasksContent += '    - yarn\n';
                                tasksContent += '  become: yes\n';
                                break;
                            
                            default:
                                tasksContent += '# Tareas para el rol ' + roleName + '\n';
                                tasksContent += '- name: Placeholder task\n';
                                tasksContent += '  debug:\n';
                                tasksContent += '    msg: "Este es un placeholder para el rol ' + roleName + '"\n';
                        }

                        fs.writeFileSync(path.join(roleDir, 'tasks', 'main.yml'), tasksContent);

                        // Crear main.yml para handlers
                        let handlersContent = '---\n';
                        
                        switch (roleName) {
                            case 'nginx':
                                handlersContent += '# Handlers para Nginx\n';
                                handlersContent += '- name: restart nginx\n';
                                handlersContent += '  service:\n';
                                handlersContent += '    name: nginx\n';
                                handlersContent += '    state: restarted\n';
                                handlersContent += '  become: yes\n';
                                break;
                            
                            case 'docker':
                                handlersContent += '# Handlers para Docker\n';
                                handlersContent += '- name: restart docker\n';
                                handlersContent += '  service:\n';
                                handlersContent += '    name: docker\n';
                                handlersContent += '    state: restarted\n';
                                handlersContent += '  become: yes\n';
                                break;
                            
                            default:
                                handlersContent += '# Handlers para el rol ' + roleName + '\n';
                                handlersContent += '# Añade handlers según sea necesario\n';
                        }

                        fs.writeFileSync(path.join(roleDir, 'handlers', 'main.yml'), handlersContent);

                        // Crear main.yml para defaults
                        let defaultsContent = '---\n';
                        defaultsContent += '# Valores predeterminados para el rol ' + roleName + '\n';
                        
                        switch (roleName) {
                            case 'nginx':
                                defaultsContent += 'nginx_worker_processes: auto\n';
                                defaultsContent += 'nginx_worker_connections: 1024\n';
                                defaultsContent += 'nginx_server_name: localhost\n';
                                defaultsContent += 'nginx_port: 80\n';
                                defaultsContent += 'nginx_proxy_pass: http://localhost:3000\n';
                                break;
                            
                            case 'node':
                                defaultsContent += 'node_version: "14.17.0"\n';
                                defaultsContent += 'node_env: production\n';
                                break;
                            
                            default:
                                defaultsContent += '# Añade valores predeterminados según sea necesario\n';
                        }

                        fs.writeFileSync(path.join(roleDir, 'defaults', 'main.yml'), defaultsContent);

                        // Crear main.yml para meta
                        let metaContent = '---\n';
                        metaContent += 'galaxy_info:\n';
                        metaContent += '  author: DevOpsAgent\n';
                        metaContent += '  description: Rol de Ansible para ' + roleName + '\n';
                        metaContent += '  company: CJ.DevMind\n';
                        metaContent += '  license: MIT\n';
                        metaContent += '  min_ansible_version: 2.9\n';
                        metaContent += '  platforms:\n';
                        metaContent += '    - name: Ubuntu\n';
                        metaContent += '      versions:\n';
                        metaContent += '        - bionic\n';
                        metaContent += '        - focal\n';
                        metaContent += '  galaxy_tags:\n';
                        metaContent += '    - ' + roleName + '\n\n';
                        metaContent += 'dependencies: []\n';

                        fs.writeFileSync(path.join(roleDir, 'meta', 'main.yml'), metaContent);

                        // Crear templates si es necesario
                        if (roleName === 'nginx') {
                            // Crear nginx.conf.j2
                            let nginxConfContent = 'user www-data;\n';
                            nginxConfContent += 'worker_processes {{ nginx_worker_processes }};\n';
                            nginxConfContent += 'pid /run/nginx.pid;\n';
                            nginxConfContent += 'include /etc/nginx/modules-enabled/*.conf;\n\n';
                            nginxConfContent += 'events {\n';
                            nginxConfContent += '    worker_connections {{ nginx_worker_connections }};\n';
                            nginxConfContent += '}\n\n';
                            nginxConfContent += 'http {\n';
                            nginxConfContent += '    sendfile on;\n';
                            nginxConfContent += '    tcp_nopush on;\n';
                            nginxConfContent += '    tcp_nodelay on;\n';
                            nginxConfContent += '    keepalive_timeout 65;\n';
                            nginxConfContent += '    types_hash_max_size 2048;\n\n';
                            nginxConfContent += '    include /etc/nginx/mime.types;\n';
                            nginxConfContent += '    default_type application/octet-stream;\n\n';
                            nginxConfContent += '    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;\n';
                            nginxConfContent += '    ssl_prefer_server_ciphers on;\n\n';
                            nginxConfContent += '    access_log /var/log/nginx/access.log;\n';
                            nginxConfContent += '    error_log /var/log/nginx/error.log;\n\n';
                            nginxConfContent += '    gzip on;\n\n';
                            nginxConfContent += '    include /etc/nginx/conf.d/*.conf;\n';
                            nginxConfContent += '    include /etc/nginx/sites-enabled/*;\n';
                            nginxConfContent += '}\n';

                            fs.writeFileSync(path.join(roleDir, 'templates', 'nginx.conf.j2'), nginxConfContent);

                            // Crear site.conf.j2
                            let siteConfContent = 'server {\n';
                            siteConfContent += '    listen {{ nginx_port }};\n';
                            siteConfContent += '    server_name {{ nginx_server_name }};\n\n';
                            siteConfContent += '    location / {\n';
                            siteConfContent += '        proxy_pass {{ nginx_proxy_pass }};\n';
                            siteConfContent += '        proxy_http_version 1.1;\n';
                            siteConfContent += '        proxy_set_header Upgrade $http_upgrade;\n';
                            siteConfContent += '        proxy_set_header Connection \'upgrade\';\n';
                            siteConfContent += '        proxy_set_header Host $host;\n';
                            siteConfContent += '        proxy_cache_bypass $http_upgrade;\n';
                            siteConfContent += '    }\n';
                            siteConfContent += '}\n';

                            fs.writeFileSync(path.join(roleDir, 'templates', 'site.conf.j2'), siteConfContent);
                        }
                    }

                    /**
                     * Crea playbooks de Ansible
                     * @param {string} playbooksDir - Directorio para playbooks
                     */
                    createAnsiblePlaybooks(playbooksDir) {
                        // Crear setup.yml
                        let setupContent = '---\n';
                        setupContent += '# Playbook para la configuración inicial de servidores\n';
                        setupContent += '- name: Configurar servidores de aplicación\n';
                        setupContent += '  hosts: "{{ target | default(\'all\') }}"\n';
                        setupContent += '  become: yes\n';
                        setupContent += '  roles:\n';
                        setupContent += '    - common\n';
                        setupContent += '    - docker\n';
                        setupContent += '    - node\n\n';
                        setupContent += '- name: Configurar servidores web\n';
                        setupContent += '  hosts: "{{ target | default(\'all\') }}"\n';
                        setupContent += '  become: yes\n';
                        setupContent += '  roles:\n';
                        setupContent += '    - nginx\n';

                        fs.writeFileSync(path.join(playbooksDir, 'setup.yml'), setupContent);

                        // Crear deploy.yml
                        let deployContent = '---\n';
                        deployContent += '# Playbook para desplegar la aplicación\n';
                        deployContent += '- name: Desplegar aplicación\n';
                        deployContent += '  hosts: "{{ target | default(\'all\') }}"\n';
                        deployContent += '  become: yes\n';
                        deployContent += '  vars:\n';
                        deployContent += '    app_version: "{{ version | default(\'latest\') }}"\n';
                        deployContent += '    app_dir: /opt/app\n';
                        deployContent += '    app_env: "{{ env | default(\'production\') }}"\n\n';
                        deployContent += '  tasks:\n';
                        deployContent += '    - name: Crear directorio de la aplicación\n';
                        deployContent += '      file:\n';
                        deployContent += '        path: "{{ app_dir }}"\n';
                        deployContent += '        state: directory\n';
                        deployContent += '        owner: "{{ ansible_user }}"\n';
                        deployContent += '        group: "{{ ansible_user }}"\n';
                        deployContent += '        mode: "0755"\n\n';
                        deployContent += '    - name: Clonar repositorio\n';
                        deployContent += '      git:\n';
                        deployContent += '        repo: "{{ git_repo }}"\n';
                        deployContent += '        dest: "{{ app_dir }}"\n';
                        deployContent += '        version: "{{ app_version }}"\n';
                        deployContent += '      when: git_repo is defined\n\n';
                        deployContent += '    - name: Copiar docker-compose.yml\n';
                        deployContent += '      template:\n';
                        deployContent += '        src: docker-compose.yml.j2\n';
                        deployContent += '        dest: "{{ app_dir }}/docker-compose.yml"\n\n';
                        deployContent += '    - name: Copiar .env\n';
                        deployContent += '      template:\n';
                        deployContent += '        src: env.j2\n';
                        deployContent += '        dest: "{{ app_dir }}/.env"\n\n';
                        deployContent += '    - name: Desplegar con Docker Compose\n';
                        deployContent += '      shell: docker-compose up -d\n';
                        deployContent += '      args:\n';
                        deployContent += '        chdir: "{{ app_dir }}"\n';

                        fs.writeFileSync(path.join(playbooksDir, 'deploy.yml'), deployContent);

                        // Crear update.yml
                        let updateContent = '---\n';
                        updateContent += '# Playbook para actualizar la aplicación\n';
                        updateContent += '- name: Actualizar aplicación\n';
                        updateContent += '  hosts: "{{ target | default(\'all\') }}"\n';
                        updateContent += '  become: yes\n';
                        updateContent += '  vars:\n';
                        updateContent += '    app_version: "{{ version | default(\'latest\') }}"\n';
                        updateContent += '    app_dir: /opt/app\n\n';
                        updateContent += '  tasks:\n';
                        updateContent += '    - name: Verificar directorio de la aplicación\n';
                        updateContent += '      stat:\n';
                        updateContent += '        path: "{{ app_dir }}"\n';
                        updateContent += '      register: app_dir_stat\n\n';
                        updateContent += '    - name: Detener contenedores\n';
                        updateContent += '      shell: docker-compose down\n';
                        updateContent += '      args:\n';
                        updateContent += '        chdir: "{{ app_dir }}"\n';
                        updateContent += '      when: app_dir_stat.stat.exists\n\n';
                        updateContent += '    - name: Actualizar repositorio\n';
                        updateContent += '      git:\n';
                        updateContent += '        repo: "{{ git_repo }}"\n';
                        updateContent += '        dest: "{{ app_dir }}"\n';
                        updateContent += '        version: "{{ app_version }}"\n';
                        updateContent += '      when: git_repo is defined\n\n';
                        updateContent += '    - name: Actualizar imágenes\n';
                        updateContent += '      shell: docker-compose pull\n';
                        updateContent += '      args:\n';
                        updateContent += '        chdir: "{{ app_dir }}"\n\n';
                        updateContent += '    - name: Iniciar contenedores\n';
                        updateContent += '      shell: docker-compose up -d\n';
                        updateContent += '      args:\n';
                        updateContent += '        chdir: "{{ app_dir }}"\n\n';
                        updateContent += '    - name: Limpiar imágenes antiguas\n';
                        updateContent += '      shell: docker image prune -af\n';
                        updateContent += '      args:\n';
                        updateContent += '        chdir: "{{ app_dir }}"\n';

                        fs.writeFileSync(path.join(playbooksDir, 'update.yml'), updateContent);

                        // Crear rollback.yml
                        let rollbackContent = '---\n';
                        rollbackContent += '# Playbook para hacer rollback a una versión anterior\n';
                        rollbackContent += '- name: Rollback de aplicación\n';
                        rollbackContent += '  hosts: "{{ target | default(\'all\') }}"\n';
                        rollbackContent += '  become: yes\n';
                        rollbackContent += '  vars:\n';
                        rollbackContent += '    app_version: "{{ version }}"\n';
                        rollbackContent += '    app_dir: /opt/app\n\n';
                        rollbackContent += '  tasks:\n';
                        rollbackContent += '    - name: Verificar que se especificó una versión\n';
                        rollbackContent += '      fail:\n';
                        rollbackContent += '        msg: "Debe especificar una versión para el rollback con -e version=X.Y.Z"\n';
                        rollbackContent += '      when: version is not defined\n\n';
                        rollbackContent += '    - name: Detener contenedores\n';
                        rollbackContent += '      shell: docker-compose down\n';
                        rollbackContent += '      args:\n';
                        rollbackContent += '        chdir: "{{ app_dir }}"\n\n';
                        rollbackContent += '    - name: Checkout a versión específica\n';
                        rollbackContent += '      git:\n';
                        rollbackContent += '        repo: "{{ git_repo }}"\n';
                        rollbackContent += '        dest: "{{ app_dir }}"\n';
                        rollbackContent += '        version: "{{ app_version }}"\n';
                        rollbackContent += '      when: git_repo is defined\n\n';
                        rollbackContent += '    - name: Iniciar contenedores\n';
                        rollbackContent += '      shell: docker-compose up -d\n';
                        rollbackContent += '      args:\n';
                        rollbackContent += '        chdir: "{{ app_dir }}"\n\n';
                        rollbackContent += '    - name: Verificar estado de la aplicación\n';
                        rollbackContent += '      uri:\n';
                        rollbackContent += '        url: "http://localhost:{{ app_port | default(3000) }}/health"\n';
                        rollbackContent += '        status_code: 200\n';
                        rollbackContent += '      register: health_check\n';
                        rollbackContent += '      retries: 5\n';
                        rollbackContent += '      delay: 10\n';
                        rollbackContent += '      until: health_check.status == 200\n';
                        rollbackContent += '      ignore_errors: yes\n\n';
                        rollbackContent += '    - name: Notificar resultado del rollback\n';
                        rollbackContent += '      debug:\n';
                        rollbackContent += '        msg: "Rollback a la versión {{ app_version }} completado {{ health_check.status == 200 | ternary(\'exitosamente\', \'con posibles problemas\') }}"\n';

                        fs.writeFileSync(path.join(playbooksDir, 'rollback.yml'), rollbackContent);

                        // Crear backup.yml
                        let backupContent = '---\n';
                        backupContent += '# Playbook para realizar copias de seguridad\n';
                        backupContent += '- name: Backup de base de datos y archivos\n';
                        backupContent += '  hosts: "{{ target | default(\'db\') }}"\n';
                        backupContent += '  become: yes\n';
                        backupContent += '  vars:\n';
                        backupContent += '    backup_dir: /var/backups/app\n';
                        backupContent += '    timestamp: "{{ lookup(\'pipe\', \'date +%Y%m%d%H%M%S\') }}"\n';
                        backupContent += '    db_name: "{{ db_name | default(\'app\') }}"\n';
                        backupContent += '    db_user: "{{ db_user | default(\'postgres\') }}"\n\n';
                        backupContent += '  tasks:\n';
                        backupContent += '    - name: Crear directorio de backup\n';
                        backupContent += '      file:\n';
                        backupContent += '        path: "{{ backup_dir }}"\n';
                        backupContent += '        state: directory\n';
                        backupContent += '        mode: "0755"\n\n';
                        backupContent += '    - name: Backup de base de datos PostgreSQL\n';
                        backupContent += '      shell: pg_dump -U {{ db_user }} {{ db_name }} > {{ backup_dir }}/{{ db_name }}_{{ timestamp }}.sql\n';
                        backupContent += '      when: db_type is not defined or db_type == "postgres"\n\n';
                        backupContent += '    - name: Backup de base de datos MySQL\n';
                        backupContent += '      shell: mysqldump -u {{ db_user }} -p{{ db_password }} {{ db_name }} > {{ backup_dir }}/{{ db_name }}_{{ timestamp }}.sql\n';
                        backupContent += '      when: db_type is defined and db_type == "mysql"\n';
                        backupContent += '      no_log: true\n\n';
                        backupContent += '    - name: Comprimir backup\n';
                        backupContent += '      archive:\n';
                        backupContent += '        path: "{{ backup_dir }}/{{ db_name }}_{{ timestamp }}.sql"\n';
                        backupContent += '        dest: "{{ backup_dir }}/{{ db_name }}_{{ timestamp }}.tar.gz"\n';
                        backupContent += '        format: gz\n\n';
                        backupContent += '    - name: Eliminar archivo SQL original\n';
                        backupContent += '      file:\n';
                        backupContent += '        path: "{{ backup_dir }}/{{ db_name }}_{{ timestamp }}.sql"\n';
                        backupContent += '        state: absent\n\n';
                        backupContent += '    - name: Listar backups disponibles\n';
                        backupContent += '      find:\n';
                        backupContent += '        paths: "{{ backup_dir }}"\n';
                        backupContent += '        patterns: "*.tar.gz"\n';
                        backupContent += '      register: backup_files\n\n';
                        backupContent += '    - name: Eliminar backups antiguos (mantener últimos 7)\n';
                        backupContent += '      shell: ls -t {{ backup_dir }}/*.tar.gz | tail -n +8 | xargs rm -f\n';
                        backupContent += '      when: backup_files.matched > 7\n';

                        fs.writeFileSync(path.join(playbooksDir, 'backup.yml'), backupContent);
                    }

                    /**
                     * Crea archivos de monitoreo
                     * @param {string} monitoringDir - Directorio para archivos de monitoreo
                     */
                    createMonitoringFiles(monitoringDir) {
                        if (!fs.existsSync(monitoringDir)) {
                            fs.mkdirSync(monitoringDir, { recursive: true });
                        }

                        // Crear directorio para Prometheus
                        const prometheusDir = path.join(monitoringDir, 'prometheus');
                        if (!fs.existsSync(prometheusDir)) {
                            fs.mkdirSync(prometheusDir, { recursive: true });
                        }

                        // Crear prometheus.yml
                        let prometheusContent = 'global:\n';
                        prometheusContent += '  scrape_interval: 15s\n';
                        prometheusContent += '  evaluation_interval: 15s\n\n';
                        prometheusContent += 'alerting:\n';
                        prometheusContent += '  alertmanagers:\n';
                        prometheusContent += '    - static_configs:\n';
                        prometheusContent += '        - targets: [\'alertmanager:9093\']\n\n';
                        prometheusContent += 'rule_files:\n';
                        prometheusContent += '  - "alert_rules.yml"\n\n';
                        prometheusContent += 'scrape_configs:\n';
                        prometheusContent += '  - job_name: "prometheus"\n';
                        prometheusContent += '    static_configs:\n';
                        prometheusContent += '      - targets: ["localhost:9090"]\n\n';
                        prometheusContent += '  - job_name: "node"\n';
                        prometheusContent += '    static_configs:\n';
                        prometheusContent += '      - targets: ["node-exporter:9100"]\n\n';
                        prometheusContent += '  - job_name: "cadvisor"\n';
                        prometheusContent += '    static_configs:\n';
                        prometheusContent += '      - targets: ["cadvisor:8080"]\n\n';
                        prometheusContent += '  - job_name: "app"\n';
                        prometheusContent += '    static_configs:\n';
                        prometheusContent += '      - targets: ["app:3000"]\n';

                        // Escribir prometheus.yml
                        fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusContent);

                        // Crear alert_rules.yml
                        let alertRulesContent = 'groups:\n';
                        alertRulesContent += '- name: example\n';
                        alertRulesContent += '  rules:\n';
                        alertRulesContent += '  - alert: HighCPULoad\n';
                        alertRulesContent += '    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n';
                        alertRulesContent += '    for: 5m\n';
                        alertRulesContent += '    labels:\n';
                        alertRulesContent += '      severity: warning\n';
                        alertRulesContent += '    annotations:\n';
                        alertRulesContent += '      summary: "High CPU load (instance {{ $labels.instance }})"\n';
                        alertRulesContent += '      description: "CPU load is > 80%\\n  VALUE = {{ $value }}%\\n  LABELS: {{ $labels }}"\n\n';
                        alertRulesContent += '  - alert: HighMemoryLoad\n';
                        alertRulesContent += '    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80\n';
                        alertRulesContent += '    for: 5m\n';
                        alertRulesContent += '    labels:\n';
                        alertRulesContent += '      severity: warning\n';
                        alertRulesContent += '    annotations:\n';
                        alertRulesContent += '      summary: "High memory load (instance {{ $labels.instance }})"\n';
                        alertRulesContent += '      description: "Memory load is > 80%\\n  VALUE = {{ $value }}%\\n  LABELS: {{ $labels }}"\n\n';
                        alertRulesContent += '  - alert: HighDiskUsage\n';
                        alertRulesContent += '    expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85\n';
                        alertRulesContent += '    for: 5m\n';
                        alertRulesContent += '    labels:\n';
                        alertRulesContent += '      severity: warning\n';
                        alertRulesContent += '    annotations:\n';
                        alertRulesContent += '      summary: "High disk usage (instance {{ $labels.instance }})"\n';
                        alertRulesContent += '      description: "Disk usage is > 85%\\n  VALUE = {{ $value }}%\\n  LABELS: {{ $labels }}"\n';

                        // Escribir alert_rules.yml
                        fs.writeFileSync(path.join(prometheusDir, 'alert_rules.yml'), alertRulesContent);

                        // Crear directorio para Alertmanager
                        const alertmanagerDir = path.join(monitoringDir, 'alertmanager');
                        if (!fs.existsSync(alertmanagerDir)) {
                            fs.mkdirSync(alertmanagerDir, { recursive: true });
                        }

                        // Crear alertmanager.yml
                        let alertmanagerContent = 'global:\n';
                        alertmanagerContent += '  resolve_timeout: 5m\n';
                        alertmanagerContent += '  smtp_smarthost: "smtp.example.com:587"\n';
                        alertmanagerContent += '  smtp_from: "alertmanager@example.com"\n';
                        alertmanagerContent += '  smtp_auth_username: "alertmanager"\n';
                        alertmanagerContent += '  smtp_auth_password: "password"\n\n';
                        alertmanagerContent += 'route:\n';
                        alertmanagerContent += '  group_by: [\'alertname\', \'instance\']\n';
                        alertmanagerContent += '  group_wait: 30s\n';
                        alertmanagerContent += '  group_interval: 5m\n';
                        alertmanagerContent += '  repeat_interval: 1h\n';
                        alertmanagerContent += '  receiver: \'email\'\n\n';
                        alertmanagerContent += 'receivers:\n';
                        alertmanagerContent += '- name: \'email\'\n';
                        alertmanagerContent += '  email_configs:\n';
                        alertmanagerContent += '  - to: "alerts@example.com"\n';
                        alertmanagerContent += '    send_resolved: true\n\n';
                        alertmanagerContent += 'inhibit_rules:\n';
                        alertmanagerContent += '  - source_match:\n';
                        alertmanagerContent += '      severity: \'critical\'\n';
                        alertmanagerContent += '    target_match:\n';
                        alertmanagerContent += '      severity: \'warning\'\n';
                        alertmanagerContent += '    equal: [\'alertname\', \'instance\']\n';

                        // Escribir alertmanager.yml
                        fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerContent);

                        // Crear directorio para Grafana
                        const grafanaDir = path.join(monitoringDir, 'grafana');
                        if (!fs.existsSync(grafanaDir)) {
                            fs.mkdirSync(grafanaDir, { recursive: true });
                        }

                        // Crear datasources.yml
                        let datasourcesContent = 'apiVersion: 1\n\n';
                        datasourcesContent += 'datasources:\n';
                        datasourcesContent += '  - name: Prometheus\n';
                        datasourcesContent += '    type: prometheus\n';
                        datasourcesContent += '    access: proxy\n';
                        datasourcesContent += '    url: http://prometheus:9090\n';
                        datasourcesContent += '    isDefault: true\n';
                        datasourcesContent += '    editable: true\n';

                        // Escribir datasources.yml
                        fs.writeFileSync(path.join(grafanaDir, 'datasources.yml'), datasourcesContent);

                        // Crear directorio para dashboards
                        const dashboardsDir = path.join(grafanaDir, 'dashboards');
                        if (!fs.existsSync(dashboardsDir)) {
                            fs.mkdirSync(dashboardsDir, { recursive: true });
                        }

                        // Crear dashboard.json (versión simplificada para este ejemplo)
                        let dashboardContent = '{\n';
                        dashboardContent += '  "annotations": {\n';
                        dashboardContent += '    "list": [\n';
                        dashboardContent += '      {\n';
                        dashboardContent += '        "builtIn": 1,\n';
                        dashboardContent += '        "datasource": "-- Grafana --",\n';
                        dashboardContent += '        "enable": true,\n';
                        dashboardContent += '        "hide": true,\n';
                        dashboardContent += '        "iconColor": "rgba(0, 211, 255, 1)",\n';
                        dashboardContent += '        "name": "Annotations & Alerts",\n';
                        dashboardContent += '        "type": "dashboard"\n';
                        dashboardContent += '      }\n';
                        dashboardContent += '    ]\n';
                        dashboardContent += '  },\n';
                        dashboardContent += '  "editable": true,\n';
                        dashboardContent += '  "gnetId": null,\n';
                        dashboardContent += '  "graphTooltip": 0,\n';
                        dashboardContent += '  "id": 1,\n';
                        dashboardContent += '  "links": [],\n';
                        dashboardContent += '  "panels": [\n';
                        dashboardContent += '    {\n';
                        dashboardContent += '      "alert": {\n';
                        dashboardContent += '        "conditions": [\n';
                        dashboardContent += '          {\n';
                        dashboardContent += '            "evaluator": {\n';
                        dashboardContent += '              "params": [80],\n';
                        dashboardContent += '              "type": "gt"\n';
                        dashboardContent += '            },\n';
                        dashboardContent += '            "operator": {"type": "and"},\n';
                        dashboardContent += '            "query": {"params": ["A", "5m", "now"]},\n';
                        dashboardContent += '            "reducer": {"params": [], "type": "avg"},\n';
                        dashboardContent += '            "type": "query"\n';
                        dashboardContent += '          }\n';
                        dashboardContent += '        ],\n';
                        dashboardContent += '        "executionErrorState": "alerting",\n';
                        dashboardContent += '        "frequency": "60s",\n';
                        dashboardContent += '        "handler": 1,\n';
                        dashboardContent += '        "name": "CPU Usage alert",\n';
                        dashboardContent += '        "noDataState": "no_data",\n';
                        dashboardContent += '        "notifications": []\n';
                        dashboardContent += '      },\n';
                        dashboardContent += '      "aliasColors": {},\n';
                        dashboardContent += '      "bars": false,\n';
                        dashboardContent += '      "dashLength": 10,\n';
                        dashboardContent += '      "dashes": false,\n';
                        dashboardContent += '      "datasource": "Prometheus",\n';
                        dashboardContent += '      "fieldConfig": {"defaults": {"custom": {}}, "overrides": []},\n';
                        dashboardContent += '      "fill": 1,\n';
                        dashboardContent += '      "fillGradient": 0,\n';
                        dashboardContent += '      "gridPos": {"h": 9, "w": 12, "x": 0, "y": 0},\n';
                        dashboardContent += '      "hiddenSeries": false,\n';
                        dashboardContent += '      "id": 2,\n';
                        dashboardContent += '      "legend": {\n';
                        dashboardContent += '        "avg": false,\n';
                        dashboardContent += '        "current": false,\n';
                        dashboardContent += '        "max": false,\n';
                        dashboardContent += '        "min": false,\n';
                        dashboardContent += '        "show": true,\n';
                        dashboardContent += '        "total": false,\n';
                        dashboardContent += '        "values": false\n';
                        dashboardContent += '      },\n';
                        dashboardContent += '      "lines": true,\n';
                        dashboardContent += '      "linewidth": 1,\n';
                        dashboardContent += '      "nullPointMode": "null",\n';
                        dashboardContent += '      "options": {"alertThreshold": true},\n';
                        dashboardContent += '      "percentage": false,\n';
                        dashboardContent += '      "pluginVersion": "7.3.7",\n';
                        dashboardContent += '      "pointradius": 2,\n';
                        dashboardContent += '      "points": false,\n';
                        dashboardContent += '      "renderer": "flot",\n';
                        dashboardContent += '      "seriesOverrides": [],\n';
                        dashboardContent += '      "spaceLength": 10,\n';
                        dashboardContent += '      "stack": false,\n';
                        dashboardContent += '      "steppedLine": false,\n';
                        dashboardContent += '      "targets": [\n';
                        dashboardContent += '        {\n';
                        dashboardContent += '          "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\\"idle\\"}[5m])) * 100)",\n';
                        dashboardContent += '          "interval": "",\n';
                        dashboardContent += '          "legendFormat": "",\n';
                        dashboardContent += '          "refId": "A"\n';
                        dashboardContent += '        }\n';
                        dashboardContent += '      ],\n';
                        dashboardContent += '      "thresholds": [\n';
                        dashboardContent += '        {\n';
                        dashboardContent += '          "colorMode": "critical",\n';
                        dashboardContent += '          "fill": true,\n';
                        dashboardContent += '          "line": true,\n';
                        dashboardContent += '          "op": "gt",\n';
                        dashboardContent += '          "value": 80\n';
                        dashboardContent += '        }\n';
                        dashboardContent += '      ],\n';
                        dashboardContent += '      "timeFrom": null,\n';
                        dashboardContent += '      "timeRegions": [],\n';
                        dashboardContent += '      "timeShift": null,\n';
                        dashboardContent += '      "title": "CPU Usage",\n';
                        dashboardContent += '      "tooltip": {"shared": true, "sort": 0, "value_type": "individual"},\n';
                        dashboardContent += '      "type": "graph",\n';
                        dashboardContent += '      "xaxis": {"buckets": null, "mode": "time", "name": null, "show": true, "values": []},\n';
                        dashboardContent += '      "yaxes": [\n';
                        dashboardContent += '        {"format": "percent", "label": null, "logBase": 1, "max": null, "min": null, "show": true},\n';
                        dashboardContent += '        {"format": "short", "label": null, "logBase": 1, "max": null, "min": null, "show": true}\n';
                        dashboardContent += '      ],\n';
                        dashboardContent += '      "yaxis": {"align": false, "alignLevel": null}\n';
                        dashboardContent += '    }\n';
                        dashboardContent += '  ],\n';
                        dashboardContent += '  "schemaVersion": 26,\n';
                        dashboardContent += '  "style": "dark",\n';
                        dashboardContent += '  "tags": [],\n';
                        dashboardContent += '  "templating": {"list": []},\n';
                        dashboardContent += '  "time": {"from": "now-6h", "to": "now"},\n';
                        dashboardContent += '  "timepicker": {},\n';
                        dashboardContent += '  "timezone": "",\n';
                        dashboardContent += '  "title": "Sistema de Monitoreo",\n';
                        dashboardContent += '  "uid": "sistema-monitoreo",\n';
                        dashboardContent += '  "version": 1\n';
                        dashboardContent += '}\n';

                        // Escribir dashboard.json
                        fs.writeFileSync(path.join(dashboardsDir, 'dashboard.json'), dashboardContent);

                        // Crear dashboard.yml
                        let dashboardYamlContent = 'apiVersion: 1\n\n';
                        dashboardYamlContent += 'providers:\n';
                        dashboardYamlContent += '  - name: \'default\'\n';
                        dashboardYamlContent += '    orgId: 1\n';
                        dashboardYamlContent += '    folder: \'\'\n';
                        dashboardYamlContent += '    type: file\n';
                        dashboardYamlContent += '    disableDeletion: false\n';
                        dashboardYamlContent += '    editable: true\n';
                        dashboardYamlContent += '    options:\n';
                        dashboardYamlContent += '      path: /etc/grafana/dashboards\n';

                        // Escribir dashboard.yml
                        fs.writeFileSync(path.join(grafanaDir, 'dashboard.yml'), dashboardYamlContent);

                        // Crear docker-compose.yml para monitoreo
                        let dockerComposeContent = 'version: "3.8"\n\n';
                        dockerComposeContent += 'services:\n';
                        dockerComposeContent += '  prometheus:\n';
                        dockerComposeContent += '    image: prom/prometheus:latest\n';
                        dockerComposeContent += '    volumes:\n';
                        dockerComposeContent += '      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n';
                        dockerComposeContent += '      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml\n';
                        dockerComposeContent += '      - prometheus_data:/prometheus\n';
                        dockerComposeContent += '    command:\n';
                        dockerComposeContent += '      - \'--config.file=/etc/prometheus/prometheus.yml\'\n';
                        dockerComposeContent += '      - \'--storage.tsdb.path=/prometheus\'\n';
                        dockerComposeContent += '      - \'--web.console.libraries=/usr/share/prometheus/console_libraries\'\n';
                        dockerComposeContent += '      - \'--web.console.templates=/usr/share/prometheus/consoles\'\n';
                        dockerComposeContent += '    ports:\n';
                        dockerComposeContent += '      - "9090:9090"\n';
                        dockerComposeContent += '    networks:\n';
                        dockerComposeContent += '      - monitoring-network\n';
                        dockerComposeContent += '    restart: unless-stopped\n\n';
                        
                        dockerComposeContent += '  alertmanager:\n';
                        dockerComposeContent += '    image: prom/alertmanager:latest\n';
                        dockerComposeContent += '    volumes:\n';
                        dockerComposeContent += '      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n';
                        dockerComposeContent += '      - alertmanager_data:/alertmanager\n';
                        dockerComposeContent += '    command:\n';
                        dockerComposeContent += '      - \'--config.file=/etc/alertmanager/alertmanager.yml\'\n';
                        dockerComposeContent += '      - \'--storage.path=/alertmanager\'\n';
                        dockerComposeContent += '    ports:\n';
                        dockerComposeContent += '      - "9093:9093"\n';
                        dockerComposeContent += '    networks:\n';
                        dockerComposeContent += '      - monitoring-network\n';
                        dockerComposeContent += '    restart: unless-stopped\n\n';
                        
                        dockerComposeContent += '  grafana:\n';
                        dockerComposeContent += '    image: grafana/grafana:latest\n';
                        dockerComposeContent += '    volumes:\n';
                        dockerComposeContent += '      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml\n';
                        dockerComposeContent += '      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml\n';
                        dockerComposeContent += '      - ./grafana/dashboards:/etc/grafana/dashboards\n';
                        dockerComposeContent += '      - grafana_data:/var/lib/grafana\n';
                        dockerComposeContent += '    environment:\n';
                        dockerComposeContent += '      - GF_SECURITY_ADMIN_USER=admin\n';
                        dockerComposeContent += '      - GF_SECURITY_ADMIN_PASSWORD=admin\n';
                        dockerComposeContent += '      - GF_USERS_ALLOW_SIGN_UP=false\n';
                        dockerComposeContent += '    ports:\n';
                        dockerComposeContent += '      - "3000:3000"\n';
                        dockerComposeContent += '    networks:\n';
                        dockerComposeContent += '      - monitoring-network\n';
                        dockerComposeContent += '    restart: unless-stopped\n\n';
                        
                        dockerComposeContent += '  node-exporter:\n';
                        dockerComposeContent += '    image: prom/node-exporter:latest\n';
                        dockerComposeContent += '    volumes:\n';
                        dockerComposeContent += '      - /proc:/host/proc:ro\n';
                        dockerComposeContent += '      - /sys:/host/sys:ro\n';
                        dockerComposeContent += '      - /:/rootfs:ro\n';
                        dockerComposeContent += '    command:\n';
                        dockerComposeContent += '      - \'--path.procfs=/host/proc\'\n';
                        dockerComposeContent += '      - \'--path.sysfs=/host/sys\'\n';
                        dockerComposeContent += '      - \'--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)\'\n';
                        dockerComposeContent += '    ports:\n';
                        dockerComposeContent += '      - "9100:9100"\n';
                        dockerComposeContent += '    networks:\n';
                        dockerComposeContent += '      - monitoring-network\n';
                        dockerComposeContent += '    restart: unless-stopped\n\n';
                        
                        dockerComposeContent += '  cadvisor:\n';
                        dockerComposeContent += '    image: gcr.io/cadvisor/cadvisor:latest\n';
                        dockerComposeContent += '    volumes:\n';
                        dockerComposeContent += '      - /:/rootfs:ro\n';
                        dockerComposeContent += '      - /var/run:/var/run:ro\n';
                        dockerComposeContent += '      - /sys:/sys:ro\n';
                        dockerComposeContent += '      - /var/lib/docker/:/var/lib/docker:ro\n';
                        dockerComposeContent += '    ports:\n';
                        dockerComposeContent += '      - "8080:8080"\n';
                        dockerComposeContent += '    networks:\n';
                        dockerComposeContent += '      - monitoring-network\n';
                        dockerComposeContent += '    restart: unless-stopped\n\n';
                        
                        dockerComposeContent += 'networks:\n';
                        dockerComposeContent += '  monitoring-network:\n';
                        dockerComposeContent += '    driver: bridge\n\n';
                        
                        dockerComposeContent += 'volumes:\n';
                        dockerComposeContent += '  prometheus_data:\n';
                        dockerComposeContent += '    driver: local\n';
                        dockerComposeContent += '  alertmanager_data:\n';
                        dockerComposeContent += '    driver: local\n';
                        dockerComposeContent += '  grafana_data:\n';
                        dockerComposeContent += '    driver: local\n';

                        // Escribir docker-compose.yml
                        fs.writeFileSync(path.join(monitoringDir, 'docker-compose.yml'), dockerComposeContent);

                        // Crear README.md para el directorio de monitoreo
                        let readmeContent = '# Sistema de Monitoreo\n\n';
                        readmeContent += 'Este directorio contiene la configuración para un stack de monitoreo completo basado en Prometheus, Alertmanager, Grafana, Node Exporter y cAdvisor.\n\n';
                        readmeContent += '## Componentes\n\n';
                        readmeContent += '- **Prometheus**: Sistema de monitoreo y base de datos de series temporales\n';
                        readmeContent += '- **Alertmanager**: Gestión de alertas para Prometheus\n';
                        readmeContent += '- **Grafana**: Visualización de métricas y dashboards\n';
                        readmeContent += '- **Node Exporter**: Exportador de métricas del sistema\n';
                        readmeContent += '- **cAdvisor**: Monitoreo de contenedores\n\n';
                        readmeContent += '## Inicio Rápido\n\n';
                        readmeContent += '```bash\n';
                        readmeContent += '# Iniciar el stack de monitoreo\n';
                        readmeContent += 'docker-compose up -d\n';
                        readmeContent += '```\n\n';
                        readmeContent += '## Acceso\n\n';
                        readmeContent += '- **Prometheus**: http://localhost:9090\n';
                        readmeContent += '- **Alertmanager**: http://localhost:9093\n';
                        readmeContent += '- **Grafana**: http://localhost:3000 (usuario: admin, contraseña: admin)\n';
                        readmeContent += '- **Node Exporter**: http://localhost:9100\n';
                        readmeContent += '- **cAdvisor**: http://localhost:8080\n\n';
                        readmeContent += '## Personalización\n\n';
                        readmeContent += '### Prometheus\n\n';
                        readmeContent += 'Edita `prometheus/prometheus.yml` para añadir nuevos targets o cambiar la configuración.\n\n';
                        readmeContent += '### Alertmanager\n\n';
                        readmeContent += 'Edita `alertmanager/alertmanager.yml` para configurar notificaciones por email, Slack, etc.\n\n';
                        readmeContent += '### Grafana\n\n';
                        readmeContent += 'Añade nuevos dashboards en `grafana/dashboards/` y asegúrate de actualizar `grafana/dashboard.yml` si es necesario.\n';

                        // Escribir README.md
                        fs.writeFileSync(path.join(monitoringDir, 'README.md'), readmeContent);

                        // Crear directorio para ELK stack
                        const elkDir = path.join(monitoringDir, 'elk');
                        if (!fs.existsSync(elkDir)) {
                            fs.mkdirSync(elkDir, { recursive: true });
                        }

                        // Crear docker-compose.yml para ELK stack
                        let elkComposeContent = 'version: "3.8"\n\n';
                        elkComposeContent += 'services:\n';
                        elkComposeContent += '  elasticsearch:\n';
                        elkComposeContent += '    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\n';
                        elkComposeContent += '    environment:\n';
                        elkComposeContent += '      - discovery.type=single-node\n';
                        elkComposeContent += '      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"\n';
                        elkComposeContent += '    volumes:\n';
                        elkComposeContent += '      - elasticsearch_data:/usr/share/elasticsearch/data\n';
                        elkComposeContent += '    ports:\n';
                        elkComposeContent += '      - "9200:9200"\n';
                        elkComposeContent += '      - "9300:9300"\n';
                        elkComposeContent += '    networks:\n';
                        elkComposeContent += '      - elk-network\n';
                        elkComposeContent += '    restart: unless-stopped\n\n';
                        
                        elkComposeContent += '  logstash:\n';
                        elkComposeContent += '    image: docker.elastic.co/logstash/logstash:7.10.0\n';
                        elkComposeContent += '    volumes:\n';
                        elkComposeContent += '      - ./logstash/pipeline:/usr/share/logstash/pipeline\n';
                        elkComposeContent += '    ports:\n';
                        elkComposeContent += '      - "5000:5000"\n';
                        elkComposeContent += '      - "9600:9600"\n';
                        elkComposeContent += '    environment:\n';
                        elkComposeContent += '      - "LS_JAVA_OPTS=-Xms256m -Xmx256m"\n';
                        elkComposeContent += '    networks:\n';
                        elkComposeContent += '      - elk-network\n';
                        elkComposeContent += '    depends_on:\n';
                        elkComposeContent += '      - elasticsearch\n';
                        elkComposeContent += '    restart: unless-stopped\n\n';
                        
                        elkComposeContent += '  kibana:\n';
                        elkComposeContent += '    image: docker.elastic.co/kibana/kibana:7.10.0\n';
                        elkComposeContent += '    ports:\n';
                        elkComposeContent += '      - "5601:5601"\n';
                        elkComposeContent += '    environment:\n';
                        elkComposeContent += '      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n';
                        elkComposeContent += '    networks:\n';
                        elkComposeContent += '      - elk-network\n';
                        elkComposeContent += '    depends_on:\n';
                        elkComposeContent += '      - elasticsearch\n';
                        elkComposeContent += '    restart: unless-stopped\n\n';
                        
                        elkComposeContent += '  filebeat:\n';
                        elkComposeContent += '    image: docker.elastic.co/beats/filebeat:7.10.0\n';
                        elkComposeContent += '    user: root\n';
                        elkComposeContent += '    volumes:\n';
                        elkComposeContent += '      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n';
                        elkComposeContent += '      - /var/lib/docker/containers:/var/lib/docker/containers:ro\n';
                        elkComposeContent += '      - /var/run/docker.sock:/var/run/docker.sock:ro\n';
                        elkComposeContent += '    networks:\n';
                        elkComposeContent += '      - elk-network\n';
                        elkComposeContent += '    depends_on:\n';
                        elkComposeContent += '      - elasticsearch\n';
                        elkComposeContent += '      - logstash\n';
                        elkComposeContent += '    restart: unless-stopped\n\n';
                        
                        elkComposeContent += 'networks:\n';
                        elkComposeContent += '  elk-network:\n';
                        elkComposeContent += '    driver: bridge\n\n';
                        
                        elkComposeContent += 'volumes:\n';
                        elkComposeContent += '  elasticsearch_data:\n';
                        elkComposeContent += '    driver: local\n';

                        // Escribir docker-compose.yml para ELK stack
                        fs.writeFileSync(path.join(elkDir, 'docker-compose.yml'), elkComposeContent);

                        // Crear directorio para Logstash pipeline
                        const logstashDir = path.join(elkDir, 'logstash');
                        if (!fs.existsSync(logstashDir)) {
                            fs.mkdirSync(logstashDir, { recursive: true });
                        }

                        const pipelineDir = path.join(logstashDir, 'pipeline');
                        if (!fs.existsSync(pipelineDir)) {
                            fs.mkdirSync(pipelineDir, { recursive: true });
                        }

                        // Crear logstash.conf
                        let logstashConfContent = 'input {\n';
                        logstashConfContent += '  beats {\n';
                        logstashConfContent += '    port => 5000\n';
                        logstashConfContent += '  }\n';
                        logstashConfContent += '}\n\n';
                        logstashConfContent += 'filter {\n';
                        logstashConfContent += '  if [container][name] =~ /^backend/ {\n';
                        logstashConfContent += '    mutate {\n';
                        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "backend-%{+YYYY.MM.dd}" }\n';
                        logstashConfContent += '    }\n';
                        logstashConfContent += '  } else if [container][name] =~ /^frontend/ {\n';
                        logstashConfContent += '    mutate {\n';
                        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "frontend-%{+YYYY.MM.dd}" }\n';
                        logstashConfContent += '    }\n';
                        logstashConfContent += '  } else {\n';
                        logstashConfContent += '    mutate {\n';
                        logstashConfContent += '      add_field => { "[@metadata][target_index]" => "logs-%{+YYYY.MM.dd}" }\n';
                        logstashConfContent += '    }\n';
                        logstashConfContent += '  }\n';
                        logstashConfContent += '}\n\n';
                        logstashConfContent += 'output {\n';
                        logstashConfContent += '  elasticsearch {\n';
                        logstashConfContent += '    hosts => ["elasticsearch:9200"]\n';
                        logstashConfContent += '    index => "%{[@metadata][target_index]}"\n';
                        logstashConfContent += '  }\n';
                        logstashConfContent += '}\n';

                        // Escribir logstash.conf
                        fs.writeFileSync(path.join(pipelineDir, 'logstash.conf'), logstashConfContent);

                        // Crear directorio para Filebeat
                        const filebeatDir = path.join(elkDir, 'filebeat');
                        if (!fs.existsSync(filebeatDir)) {
                            fs.mkdirSync(filebeatDir, { recursive: true });
                        }

                        // Crear filebeat.yml
                        let filebeatContent = 'filebeat.inputs:\n';
                        filebeatContent += '- type: container\n';
                        filebeatContent += '  paths:\n';
                        filebeatContent += '    - /var/lib/docker/containers/*/*.log\n';
                        filebeatContent += '  processors:\n';
                        filebeatContent += '    - add_docker_metadata:\n';
                        filebeatContent += '        host: "unix:///var/run/docker.sock"\n\n';
                        filebeatContent += 'processors:\n';
                        filebeatContent += '  - add_host_metadata: ~\n';
                        filebeatContent += '  - add_cloud_metadata: ~\n\n';
                        filebeatContent += 'output.logstash:\n';
                        filebeatContent += '  hosts: ["logstash:5000"]\n';

                        // Escribir filebeat.yml
                        fs.writeFileSync(path.join(filebeatDir, 'filebeat.yml'), filebeatContent);

                        // Crear README.md para ELK stack
                        let elkReadmeContent = '# ELK Stack para Logging\n\n';
                        elkReadmeContent += 'Este directorio contiene la configuración para un stack ELK (Elasticsearch, Logstash, Kibana) con Filebeat para la recolección y análisis de logs.\n\n';
                        elkReadmeContent += '## Componentes\n\n';
                        elkReadmeContent += '- **Elasticsearch**: Motor de búsqueda y análisis\n';
                        elkReadmeContent += '- **Logstash**: Procesamiento de datos y logs\n';
                        elkReadmeContent += '- **Kibana**: Visualización de datos\n';
                        elkReadmeContent += '- **Filebeat**: Recolector de logs\n\n';
                        elkReadmeContent += '## Inicio Rápido\n\n';
                        elkReadmeContent += '```bash\n';
                        elkReadmeContent += '# Iniciar el stack ELK\n';
                        elkReadmeContent += 'docker-compose up -d\n';
                        elkReadmeContent += '```\n\n';
                        elkReadmeContent += '## Acceso\n\n';
                        elkReadmeContent += '- **Elasticsearch**: http://localhost:9200\n';
                        elkReadmeContent += '- **Kibana**: http://localhost:5601\n\n';
                        elkReadmeContent += '## Personalización\n\n';
                        elkReadmeContent += '### Logstash\n\n';
                        elkReadmeContent += 'Edita `logstash/pipeline/logstash.conf` para modificar el procesamiento de logs.\n\n';
                        elkReadmeContent += '### Filebeat\n\n';
                        elkReadmeContent += 'Edita `filebeat/filebeat.yml` para configurar la recolección de logs.\n';

                        // Escribir README.md para ELK stack
                        fs.writeFileSync(path.join(elkDir, 'README.md'), elkReadmeContent);
                    }

                    /**
                     * Crea archivos de CI/CD
                     * @param {string} cicdDir - Directorio para archivos de CI/CD
                     */
                    createCICDFiles(cicdDir) {
                        if (!fs.existsSync(cicdDir)) {
                            fs.mkdirSync(cicdDir, { recursive: true });
                        }

                        // Crear directorios para diferentes sistemas de CI/CD
                        const githubDir = path.join(cicdDir, 'github');
                        const jenkinsDir = path.join(cicdDir, 'jenkins');
                        const gitlabDir = path.join(cicdDir, 'gitlab');

                        if (!fs.existsSync(githubDir)) {
                            fs.mkdirSync(githubDir, { recursive: true });
                            fs.mkdirSync(path.join(githubDir, 'workflows'), { recursive: true });
                        }

                        if (!fs.existsSync(jenkinsDir)) {
                            fs.mkdirSync(jenkinsDir, { recursive: true });
                        }

                        if (!fs.existsSync(gitlabDir)) {
                            fs.mkdirSync(gitlabDir, { recursive: true });
                        }

                        // GitHub Actions workflow para CI
                        let githubCIContent = 'name: CI\n\n';
                        githubCIContent += 'on:\n';
                        githubCIContent += '  push:\n';
                        githubCIContent += '    branches: [ main, develop ]\n';
                        githubCIContent += '  pull_request:\n';
                        githubCIContent += '    branches: [ main, develop ]\n\n';
                        githubCIContent += 'jobs:\n';
                        githubCIContent += '  build-and-test:\n';
                        githubCIContent += '    runs-on: ubuntu-latest\n\n';
                        githubCIContent += '    steps:\n';
                        githubCIContent += '    - uses: actions/checkout@v2\n\n';
                        githubCIContent += '    - name: Set up Node.js\n';
                        githubCIContent += '      uses: actions/setup-node@v2\n';
                        githubCIContent += '      with:\n';
                        githubCIContent += '        node-version: 14\n\n';
                        githubCIContent += '    - name: Install dependencies\n';
                        githubCIContent += '      run: npm ci\n\n';
                        githubCIContent += '    - name: Run linter\n';
                        githubCIContent += '      run: npm run lint\n\n';
                        githubCIContent += '    - name: Run tests\n';
                        githubCIContent += '      run: npm test\n\n';
                        githubCIContent += '    - name: Build\n';
                        githubCIContent += '      run: npm run build\n';

                        // Escribir GitHub CI workflow
                        fs.writeFileSync(path.join(githubDir, 'workflows', 'ci.yml'), githubCIContent);

                        // GitHub Actions workflow para CD
                        let githubCDContent = 'name: CD\n\n';
                        githubCDContent += 'on:\n';
                        githubCDContent += '  push:\n';
                        githubCDContent += '    branches: [ main ]\n';
                        githubCDContent += '    tags:\n';
                        githubCDContent += '      - \'v*\'\n\n';
                        githubCDContent += 'jobs:\n';
                        githubCDContent += '  build-and-deploy:\n';
                        githubCDContent += '    runs-on: ubuntu-latest\n\n';
                        githubCDContent += '    steps:\n';
                        githubCDContent += '    - uses: actions/checkout@v2\n\n';
                        githubCDContent += '    - name: Set up Node.js\n';
                        githubCDContent += '      uses: actions/setup-node@v2\n';
                        githubCDContent += '      with:\n';
                        githubCDContent += '        node-version: 14\n\n';
                        githubCDContent += '    - name: Install dependencies\n';
                        githubCDContent += '      run: npm ci\n\n';
                        githubCDContent += '    - name: Build\n';
                        githubCDContent += '      run: npm run build\n\n';
                        githubCDContent += '    - name: Set up Docker Buildx\n';
                        githubCDContent += '      uses: docker/setup-buildx-action@v1\n\n';
                        githubCDContent += '    - name: Login to DockerHub\n';
                        githubCDContent += '      uses: docker/login-action@v1\n';
                        githubCDContent += '      with:\n';
                        githubCDContent += '        username: ${{ secrets.DOCKERHUB_USERNAME }}\n';
                        githubCDContent += '        password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n';
                        githubCDContent += '    - name: Extract metadata\n';
                        githubCDContent += '      id: meta\n';
                        githubCDContent += '      uses: docker/metadata-action@v3\n';
                        githubCDContent += '      with:\n';
                        githubCDContent += '        images: myorg/myapp\n';
                        githubCDContent += '        tags: |\n';
                        githubCDContent += '          type=semver,pattern={{version}}\n';
                        githubCDContent += '          type=ref,event=branch\n\n';
                        githubCDContent += '    - name: Build and push Docker image\n';
                        githubCDContent += '      uses: docker/build-push-action@v2\n';
                        githubCDContent += '      with:\n';
                        githubCDContent += '        context: .\n';
                        githubCDContent += '        push: true\n';
                        githubCDContent += '        tags: ${{ steps.meta.outputs.tags }}\n';
                        githubCDContent += '        labels: ${{ steps.meta.outputs.labels }}\n\n';
                        githubCDContent += '    - name: Deploy to production\n';
                        githubCDContent += '      if: startsWith(github.ref, \'refs/tags/v\')\n';
                        githubCDContent += '      uses: appleboy/ssh-action@master\n';
                        githubCDContent += '      with:\n';
                        githubCDContent += '        host: ${{ secrets.PROD_HOST }}\n';
                        githubCDContent += '        username: ${{ secrets.PROD_USERNAME }}\n';
                        githubCDContent += '        key: ${{ secrets.PROD_SSH_KEY }}\n';
                        githubCDContent += '        script: |\n';
                        githubCDContent += '          cd /opt/app\n';
                        githubCDContent += '          docker-compose pull\n';
                        githubCDContent += '          docker-compose up -d\n';
                        githubCDContent += '          docker image prune -af\n';

                        // Escribir GitHub CD workflow
                        fs.writeFileSync(path.join(githubDir, 'workflows', 'cd.yml'), githubCDContent);

                        // Jenkinsfile
                        let jenkinsfileContent = 'pipeline {\n';
                        jenkinsfileContent += '    agent {\n';
                        jenkinsfileContent += '        docker {\n';
                        jenkinsfileContent += '            image \'node:14-alpine\'\n';
                        jenkinsfileContent += '        }\n';
                        jenkinsfileContent += '    }\n\n';
                        jenkinsfileContent += '    stages {\n';
                        jenkinsfileContent += '        stage(\'Install\') {\n';
                        jenkinsfileContent += '            steps {\n';
                        jenkinsfileContent += '                sh \'npm ci\'\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '        }\n\n';
                        jenkinsfileContent += '        stage(\'Lint\') {\n';
                        jenkinsfileContent += '            steps {\n';
                        jenkinsfileContent += '                sh \'npm run lint\'\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '        }\n\n';
                        jenkinsfileContent += '        stage(\'Test\') {\n';
                        jenkinsfileContent += '            steps {\n';
                        jenkinsfileContent += '                sh \'npm test\'\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '        }\n\n';
                        jenkinsfileContent += '        stage(\'Build\') {\n';
                        jenkinsfileContent += '            steps {\n';
                        jenkinsfileContent += '                sh \'npm run build\'\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '        }\n\n';
                        jenkinsfileContent += '        stage(\'Docker Build\') {\n';
                        jenkinsfileContent += '            when {\n';
                        jenkinsfileContent += '                branch \'main\'\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '            steps {\n';
                        jenkinsfileContent += '                sh \'docker build -t myorg/myapp:${BUILD_NUMBER} .\'\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '        }\n\n';
                        jenkinsfileContent += '        stage(\'Docker Push\') {\n';
                        jenkinsfileContent += '            when {\n';
                        jenkinsfileContent += '                branch \'main\'\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '            steps {\n';
                        jenkinsfileContent += '                withCredentials([usernamePassword(credentialsId: \'docker-hub\', passwordVariable: \'DOCKER_PASSWORD\', usernameVariable: \'DOCKER_USERNAME\')]) {\n';
                        jenkinsfileContent += '                    sh \'echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin\'\n';
                        jenkinsfileContent += '                    sh \'docker push myorg/myapp:${BUILD_NUMBER}\'\n';
                        jenkinsfileContent += '                    sh \'docker tag myorg/myapp:${BUILD_NUMBER} myorg/myapp:latest\'\n';
                        jenkinsfileContent += '                    sh \'docker push myorg/myapp:latest\'\n';
                        jenkinsfileContent += '                }\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '        }\n\n';
                        jenkinsfileContent += '        stage(\'Deploy\') {\n';
                        jenkinsfileContent += '            when {\n';
                        jenkinsfileContent += '                branch \'main\'\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '            steps {\n';
                        jenkinsfileContent += '                sshagent([\'production-server\']) {\n';
                        jenkinsfileContent += '                    sh \'ssh user@production-server "cd /opt/app && docker-compose pull && docker-compose up -d && docker image prune -af"\'\n';
                        jenkinsfileContent += '                }\n';
                        jenkinsfileContent += '            }\n';
                        jenkinsfileContent += '        }\n';
                        jenkinsfileContent += '    }\n\n';
                        jenkinsfileContent += '    post {\n';
                        jenkinsfileContent += '        always {\n';
                        jenkinsfileContent += '            cleanWs()\n';
                        jenkinsfileContent += '        }\n';
                        jenkinsfileContent += '        success {\n';
                        jenkinsfileContent += '            echo \'Build successful!\'\n';
                        jenkinsfileContent += '        }\n';
                        jenkinsfileContent += '        failure {\n';
                        jenkinsfileContent += '            echo \'Build failed!\'\n';
                        jenkinsfileContent += '        }\n';
                        jenkinsfileContent += '    }\n';
                        jenkinsfileContent += '}\n';

                        // Escribir Jenkinsfile
                        fs.writeFileSync(path.join(jenkinsDir, 'Jenkinsfile'), jenkinsfileContent);

                        // GitLab CI/CD
                        let gitlabCIContent = 'stages:\n';
                        gitlabCIContent += '  - install\n';
                        gitlabCIContent += '  - test\n';
                        gitlabCIContent += '  - build\n';
                        gitlabCIContent += '  - deploy\n\n';
                        gitlabCIContent += 'variables:\n';
                        gitlabCIContent += '  DOCKER_DRIVER: overlay2\n\n';
                        gitlabCIContent += 'cache:\n';
                        gitlabCIContent += '  paths:\n';
                        gitlabCIContent += '    - node_modules/\n\n';
                        gitlabCIContent += 'install:\n';
                        gitlabCIContent += '  stage: install\n';
                        gitlabCIContent += '  image: node:14-alpine\n';
                        gitlabCIContent += '  script:\n';
                        gitlabCIContent += '    - npm ci\n\n';
                        gitlabCIContent += 'lint:\n';
                        gitlabCIContent += '  stage: test\n';
                        gitlabCIContent += '  image: node:14-alpine\n';
                        gitlabCIContent += '  script:\n';
                        gitlabCIContent += '    - npm run lint\n\n';
                        gitlabCIContent += 'test:\n';
                        gitlabCIContent += '  stage: test\n';
                        gitlabCIContent += '  image: node:14-alpine\n';
                        gitlabCIContent += '  script:\n';
                        gitlabCIContent += '    - npm test\n\n';
                        gitlabCIContent += 'build:\n';
                        gitlabCIContent += '  stage: build\n';
                        gitlabCIContent += '  image: node:14-alpine\n';
                        gitlabCIContent += '  script:\n';
                        gitlabCIContent += '    - npm run build\n';
                        gitlabCIContent += '  artifacts:\n';
                        gitlabCIContent += '    paths:\n';
                        gitlabCIContent += '      - dist/\n\n';
                        gitlabCIContent += 'docker-build:\n';
                        gitlabCIContent += '  stage: build\n';
                        gitlabCIContent += '  image: docker:19.03.12\n';
                        gitlabCIContent += '  services:\n';
                        gitlabCIContent += '    - docker:19.03.12-dind\n';
                        gitlabCIContent += '  script:\n';
                        gitlabCIContent += '    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n';
                        gitlabCIContent += '    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA .\n';
                        gitlabCIContent += '    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA\n';
                        gitlabCIContent += '  only:\n';
                        gitlabCIContent += '    - main\n';
                        gitlabCIContent += '    - tags\n\n';
                        gitlabCIContent += 'deploy-staging:\n';
                        gitlabCIContent += '  stage: deploy\n';
                        gitlabCIContent += '  image: alpine:latest\n';
                        gitlabCIContent += '  before_script:\n';
                        gitlabCIContent += '    - apk add --no-cache openssh-client\n';
                        gitlabCIContent += '    - eval $(ssh-agent -s)\n';
                        gitlabCIContent += '    - echo "$STAGING_SSH_PRIVATE_KEY" | tr -d \'\\r\' | ssh-add -\n';
                        gitlabCIContent += '    - mkdir -p ~/.ssh\n';
                        gitlabCIContent += '    - chmod 700 ~/.ssh\n';
                        gitlabCIContent += '    - echo "$STAGING_SSH_KNOWN_HOSTS" > ~/.ssh/known_hosts\n';
                        gitlabCIContent += '    - chmod 644 ~/.ssh/known_hosts\n';
                        gitlabCIContent += '  script:\n';
                        gitlabCIContent += '    - ssh $STAGING_SSH_USER@$STAGING_SSH_HOST "cd /opt/app && docker-compose pull && docker-compose up -d && docker image prune -af"\n';
                        gitlabCIContent += '  only:\n';
                        gitlabCIContent += '    - main\n\n';
                        gitlabCIContent += 'deploy-production:\n';
                        gitlabCIContent += '  stage: deploy\n';
                        gitlabCIContent += '  image: alpine:latest\n';
                        gitlabCIContent += '  before_script:\n';
                        gitlabCIContent += '    - apk add --no-cache openssh-client\n';
                        gitlabCIContent += '    - eval $(ssh-agent -s)\n';
                        gitlabCIContent += '    - echo "$PRODUCTION_SSH_PRIVATE_KEY" | tr -d \'\\r\' | ssh-add -\n';
                        gitlabCIContent += '    - mkdir -p ~/.ssh\n';
                        gitlabCIContent += '    - chmod 700 ~/.ssh\n';
                        gitlabCIContent += '    - echo "$PRODUCTION_SSH_KNOWN_HOSTS" > ~/.ssh/known_hosts\n';
                        gitlabCIContent += '    - chmod 644 ~/.ssh/known_hosts\n';
                        gitlabCIContent += '  script:\n';
                        gitlabCIContent += '    - ssh $PRODUCTION_SSH_USER@$PRODUCTION_SSH_HOST "cd /opt/app && docker-compose pull && docker-compose up -d && docker image prune -af"\n';
                        gitlabCIContent += '  only:\n';
                        gitlabCIContent += '    - tags\n';
                        gitlabCIContent += '  when: manual\n';

                        // Escribir GitLab CI/CD
                        fs.writeFileSync(path.join(gitlabDir, '.gitlab-ci.yml'), gitlabCIContent);

                        // Crear README.md para CI/CD
                        let cicdReadmeContent = '# Configuración de CI/CD\n\n';
                        cicdReadmeContent += 'Este directorio contiene configuraciones para diferentes sistemas de CI/CD:\n\n';
                        cicdReadmeContent += '## GitHub Actions\n\n';
                        cicdReadmeContent += 'Los workflows de GitHub Actions se encuentran en el directorio `github/workflows/`:\n\n';
                        cicdReadmeContent += '- `ci.yml`: Pipeline de Integración Continua que se ejecuta en cada push y pull request a las ramas main y develop.\n';
                        cicdReadmeContent += '- `cd.yml`: Pipeline de Despliegue Continuo que se ejecuta en cada push a la rama main y en cada tag.\n\n';
                        cicdReadmeContent += '## Jenkins\n\n';
                        cicdReadmeContent += 'El archivo `jenkins/Jenkinsfile` define un pipeline completo de CI/CD para Jenkins.\n\n';
                        cicdReadmeContent += '## GitLab CI/CD\n\n';
                        cicdReadmeContent += 'El archivo `.gitlab-ci.yml` define un pipeline completo de CI/CD para GitLab.\n\n';
                        cicdReadmeContent += '## Configuración\n\n';
                        cicdReadmeContent += '### GitHub Actions\n\n';
                        cicdReadmeContent += 'Para utilizar GitHub Actions, necesitas configurar los siguientes secrets en tu repositorio:\n\n';
                        cicdReadmeContent += '- `DOCKERHUB_USERNAME`: Tu nombre de usuario de Docker Hub\n';
                        cicdReadmeContent += '- `DOCKERHUB_TOKEN`: Tu token de acceso a Docker Hub\n';
                        cicdReadmeContent += '- `PROD_HOST`: La dirección IP o hostname del servidor de producción\n';
                        cicdReadmeContent += '- `PROD_USERNAME`: El nombre de usuario para SSH en el servidor de producción\n';
                        cicdReadmeContent += '- `PROD_SSH_KEY`: La clave SSH privada para acceder al servidor de producción\n\n';
                        cicdReadmeContent += '### Jenkins\n\n';
                        cicdReadmeContent += 'Para utilizar Jenkins, necesitas configurar las siguientes credenciales:\n\n';
                        cicdReadmeContent += '- `docker-hub`: Credenciales de tipo Username with password para Docker Hub\n';
                        cicdReadmeContent += '- `production-server`: Credenciales de tipo SSH Username with private key para el servidor de producción\n\n';
                        cicdReadmeContent += '### GitLab CI/CD\n\n';
                        cicdReadmeContent += 'Para utilizar GitLab CI/CD, necesitas configurar las siguientes variables:\n\n';
                        cicdReadmeContent += '- `STAGING_SSH_PRIVATE_KEY`: La clave SSH privada para acceder al servidor de staging\n';
                        cicdReadmeContent += '- `STAGING_SSH_KNOWN_HOSTS`: El contenido del archivo known_hosts para el servidor de staging\n';
                        cicdReadmeContent += '- `STAGING_SSH_USER`: El nombre de usuario para SSH en el servidor de staging\n';
                        cicdReadmeContent += '- `STAGING_SSH_HOST`: La dirección IP o hostname del servidor de staging\n';
                        cicdReadmeContent += '- `PRODUCTION_SSH_PRIVATE_KEY`: La clave SSH privada para acceder al servidor de producción\n';
                        cicdReadmeContent += '- `PRODUCTION_SSH_KNOWN_HOSTS`: El contenido del archivo known_hosts para el servidor de producción\n';
                        cicdReadmeContent += '- `PRODUCTION_SSH_USER`: El nombre de usuario para SSH en el servidor de producción\n';
                        cicdReadmeContent += '- `PRODUCTION_SSH_HOST`: La dirección IP o hostname del servidor de producción\n';

                        // Escribir README.md para CI/CD
                        fs.writeFileSync(path.join(cicdDir, 'README.md'), cicdReadmeContent);
                    }

                    /**
                     * Crea archivos de infraestructura como código (IaC)
                     * @param {string} iacDir - Directorio para archivos de IaC
                     */
                    createIaCFiles(iacDir) {
                        if (!fs.existsSync(iacDir)) {
                            fs.mkdirSync(iacDir, { recursive: true });
                        }

                        // Crear directorios para diferentes herramientas de IaC
                        const terraformDir = path.join(iacDir, 'terraform');
                        const ansibleDir = path.join(iacDir, 'ansible');
                        const pulumDir = path.join(iacDir, 'pulumi');

                        if (!fs.existsSync(terraformDir)) {
                            fs.mkdirSync(terraformDir, { recursive: true });
                        }

                        if (!fs.existsSync(ansibleDir)) {
                            fs.mkdirSync(ansibleDir, { recursive: true });
                            fs.mkdirSync(path.join(ansibleDir, 'roles'), { recursive: true });
                            fs.mkdirSync(path.join(ansibleDir, 'inventories'), { recursive: true });
                        }

                        if (!fs.existsSync(pulumDir)) {
                            fs.mkdirSync(pulumDir, { recursive: true });
                        }

                        // Terraform - main.tf
                        let terraformMainContent = 'provider "aws" {\n';
                        terraformMainContent += '  region = var.aws_region\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_vpc" "main" {\n';
                        terraformMainContent += '  cidr_block           = var.vpc_cidr\n';
                        terraformMainContent += '  enable_dns_hostnames = true\n';
                        terraformMainContent += '  enable_dns_support   = true\n\n';
                        terraformMainContent += '  tags = {\n';
                        terraformMainContent += '    Name = "${var.project_name}-vpc"\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_subnet" "public" {\n';
                        terraformMainContent += '  count                   = length(var.public_subnets)\n';
                        terraformMainContent += '  vpc_id                  = aws_vpc.main.id\n';
                        terraformMainContent += '  cidr_block              = var.public_subnets[count.index]\n';
                        terraformMainContent += '  availability_zone       = var.availability_zones[count.index]\n';
                        terraformMainContent += '  map_public_ip_on_launch = true\n\n';
                        terraformMainContent += '  tags = {\n';
                        terraformMainContent += '    Name = "${var.project_name}-public-subnet-${count.index}"\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_subnet" "private" {\n';
                        terraformMainContent += '  count             = length(var.private_subnets)\n';
                        terraformMainContent += '  vpc_id            = aws_vpc.main.id\n';
                        terraformMainContent += '  cidr_block        = var.private_subnets[count.index]\n';
                        terraformMainContent += '  availability_zone = var.availability_zones[count.index]\n\n';
                        terraformMainContent += '  tags = {\n';
                        terraformMainContent += '    Name = "${var.project_name}-private-subnet-${count.index}"\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_internet_gateway" "main" {\n';
                        terraformMainContent += '  vpc_id = aws_vpc.main.id\n\n';
                        terraformMainContent += '  tags = {\n';
                        terraformMainContent += '    Name = "${var.project_name}-igw"\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_route_table" "public" {\n';
                        terraformMainContent += '  vpc_id = aws_vpc.main.id\n\n';
                        terraformMainContent += '  route {\n';
                        terraformMainContent += '    cidr_block = "0.0.0.0/0"\n';
                        terraformMainContent += '    gateway_id = aws_internet_gateway.main.id\n';
                        terraformMainContent += '  }\n\n';
                        terraformMainContent += '  tags = {\n';
                        terraformMainContent += '    Name = "${var.project_name}-public-rt"\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_route_table_association" "public" {\n';
                        terraformMainContent += '  count          = length(var.public_subnets)\n';
                        terraformMainContent += '  subnet_id      = aws_subnet.public[count.index].id\n';
                        terraformMainContent += '  route_table_id = aws_route_table.public.id\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_security_group" "web" {\n';
                        terraformMainContent += '  name        = "${var.project_name}-web-sg"\n';
                        terraformMainContent += '  description = "Security group for web servers"\n';
                        terraformMainContent += '  vpc_id      = aws_vpc.main.id\n\n';
                        terraformMainContent += '  ingress {\n';
                        terraformMainContent += '    from_port   = 80\n';
                        terraformMainContent += '    to_port     = 80\n';
                        terraformMainContent += '    protocol    = "tcp"\n';
                        terraformMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                        terraformMainContent += '  }\n\n';
                        terraformMainContent += '  ingress {\n';
                        terraformMainContent += '    from_port   = 443\n';
                        terraformMainContent += '    to_port     = 443\n';
                        terraformMainContent += '    protocol    = "tcp"\n';
                        terraformMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                        terraformMainContent += '  }\n\n';
                        terraformMainContent += '  ingress {\n';
                        terraformMainContent += '    from_port   = 22\n';
                        terraformMainContent += '    to_port     = 22\n';
                        terraformMainContent += '    protocol    = "tcp"\n';
                        terraformMainContent += '    cidr_blocks = [var.admin_ip]\n';
                        terraformMainContent += '  }\n\n';
                        terraformMainContent += '  egress {\n';
                        terraformMainContent += '    from_port   = 0\n';
                        terraformMainContent += '    to_port     = 0\n';
                        terraformMainContent += '    protocol    = "-1"\n';
                        terraformMainContent += '    cidr_blocks = ["0.0.0.0/0"]\n';
                        terraformMainContent += '  }\n\n';
                        terraformMainContent += '  tags = {\n';
                        terraformMainContent += '    Name = "${var.project_name}-web-sg"\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_instance" "web" {\n';
                        terraformMainContent += '  count                  = var.web_instance_count\n';
                        terraformMainContent += '  ami                    = var.web_instance_ami\n';
                        terraformMainContent += '  instance_type          = var.web_instance_type\n';
                        terraformMainContent += '  subnet_id              = aws_subnet.public[count.index % length(var.public_subnets)].id\n';
                        terraformMainContent += '  vpc_security_group_ids = [aws_security_group.web.id]\n';
                        terraformMainContent += '  key_name               = var.key_name\n\n';
                        terraformMainContent += '  tags = {\n';
                        terraformMainContent += '    Name = "${var.project_name}-web-${count.index}"\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_lb" "web" {\n';
                        terraformMainContent += '  name               = "${var.project_name}-web-lb"\n';
                        terraformMainContent += '  internal           = false\n';
                        terraformMainContent += '  load_balancer_type = "application"\n';
                        terraformMainContent += '  security_groups    = [aws_security_group.web.id]\n';
                        terraformMainContent += '  subnets            = aws_subnet.public[*].id\n\n';
                        terraformMainContent += '  tags = {\n';
                        terraformMainContent += '    Name = "${var.project_name}-web-lb"\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_lb_target_group" "web" {\n';
                        terraformMainContent += '  name     = "${var.project_name}-web-tg"\n';
                        terraformMainContent += '  port     = 80\n';
                        terraformMainContent += '  protocol = "HTTP"\n';
                        terraformMainContent += '  vpc_id   = aws_vpc.main.id\n\n';
                        terraformMainContent += '  health_check {\n';
                        terraformMainContent += '    path                = "/"\n';
                        terraformMainContent += '    port                = "traffic-port"\n';
                        terraformMainContent += '    healthy_threshold   = 2\n';
                        terraformMainContent += '    unhealthy_threshold = 2\n';
                        terraformMainContent += '    timeout             = 3\n';
                        terraformMainContent += '    interval            = 30\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_lb_target_group_attachment" "web" {\n';
                        terraformMainContent += '  count            = var.web_instance_count\n';
                        terraformMainContent += '  target_group_arn = aws_lb_target_group.web.arn\n';
                        terraformMainContent += '  target_id        = aws_instance.web[count.index].id\n';
                        terraformMainContent += '  port             = 80\n';
                        terraformMainContent += '}\n\n';
                        terraformMainContent += 'resource "aws_lb_listener" "web" {\n';
                        terraformMainContent += '  load_balancer_arn = aws_lb.web.arn\n';
                        terraformMainContent += '  port              = 80\n';
                        terraformMainContent += '  protocol          = "HTTP"\n\n';
                        terraformMainContent += '  default_action {\n';
                        terraformMainContent += '    type             = "forward"\n';
                        terraformMainContent += '    target_group_arn = aws_lb_target_group.web.arn\n';
                        terraformMainContent += '  }\n';
                        terraformMainContent += '}\n';

                        // Escribir Terraform main.tf
                        fs.writeFileSync(path.join(terraformDir, 'main.tf'), terraformMainContent);

                        // Terraform - variables.tf
                        let terraformVarsContent = 'variable "aws_region" {\n';
                        terraformVarsContent += '  description = "AWS region"\n';
                        terraformVarsContent += '  default     = "us-west-2"\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "project_name" {\n';
                        terraformVarsContent += '  description = "Project name"\n';
                        terraformVarsContent += '  default     = "myapp"\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "vpc_cidr" {\n';
                        terraformVarsContent += '  description = "CIDR block for VPC"\n';
                        terraformVarsContent += '  default     = "10.0.0.0/16"\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "public_subnets" {\n';
                        terraformVarsContent += '  description = "CIDR blocks for public subnets"\n';
                        terraformVarsContent += '  default     = ["10.0.1.0/24", "10.0.2.0/24"]\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "private_subnets" {\n';
                        terraformVarsContent += '  description = "CIDR blocks for private subnets"\n';
                        terraformVarsContent += '  default     = ["10.0.3.0/24", "10.0.4.0/24"]\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "availability_zones" {\n';
                        terraformVarsContent += '  description = "Availability zones"\n';
                        terraformVarsContent += '  default     = ["us-west-2a", "us-west-2b"]\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "admin_ip" {\n';
                        terraformVarsContent += '  description = "IP address allowed to connect via SSH"\n';
                        terraformVarsContent += '  default     = "0.0.0.0/0"\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "web_instance_count" {\n';
                        terraformVarsContent += '  description = "Number of web instances"\n';
                        terraformVarsContent += '  default     = 2\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "web_instance_ami" {\n';
                        terraformVarsContent += '  description = "AMI for web instances"\n';
                        terraformVarsContent += '  default     = "ami-0c55b159cbfafe1f0"\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "web_instance_type" {\n';
                        terraformVarsContent += '  description = "Instance type for web instances"\n';
                        terraformVarsContent += '  default     = "t2.micro"\n';
                        terraformVarsContent += '}\n\n';
                        terraformVarsContent += 'variable "key_name" {\n';
                        terraformVarsContent += '  description = "Key pair name"\n';
                        terraformVarsContent += '  default     = "myapp-key"\n';
                        terraformVarsContent += '}\n';

                        // Escribir Terraform variables.tf
                        fs.writeFileSync(path.join(terraformDir, 'variables.tf'), terraformVarsContent);

                        // Terraform - outputs.tf
                        let terraformOutputsContent = 'output "vpc_id" {\n';
                        terraformOutputsContent += '  description = "ID of the VPC"\n';
                        terraformOutputsContent += '  value       = aws_vpc.main.id\n';
                        terraformOutputsContent += '}\n\n';
                        terraformOutputsContent += 'output "public_subnet_ids" {\n';
                        terraformOutputsContent += '  description = "IDs of the public subnets"\n';
                        terraformOutputsContent += '  value       = aws_subnet.public[*].id\n';
                        terraformOutputsContent += '}\n\n';
                        terraformOutputsContent += 'output "private_subnet_ids" {\n';
                        terraformOutputsContent += '  description = "IDs of the private subnets"\n';
                        terraformOutputsContent += '  value       = aws_subnet.private[*].id\n';
                        terraformOutputsContent += '}\n\n';
                        terraformOutputsContent += 'output "web_security_group_id" {\n';
                        terraformOutputsContent += '  description = "ID of the web security group"\n';
                        terraformOutputsContent += '  value       = aws_security_group.web.id\n';
                        terraformOutputsContent += '}\n\n';
                        terraformOutputsContent += 'output "web_instance_ids" {\n';
                        terraformOutputsContent += '  description = "IDs of the web instances"\n';
                        terraformOutputsContent += '  value       = aws_instance.web[*].id\n';
                        terraformOutputsContent +=